{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5207951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationESs\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import wandb\n",
    "import sys\n",
    "from configmypy import ConfigPipeline, YamlConfig, ArgparseConfig\n",
    "from neuralop import get_model\n",
    "from neuralop import Trainer\n",
    "from neuralop.training import setup\n",
    "from neuralop.datasets import load_darcy_pt\n",
    "from neuralop.utils import get_wandb_api_key, count_params\n",
    "from neuralop import LpLoss, H1Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58756822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=8\n",
      "tfno2d.n_modes_width=8\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.2\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 56641\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 4, 4), rank=(19, 19, 2, 2))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 4, 4), rank=(19, 19, 2, 2))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 4, 4), rank=(19, 19, 2, 2))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 4, 4), rank=(19, 19, 2, 2))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 4, 4), rank=(19, 19, 2, 2))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 4, 4), rank=(19, 19, 2, 2))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 4, 4), rank=(19, 19, 2, 2))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 4, 4), rank=(19, 19, 2, 2))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f776fdbb790>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f776fdbbd90>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f776fdbbd90>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f776fdbbe50>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=4.40, avg_loss=11.3448, train_err=0.5672, 32_h1=0.3849, 32_l2=0.2471, 64_h1=0.4519, 64_l2=0.2502\n",
      "[1] time=2.25, avg_loss=6.0378, train_err=0.3019, 32_h1=0.2962, 32_l2=0.2058, 64_h1=0.3345, 64_l2=0.1997\n",
      "[2] time=2.35, avg_loss=4.8864, train_err=0.2443, 32_h1=0.2525, 32_l2=0.1668, 64_h1=0.3201, 64_l2=0.1719\n",
      "[3] time=2.30, avg_loss=4.3280, train_err=0.2164, 32_h1=0.2155, 32_l2=0.1382, 64_h1=0.2642, 64_l2=0.1342\n",
      "[4] time=2.34, avg_loss=3.8615, train_err=0.1931, 32_h1=0.1856, 32_l2=0.1110, 64_h1=0.2642, 64_l2=0.1202\n",
      "[5] time=2.29, avg_loss=3.7024, train_err=0.1851, 32_h1=0.1802, 32_l2=0.1060, 64_h1=0.2531, 64_l2=0.1156\n",
      "[6] time=2.38, avg_loss=3.4090, train_err=0.1704, 32_h1=0.1640, 32_l2=0.0920, 64_h1=0.2341, 64_l2=0.1017\n",
      "[7] time=2.31, avg_loss=3.3325, train_err=0.1666, 32_h1=0.1673, 32_l2=0.0998, 64_h1=0.2434, 64_l2=0.1080\n",
      "[8] time=2.37, avg_loss=3.1711, train_err=0.1586, 32_h1=0.1646, 32_l2=0.1001, 64_h1=0.2293, 64_l2=0.1068\n",
      "[9] time=2.31, avg_loss=3.0765, train_err=0.1538, 32_h1=0.1574, 32_l2=0.0984, 64_h1=0.2417, 64_l2=0.1113\n",
      "[10] time=2.32, avg_loss=2.9918, train_err=0.1496, 32_h1=0.1515, 32_l2=0.0905, 64_h1=0.2262, 64_l2=0.0975\n",
      "[11] time=2.35, avg_loss=2.9444, train_err=0.1472, 32_h1=0.1418, 32_l2=0.0775, 64_h1=0.2284, 64_l2=0.0916\n",
      "[12] time=2.33, avg_loss=2.8165, train_err=0.1408, 32_h1=0.1383, 32_l2=0.0747, 64_h1=0.2184, 64_l2=0.0876\n",
      "[13] time=2.39, avg_loss=2.8400, train_err=0.1420, 32_h1=0.1357, 32_l2=0.0712, 64_h1=0.2155, 64_l2=0.0807\n",
      "[14] time=2.34, avg_loss=2.6701, train_err=0.1335, 32_h1=0.1327, 32_l2=0.0706, 64_h1=0.2169, 64_l2=0.0865\n",
      "[15] time=2.39, avg_loss=2.6989, train_err=0.1349, 32_h1=0.1419, 32_l2=0.0898, 64_h1=0.2190, 64_l2=0.1028\n",
      "[16] time=2.35, avg_loss=2.5326, train_err=0.1266, 32_h1=0.1366, 32_l2=0.0805, 64_h1=0.2327, 64_l2=0.0930\n",
      "[17] time=2.08, avg_loss=2.6253, train_err=0.1313, 32_h1=0.1349, 32_l2=0.0786, 64_h1=0.2080, 64_l2=0.0857\n",
      "[18] time=2.11, avg_loss=2.5558, train_err=0.1278, 32_h1=0.1282, 32_l2=0.0696, 64_h1=0.2212, 64_l2=0.0842\n",
      "[19] time=2.19, avg_loss=2.4675, train_err=0.1234, 32_h1=0.1240, 32_l2=0.0665, 64_h1=0.2066, 64_l2=0.0739\n",
      "[20] time=2.17, avg_loss=2.4383, train_err=0.1219, 32_h1=0.1253, 32_l2=0.0663, 64_h1=0.2068, 64_l2=0.0723\n",
      "[21] time=2.18, avg_loss=2.4222, train_err=0.1211, 32_h1=0.1193, 32_l2=0.0616, 64_h1=0.2104, 64_l2=0.0739\n",
      "[22] time=2.00, avg_loss=2.4278, train_err=0.1214, 32_h1=0.1332, 32_l2=0.0884, 64_h1=0.2196, 64_l2=0.0977\n",
      "[23] time=2.00, avg_loss=2.3772, train_err=0.1189, 32_h1=0.1210, 32_l2=0.0650, 64_h1=0.2036, 64_l2=0.0759\n",
      "[24] time=2.01, avg_loss=2.3612, train_err=0.1181, 32_h1=0.1225, 32_l2=0.0730, 64_h1=0.2115, 64_l2=0.0856\n",
      "[25] time=2.06, avg_loss=2.2973, train_err=0.1149, 32_h1=0.1165, 32_l2=0.0574, 64_h1=0.2096, 64_l2=0.0715\n",
      "[26] time=2.16, avg_loss=2.2852, train_err=0.1143, 32_h1=0.1309, 32_l2=0.0772, 64_h1=0.2013, 64_l2=0.0898\n",
      "[27] time=2.17, avg_loss=2.3371, train_err=0.1169, 32_h1=0.1141, 32_l2=0.0587, 64_h1=0.2072, 64_l2=0.0722\n",
      "[28] time=2.16, avg_loss=2.2270, train_err=0.1114, 32_h1=0.1110, 32_l2=0.0562, 64_h1=0.1935, 64_l2=0.0696\n",
      "[29] time=2.18, avg_loss=2.1741, train_err=0.1087, 32_h1=0.1124, 32_l2=0.0604, 64_h1=0.2005, 64_l2=0.0753\n",
      "[30] time=2.18, avg_loss=2.2587, train_err=0.1129, 32_h1=0.1147, 32_l2=0.0601, 64_h1=0.2061, 64_l2=0.0698\n",
      "[31] time=2.07, avg_loss=2.1731, train_err=0.1087, 32_h1=0.1079, 32_l2=0.0536, 64_h1=0.1905, 64_l2=0.0662\n",
      "[32] time=2.01, avg_loss=2.1900, train_err=0.1095, 32_h1=0.1111, 32_l2=0.0557, 64_h1=0.2067, 64_l2=0.0733\n",
      "[33] time=2.01, avg_loss=2.1641, train_err=0.1082, 32_h1=0.1101, 32_l2=0.0580, 64_h1=0.1938, 64_l2=0.0699\n",
      "[34] time=2.06, avg_loss=2.1432, train_err=0.1072, 32_h1=0.1097, 32_l2=0.0563, 64_h1=0.1937, 64_l2=0.0709\n",
      "[35] time=2.03, avg_loss=2.1086, train_err=0.1054, 32_h1=0.1080, 32_l2=0.0563, 64_h1=0.2008, 64_l2=0.0725\n",
      "[36] time=2.05, avg_loss=2.1329, train_err=0.1066, 32_h1=0.1207, 32_l2=0.0712, 64_h1=0.2019, 64_l2=0.0850\n",
      "[37] time=2.22, avg_loss=2.1177, train_err=0.1059, 32_h1=0.1216, 32_l2=0.0777, 64_h1=0.2009, 64_l2=0.0895\n",
      "[38] time=2.18, avg_loss=2.1423, train_err=0.1071, 32_h1=0.1069, 32_l2=0.0546, 64_h1=0.1872, 64_l2=0.0670\n",
      "[39] time=2.14, avg_loss=2.0923, train_err=0.1046, 32_h1=0.1092, 32_l2=0.0546, 64_h1=0.1817, 64_l2=0.0658\n",
      "[40] time=2.07, avg_loss=2.0714, train_err=0.1036, 32_h1=0.1085, 32_l2=0.0555, 64_h1=0.1871, 64_l2=0.0738\n",
      "[41] time=2.12, avg_loss=2.1075, train_err=0.1054, 32_h1=0.1108, 32_l2=0.0616, 64_h1=0.1897, 64_l2=0.0714\n",
      "[42] time=2.09, avg_loss=2.0550, train_err=0.1028, 32_h1=0.1047, 32_l2=0.0538, 64_h1=0.1856, 64_l2=0.0638\n",
      "[43] time=2.13, avg_loss=2.1350, train_err=0.1067, 32_h1=0.1038, 32_l2=0.0523, 64_h1=0.1840, 64_l2=0.0623\n",
      "[44] time=2.10, avg_loss=2.0861, train_err=0.1043, 32_h1=0.1049, 32_l2=0.0524, 64_h1=0.1978, 64_l2=0.0707\n",
      "[45] time=2.15, avg_loss=2.0628, train_err=0.1031, 32_h1=0.1122, 32_l2=0.0634, 64_h1=0.1949, 64_l2=0.0729\n",
      "[46] time=2.20, avg_loss=2.0111, train_err=0.1006, 32_h1=0.1088, 32_l2=0.0613, 64_h1=0.2010, 64_l2=0.0816\n",
      "[47] time=2.36, avg_loss=2.0347, train_err=0.1017, 32_h1=0.1047, 32_l2=0.0570, 64_h1=0.1930, 64_l2=0.0639\n",
      "[48] time=2.32, avg_loss=1.9675, train_err=0.0984, 32_h1=0.1000, 32_l2=0.0488, 64_h1=0.1869, 64_l2=0.0620\n",
      "[49] time=2.28, avg_loss=1.9559, train_err=0.0978, 32_h1=0.1012, 32_l2=0.0505, 64_h1=0.1846, 64_l2=0.0586\n",
      "[50] time=2.27, avg_loss=1.9920, train_err=0.0996, 32_h1=0.1033, 32_l2=0.0538, 64_h1=0.1818, 64_l2=0.0664\n",
      "[51] time=2.38, avg_loss=2.0018, train_err=0.1001, 32_h1=0.1018, 32_l2=0.0498, 64_h1=0.1865, 64_l2=0.0643\n",
      "[52] time=2.31, avg_loss=1.9624, train_err=0.0981, 32_h1=0.1032, 32_l2=0.0518, 64_h1=0.1868, 64_l2=0.0662\n",
      "[53] time=2.30, avg_loss=1.9660, train_err=0.0983, 32_h1=0.1038, 32_l2=0.0579, 64_h1=0.1874, 64_l2=0.0675\n",
      "[54] time=2.31, avg_loss=1.9800, train_err=0.0990, 32_h1=0.0996, 32_l2=0.0515, 64_h1=0.1822, 64_l2=0.0647\n",
      "[55] time=2.38, avg_loss=1.9374, train_err=0.0969, 32_h1=0.1019, 32_l2=0.0508, 64_h1=0.1785, 64_l2=0.0612\n",
      "[56] time=2.28, avg_loss=1.9104, train_err=0.0955, 32_h1=0.0987, 32_l2=0.0505, 64_h1=0.1855, 64_l2=0.0643\n",
      "[57] time=2.31, avg_loss=1.9445, train_err=0.0972, 32_h1=0.1151, 32_l2=0.0776, 64_h1=0.1946, 64_l2=0.0870\n",
      "[58] time=2.35, avg_loss=1.9546, train_err=0.0977, 32_h1=0.0979, 32_l2=0.0482, 64_h1=0.1854, 64_l2=0.0595\n",
      "[59] time=2.29, avg_loss=1.9291, train_err=0.0965, 32_h1=0.1010, 32_l2=0.0538, 64_h1=0.1879, 64_l2=0.0726\n",
      "[60] time=2.33, avg_loss=1.9442, train_err=0.0972, 32_h1=0.1033, 32_l2=0.0587, 64_h1=0.1829, 64_l2=0.0691\n",
      "[61] time=2.34, avg_loss=1.9342, train_err=0.0967, 32_h1=0.0979, 32_l2=0.0492, 64_h1=0.1847, 64_l2=0.0624\n",
      "[62] time=2.32, avg_loss=1.8946, train_err=0.0947, 32_h1=0.0976, 32_l2=0.0471, 64_h1=0.1821, 64_l2=0.0550\n",
      "[63] time=2.27, avg_loss=1.8910, train_err=0.0945, 32_h1=0.0958, 32_l2=0.0474, 64_h1=0.1820, 64_l2=0.0638\n",
      "[64] time=2.33, avg_loss=1.8275, train_err=0.0914, 32_h1=0.1037, 32_l2=0.0599, 64_h1=0.1901, 64_l2=0.0698\n",
      "[65] time=2.29, avg_loss=1.9296, train_err=0.0965, 32_h1=0.0988, 32_l2=0.0540, 64_h1=0.1910, 64_l2=0.0645\n",
      "[66] time=2.32, avg_loss=1.8493, train_err=0.0925, 32_h1=0.0977, 32_l2=0.0481, 64_h1=0.1972, 64_l2=0.0641\n",
      "[67] time=2.41, avg_loss=1.9002, train_err=0.0950, 32_h1=0.1020, 32_l2=0.0550, 64_h1=0.1886, 64_l2=0.0683\n",
      "[68] time=2.30, avg_loss=1.8350, train_err=0.0917, 32_h1=0.0962, 32_l2=0.0473, 64_h1=0.1921, 64_l2=0.0650\n",
      "[69] time=2.32, avg_loss=1.8116, train_err=0.0906, 32_h1=0.1019, 32_l2=0.0607, 64_h1=0.1874, 64_l2=0.0745\n",
      "[70] time=2.39, avg_loss=1.8656, train_err=0.0933, 32_h1=0.1001, 32_l2=0.0557, 64_h1=0.1923, 64_l2=0.0684\n",
      "[71] time=2.29, avg_loss=1.9071, train_err=0.0954, 32_h1=0.0992, 32_l2=0.0533, 64_h1=0.1881, 64_l2=0.0628\n",
      "[72] time=2.27, avg_loss=1.8173, train_err=0.0909, 32_h1=0.1025, 32_l2=0.0593, 64_h1=0.1821, 64_l2=0.0706\n",
      "[73] time=2.31, avg_loss=1.8314, train_err=0.0916, 32_h1=0.0980, 32_l2=0.0487, 64_h1=0.1920, 64_l2=0.0624\n",
      "[74] time=2.27, avg_loss=1.8037, train_err=0.0902, 32_h1=0.0962, 32_l2=0.0471, 64_h1=0.1834, 64_l2=0.0624\n",
      "[75] time=2.28, avg_loss=1.7874, train_err=0.0894, 32_h1=0.0948, 32_l2=0.0474, 64_h1=0.1791, 64_l2=0.0592\n",
      "[76] time=2.25, avg_loss=1.8053, train_err=0.0903, 32_h1=0.0943, 32_l2=0.0457, 64_h1=0.1792, 64_l2=0.0575\n",
      "[77] time=2.35, avg_loss=1.8153, train_err=0.0908, 32_h1=0.0971, 32_l2=0.0526, 64_h1=0.1828, 64_l2=0.0677\n",
      "[78] time=2.33, avg_loss=1.8019, train_err=0.0901, 32_h1=0.0959, 32_l2=0.0485, 64_h1=0.1870, 64_l2=0.0645\n",
      "[79] time=2.30, avg_loss=1.8322, train_err=0.0916, 32_h1=0.1051, 32_l2=0.0624, 64_h1=0.1868, 64_l2=0.0734\n",
      "[80] time=2.34, avg_loss=1.7735, train_err=0.0887, 32_h1=0.0932, 32_l2=0.0444, 64_h1=0.1760, 64_l2=0.0571\n",
      "[81] time=2.25, avg_loss=1.7948, train_err=0.0897, 32_h1=0.1013, 32_l2=0.0578, 64_h1=0.1905, 64_l2=0.0737\n",
      "[82] time=2.34, avg_loss=1.7729, train_err=0.0886, 32_h1=0.0954, 32_l2=0.0531, 64_h1=0.1842, 64_l2=0.0701\n",
      "[83] time=2.38, avg_loss=1.7857, train_err=0.0893, 32_h1=0.0935, 32_l2=0.0460, 64_h1=0.1829, 64_l2=0.0612\n",
      "[84] time=2.40, avg_loss=1.7924, train_err=0.0896, 32_h1=0.0922, 32_l2=0.0444, 64_h1=0.1795, 64_l2=0.0571\n",
      "[85] time=2.35, avg_loss=1.7409, train_err=0.0870, 32_h1=0.0903, 32_l2=0.0431, 64_h1=0.1842, 64_l2=0.0626\n",
      "[86] time=2.18, avg_loss=1.7403, train_err=0.0870, 32_h1=0.0938, 32_l2=0.0465, 64_h1=0.1789, 64_l2=0.0594\n",
      "[87] time=2.18, avg_loss=1.7452, train_err=0.0873, 32_h1=0.0914, 32_l2=0.0445, 64_h1=0.1841, 64_l2=0.0634\n",
      "[88] time=2.19, avg_loss=1.7834, train_err=0.0892, 32_h1=0.1021, 32_l2=0.0613, 64_h1=0.1947, 64_l2=0.0730\n",
      "[89] time=2.08, avg_loss=1.7526, train_err=0.0876, 32_h1=0.0911, 32_l2=0.0439, 64_h1=0.1791, 64_l2=0.0599\n",
      "[90] time=2.09, avg_loss=1.7355, train_err=0.0868, 32_h1=0.0945, 32_l2=0.0496, 64_h1=0.1898, 64_l2=0.0622\n",
      "[91] time=2.16, avg_loss=1.7420, train_err=0.0871, 32_h1=0.0917, 32_l2=0.0442, 64_h1=0.1821, 64_l2=0.0585\n",
      "[92] time=2.22, avg_loss=1.7332, train_err=0.0867, 32_h1=0.0953, 32_l2=0.0483, 64_h1=0.1846, 64_l2=0.0638\n",
      "[93] time=2.19, avg_loss=1.7181, train_err=0.0859, 32_h1=0.0898, 32_l2=0.0455, 64_h1=0.1830, 64_l2=0.0595\n",
      "[94] time=2.18, avg_loss=1.7076, train_err=0.0854, 32_h1=0.0983, 32_l2=0.0590, 64_h1=0.1888, 64_l2=0.0722\n",
      "[95] time=2.02, avg_loss=1.7141, train_err=0.0857, 32_h1=0.0902, 32_l2=0.0446, 64_h1=0.1805, 64_l2=0.0585\n",
      "[96] time=2.06, avg_loss=1.7424, train_err=0.0871, 32_h1=0.0919, 32_l2=0.0437, 64_h1=0.1883, 64_l2=0.0619\n",
      "[97] time=2.09, avg_loss=1.7134, train_err=0.0857, 32_h1=0.0896, 32_l2=0.0429, 64_h1=0.1780, 64_l2=0.0563\n",
      "[98] time=2.01, avg_loss=1.6799, train_err=0.0840, 32_h1=0.0929, 32_l2=0.0474, 64_h1=0.1808, 64_l2=0.0639\n",
      "[99] time=2.07, avg_loss=1.6950, train_err=0.0847, 32_h1=0.0894, 32_l2=0.0429, 64_h1=0.1796, 64_l2=0.0607\n",
      "[100] time=2.04, avg_loss=1.6993, train_err=0.0850, 32_h1=0.0899, 32_l2=0.0436, 64_h1=0.1872, 64_l2=0.0605\n",
      "[101] time=2.18, avg_loss=1.7167, train_err=0.0858, 32_h1=0.0899, 32_l2=0.0448, 64_h1=0.1836, 64_l2=0.0595\n",
      "[102] time=2.05, avg_loss=1.6862, train_err=0.0843, 32_h1=0.0901, 32_l2=0.0450, 64_h1=0.1790, 64_l2=0.0566\n",
      "[103] time=2.10, avg_loss=1.6932, train_err=0.0847, 32_h1=0.0899, 32_l2=0.0464, 64_h1=0.1811, 64_l2=0.0591\n",
      "[104] time=2.12, avg_loss=1.6752, train_err=0.0838, 32_h1=0.0898, 32_l2=0.0441, 64_h1=0.1763, 64_l2=0.0605\n",
      "[105] time=2.18, avg_loss=1.6894, train_err=0.0845, 32_h1=0.0907, 32_l2=0.0461, 64_h1=0.1856, 64_l2=0.0606\n",
      "[106] time=2.08, avg_loss=1.6702, train_err=0.0835, 32_h1=0.0886, 32_l2=0.0417, 64_h1=0.1804, 64_l2=0.0601\n",
      "[107] time=2.03, avg_loss=1.6691, train_err=0.0835, 32_h1=0.0903, 32_l2=0.0450, 64_h1=0.1751, 64_l2=0.0597\n",
      "[108] time=2.04, avg_loss=1.6567, train_err=0.0828, 32_h1=0.0926, 32_l2=0.0469, 64_h1=0.1827, 64_l2=0.0638\n",
      "[109] time=2.04, avg_loss=1.6963, train_err=0.0848, 32_h1=0.0931, 32_l2=0.0496, 64_h1=0.1762, 64_l2=0.0629\n",
      "[110] time=2.03, avg_loss=1.6587, train_err=0.0829, 32_h1=0.0895, 32_l2=0.0440, 64_h1=0.1799, 64_l2=0.0638\n",
      "[111] time=2.05, avg_loss=1.6592, train_err=0.0830, 32_h1=0.0875, 32_l2=0.0412, 64_h1=0.1732, 64_l2=0.0577\n",
      "[112] time=2.06, avg_loss=1.7140, train_err=0.0857, 32_h1=0.0882, 32_l2=0.0433, 64_h1=0.1813, 64_l2=0.0630\n",
      "[113] time=2.09, avg_loss=1.6304, train_err=0.0815, 32_h1=0.0875, 32_l2=0.0428, 64_h1=0.1769, 64_l2=0.0559\n",
      "[114] time=2.01, avg_loss=1.6459, train_err=0.0823, 32_h1=0.0885, 32_l2=0.0424, 64_h1=0.1849, 64_l2=0.0619\n",
      "[115] time=2.36, avg_loss=1.6631, train_err=0.0832, 32_h1=0.0937, 32_l2=0.0525, 64_h1=0.1905, 64_l2=0.0655\n",
      "[116] time=2.37, avg_loss=1.6578, train_err=0.0829, 32_h1=0.0870, 32_l2=0.0407, 64_h1=0.1852, 64_l2=0.0603\n",
      "[117] time=2.31, avg_loss=1.6253, train_err=0.0813, 32_h1=0.0890, 32_l2=0.0434, 64_h1=0.1813, 64_l2=0.0630\n",
      "[118] time=2.35, avg_loss=1.6233, train_err=0.0812, 32_h1=0.0859, 32_l2=0.0406, 64_h1=0.1757, 64_l2=0.0586\n",
      "[119] time=2.34, avg_loss=1.6369, train_err=0.0818, 32_h1=0.0912, 32_l2=0.0465, 64_h1=0.1822, 64_l2=0.0604\n",
      "[120] time=2.30, avg_loss=1.6470, train_err=0.0823, 32_h1=0.0862, 32_l2=0.0399, 64_h1=0.1772, 64_l2=0.0548\n",
      "[121] time=2.36, avg_loss=1.6169, train_err=0.0808, 32_h1=0.0869, 32_l2=0.0416, 64_h1=0.1786, 64_l2=0.0549\n",
      "[122] time=2.36, avg_loss=1.6119, train_err=0.0806, 32_h1=0.0860, 32_l2=0.0402, 64_h1=0.1766, 64_l2=0.0562\n",
      "[123] time=2.29, avg_loss=1.6093, train_err=0.0805, 32_h1=0.0893, 32_l2=0.0451, 64_h1=0.1764, 64_l2=0.0585\n",
      "[124] time=2.30, avg_loss=1.6107, train_err=0.0805, 32_h1=0.0860, 32_l2=0.0406, 64_h1=0.1800, 64_l2=0.0597\n",
      "[125] time=2.34, avg_loss=1.6096, train_err=0.0805, 32_h1=0.0868, 32_l2=0.0414, 64_h1=0.1738, 64_l2=0.0565\n",
      "[126] time=2.30, avg_loss=1.6311, train_err=0.0816, 32_h1=0.0870, 32_l2=0.0409, 64_h1=0.1842, 64_l2=0.0559\n",
      "[127] time=2.32, avg_loss=1.5920, train_err=0.0796, 32_h1=0.0865, 32_l2=0.0406, 64_h1=0.1734, 64_l2=0.0548\n",
      "[128] time=2.37, avg_loss=1.6155, train_err=0.0808, 32_h1=0.0876, 32_l2=0.0435, 64_h1=0.1844, 64_l2=0.0620\n",
      "[129] time=2.29, avg_loss=1.5924, train_err=0.0796, 32_h1=0.0880, 32_l2=0.0431, 64_h1=0.1830, 64_l2=0.0638\n",
      "[130] time=2.33, avg_loss=1.5901, train_err=0.0795, 32_h1=0.0873, 32_l2=0.0422, 64_h1=0.1776, 64_l2=0.0606\n",
      "[131] time=2.38, avg_loss=1.6045, train_err=0.0802, 32_h1=0.0871, 32_l2=0.0420, 64_h1=0.1773, 64_l2=0.0584\n",
      "[132] time=2.32, avg_loss=1.6086, train_err=0.0804, 32_h1=0.0885, 32_l2=0.0451, 64_h1=0.1839, 64_l2=0.0607\n",
      "[133] time=2.36, avg_loss=1.5875, train_err=0.0794, 32_h1=0.0871, 32_l2=0.0429, 64_h1=0.1817, 64_l2=0.0556\n",
      "[134] time=2.35, avg_loss=1.5870, train_err=0.0793, 32_h1=0.0855, 32_l2=0.0400, 64_h1=0.1767, 64_l2=0.0563\n",
      "[135] time=2.30, avg_loss=1.5897, train_err=0.0795, 32_h1=0.0877, 32_l2=0.0430, 64_h1=0.1809, 64_l2=0.0596\n",
      "[136] time=2.32, avg_loss=1.5912, train_err=0.0796, 32_h1=0.0857, 32_l2=0.0400, 64_h1=0.1828, 64_l2=0.0586\n",
      "[137] time=2.39, avg_loss=1.5588, train_err=0.0779, 32_h1=0.0851, 32_l2=0.0394, 64_h1=0.1820, 64_l2=0.0568\n",
      "[138] time=2.32, avg_loss=1.5661, train_err=0.0783, 32_h1=0.0855, 32_l2=0.0401, 64_h1=0.1794, 64_l2=0.0589\n",
      "[139] time=2.40, avg_loss=1.5769, train_err=0.0788, 32_h1=0.0868, 32_l2=0.0442, 64_h1=0.1852, 64_l2=0.0625\n",
      "[140] time=2.35, avg_loss=1.5671, train_err=0.0784, 32_h1=0.0853, 32_l2=0.0415, 64_h1=0.1752, 64_l2=0.0549\n",
      "[141] time=2.25, avg_loss=1.5595, train_err=0.0780, 32_h1=0.0870, 32_l2=0.0425, 64_h1=0.1844, 64_l2=0.0590\n",
      "[142] time=2.36, avg_loss=1.5759, train_err=0.0788, 32_h1=0.0912, 32_l2=0.0517, 64_h1=0.1847, 64_l2=0.0632\n",
      "[143] time=2.29, avg_loss=1.5719, train_err=0.0786, 32_h1=0.0882, 32_l2=0.0460, 64_h1=0.1812, 64_l2=0.0613\n",
      "[144] time=2.30, avg_loss=1.5467, train_err=0.0773, 32_h1=0.0843, 32_l2=0.0393, 64_h1=0.1750, 64_l2=0.0535\n",
      "[145] time=2.31, avg_loss=1.5550, train_err=0.0777, 32_h1=0.0855, 32_l2=0.0405, 64_h1=0.1813, 64_l2=0.0579\n",
      "[146] time=2.33, avg_loss=1.5457, train_err=0.0773, 32_h1=0.0901, 32_l2=0.0471, 64_h1=0.1860, 64_l2=0.0619\n",
      "[147] time=2.32, avg_loss=1.5511, train_err=0.0776, 32_h1=0.0837, 32_l2=0.0389, 64_h1=0.1771, 64_l2=0.0564\n",
      "[148] time=2.32, avg_loss=1.5463, train_err=0.0773, 32_h1=0.0867, 32_l2=0.0427, 64_h1=0.1791, 64_l2=0.0590\n",
      "[149] time=2.28, avg_loss=1.5557, train_err=0.0778, 32_h1=0.0856, 32_l2=0.0416, 64_h1=0.1813, 64_l2=0.0597\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=10\n",
      "tfno2d.n_modes_width=10\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.2\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 92385\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 5, 5), rank=(20, 20, 3, 3))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 5, 5), rank=(20, 20, 3, 3))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 5, 5), rank=(20, 20, 3, 3))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 5, 5), rank=(20, 20, 3, 3))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 5, 5), rank=(20, 20, 3, 3))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 5, 5), rank=(20, 20, 3, 3))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 5, 5), rank=(20, 20, 3, 3))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 5, 5), rank=(20, 20, 3, 3))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f7854c9e490>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f776fdbbd60>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f776fdbbd60>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f7854c7bdf0>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.35, avg_loss=10.9153, train_err=0.5458, 32_h1=0.3355, 32_l2=0.2288, 64_h1=0.3926, 64_l2=0.2345\n",
      "[1] time=2.40, avg_loss=5.5592, train_err=0.2780, 32_h1=0.2316, 32_l2=0.1536, 64_h1=0.3127, 64_l2=0.1701\n",
      "[2] time=2.38, avg_loss=4.3571, train_err=0.2179, 32_h1=0.1971, 32_l2=0.1274, 64_h1=0.2787, 64_l2=0.1461\n",
      "[3] time=2.32, avg_loss=3.8200, train_err=0.1910, 32_h1=0.1930, 32_l2=0.1318, 64_h1=0.2612, 64_l2=0.1424\n",
      "[4] time=2.16, avg_loss=3.5198, train_err=0.1760, 32_h1=0.1661, 32_l2=0.1056, 64_h1=0.2455, 64_l2=0.1211\n",
      "[5] time=2.14, avg_loss=3.3409, train_err=0.1670, 32_h1=0.1790, 32_l2=0.1399, 64_h1=0.2562, 64_l2=0.1508\n",
      "[6] time=2.16, avg_loss=3.0757, train_err=0.1538, 32_h1=0.1416, 32_l2=0.0837, 64_h1=0.2214, 64_l2=0.0978\n",
      "[7] time=2.17, avg_loss=2.9061, train_err=0.1453, 32_h1=0.1417, 32_l2=0.0841, 64_h1=0.2171, 64_l2=0.0975\n",
      "[8] time=2.28, avg_loss=2.8056, train_err=0.1403, 32_h1=0.1342, 32_l2=0.0800, 64_h1=0.2133, 64_l2=0.0940\n",
      "[9] time=2.26, avg_loss=2.6154, train_err=0.1308, 32_h1=0.1236, 32_l2=0.0712, 64_h1=0.1973, 64_l2=0.0814\n",
      "[10] time=2.21, avg_loss=2.5694, train_err=0.1285, 32_h1=0.1337, 32_l2=0.0939, 64_h1=0.2086, 64_l2=0.1031\n",
      "[11] time=2.18, avg_loss=2.5061, train_err=0.1253, 32_h1=0.1500, 32_l2=0.1083, 64_h1=0.2088, 64_l2=0.1166\n",
      "[12] time=2.15, avg_loss=2.5087, train_err=0.1254, 32_h1=0.1288, 32_l2=0.0773, 64_h1=0.2059, 64_l2=0.0918\n",
      "[13] time=2.19, avg_loss=2.3055, train_err=0.1153, 32_h1=0.1140, 32_l2=0.0639, 64_h1=0.1889, 64_l2=0.0762\n",
      "[14] time=2.05, avg_loss=2.2984, train_err=0.1149, 32_h1=0.1314, 32_l2=0.0830, 64_h1=0.2062, 64_l2=0.0877\n",
      "[15] time=2.10, avg_loss=2.3225, train_err=0.1161, 32_h1=0.1121, 32_l2=0.0628, 64_h1=0.1767, 64_l2=0.0670\n",
      "[16] time=2.06, avg_loss=2.1863, train_err=0.1093, 32_h1=0.1057, 32_l2=0.0555, 64_h1=0.1906, 64_l2=0.0730\n",
      "[17] time=2.05, avg_loss=2.2140, train_err=0.1107, 32_h1=0.1169, 32_l2=0.0659, 64_h1=0.1750, 64_l2=0.0708\n",
      "[18] time=2.22, avg_loss=2.1860, train_err=0.1093, 32_h1=0.1065, 32_l2=0.0606, 64_h1=0.1848, 64_l2=0.0682\n",
      "[19] time=2.13, avg_loss=2.1340, train_err=0.1067, 32_h1=0.1163, 32_l2=0.0761, 64_h1=0.1823, 64_l2=0.0892\n",
      "[20] time=2.06, avg_loss=2.1836, train_err=0.1092, 32_h1=0.1015, 32_l2=0.0550, 64_h1=0.1845, 64_l2=0.0696\n",
      "[21] time=2.05, avg_loss=2.0403, train_err=0.1020, 32_h1=0.1058, 32_l2=0.0621, 64_h1=0.1749, 64_l2=0.0753\n",
      "[22] time=2.03, avg_loss=2.0536, train_err=0.1027, 32_h1=0.0992, 32_l2=0.0529, 64_h1=0.1737, 64_l2=0.0617\n",
      "[23] time=2.04, avg_loss=2.1177, train_err=0.1059, 32_h1=0.1097, 32_l2=0.0707, 64_h1=0.1773, 64_l2=0.0804\n",
      "[24] time=2.04, avg_loss=1.9711, train_err=0.0986, 32_h1=0.0993, 32_l2=0.0537, 64_h1=0.1772, 64_l2=0.0694\n",
      "[25] time=2.04, avg_loss=1.9706, train_err=0.0985, 32_h1=0.0990, 32_l2=0.0540, 64_h1=0.1751, 64_l2=0.0642\n",
      "[26] time=2.12, avg_loss=1.9510, train_err=0.0975, 32_h1=0.1108, 32_l2=0.0638, 64_h1=0.1714, 64_l2=0.0730\n",
      "[27] time=2.05, avg_loss=1.9620, train_err=0.0981, 32_h1=0.0961, 32_l2=0.0498, 64_h1=0.1741, 64_l2=0.0609\n",
      "[28] time=2.04, avg_loss=1.8974, train_err=0.0949, 32_h1=0.0969, 32_l2=0.0523, 64_h1=0.1684, 64_l2=0.0596\n",
      "[29] time=2.05, avg_loss=1.8959, train_err=0.0948, 32_h1=0.1006, 32_l2=0.0563, 64_h1=0.1776, 64_l2=0.0713\n",
      "[30] time=2.08, avg_loss=1.9647, train_err=0.0982, 32_h1=0.0935, 32_l2=0.0512, 64_h1=0.1764, 64_l2=0.0630\n",
      "[31] time=2.06, avg_loss=1.8303, train_err=0.0915, 32_h1=0.0932, 32_l2=0.0506, 64_h1=0.1696, 64_l2=0.0625\n",
      "[32] time=2.08, avg_loss=1.8502, train_err=0.0925, 32_h1=0.0999, 32_l2=0.0555, 64_h1=0.1722, 64_l2=0.0631\n",
      "[33] time=2.29, avg_loss=1.8125, train_err=0.0906, 32_h1=0.0904, 32_l2=0.0464, 64_h1=0.1663, 64_l2=0.0547\n",
      "[34] time=2.41, avg_loss=1.8589, train_err=0.0929, 32_h1=0.1004, 32_l2=0.0609, 64_h1=0.1697, 64_l2=0.0689\n",
      "[35] time=2.38, avg_loss=1.8064, train_err=0.0903, 32_h1=0.0920, 32_l2=0.0479, 64_h1=0.1712, 64_l2=0.0606\n",
      "[36] time=2.38, avg_loss=1.8360, train_err=0.0918, 32_h1=0.1060, 32_l2=0.0681, 64_h1=0.1722, 64_l2=0.0736\n",
      "[37] time=2.36, avg_loss=1.8106, train_err=0.0905, 32_h1=0.1065, 32_l2=0.0689, 64_h1=0.1778, 64_l2=0.0790\n",
      "[38] time=2.47, avg_loss=1.7976, train_err=0.0899, 32_h1=0.0873, 32_l2=0.0432, 64_h1=0.1639, 64_l2=0.0555\n",
      "[39] time=2.39, avg_loss=1.8067, train_err=0.0903, 32_h1=0.0936, 32_l2=0.0527, 64_h1=0.1715, 64_l2=0.0621\n",
      "[40] time=2.42, avg_loss=1.7798, train_err=0.0890, 32_h1=0.0909, 32_l2=0.0506, 64_h1=0.1762, 64_l2=0.0680\n",
      "[41] time=2.38, avg_loss=1.7788, train_err=0.0889, 32_h1=0.0961, 32_l2=0.0535, 64_h1=0.1740, 64_l2=0.0611\n",
      "[42] time=2.35, avg_loss=1.7674, train_err=0.0884, 32_h1=0.0873, 32_l2=0.0438, 64_h1=0.1605, 64_l2=0.0568\n",
      "[43] time=2.33, avg_loss=1.7208, train_err=0.0860, 32_h1=0.0893, 32_l2=0.0486, 64_h1=0.1680, 64_l2=0.0608\n",
      "[44] time=2.35, avg_loss=1.7271, train_err=0.0864, 32_h1=0.0890, 32_l2=0.0519, 64_h1=0.1653, 64_l2=0.0654\n",
      "[45] time=2.37, avg_loss=1.7107, train_err=0.0855, 32_h1=0.0893, 32_l2=0.0469, 64_h1=0.1709, 64_l2=0.0634\n",
      "[46] time=2.36, avg_loss=1.7490, train_err=0.0874, 32_h1=0.0886, 32_l2=0.0491, 64_h1=0.1647, 64_l2=0.0629\n",
      "[47] time=2.35, avg_loss=1.6890, train_err=0.0844, 32_h1=0.0960, 32_l2=0.0633, 64_h1=0.1691, 64_l2=0.0704\n",
      "[48] time=2.35, avg_loss=1.8194, train_err=0.0910, 32_h1=0.0857, 32_l2=0.0424, 64_h1=0.1666, 64_l2=0.0567\n",
      "[49] time=2.38, avg_loss=1.7022, train_err=0.0851, 32_h1=0.0888, 32_l2=0.0465, 64_h1=0.1648, 64_l2=0.0591\n",
      "[50] time=2.38, avg_loss=1.7116, train_err=0.0856, 32_h1=0.0839, 32_l2=0.0409, 64_h1=0.1578, 64_l2=0.0497\n",
      "[51] time=2.33, avg_loss=1.6589, train_err=0.0829, 32_h1=0.0861, 32_l2=0.0432, 64_h1=0.1709, 64_l2=0.0627\n",
      "[52] time=2.35, avg_loss=1.6788, train_err=0.0839, 32_h1=0.0879, 32_l2=0.0429, 64_h1=0.1691, 64_l2=0.0567\n",
      "[53] time=2.39, avg_loss=1.7476, train_err=0.0874, 32_h1=0.0878, 32_l2=0.0465, 64_h1=0.1657, 64_l2=0.0594\n",
      "[54] time=2.41, avg_loss=1.6541, train_err=0.0827, 32_h1=0.0922, 32_l2=0.0525, 64_h1=0.1802, 64_l2=0.0663\n",
      "[55] time=2.39, avg_loss=1.6362, train_err=0.0818, 32_h1=0.0888, 32_l2=0.0477, 64_h1=0.1781, 64_l2=0.0659\n",
      "[56] time=2.38, avg_loss=1.6732, train_err=0.0837, 32_h1=0.0875, 32_l2=0.0482, 64_h1=0.1673, 64_l2=0.0656\n",
      "[57] time=2.39, avg_loss=1.6346, train_err=0.0817, 32_h1=0.0832, 32_l2=0.0406, 64_h1=0.1649, 64_l2=0.0512\n",
      "[58] time=2.37, avg_loss=1.6333, train_err=0.0817, 32_h1=0.0835, 32_l2=0.0410, 64_h1=0.1684, 64_l2=0.0556\n",
      "[59] time=2.34, avg_loss=1.6783, train_err=0.0839, 32_h1=0.0839, 32_l2=0.0412, 64_h1=0.1612, 64_l2=0.0541\n",
      "[60] time=2.36, avg_loss=1.6323, train_err=0.0816, 32_h1=0.0894, 32_l2=0.0521, 64_h1=0.1664, 64_l2=0.0627\n",
      "[61] time=2.41, avg_loss=1.6201, train_err=0.0810, 32_h1=0.0853, 32_l2=0.0455, 64_h1=0.1721, 64_l2=0.0595\n",
      "[62] time=2.35, avg_loss=1.6198, train_err=0.0810, 32_h1=0.0851, 32_l2=0.0427, 64_h1=0.1651, 64_l2=0.0549\n",
      "[63] time=2.34, avg_loss=1.6162, train_err=0.0808, 32_h1=0.0848, 32_l2=0.0445, 64_h1=0.1579, 64_l2=0.0526\n",
      "[64] time=2.35, avg_loss=1.5786, train_err=0.0789, 32_h1=0.0832, 32_l2=0.0427, 64_h1=0.1701, 64_l2=0.0634\n",
      "[65] time=2.33, avg_loss=1.6136, train_err=0.0807, 32_h1=0.0844, 32_l2=0.0425, 64_h1=0.1628, 64_l2=0.0526\n",
      "[66] time=2.34, avg_loss=1.6291, train_err=0.0815, 32_h1=0.0988, 32_l2=0.0624, 64_h1=0.1732, 64_l2=0.0726\n",
      "[67] time=2.34, avg_loss=1.5692, train_err=0.0785, 32_h1=0.0812, 32_l2=0.0402, 64_h1=0.1649, 64_l2=0.0550\n",
      "[68] time=2.33, avg_loss=1.5889, train_err=0.0794, 32_h1=0.0806, 32_l2=0.0385, 64_h1=0.1703, 64_l2=0.0558\n",
      "[69] time=2.33, avg_loss=1.6043, train_err=0.0802, 32_h1=0.0811, 32_l2=0.0383, 64_h1=0.1722, 64_l2=0.0557\n",
      "[70] time=2.34, avg_loss=1.5996, train_err=0.0800, 32_h1=0.0869, 32_l2=0.0467, 64_h1=0.1678, 64_l2=0.0590\n",
      "[71] time=2.24, avg_loss=1.5703, train_err=0.0785, 32_h1=0.0879, 32_l2=0.0511, 64_h1=0.1636, 64_l2=0.0656\n",
      "[72] time=2.07, avg_loss=1.5658, train_err=0.0783, 32_h1=0.0816, 32_l2=0.0404, 64_h1=0.1690, 64_l2=0.0570\n",
      "[73] time=2.09, avg_loss=1.5636, train_err=0.0782, 32_h1=0.0796, 32_l2=0.0380, 64_h1=0.1668, 64_l2=0.0531\n",
      "[74] time=2.03, avg_loss=1.5930, train_err=0.0796, 32_h1=0.0821, 32_l2=0.0422, 64_h1=0.1722, 64_l2=0.0603\n",
      "[75] time=2.04, avg_loss=1.5963, train_err=0.0798, 32_h1=0.0841, 32_l2=0.0417, 64_h1=0.1618, 64_l2=0.0558\n",
      "[76] time=2.14, avg_loss=1.5363, train_err=0.0768, 32_h1=0.0851, 32_l2=0.0455, 64_h1=0.1640, 64_l2=0.0586\n",
      "[77] time=2.24, avg_loss=1.5450, train_err=0.0772, 32_h1=0.0833, 32_l2=0.0468, 64_h1=0.1664, 64_l2=0.0581\n",
      "[78] time=2.17, avg_loss=1.5610, train_err=0.0781, 32_h1=0.0827, 32_l2=0.0434, 64_h1=0.1623, 64_l2=0.0567\n",
      "[79] time=2.23, avg_loss=1.5750, train_err=0.0788, 32_h1=0.0826, 32_l2=0.0426, 64_h1=0.1651, 64_l2=0.0570\n",
      "[80] time=2.14, avg_loss=1.5674, train_err=0.0784, 32_h1=0.0819, 32_l2=0.0421, 64_h1=0.1612, 64_l2=0.0584\n",
      "[81] time=2.10, avg_loss=1.5279, train_err=0.0764, 32_h1=0.0815, 32_l2=0.0399, 64_h1=0.1659, 64_l2=0.0583\n",
      "[82] time=2.22, avg_loss=1.5392, train_err=0.0770, 32_h1=0.0784, 32_l2=0.0369, 64_h1=0.1635, 64_l2=0.0520\n",
      "[83] time=2.09, avg_loss=1.5216, train_err=0.0761, 32_h1=0.0799, 32_l2=0.0387, 64_h1=0.1637, 64_l2=0.0548\n",
      "[84] time=2.04, avg_loss=1.5081, train_err=0.0754, 32_h1=0.0795, 32_l2=0.0384, 64_h1=0.1669, 64_l2=0.0526\n",
      "[85] time=2.24, avg_loss=1.5106, train_err=0.0755, 32_h1=0.0828, 32_l2=0.0435, 64_h1=0.1672, 64_l2=0.0605\n",
      "[86] time=2.12, avg_loss=1.5726, train_err=0.0786, 32_h1=0.0856, 32_l2=0.0448, 64_h1=0.1648, 64_l2=0.0526\n",
      "[87] time=2.07, avg_loss=1.5359, train_err=0.0768, 32_h1=0.0787, 32_l2=0.0388, 64_h1=0.1624, 64_l2=0.0553\n",
      "[88] time=2.14, avg_loss=1.5259, train_err=0.0763, 32_h1=0.0791, 32_l2=0.0379, 64_h1=0.1647, 64_l2=0.0567\n",
      "[89] time=2.14, avg_loss=1.5016, train_err=0.0751, 32_h1=0.0797, 32_l2=0.0391, 64_h1=0.1685, 64_l2=0.0558\n",
      "[90] time=2.18, avg_loss=1.5024, train_err=0.0751, 32_h1=0.0804, 32_l2=0.0411, 64_h1=0.1625, 64_l2=0.0590\n",
      "[91] time=2.18, avg_loss=1.4755, train_err=0.0738, 32_h1=0.0809, 32_l2=0.0412, 64_h1=0.1623, 64_l2=0.0513\n",
      "[92] time=2.14, avg_loss=1.5031, train_err=0.0752, 32_h1=0.0812, 32_l2=0.0389, 64_h1=0.1561, 64_l2=0.0519\n",
      "[93] time=2.16, avg_loss=1.5030, train_err=0.0752, 32_h1=0.0786, 32_l2=0.0381, 64_h1=0.1654, 64_l2=0.0534\n",
      "[94] time=2.21, avg_loss=1.4867, train_err=0.0743, 32_h1=0.0887, 32_l2=0.0543, 64_h1=0.1700, 64_l2=0.0695\n",
      "[95] time=2.13, avg_loss=1.5091, train_err=0.0755, 32_h1=0.0789, 32_l2=0.0387, 64_h1=0.1633, 64_l2=0.0533\n",
      "[96] time=2.24, avg_loss=1.4611, train_err=0.0731, 32_h1=0.0791, 32_l2=0.0384, 64_h1=0.1679, 64_l2=0.0551\n",
      "[97] time=2.24, avg_loss=1.4779, train_err=0.0739, 32_h1=0.0771, 32_l2=0.0367, 64_h1=0.1583, 64_l2=0.0506\n",
      "[98] time=2.14, avg_loss=1.4711, train_err=0.0736, 32_h1=0.0773, 32_l2=0.0364, 64_h1=0.1644, 64_l2=0.0546\n",
      "[99] time=2.11, avg_loss=1.4662, train_err=0.0733, 32_h1=0.0777, 32_l2=0.0371, 64_h1=0.1678, 64_l2=0.0557\n",
      "[100] time=2.34, avg_loss=1.4802, train_err=0.0740, 32_h1=0.0814, 32_l2=0.0419, 64_h1=0.1681, 64_l2=0.0598\n",
      "[101] time=2.31, avg_loss=1.4852, train_err=0.0743, 32_h1=0.0786, 32_l2=0.0388, 64_h1=0.1689, 64_l2=0.0564\n",
      "[102] time=2.35, avg_loss=1.4901, train_err=0.0745, 32_h1=0.0798, 32_l2=0.0403, 64_h1=0.1647, 64_l2=0.0548\n",
      "[103] time=2.34, avg_loss=1.4978, train_err=0.0749, 32_h1=0.0800, 32_l2=0.0410, 64_h1=0.1601, 64_l2=0.0544\n",
      "[104] time=2.39, avg_loss=1.4696, train_err=0.0735, 32_h1=0.0793, 32_l2=0.0396, 64_h1=0.1699, 64_l2=0.0594\n",
      "[105] time=2.35, avg_loss=1.4460, train_err=0.0723, 32_h1=0.0831, 32_l2=0.0444, 64_h1=0.1592, 64_l2=0.0551\n",
      "[106] time=2.35, avg_loss=1.4933, train_err=0.0747, 32_h1=0.0798, 32_l2=0.0411, 64_h1=0.1602, 64_l2=0.0547\n",
      "[107] time=2.35, avg_loss=1.4257, train_err=0.0713, 32_h1=0.0827, 32_l2=0.0472, 64_h1=0.1628, 64_l2=0.0604\n",
      "[108] time=2.35, avg_loss=1.4429, train_err=0.0721, 32_h1=0.0818, 32_l2=0.0462, 64_h1=0.1676, 64_l2=0.0581\n",
      "[109] time=2.39, avg_loss=1.4343, train_err=0.0717, 32_h1=0.0781, 32_l2=0.0382, 64_h1=0.1641, 64_l2=0.0544\n",
      "[110] time=2.30, avg_loss=1.4408, train_err=0.0720, 32_h1=0.0802, 32_l2=0.0393, 64_h1=0.1652, 64_l2=0.0499\n",
      "[111] time=2.39, avg_loss=1.4305, train_err=0.0715, 32_h1=0.0788, 32_l2=0.0397, 64_h1=0.1641, 64_l2=0.0555\n",
      "[112] time=2.39, avg_loss=1.4187, train_err=0.0709, 32_h1=0.0758, 32_l2=0.0356, 64_h1=0.1637, 64_l2=0.0546\n",
      "[113] time=2.35, avg_loss=1.4031, train_err=0.0702, 32_h1=0.0783, 32_l2=0.0408, 64_h1=0.1590, 64_l2=0.0553\n",
      "[114] time=2.33, avg_loss=1.4474, train_err=0.0724, 32_h1=0.0778, 32_l2=0.0381, 64_h1=0.1625, 64_l2=0.0564\n",
      "[115] time=2.37, avg_loss=1.4218, train_err=0.0711, 32_h1=0.0779, 32_l2=0.0406, 64_h1=0.1664, 64_l2=0.0568\n",
      "[116] time=2.35, avg_loss=1.4381, train_err=0.0719, 32_h1=0.0775, 32_l2=0.0382, 64_h1=0.1586, 64_l2=0.0511\n",
      "[117] time=2.35, avg_loss=1.4140, train_err=0.0707, 32_h1=0.0770, 32_l2=0.0386, 64_h1=0.1608, 64_l2=0.0525\n",
      "[118] time=2.32, avg_loss=1.4537, train_err=0.0727, 32_h1=0.0800, 32_l2=0.0438, 64_h1=0.1651, 64_l2=0.0560\n",
      "[119] time=2.32, avg_loss=1.4039, train_err=0.0702, 32_h1=0.0784, 32_l2=0.0387, 64_h1=0.1622, 64_l2=0.0565\n",
      "[120] time=2.31, avg_loss=1.4131, train_err=0.0707, 32_h1=0.0788, 32_l2=0.0390, 64_h1=0.1701, 64_l2=0.0586\n",
      "[121] time=2.39, avg_loss=1.4001, train_err=0.0700, 32_h1=0.0764, 32_l2=0.0361, 64_h1=0.1709, 64_l2=0.0565\n",
      "[122] time=2.34, avg_loss=1.3910, train_err=0.0696, 32_h1=0.0780, 32_l2=0.0396, 64_h1=0.1610, 64_l2=0.0552\n",
      "[123] time=2.38, avg_loss=1.4068, train_err=0.0703, 32_h1=0.0759, 32_l2=0.0359, 64_h1=0.1604, 64_l2=0.0502\n",
      "[124] time=2.33, avg_loss=1.3848, train_err=0.0692, 32_h1=0.0778, 32_l2=0.0389, 64_h1=0.1594, 64_l2=0.0504\n",
      "[125] time=2.35, avg_loss=1.3995, train_err=0.0700, 32_h1=0.0792, 32_l2=0.0400, 64_h1=0.1647, 64_l2=0.0550\n",
      "[126] time=2.35, avg_loss=1.3820, train_err=0.0691, 32_h1=0.0761, 32_l2=0.0363, 64_h1=0.1617, 64_l2=0.0530\n",
      "[127] time=2.37, avg_loss=1.3947, train_err=0.0697, 32_h1=0.0779, 32_l2=0.0389, 64_h1=0.1631, 64_l2=0.0524\n",
      "[128] time=2.35, avg_loss=1.3988, train_err=0.0699, 32_h1=0.0782, 32_l2=0.0389, 64_h1=0.1673, 64_l2=0.0578\n",
      "[129] time=2.38, avg_loss=1.4052, train_err=0.0703, 32_h1=0.0780, 32_l2=0.0405, 64_h1=0.1578, 64_l2=0.0532\n",
      "[130] time=2.39, avg_loss=1.3670, train_err=0.0684, 32_h1=0.0745, 32_l2=0.0346, 64_h1=0.1654, 64_l2=0.0539\n",
      "[131] time=2.33, avg_loss=1.3973, train_err=0.0699, 32_h1=0.0774, 32_l2=0.0384, 64_h1=0.1644, 64_l2=0.0563\n",
      "[132] time=2.38, avg_loss=1.3689, train_err=0.0684, 32_h1=0.0811, 32_l2=0.0478, 64_h1=0.1664, 64_l2=0.0588\n",
      "[133] time=2.32, avg_loss=1.3765, train_err=0.0688, 32_h1=0.0762, 32_l2=0.0367, 64_h1=0.1657, 64_l2=0.0520\n",
      "[134] time=2.37, avg_loss=1.4269, train_err=0.0713, 32_h1=0.0784, 32_l2=0.0405, 64_h1=0.1661, 64_l2=0.0577\n",
      "[135] time=2.36, avg_loss=1.3640, train_err=0.0682, 32_h1=0.0755, 32_l2=0.0363, 64_h1=0.1632, 64_l2=0.0503\n",
      "[136] time=2.35, avg_loss=1.3641, train_err=0.0682, 32_h1=0.0748, 32_l2=0.0350, 64_h1=0.1633, 64_l2=0.0516\n",
      "[137] time=2.32, avg_loss=1.3513, train_err=0.0676, 32_h1=0.0755, 32_l2=0.0361, 64_h1=0.1648, 64_l2=0.0543\n",
      "[138] time=2.33, avg_loss=1.3599, train_err=0.0680, 32_h1=0.0758, 32_l2=0.0358, 64_h1=0.1630, 64_l2=0.0487\n",
      "[139] time=2.17, avg_loss=1.3441, train_err=0.0672, 32_h1=0.0767, 32_l2=0.0401, 64_h1=0.1653, 64_l2=0.0537\n",
      "[140] time=2.18, avg_loss=1.3727, train_err=0.0686, 32_h1=0.0785, 32_l2=0.0401, 64_h1=0.1614, 64_l2=0.0547\n",
      "[141] time=2.20, avg_loss=1.3649, train_err=0.0682, 32_h1=0.0765, 32_l2=0.0370, 64_h1=0.1680, 64_l2=0.0536\n",
      "[142] time=2.05, avg_loss=1.3531, train_err=0.0677, 32_h1=0.0760, 32_l2=0.0358, 64_h1=0.1606, 64_l2=0.0502\n",
      "[143] time=2.03, avg_loss=1.3625, train_err=0.0681, 32_h1=0.0753, 32_l2=0.0359, 64_h1=0.1633, 64_l2=0.0530\n",
      "[144] time=2.09, avg_loss=1.3468, train_err=0.0673, 32_h1=0.0782, 32_l2=0.0414, 64_h1=0.1617, 64_l2=0.0568\n",
      "[145] time=2.05, avg_loss=1.3465, train_err=0.0673, 32_h1=0.0739, 32_l2=0.0340, 64_h1=0.1633, 64_l2=0.0504\n",
      "[146] time=2.08, avg_loss=1.3376, train_err=0.0669, 32_h1=0.0762, 32_l2=0.0365, 64_h1=0.1626, 64_l2=0.0489\n",
      "[147] time=2.17, avg_loss=1.3352, train_err=0.0668, 32_h1=0.0748, 32_l2=0.0352, 64_h1=0.1620, 64_l2=0.0508\n",
      "[148] time=2.19, avg_loss=1.3435, train_err=0.0672, 32_h1=0.0749, 32_l2=0.0351, 64_h1=0.1611, 64_l2=0.0507\n",
      "[149] time=2.14, avg_loss=1.3388, train_err=0.0669, 32_h1=0.0752, 32_l2=0.0360, 64_h1=0.1653, 64_l2=0.0531\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.2\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 137473\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f776fdbb1c0>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f776fdbb820>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f776fdbb820>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f7854c9e490>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.08, avg_loss=11.2666, train_err=0.5633, 32_h1=0.3230, 32_l2=0.2239, 64_h1=0.3827, 64_l2=0.2292\n",
      "[1] time=2.06, avg_loss=5.3181, train_err=0.2659, 32_h1=0.2195, 32_l2=0.1473, 64_h1=0.2985, 64_l2=0.1629\n",
      "[2] time=2.09, avg_loss=4.1127, train_err=0.2056, 32_h1=0.2112, 32_l2=0.1527, 64_h1=0.2572, 64_l2=0.1565\n",
      "[3] time=2.21, avg_loss=3.4936, train_err=0.1747, 32_h1=0.1810, 32_l2=0.1261, 64_h1=0.2318, 64_l2=0.1273\n",
      "[4] time=2.22, avg_loss=3.2757, train_err=0.1638, 32_h1=0.1505, 32_l2=0.1004, 64_h1=0.2255, 64_l2=0.1106\n",
      "[5] time=2.22, avg_loss=2.9448, train_err=0.1472, 32_h1=0.1400, 32_l2=0.0873, 64_h1=0.2175, 64_l2=0.1005\n",
      "[6] time=2.22, avg_loss=2.8310, train_err=0.1416, 32_h1=0.1604, 32_l2=0.1122, 64_h1=0.2021, 64_l2=0.1113\n",
      "[7] time=2.24, avg_loss=2.6706, train_err=0.1335, 32_h1=0.1262, 32_l2=0.0799, 64_h1=0.1988, 64_l2=0.0908\n",
      "[8] time=2.09, avg_loss=2.5105, train_err=0.1255, 32_h1=0.1271, 32_l2=0.0830, 64_h1=0.2057, 64_l2=0.0990\n",
      "[9] time=2.05, avg_loss=2.4648, train_err=0.1232, 32_h1=0.1147, 32_l2=0.0671, 64_h1=0.1798, 64_l2=0.0728\n",
      "[10] time=2.07, avg_loss=2.2540, train_err=0.1127, 32_h1=0.1520, 32_l2=0.1149, 64_h1=0.2010, 64_l2=0.1228\n",
      "[11] time=2.22, avg_loss=2.3138, train_err=0.1157, 32_h1=0.1059, 32_l2=0.0610, 64_h1=0.1777, 64_l2=0.0702\n",
      "[12] time=2.21, avg_loss=2.1074, train_err=0.1054, 32_h1=0.1063, 32_l2=0.0626, 64_h1=0.1791, 64_l2=0.0751\n",
      "[13] time=2.21, avg_loss=2.1092, train_err=0.1055, 32_h1=0.1247, 32_l2=0.0918, 64_h1=0.1800, 64_l2=0.0946\n",
      "[14] time=2.16, avg_loss=2.0663, train_err=0.1033, 32_h1=0.0995, 32_l2=0.0550, 64_h1=0.1663, 64_l2=0.0601\n",
      "[15] time=2.11, avg_loss=2.0449, train_err=0.1022, 32_h1=0.1014, 32_l2=0.0575, 64_h1=0.1727, 64_l2=0.0706\n",
      "[16] time=2.03, avg_loss=1.9946, train_err=0.0997, 32_h1=0.1018, 32_l2=0.0619, 64_h1=0.1640, 64_l2=0.0657\n",
      "[17] time=2.06, avg_loss=1.9547, train_err=0.0977, 32_h1=0.1030, 32_l2=0.0636, 64_h1=0.1674, 64_l2=0.0687\n",
      "[18] time=2.35, avg_loss=1.9398, train_err=0.0970, 32_h1=0.0951, 32_l2=0.0568, 64_h1=0.1724, 64_l2=0.0664\n",
      "[19] time=2.37, avg_loss=1.9061, train_err=0.0953, 32_h1=0.0957, 32_l2=0.0535, 64_h1=0.1622, 64_l2=0.0572\n",
      "[20] time=2.35, avg_loss=1.8400, train_err=0.0920, 32_h1=0.0992, 32_l2=0.0578, 64_h1=0.1694, 64_l2=0.0715\n",
      "[21] time=2.32, avg_loss=1.9592, train_err=0.0980, 32_h1=0.0929, 32_l2=0.0499, 64_h1=0.1638, 64_l2=0.0602\n",
      "[22] time=2.33, avg_loss=1.8197, train_err=0.0910, 32_h1=0.0938, 32_l2=0.0518, 64_h1=0.1687, 64_l2=0.0603\n",
      "[23] time=2.38, avg_loss=1.8376, train_err=0.0919, 32_h1=0.0887, 32_l2=0.0467, 64_h1=0.1623, 64_l2=0.0563\n",
      "[24] time=2.35, avg_loss=1.7974, train_err=0.0899, 32_h1=0.0952, 32_l2=0.0550, 64_h1=0.1685, 64_l2=0.0651\n",
      "[25] time=2.36, avg_loss=1.8256, train_err=0.0913, 32_h1=0.0953, 32_l2=0.0509, 64_h1=0.1661, 64_l2=0.0651\n",
      "[26] time=2.35, avg_loss=1.8114, train_err=0.0906, 32_h1=0.0870, 32_l2=0.0460, 64_h1=0.1604, 64_l2=0.0568\n",
      "[27] time=2.33, avg_loss=1.7749, train_err=0.0887, 32_h1=0.0873, 32_l2=0.0488, 64_h1=0.1636, 64_l2=0.0617\n",
      "[28] time=2.33, avg_loss=1.7316, train_err=0.0866, 32_h1=0.0844, 32_l2=0.0433, 64_h1=0.1583, 64_l2=0.0564\n",
      "[29] time=2.35, avg_loss=1.7849, train_err=0.0892, 32_h1=0.0873, 32_l2=0.0477, 64_h1=0.1654, 64_l2=0.0672\n",
      "[30] time=2.34, avg_loss=1.7131, train_err=0.0857, 32_h1=0.0824, 32_l2=0.0423, 64_h1=0.1540, 64_l2=0.0533\n",
      "[31] time=2.39, avg_loss=1.7402, train_err=0.0870, 32_h1=0.0874, 32_l2=0.0497, 64_h1=0.1624, 64_l2=0.0613\n",
      "[32] time=2.34, avg_loss=1.6981, train_err=0.0849, 32_h1=0.0840, 32_l2=0.0443, 64_h1=0.1707, 64_l2=0.0658\n",
      "[33] time=2.35, avg_loss=1.7073, train_err=0.0854, 32_h1=0.0849, 32_l2=0.0458, 64_h1=0.1667, 64_l2=0.0631\n",
      "[34] time=2.36, avg_loss=1.6949, train_err=0.0847, 32_h1=0.0825, 32_l2=0.0409, 64_h1=0.1550, 64_l2=0.0562\n",
      "[35] time=2.32, avg_loss=1.6465, train_err=0.0823, 32_h1=0.0827, 32_l2=0.0436, 64_h1=0.1698, 64_l2=0.0608\n",
      "[36] time=2.35, avg_loss=1.6283, train_err=0.0814, 32_h1=0.0821, 32_l2=0.0415, 64_h1=0.1685, 64_l2=0.0597\n",
      "[37] time=2.32, avg_loss=1.6128, train_err=0.0806, 32_h1=0.0809, 32_l2=0.0411, 64_h1=0.1543, 64_l2=0.0521\n",
      "[38] time=2.43, avg_loss=1.6331, train_err=0.0817, 32_h1=0.0791, 32_l2=0.0396, 64_h1=0.1596, 64_l2=0.0548\n",
      "[39] time=2.31, avg_loss=1.6268, train_err=0.0813, 32_h1=0.0807, 32_l2=0.0414, 64_h1=0.1576, 64_l2=0.0541\n",
      "[40] time=2.31, avg_loss=1.6253, train_err=0.0813, 32_h1=0.0866, 32_l2=0.0500, 64_h1=0.1647, 64_l2=0.0624\n",
      "[41] time=2.30, avg_loss=1.6224, train_err=0.0811, 32_h1=0.0830, 32_l2=0.0437, 64_h1=0.1616, 64_l2=0.0581\n",
      "[42] time=2.42, avg_loss=1.5772, train_err=0.0789, 32_h1=0.0792, 32_l2=0.0391, 64_h1=0.1542, 64_l2=0.0531\n",
      "[43] time=2.32, avg_loss=1.6559, train_err=0.0828, 32_h1=0.0808, 32_l2=0.0419, 64_h1=0.1662, 64_l2=0.0580\n",
      "[44] time=2.33, avg_loss=1.5528, train_err=0.0776, 32_h1=0.0790, 32_l2=0.0393, 64_h1=0.1620, 64_l2=0.0580\n",
      "[45] time=2.35, avg_loss=1.5564, train_err=0.0778, 32_h1=0.0787, 32_l2=0.0396, 64_h1=0.1521, 64_l2=0.0510\n",
      "[46] time=2.40, avg_loss=1.5846, train_err=0.0792, 32_h1=0.0817, 32_l2=0.0427, 64_h1=0.1663, 64_l2=0.0593\n",
      "[47] time=2.37, avg_loss=1.5706, train_err=0.0785, 32_h1=0.0825, 32_l2=0.0481, 64_h1=0.1624, 64_l2=0.0646\n",
      "[48] time=2.36, avg_loss=1.5916, train_err=0.0796, 32_h1=0.0861, 32_l2=0.0487, 64_h1=0.1571, 64_l2=0.0514\n",
      "[49] time=2.33, avg_loss=1.5597, train_err=0.0780, 32_h1=0.0800, 32_l2=0.0411, 64_h1=0.1593, 64_l2=0.0480\n",
      "[50] time=2.34, avg_loss=1.5694, train_err=0.0785, 32_h1=0.0840, 32_l2=0.0491, 64_h1=0.1552, 64_l2=0.0583\n",
      "[51] time=2.33, avg_loss=1.5526, train_err=0.0776, 32_h1=0.0812, 32_l2=0.0472, 64_h1=0.1558, 64_l2=0.0606\n",
      "[52] time=2.32, avg_loss=1.5219, train_err=0.0761, 32_h1=0.0786, 32_l2=0.0405, 64_h1=0.1557, 64_l2=0.0560\n",
      "[53] time=2.33, avg_loss=1.4911, train_err=0.0746, 32_h1=0.0838, 32_l2=0.0503, 64_h1=0.1717, 64_l2=0.0670\n",
      "[54] time=2.44, avg_loss=1.5269, train_err=0.0763, 32_h1=0.0780, 32_l2=0.0390, 64_h1=0.1591, 64_l2=0.0527\n",
      "[55] time=2.33, avg_loss=1.5066, train_err=0.0753, 32_h1=0.0818, 32_l2=0.0448, 64_h1=0.1599, 64_l2=0.0548\n",
      "[56] time=2.36, avg_loss=1.5163, train_err=0.0758, 32_h1=0.0778, 32_l2=0.0395, 64_h1=0.1614, 64_l2=0.0497\n",
      "[57] time=2.13, avg_loss=1.5037, train_err=0.0752, 32_h1=0.0798, 32_l2=0.0416, 64_h1=0.1636, 64_l2=0.0617\n",
      "[58] time=2.12, avg_loss=1.5212, train_err=0.0761, 32_h1=0.0804, 32_l2=0.0464, 64_h1=0.1608, 64_l2=0.0575\n",
      "[59] time=2.12, avg_loss=1.4840, train_err=0.0742, 32_h1=0.0815, 32_l2=0.0425, 64_h1=0.1571, 64_l2=0.0574\n",
      "[60] time=2.05, avg_loss=1.4897, train_err=0.0745, 32_h1=0.0767, 32_l2=0.0404, 64_h1=0.1601, 64_l2=0.0536\n",
      "[61] time=2.08, avg_loss=1.4965, train_err=0.0748, 32_h1=0.0793, 32_l2=0.0422, 64_h1=0.1500, 64_l2=0.0512\n",
      "[62] time=2.05, avg_loss=1.5514, train_err=0.0776, 32_h1=0.0795, 32_l2=0.0431, 64_h1=0.1618, 64_l2=0.0562\n",
      "[63] time=2.15, avg_loss=1.4883, train_err=0.0744, 32_h1=0.0743, 32_l2=0.0351, 64_h1=0.1593, 64_l2=0.0510\n",
      "[64] time=2.21, avg_loss=1.5653, train_err=0.0783, 32_h1=0.0771, 32_l2=0.0389, 64_h1=0.1545, 64_l2=0.0499\n",
      "[65] time=2.21, avg_loss=1.4730, train_err=0.0736, 32_h1=0.0771, 32_l2=0.0393, 64_h1=0.1566, 64_l2=0.0531\n",
      "[66] time=2.18, avg_loss=1.4727, train_err=0.0736, 32_h1=0.0765, 32_l2=0.0405, 64_h1=0.1514, 64_l2=0.0501\n",
      "[67] time=2.21, avg_loss=1.4429, train_err=0.0721, 32_h1=0.0796, 32_l2=0.0451, 64_h1=0.1620, 64_l2=0.0591\n",
      "[68] time=2.15, avg_loss=1.4477, train_err=0.0724, 32_h1=0.0771, 32_l2=0.0402, 64_h1=0.1567, 64_l2=0.0500\n",
      "[69] time=2.13, avg_loss=1.4416, train_err=0.0721, 32_h1=0.0745, 32_l2=0.0359, 64_h1=0.1571, 64_l2=0.0512\n",
      "[70] time=2.17, avg_loss=1.4810, train_err=0.0741, 32_h1=0.0752, 32_l2=0.0369, 64_h1=0.1599, 64_l2=0.0508\n",
      "[71] time=2.21, avg_loss=1.4366, train_err=0.0718, 32_h1=0.0738, 32_l2=0.0351, 64_h1=0.1504, 64_l2=0.0478\n",
      "[72] time=2.23, avg_loss=1.4682, train_err=0.0734, 32_h1=0.0747, 32_l2=0.0364, 64_h1=0.1580, 64_l2=0.0548\n",
      "[73] time=2.14, avg_loss=1.4618, train_err=0.0731, 32_h1=0.0772, 32_l2=0.0389, 64_h1=0.1584, 64_l2=0.0538\n",
      "[74] time=2.06, avg_loss=1.4591, train_err=0.0730, 32_h1=0.0842, 32_l2=0.0538, 64_h1=0.1565, 64_l2=0.0623\n",
      "[75] time=2.13, avg_loss=1.4351, train_err=0.0718, 32_h1=0.0771, 32_l2=0.0400, 64_h1=0.1632, 64_l2=0.0539\n",
      "[76] time=2.22, avg_loss=1.4397, train_err=0.0720, 32_h1=0.0735, 32_l2=0.0349, 64_h1=0.1603, 64_l2=0.0520\n",
      "[77] time=2.13, avg_loss=1.4350, train_err=0.0717, 32_h1=0.0743, 32_l2=0.0355, 64_h1=0.1522, 64_l2=0.0522\n",
      "[78] time=2.23, avg_loss=1.4287, train_err=0.0714, 32_h1=0.0802, 32_l2=0.0457, 64_h1=0.1551, 64_l2=0.0578\n",
      "[79] time=2.25, avg_loss=1.4705, train_err=0.0735, 32_h1=0.0792, 32_l2=0.0449, 64_h1=0.1562, 64_l2=0.0563\n",
      "[80] time=2.08, avg_loss=1.4453, train_err=0.0723, 32_h1=0.0754, 32_l2=0.0386, 64_h1=0.1561, 64_l2=0.0550\n",
      "[81] time=2.05, avg_loss=1.4796, train_err=0.0740, 32_h1=0.0735, 32_l2=0.0354, 64_h1=0.1598, 64_l2=0.0533\n",
      "[82] time=2.07, avg_loss=1.4069, train_err=0.0703, 32_h1=0.0781, 32_l2=0.0435, 64_h1=0.1549, 64_l2=0.0534\n",
      "[83] time=2.04, avg_loss=1.4138, train_err=0.0707, 32_h1=0.0748, 32_l2=0.0376, 64_h1=0.1533, 64_l2=0.0489\n",
      "[84] time=2.05, avg_loss=1.3943, train_err=0.0697, 32_h1=0.0761, 32_l2=0.0397, 64_h1=0.1584, 64_l2=0.0525\n",
      "[85] time=2.19, avg_loss=1.3894, train_err=0.0695, 32_h1=0.0759, 32_l2=0.0398, 64_h1=0.1544, 64_l2=0.0525\n",
      "[86] time=2.25, avg_loss=1.3912, train_err=0.0696, 32_h1=0.0763, 32_l2=0.0396, 64_h1=0.1620, 64_l2=0.0558\n",
      "[87] time=2.38, avg_loss=1.3956, train_err=0.0698, 32_h1=0.0743, 32_l2=0.0373, 64_h1=0.1605, 64_l2=0.0561\n",
      "[88] time=2.33, avg_loss=1.3848, train_err=0.0692, 32_h1=0.0740, 32_l2=0.0375, 64_h1=0.1605, 64_l2=0.0501\n",
      "[89] time=2.32, avg_loss=1.3998, train_err=0.0700, 32_h1=0.0816, 32_l2=0.0471, 64_h1=0.1635, 64_l2=0.0565\n",
      "[90] time=2.36, avg_loss=1.3848, train_err=0.0692, 32_h1=0.0737, 32_l2=0.0364, 64_h1=0.1585, 64_l2=0.0500\n",
      "[91] time=2.44, avg_loss=1.3660, train_err=0.0683, 32_h1=0.0735, 32_l2=0.0366, 64_h1=0.1551, 64_l2=0.0518\n",
      "[92] time=2.31, avg_loss=1.3554, train_err=0.0678, 32_h1=0.0769, 32_l2=0.0408, 64_h1=0.1564, 64_l2=0.0551\n",
      "[93] time=2.34, avg_loss=1.4238, train_err=0.0712, 32_h1=0.0752, 32_l2=0.0376, 64_h1=0.1568, 64_l2=0.0540\n",
      "[94] time=2.38, avg_loss=1.3676, train_err=0.0684, 32_h1=0.0765, 32_l2=0.0405, 64_h1=0.1640, 64_l2=0.0570\n",
      "[95] time=2.36, avg_loss=1.3952, train_err=0.0698, 32_h1=0.0775, 32_l2=0.0435, 64_h1=0.1592, 64_l2=0.0549\n",
      "[96] time=2.41, avg_loss=1.3930, train_err=0.0696, 32_h1=0.0721, 32_l2=0.0351, 64_h1=0.1559, 64_l2=0.0505\n",
      "[97] time=2.36, avg_loss=1.3747, train_err=0.0687, 32_h1=0.0754, 32_l2=0.0387, 64_h1=0.1566, 64_l2=0.0518\n",
      "[98] time=2.36, avg_loss=1.3557, train_err=0.0678, 32_h1=0.0735, 32_l2=0.0369, 64_h1=0.1574, 64_l2=0.0542\n",
      "[99] time=2.33, avg_loss=1.3722, train_err=0.0686, 32_h1=0.0754, 32_l2=0.0391, 64_h1=0.1546, 64_l2=0.0531\n",
      "[100] time=2.37, avg_loss=1.3440, train_err=0.0672, 32_h1=0.0740, 32_l2=0.0362, 64_h1=0.1611, 64_l2=0.0511\n",
      "[101] time=2.40, avg_loss=1.3440, train_err=0.0672, 32_h1=0.0767, 32_l2=0.0408, 64_h1=0.1555, 64_l2=0.0512\n",
      "[102] time=2.45, avg_loss=1.3606, train_err=0.0680, 32_h1=0.0739, 32_l2=0.0360, 64_h1=0.1564, 64_l2=0.0510\n",
      "[103] time=2.37, avg_loss=1.3598, train_err=0.0680, 32_h1=0.0773, 32_l2=0.0387, 64_h1=0.1664, 64_l2=0.0546\n",
      "[104] time=2.31, avg_loss=1.3635, train_err=0.0682, 32_h1=0.0755, 32_l2=0.0389, 64_h1=0.1680, 64_l2=0.0546\n",
      "[105] time=2.34, avg_loss=1.3582, train_err=0.0679, 32_h1=0.0730, 32_l2=0.0361, 64_h1=0.1558, 64_l2=0.0524\n",
      "[106] time=2.30, avg_loss=1.3360, train_err=0.0668, 32_h1=0.0759, 32_l2=0.0390, 64_h1=0.1553, 64_l2=0.0459\n",
      "[107] time=2.36, avg_loss=1.3494, train_err=0.0675, 32_h1=0.0760, 32_l2=0.0397, 64_h1=0.1537, 64_l2=0.0519\n",
      "[108] time=2.32, avg_loss=1.3456, train_err=0.0673, 32_h1=0.0781, 32_l2=0.0432, 64_h1=0.1639, 64_l2=0.0581\n",
      "[109] time=2.35, avg_loss=1.3396, train_err=0.0670, 32_h1=0.0728, 32_l2=0.0352, 64_h1=0.1623, 64_l2=0.0516\n",
      "[110] time=2.35, avg_loss=1.3189, train_err=0.0659, 32_h1=0.0757, 32_l2=0.0420, 64_h1=0.1564, 64_l2=0.0567\n",
      "[111] time=2.37, avg_loss=1.3130, train_err=0.0657, 32_h1=0.0715, 32_l2=0.0333, 64_h1=0.1550, 64_l2=0.0466\n",
      "[112] time=2.35, avg_loss=1.3089, train_err=0.0654, 32_h1=0.0742, 32_l2=0.0394, 64_h1=0.1555, 64_l2=0.0541\n",
      "[113] time=2.31, avg_loss=1.2956, train_err=0.0648, 32_h1=0.0717, 32_l2=0.0339, 64_h1=0.1568, 64_l2=0.0508\n",
      "[114] time=2.42, avg_loss=1.3101, train_err=0.0655, 32_h1=0.0732, 32_l2=0.0368, 64_h1=0.1619, 64_l2=0.0558\n",
      "[115] time=2.34, avg_loss=1.3166, train_err=0.0658, 32_h1=0.0744, 32_l2=0.0388, 64_h1=0.1635, 64_l2=0.0567\n",
      "[116] time=2.32, avg_loss=1.3298, train_err=0.0665, 32_h1=0.0778, 32_l2=0.0428, 64_h1=0.1613, 64_l2=0.0573\n",
      "[117] time=2.36, avg_loss=1.3434, train_err=0.0672, 32_h1=0.0746, 32_l2=0.0389, 64_h1=0.1614, 64_l2=0.0533\n",
      "[118] time=2.40, avg_loss=1.2978, train_err=0.0649, 32_h1=0.0733, 32_l2=0.0370, 64_h1=0.1585, 64_l2=0.0495\n",
      "[119] time=2.38, avg_loss=1.3015, train_err=0.0651, 32_h1=0.0719, 32_l2=0.0338, 64_h1=0.1551, 64_l2=0.0488\n",
      "[120] time=2.37, avg_loss=1.2873, train_err=0.0644, 32_h1=0.0721, 32_l2=0.0348, 64_h1=0.1552, 64_l2=0.0512\n",
      "[121] time=2.38, avg_loss=1.2905, train_err=0.0645, 32_h1=0.0744, 32_l2=0.0384, 64_h1=0.1650, 64_l2=0.0556\n",
      "[122] time=2.36, avg_loss=1.3013, train_err=0.0651, 32_h1=0.0772, 32_l2=0.0395, 64_h1=0.1645, 64_l2=0.0558\n",
      "[123] time=2.35, avg_loss=1.2940, train_err=0.0647, 32_h1=0.0720, 32_l2=0.0345, 64_h1=0.1521, 64_l2=0.0496\n",
      "[124] time=2.31, avg_loss=1.2781, train_err=0.0639, 32_h1=0.0717, 32_l2=0.0335, 64_h1=0.1637, 64_l2=0.0530\n",
      "[125] time=2.25, avg_loss=1.2896, train_err=0.0645, 32_h1=0.0724, 32_l2=0.0353, 64_h1=0.1559, 64_l2=0.0516\n",
      "[126] time=2.05, avg_loss=1.3455, train_err=0.0673, 32_h1=0.0767, 32_l2=0.0409, 64_h1=0.1626, 64_l2=0.0560\n",
      "[127] time=2.05, avg_loss=1.2966, train_err=0.0648, 32_h1=0.0726, 32_l2=0.0349, 64_h1=0.1604, 64_l2=0.0512\n",
      "[128] time=2.05, avg_loss=1.2680, train_err=0.0634, 32_h1=0.0752, 32_l2=0.0386, 64_h1=0.1562, 64_l2=0.0519\n",
      "[129] time=2.07, avg_loss=1.2845, train_err=0.0642, 32_h1=0.0720, 32_l2=0.0345, 64_h1=0.1536, 64_l2=0.0496\n",
      "[130] time=2.08, avg_loss=1.2674, train_err=0.0634, 32_h1=0.0715, 32_l2=0.0337, 64_h1=0.1574, 64_l2=0.0506\n",
      "[131] time=2.13, avg_loss=1.2722, train_err=0.0636, 32_h1=0.0729, 32_l2=0.0348, 64_h1=0.1671, 64_l2=0.0551\n",
      "[132] time=2.22, avg_loss=1.2622, train_err=0.0631, 32_h1=0.0719, 32_l2=0.0346, 64_h1=0.1555, 64_l2=0.0502\n",
      "[133] time=2.21, avg_loss=1.2790, train_err=0.0639, 32_h1=0.0716, 32_l2=0.0336, 64_h1=0.1555, 64_l2=0.0487\n",
      "[134] time=2.20, avg_loss=1.2650, train_err=0.0633, 32_h1=0.0736, 32_l2=0.0376, 64_h1=0.1557, 64_l2=0.0489\n",
      "[135] time=2.10, avg_loss=1.2753, train_err=0.0638, 32_h1=0.0718, 32_l2=0.0333, 64_h1=0.1567, 64_l2=0.0468\n",
      "[136] time=2.08, avg_loss=1.2840, train_err=0.0642, 32_h1=0.0713, 32_l2=0.0336, 64_h1=0.1596, 64_l2=0.0503\n",
      "[137] time=2.04, avg_loss=1.2568, train_err=0.0628, 32_h1=0.0712, 32_l2=0.0329, 64_h1=0.1593, 64_l2=0.0482\n",
      "[138] time=2.12, avg_loss=1.2547, train_err=0.0627, 32_h1=0.0729, 32_l2=0.0356, 64_h1=0.1635, 64_l2=0.0570\n",
      "[139] time=2.05, avg_loss=1.2566, train_err=0.0628, 32_h1=0.0721, 32_l2=0.0346, 64_h1=0.1623, 64_l2=0.0551\n",
      "[140] time=2.03, avg_loss=1.2510, train_err=0.0626, 32_h1=0.0715, 32_l2=0.0338, 64_h1=0.1607, 64_l2=0.0521\n",
      "[141] time=2.07, avg_loss=1.2387, train_err=0.0619, 32_h1=0.0710, 32_l2=0.0335, 64_h1=0.1557, 64_l2=0.0499\n",
      "[142] time=2.24, avg_loss=1.2508, train_err=0.0625, 32_h1=0.0730, 32_l2=0.0357, 64_h1=0.1552, 64_l2=0.0479\n",
      "[143] time=2.09, avg_loss=1.2585, train_err=0.0629, 32_h1=0.0737, 32_l2=0.0375, 64_h1=0.1576, 64_l2=0.0495\n",
      "[144] time=2.18, avg_loss=1.2676, train_err=0.0634, 32_h1=0.0706, 32_l2=0.0324, 64_h1=0.1574, 64_l2=0.0494\n",
      "[145] time=2.22, avg_loss=1.2434, train_err=0.0622, 32_h1=0.0710, 32_l2=0.0333, 64_h1=0.1569, 64_l2=0.0501\n",
      "[146] time=2.21, avg_loss=1.2455, train_err=0.0623, 32_h1=0.0728, 32_l2=0.0371, 64_h1=0.1576, 64_l2=0.0501\n",
      "[147] time=2.18, avg_loss=1.2317, train_err=0.0616, 32_h1=0.0710, 32_l2=0.0335, 64_h1=0.1593, 64_l2=0.0491\n",
      "[148] time=2.09, avg_loss=1.2240, train_err=0.0612, 32_h1=0.0720, 32_l2=0.0352, 64_h1=0.1549, 64_l2=0.0504\n",
      "[149] time=2.05, avg_loss=1.2290, train_err=0.0615, 32_h1=0.0722, 32_l2=0.0355, 64_h1=0.1565, 64_l2=0.0485\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=14\n",
      "tfno2d.n_modes_width=14\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.2\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 212849\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 7, 7), rank=(21, 21, 5, 5))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 7, 7), rank=(21, 21, 5, 5))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 7, 7), rank=(21, 21, 5, 5))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 7, 7), rank=(21, 21, 5, 5))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 7, 7), rank=(21, 21, 5, 5))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 7, 7), rank=(21, 21, 5, 5))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 7, 7), rank=(21, 21, 5, 5))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 7, 7), rank=(21, 21, 5, 5))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f7761b37d60>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f7761b3cca0>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f7761b3cca0>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f7761b37cd0>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.08, avg_loss=10.6926, train_err=0.5346, 32_h1=0.2932, 32_l2=0.2024, 64_h1=0.3410, 64_l2=0.2085\n",
      "[1] time=2.13, avg_loss=4.7515, train_err=0.2376, 32_h1=0.1937, 32_l2=0.1274, 64_h1=0.2529, 64_l2=0.1365\n",
      "[2] time=2.09, avg_loss=3.7314, train_err=0.1866, 32_h1=0.1707, 32_l2=0.1129, 64_h1=0.2301, 64_l2=0.1181\n",
      "[3] time=2.06, avg_loss=3.1821, train_err=0.1591, 32_h1=0.1524, 32_l2=0.0983, 64_h1=0.2129, 64_l2=0.0998\n",
      "[4] time=2.35, avg_loss=2.8573, train_err=0.1429, 32_h1=0.1396, 32_l2=0.0911, 64_h1=0.2038, 64_l2=0.0986\n",
      "[5] time=2.36, avg_loss=2.6725, train_err=0.1336, 32_h1=0.1399, 32_l2=0.0867, 64_h1=0.2075, 64_l2=0.0959\n",
      "[6] time=2.38, avg_loss=2.4270, train_err=0.1214, 32_h1=0.1213, 32_l2=0.0729, 64_h1=0.1940, 64_l2=0.0883\n",
      "[7] time=2.32, avg_loss=2.4432, train_err=0.1222, 32_h1=0.1205, 32_l2=0.0715, 64_h1=0.1967, 64_l2=0.0833\n",
      "[8] time=2.39, avg_loss=2.2377, train_err=0.1119, 32_h1=0.1089, 32_l2=0.0666, 64_h1=0.1743, 64_l2=0.0742\n",
      "[9] time=2.33, avg_loss=2.1582, train_err=0.1079, 32_h1=0.1045, 32_l2=0.0623, 64_h1=0.1841, 64_l2=0.0724\n",
      "[10] time=2.32, avg_loss=2.0341, train_err=0.1017, 32_h1=0.0996, 32_l2=0.0557, 64_h1=0.1779, 64_l2=0.0707\n",
      "[11] time=2.33, avg_loss=2.0218, train_err=0.1011, 32_h1=0.0998, 32_l2=0.0593, 64_h1=0.1769, 64_l2=0.0702\n",
      "[12] time=2.33, avg_loss=1.9728, train_err=0.0986, 32_h1=0.1123, 32_l2=0.0854, 64_h1=0.1830, 64_l2=0.0913\n",
      "[13] time=2.37, avg_loss=1.8896, train_err=0.0945, 32_h1=0.0942, 32_l2=0.0522, 64_h1=0.1615, 64_l2=0.0603\n",
      "[14] time=2.34, avg_loss=1.8662, train_err=0.0933, 32_h1=0.1029, 32_l2=0.0622, 64_h1=0.1809, 64_l2=0.0722\n",
      "[15] time=2.35, avg_loss=1.7953, train_err=0.0898, 32_h1=0.0933, 32_l2=0.0542, 64_h1=0.1661, 64_l2=0.0628\n",
      "[16] time=2.40, avg_loss=1.8075, train_err=0.0904, 32_h1=0.0872, 32_l2=0.0476, 64_h1=0.1631, 64_l2=0.0561\n",
      "[17] time=2.36, avg_loss=1.7566, train_err=0.0878, 32_h1=0.0969, 32_l2=0.0658, 64_h1=0.1682, 64_l2=0.0781\n",
      "[18] time=2.36, avg_loss=1.7445, train_err=0.0872, 32_h1=0.0834, 32_l2=0.0426, 64_h1=0.1606, 64_l2=0.0597\n",
      "[19] time=2.38, avg_loss=1.7016, train_err=0.0851, 32_h1=0.0902, 32_l2=0.0546, 64_h1=0.1638, 64_l2=0.0634\n",
      "[20] time=2.35, avg_loss=1.7232, train_err=0.0862, 32_h1=0.0982, 32_l2=0.0615, 64_h1=0.1695, 64_l2=0.0683\n",
      "[21] time=2.35, avg_loss=1.7393, train_err=0.0870, 32_h1=0.0841, 32_l2=0.0432, 64_h1=0.1559, 64_l2=0.0547\n",
      "[22] time=2.37, avg_loss=1.6510, train_err=0.0826, 32_h1=0.0883, 32_l2=0.0563, 64_h1=0.1563, 64_l2=0.0648\n",
      "[23] time=2.37, avg_loss=1.6781, train_err=0.0839, 32_h1=0.0915, 32_l2=0.0523, 64_h1=0.1729, 64_l2=0.0696\n",
      "[24] time=2.42, avg_loss=1.6309, train_err=0.0815, 32_h1=0.0898, 32_l2=0.0556, 64_h1=0.1615, 64_l2=0.0662\n",
      "[25] time=2.35, avg_loss=1.6496, train_err=0.0825, 32_h1=0.0822, 32_l2=0.0454, 64_h1=0.1551, 64_l2=0.0572\n",
      "[26] time=2.34, avg_loss=1.6128, train_err=0.0806, 32_h1=0.0788, 32_l2=0.0389, 64_h1=0.1599, 64_l2=0.0537\n",
      "[27] time=2.35, avg_loss=1.5779, train_err=0.0789, 32_h1=0.0790, 32_l2=0.0389, 64_h1=0.1541, 64_l2=0.0519\n",
      "[28] time=2.34, avg_loss=1.5782, train_err=0.0789, 32_h1=0.0857, 32_l2=0.0526, 64_h1=0.1566, 64_l2=0.0568\n",
      "[29] time=2.35, avg_loss=1.5587, train_err=0.0779, 32_h1=0.0775, 32_l2=0.0384, 64_h1=0.1536, 64_l2=0.0546\n",
      "[30] time=2.36, avg_loss=1.5883, train_err=0.0794, 32_h1=0.0775, 32_l2=0.0395, 64_h1=0.1564, 64_l2=0.0553\n",
      "[31] time=2.35, avg_loss=1.5552, train_err=0.0778, 32_h1=0.0839, 32_l2=0.0465, 64_h1=0.1669, 64_l2=0.0642\n",
      "[32] time=2.35, avg_loss=1.5771, train_err=0.0789, 32_h1=0.0790, 32_l2=0.0405, 64_h1=0.1671, 64_l2=0.0605\n",
      "[33] time=2.33, avg_loss=1.5475, train_err=0.0774, 32_h1=0.0829, 32_l2=0.0474, 64_h1=0.1631, 64_l2=0.0637\n",
      "[34] time=2.35, avg_loss=1.6324, train_err=0.0816, 32_h1=0.0901, 32_l2=0.0522, 64_h1=0.1697, 64_l2=0.0708\n",
      "[35] time=2.37, avg_loss=1.5156, train_err=0.0758, 32_h1=0.0782, 32_l2=0.0411, 64_h1=0.1611, 64_l2=0.0529\n",
      "[36] time=2.35, avg_loss=1.5303, train_err=0.0765, 32_h1=0.0837, 32_l2=0.0471, 64_h1=0.1607, 64_l2=0.0614\n",
      "[37] time=2.34, avg_loss=1.5174, train_err=0.0759, 32_h1=0.0785, 32_l2=0.0444, 64_h1=0.1664, 64_l2=0.0633\n",
      "[38] time=2.35, avg_loss=1.5217, train_err=0.0761, 32_h1=0.0797, 32_l2=0.0419, 64_h1=0.1620, 64_l2=0.0589\n",
      "[39] time=2.37, avg_loss=1.5270, train_err=0.0763, 32_h1=0.0772, 32_l2=0.0391, 64_h1=0.1574, 64_l2=0.0507\n",
      "[40] time=2.40, avg_loss=1.4980, train_err=0.0749, 32_h1=0.0786, 32_l2=0.0415, 64_h1=0.1600, 64_l2=0.0553\n",
      "[41] time=2.36, avg_loss=1.5527, train_err=0.0776, 32_h1=0.0852, 32_l2=0.0516, 64_h1=0.1585, 64_l2=0.0660\n",
      "[42] time=2.27, avg_loss=1.4826, train_err=0.0741, 32_h1=0.0743, 32_l2=0.0358, 64_h1=0.1612, 64_l2=0.0538\n",
      "[43] time=2.12, avg_loss=1.4755, train_err=0.0738, 32_h1=0.0810, 32_l2=0.0454, 64_h1=0.1651, 64_l2=0.0600\n",
      "[44] time=2.17, avg_loss=1.4781, train_err=0.0739, 32_h1=0.0745, 32_l2=0.0364, 64_h1=0.1626, 64_l2=0.0529\n",
      "[45] time=2.06, avg_loss=1.4793, train_err=0.0740, 32_h1=0.0899, 32_l2=0.0544, 64_h1=0.1662, 64_l2=0.0674\n",
      "[46] time=2.09, avg_loss=1.4969, train_err=0.0748, 32_h1=0.0832, 32_l2=0.0500, 64_h1=0.1624, 64_l2=0.0581\n",
      "[47] time=2.17, avg_loss=1.4687, train_err=0.0734, 32_h1=0.0748, 32_l2=0.0365, 64_h1=0.1572, 64_l2=0.0496\n",
      "[48] time=2.09, avg_loss=1.4438, train_err=0.0722, 32_h1=0.0741, 32_l2=0.0374, 64_h1=0.1516, 64_l2=0.0517\n",
      "[49] time=2.05, avg_loss=1.4626, train_err=0.0731, 32_h1=0.0755, 32_l2=0.0370, 64_h1=0.1526, 64_l2=0.0486\n",
      "[50] time=2.06, avg_loss=1.4512, train_err=0.0726, 32_h1=0.0825, 32_l2=0.0496, 64_h1=0.1579, 64_l2=0.0651\n",
      "[51] time=2.06, avg_loss=1.4749, train_err=0.0737, 32_h1=0.0771, 32_l2=0.0415, 64_h1=0.1589, 64_l2=0.0532\n",
      "[52] time=2.05, avg_loss=1.4588, train_err=0.0729, 32_h1=0.0761, 32_l2=0.0411, 64_h1=0.1533, 64_l2=0.0533\n",
      "[53] time=2.06, avg_loss=1.4211, train_err=0.0711, 32_h1=0.0824, 32_l2=0.0493, 64_h1=0.1552, 64_l2=0.0594\n",
      "[54] time=2.13, avg_loss=1.4442, train_err=0.0722, 32_h1=0.0748, 32_l2=0.0383, 64_h1=0.1616, 64_l2=0.0551\n",
      "[55] time=2.09, avg_loss=1.4041, train_err=0.0702, 32_h1=0.0731, 32_l2=0.0361, 64_h1=0.1572, 64_l2=0.0520\n",
      "[56] time=2.06, avg_loss=1.4176, train_err=0.0709, 32_h1=0.0728, 32_l2=0.0343, 64_h1=0.1553, 64_l2=0.0525\n",
      "[57] time=2.05, avg_loss=1.4342, train_err=0.0717, 32_h1=0.0741, 32_l2=0.0382, 64_h1=0.1573, 64_l2=0.0591\n",
      "[58] time=2.04, avg_loss=1.4178, train_err=0.0709, 32_h1=0.0754, 32_l2=0.0398, 64_h1=0.1561, 64_l2=0.0598\n",
      "[59] time=2.06, avg_loss=1.4466, train_err=0.0723, 32_h1=0.0783, 32_l2=0.0439, 64_h1=0.1561, 64_l2=0.0604\n",
      "[60] time=2.12, avg_loss=1.4152, train_err=0.0708, 32_h1=0.0729, 32_l2=0.0361, 64_h1=0.1581, 64_l2=0.0540\n",
      "[61] time=2.10, avg_loss=1.4310, train_err=0.0716, 32_h1=0.0754, 32_l2=0.0389, 64_h1=0.1603, 64_l2=0.0569\n",
      "[62] time=2.18, avg_loss=1.3953, train_err=0.0698, 32_h1=0.0733, 32_l2=0.0363, 64_h1=0.1612, 64_l2=0.0540\n",
      "[63] time=2.21, avg_loss=1.3694, train_err=0.0685, 32_h1=0.0751, 32_l2=0.0386, 64_h1=0.1626, 64_l2=0.0581\n",
      "[64] time=2.17, avg_loss=1.3806, train_err=0.0690, 32_h1=0.0760, 32_l2=0.0408, 64_h1=0.1609, 64_l2=0.0598\n",
      "[65] time=2.08, avg_loss=1.4143, train_err=0.0707, 32_h1=0.0834, 32_l2=0.0502, 64_h1=0.1620, 64_l2=0.0717\n",
      "[66] time=2.23, avg_loss=1.3770, train_err=0.0689, 32_h1=0.0752, 32_l2=0.0409, 64_h1=0.1618, 64_l2=0.0520\n",
      "[67] time=2.20, avg_loss=1.3984, train_err=0.0699, 32_h1=0.0739, 32_l2=0.0362, 64_h1=0.1529, 64_l2=0.0508\n",
      "[68] time=2.16, avg_loss=1.3548, train_err=0.0677, 32_h1=0.0742, 32_l2=0.0368, 64_h1=0.1540, 64_l2=0.0504\n",
      "[69] time=2.14, avg_loss=1.3914, train_err=0.0696, 32_h1=0.0738, 32_l2=0.0357, 64_h1=0.1625, 64_l2=0.0542\n",
      "[70] time=2.21, avg_loss=1.3924, train_err=0.0696, 32_h1=0.0725, 32_l2=0.0354, 64_h1=0.1579, 64_l2=0.0550\n",
      "[71] time=2.22, avg_loss=1.3448, train_err=0.0672, 32_h1=0.0740, 32_l2=0.0381, 64_h1=0.1616, 64_l2=0.0545\n",
      "[72] time=2.46, avg_loss=1.3805, train_err=0.0690, 32_h1=0.0757, 32_l2=0.0420, 64_h1=0.1589, 64_l2=0.0601\n",
      "[73] time=2.49, avg_loss=1.3753, train_err=0.0688, 32_h1=0.0763, 32_l2=0.0407, 64_h1=0.1629, 64_l2=0.0592\n",
      "[74] time=2.42, avg_loss=1.3695, train_err=0.0685, 32_h1=0.0754, 32_l2=0.0395, 64_h1=0.1528, 64_l2=0.0506\n",
      "[75] time=2.33, avg_loss=1.3541, train_err=0.0677, 32_h1=0.0735, 32_l2=0.0363, 64_h1=0.1592, 64_l2=0.0549\n",
      "[76] time=2.36, avg_loss=1.3532, train_err=0.0677, 32_h1=0.0740, 32_l2=0.0377, 64_h1=0.1583, 64_l2=0.0538\n",
      "[77] time=2.38, avg_loss=1.3291, train_err=0.0665, 32_h1=0.0734, 32_l2=0.0371, 64_h1=0.1621, 64_l2=0.0549\n",
      "[78] time=2.34, avg_loss=1.3226, train_err=0.0661, 32_h1=0.0728, 32_l2=0.0364, 64_h1=0.1625, 64_l2=0.0574\n",
      "[79] time=2.35, avg_loss=1.3558, train_err=0.0678, 32_h1=0.0710, 32_l2=0.0337, 64_h1=0.1565, 64_l2=0.0501\n",
      "[80] time=2.38, avg_loss=1.3144, train_err=0.0657, 32_h1=0.0718, 32_l2=0.0347, 64_h1=0.1632, 64_l2=0.0533\n",
      "[81] time=2.36, avg_loss=1.3314, train_err=0.0666, 32_h1=0.0719, 32_l2=0.0354, 64_h1=0.1588, 64_l2=0.0527\n",
      "[82] time=2.36, avg_loss=1.3227, train_err=0.0661, 32_h1=0.0747, 32_l2=0.0381, 64_h1=0.1638, 64_l2=0.0519\n",
      "[83] time=2.34, avg_loss=1.3183, train_err=0.0659, 32_h1=0.0761, 32_l2=0.0424, 64_h1=0.1557, 64_l2=0.0598\n",
      "[84] time=2.41, avg_loss=1.3117, train_err=0.0656, 32_h1=0.0736, 32_l2=0.0365, 64_h1=0.1631, 64_l2=0.0500\n",
      "[85] time=2.36, avg_loss=1.3152, train_err=0.0658, 32_h1=0.0752, 32_l2=0.0389, 64_h1=0.1607, 64_l2=0.0541\n",
      "[86] time=2.37, avg_loss=1.3224, train_err=0.0661, 32_h1=0.0738, 32_l2=0.0369, 64_h1=0.1590, 64_l2=0.0562\n",
      "[87] time=2.32, avg_loss=1.3056, train_err=0.0653, 32_h1=0.0724, 32_l2=0.0352, 64_h1=0.1580, 64_l2=0.0508\n",
      "[88] time=2.38, avg_loss=1.3216, train_err=0.0661, 32_h1=0.0738, 32_l2=0.0364, 64_h1=0.1578, 64_l2=0.0517\n",
      "[89] time=2.32, avg_loss=1.2865, train_err=0.0643, 32_h1=0.0729, 32_l2=0.0361, 64_h1=0.1574, 64_l2=0.0551\n",
      "[90] time=2.37, avg_loss=1.2965, train_err=0.0648, 32_h1=0.0763, 32_l2=0.0410, 64_h1=0.1615, 64_l2=0.0597\n",
      "[91] time=2.36, avg_loss=1.3160, train_err=0.0658, 32_h1=0.0728, 32_l2=0.0375, 64_h1=0.1597, 64_l2=0.0551\n",
      "[92] time=2.36, avg_loss=1.2794, train_err=0.0640, 32_h1=0.0733, 32_l2=0.0378, 64_h1=0.1624, 64_l2=0.0548\n",
      "[93] time=2.36, avg_loss=1.2781, train_err=0.0639, 32_h1=0.0722, 32_l2=0.0354, 64_h1=0.1589, 64_l2=0.0554\n",
      "[94] time=2.33, avg_loss=1.2695, train_err=0.0635, 32_h1=0.0721, 32_l2=0.0346, 64_h1=0.1577, 64_l2=0.0544\n",
      "[95] time=2.38, avg_loss=1.3389, train_err=0.0669, 32_h1=0.0719, 32_l2=0.0347, 64_h1=0.1638, 64_l2=0.0543\n",
      "[96] time=2.34, avg_loss=1.2731, train_err=0.0637, 32_h1=0.0747, 32_l2=0.0386, 64_h1=0.1631, 64_l2=0.0566\n",
      "[97] time=2.41, avg_loss=1.2811, train_err=0.0641, 32_h1=0.0724, 32_l2=0.0341, 64_h1=0.1652, 64_l2=0.0548\n",
      "[98] time=2.33, avg_loss=1.2783, train_err=0.0639, 32_h1=0.0718, 32_l2=0.0348, 64_h1=0.1634, 64_l2=0.0554\n",
      "[99] time=2.37, avg_loss=1.2651, train_err=0.0633, 32_h1=0.0721, 32_l2=0.0349, 64_h1=0.1601, 64_l2=0.0536\n",
      "[100] time=2.37, avg_loss=1.2611, train_err=0.0631, 32_h1=0.0721, 32_l2=0.0351, 64_h1=0.1621, 64_l2=0.0526\n",
      "[101] time=2.36, avg_loss=1.2579, train_err=0.0629, 32_h1=0.0756, 32_l2=0.0378, 64_h1=0.1583, 64_l2=0.0578\n",
      "[102] time=2.37, avg_loss=1.2772, train_err=0.0639, 32_h1=0.0751, 32_l2=0.0385, 64_h1=0.1664, 64_l2=0.0578\n",
      "[103] time=2.32, avg_loss=1.2461, train_err=0.0623, 32_h1=0.0721, 32_l2=0.0342, 64_h1=0.1565, 64_l2=0.0494\n",
      "[104] time=2.33, avg_loss=1.2539, train_err=0.0627, 32_h1=0.0728, 32_l2=0.0352, 64_h1=0.1578, 64_l2=0.0564\n",
      "[105] time=2.35, avg_loss=1.2379, train_err=0.0619, 32_h1=0.0748, 32_l2=0.0394, 64_h1=0.1623, 64_l2=0.0561\n",
      "[106] time=2.34, avg_loss=1.2447, train_err=0.0622, 32_h1=0.0730, 32_l2=0.0362, 64_h1=0.1664, 64_l2=0.0570\n",
      "[107] time=2.40, avg_loss=1.2215, train_err=0.0611, 32_h1=0.0743, 32_l2=0.0389, 64_h1=0.1596, 64_l2=0.0538\n",
      "[108] time=2.33, avg_loss=1.2285, train_err=0.0614, 32_h1=0.0758, 32_l2=0.0407, 64_h1=0.1633, 64_l2=0.0569\n",
      "[109] time=2.34, avg_loss=1.2576, train_err=0.0629, 32_h1=0.0738, 32_l2=0.0363, 64_h1=0.1606, 64_l2=0.0576\n",
      "[110] time=2.25, avg_loss=1.2131, train_err=0.0607, 32_h1=0.0721, 32_l2=0.0341, 64_h1=0.1608, 64_l2=0.0537\n",
      "[111] time=2.10, avg_loss=1.2178, train_err=0.0609, 32_h1=0.0776, 32_l2=0.0410, 64_h1=0.1638, 64_l2=0.0581\n",
      "[112] time=2.20, avg_loss=1.2071, train_err=0.0604, 32_h1=0.0741, 32_l2=0.0374, 64_h1=0.1592, 64_l2=0.0551\n",
      "[113] time=2.10, avg_loss=1.2203, train_err=0.0610, 32_h1=0.0748, 32_l2=0.0410, 64_h1=0.1602, 64_l2=0.0606\n",
      "[114] time=2.20, avg_loss=1.2133, train_err=0.0607, 32_h1=0.0730, 32_l2=0.0361, 64_h1=0.1600, 64_l2=0.0530\n",
      "[115] time=2.24, avg_loss=1.2217, train_err=0.0611, 32_h1=0.0737, 32_l2=0.0353, 64_h1=0.1639, 64_l2=0.0554\n",
      "[116] time=2.24, avg_loss=1.2013, train_err=0.0601, 32_h1=0.0740, 32_l2=0.0357, 64_h1=0.1644, 64_l2=0.0594\n",
      "[117] time=2.09, avg_loss=1.1897, train_err=0.0595, 32_h1=0.0720, 32_l2=0.0337, 64_h1=0.1576, 64_l2=0.0534\n",
      "[118] time=2.15, avg_loss=1.1971, train_err=0.0599, 32_h1=0.0745, 32_l2=0.0362, 64_h1=0.1635, 64_l2=0.0524\n",
      "[119] time=2.29, avg_loss=1.1948, train_err=0.0597, 32_h1=0.0737, 32_l2=0.0356, 64_h1=0.1648, 64_l2=0.0560\n",
      "[120] time=2.11, avg_loss=1.2109, train_err=0.0605, 32_h1=0.0750, 32_l2=0.0375, 64_h1=0.1673, 64_l2=0.0587\n",
      "[121] time=2.06, avg_loss=1.1764, train_err=0.0588, 32_h1=0.0727, 32_l2=0.0341, 64_h1=0.1629, 64_l2=0.0521\n",
      "[122] time=2.17, avg_loss=1.1679, train_err=0.0584, 32_h1=0.0745, 32_l2=0.0367, 64_h1=0.1589, 64_l2=0.0528\n",
      "[123] time=2.28, avg_loss=1.1945, train_err=0.0597, 32_h1=0.0766, 32_l2=0.0395, 64_h1=0.1663, 64_l2=0.0629\n",
      "[124] time=2.22, avg_loss=1.1715, train_err=0.0586, 32_h1=0.0727, 32_l2=0.0344, 64_h1=0.1632, 64_l2=0.0559\n",
      "[125] time=2.22, avg_loss=1.1491, train_err=0.0575, 32_h1=0.0747, 32_l2=0.0372, 64_h1=0.1634, 64_l2=0.0559\n",
      "[126] time=2.23, avg_loss=1.2068, train_err=0.0603, 32_h1=0.0757, 32_l2=0.0402, 64_h1=0.1649, 64_l2=0.0571\n",
      "[127] time=2.09, avg_loss=1.1520, train_err=0.0576, 32_h1=0.0771, 32_l2=0.0398, 64_h1=0.1662, 64_l2=0.0536\n",
      "[128] time=2.04, avg_loss=1.1461, train_err=0.0573, 32_h1=0.0754, 32_l2=0.0375, 64_h1=0.1638, 64_l2=0.0566\n",
      "[129] time=2.10, avg_loss=1.1720, train_err=0.0586, 32_h1=0.0735, 32_l2=0.0349, 64_h1=0.1636, 64_l2=0.0538\n",
      "[130] time=2.06, avg_loss=1.1313, train_err=0.0566, 32_h1=0.0730, 32_l2=0.0340, 64_h1=0.1664, 64_l2=0.0538\n",
      "[131] time=2.11, avg_loss=1.1139, train_err=0.0557, 32_h1=0.0727, 32_l2=0.0337, 64_h1=0.1618, 64_l2=0.0518\n",
      "[132] time=2.28, avg_loss=1.1301, train_err=0.0565, 32_h1=0.0757, 32_l2=0.0388, 64_h1=0.1613, 64_l2=0.0567\n",
      "[133] time=2.10, avg_loss=1.1392, train_err=0.0570, 32_h1=0.0773, 32_l2=0.0391, 64_h1=0.1657, 64_l2=0.0588\n",
      "[134] time=2.06, avg_loss=1.1504, train_err=0.0575, 32_h1=0.0745, 32_l2=0.0361, 64_h1=0.1641, 64_l2=0.0542\n",
      "[135] time=2.07, avg_loss=1.1259, train_err=0.0563, 32_h1=0.0743, 32_l2=0.0366, 64_h1=0.1621, 64_l2=0.0540\n",
      "[136] time=2.10, avg_loss=1.1130, train_err=0.0557, 32_h1=0.0750, 32_l2=0.0367, 64_h1=0.1669, 64_l2=0.0566\n",
      "[137] time=2.21, avg_loss=1.1250, train_err=0.0563, 32_h1=0.0755, 32_l2=0.0388, 64_h1=0.1659, 64_l2=0.0562\n",
      "[138] time=2.20, avg_loss=1.1170, train_err=0.0558, 32_h1=0.0765, 32_l2=0.0378, 64_h1=0.1616, 64_l2=0.0497\n",
      "[139] time=2.44, avg_loss=1.1023, train_err=0.0551, 32_h1=0.0764, 32_l2=0.0377, 64_h1=0.1701, 64_l2=0.0607\n",
      "[140] time=2.40, avg_loss=1.0939, train_err=0.0547, 32_h1=0.0745, 32_l2=0.0352, 64_h1=0.1628, 64_l2=0.0545\n",
      "[141] time=2.35, avg_loss=1.0756, train_err=0.0538, 32_h1=0.0746, 32_l2=0.0352, 64_h1=0.1653, 64_l2=0.0545\n",
      "[142] time=2.34, avg_loss=1.0938, train_err=0.0547, 32_h1=0.0768, 32_l2=0.0400, 64_h1=0.1657, 64_l2=0.0534\n",
      "[143] time=2.36, avg_loss=1.0971, train_err=0.0549, 32_h1=0.0744, 32_l2=0.0347, 64_h1=0.1649, 64_l2=0.0548\n",
      "[144] time=2.40, avg_loss=1.0859, train_err=0.0543, 32_h1=0.0753, 32_l2=0.0355, 64_h1=0.1638, 64_l2=0.0574\n",
      "[145] time=2.37, avg_loss=1.0788, train_err=0.0539, 32_h1=0.0762, 32_l2=0.0374, 64_h1=0.1695, 64_l2=0.0569\n",
      "[146] time=2.37, avg_loss=1.0721, train_err=0.0536, 32_h1=0.0754, 32_l2=0.0359, 64_h1=0.1687, 64_l2=0.0578\n",
      "[147] time=2.36, avg_loss=1.0499, train_err=0.0525, 32_h1=0.0750, 32_l2=0.0353, 64_h1=0.1660, 64_l2=0.0557\n",
      "[148] time=2.36, avg_loss=1.0581, train_err=0.0529, 32_h1=0.0746, 32_l2=0.0346, 64_h1=0.1654, 64_l2=0.0526\n",
      "[149] time=2.35, avg_loss=1.0592, train_err=0.0530, 32_h1=0.0748, 32_l2=0.0351, 64_h1=0.1627, 64_l2=0.0518\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=16\n",
      "tfno2d.n_modes_width=16\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.2\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 213009\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 8, 8), rank=(21, 21, 5, 5))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 8, 8), rank=(21, 21, 5, 5))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 8, 8), rank=(21, 21, 5, 5))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 8, 8), rank=(21, 21, 5, 5))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 8, 8), rank=(21, 21, 5, 5))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 8, 8), rank=(21, 21, 5, 5))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 8, 8), rank=(21, 21, 5, 5))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 8, 8), rank=(21, 21, 5, 5))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f7761b6d6a0>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f7761b37d60>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f7761b37d60>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f7854c9e2b0>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.35, avg_loss=10.4957, train_err=0.5248, 32_h1=0.3082, 32_l2=0.2097, 64_h1=0.3537, 64_l2=0.2110\n",
      "[1] time=2.33, avg_loss=4.7463, train_err=0.2373, 32_h1=0.2098, 32_l2=0.1463, 64_h1=0.2481, 64_l2=0.1399\n",
      "[2] time=2.31, avg_loss=3.7372, train_err=0.1869, 32_h1=0.1802, 32_l2=0.1240, 64_h1=0.2397, 64_l2=0.1362\n",
      "[3] time=2.35, avg_loss=3.2028, train_err=0.1601, 32_h1=0.1521, 32_l2=0.0981, 64_h1=0.2151, 64_l2=0.1035\n",
      "[4] time=2.31, avg_loss=2.8606, train_err=0.1430, 32_h1=0.1410, 32_l2=0.0901, 64_h1=0.2071, 64_l2=0.1013\n",
      "[5] time=2.41, avg_loss=2.6382, train_err=0.1319, 32_h1=0.1305, 32_l2=0.0834, 64_h1=0.1898, 64_l2=0.0869\n",
      "[6] time=2.33, avg_loss=2.4752, train_err=0.1238, 32_h1=0.1164, 32_l2=0.0688, 64_h1=0.1912, 64_l2=0.0805\n",
      "[7] time=2.35, avg_loss=2.2703, train_err=0.1135, 32_h1=0.1138, 32_l2=0.0664, 64_h1=0.1777, 64_l2=0.0801\n",
      "[8] time=2.36, avg_loss=2.2847, train_err=0.1142, 32_h1=0.1048, 32_l2=0.0613, 64_h1=0.1690, 64_l2=0.0689\n",
      "[9] time=2.39, avg_loss=2.1422, train_err=0.1071, 32_h1=0.1209, 32_l2=0.0867, 64_h1=0.1924, 64_l2=0.0954\n",
      "[10] time=2.38, avg_loss=2.0266, train_err=0.1013, 32_h1=0.0950, 32_l2=0.0511, 64_h1=0.1730, 64_l2=0.0653\n",
      "[11] time=2.36, avg_loss=2.0064, train_err=0.1003, 32_h1=0.1070, 32_l2=0.0652, 64_h1=0.1781, 64_l2=0.0799\n",
      "[12] time=2.32, avg_loss=1.9563, train_err=0.0978, 32_h1=0.0965, 32_l2=0.0545, 64_h1=0.1699, 64_l2=0.0674\n",
      "[13] time=2.36, avg_loss=1.8801, train_err=0.0940, 32_h1=0.0919, 32_l2=0.0521, 64_h1=0.1692, 64_l2=0.0653\n",
      "[14] time=2.37, avg_loss=1.8718, train_err=0.0936, 32_h1=0.0916, 32_l2=0.0543, 64_h1=0.1664, 64_l2=0.0654\n",
      "[15] time=2.39, avg_loss=1.7908, train_err=0.0895, 32_h1=0.0845, 32_l2=0.0430, 64_h1=0.1664, 64_l2=0.0542\n",
      "[16] time=2.37, avg_loss=1.7501, train_err=0.0875, 32_h1=0.0858, 32_l2=0.0456, 64_h1=0.1602, 64_l2=0.0547\n",
      "[17] time=2.39, avg_loss=1.7881, train_err=0.0894, 32_h1=0.0903, 32_l2=0.0511, 64_h1=0.1655, 64_l2=0.0684\n",
      "[18] time=2.33, avg_loss=1.7457, train_err=0.0873, 32_h1=0.0957, 32_l2=0.0557, 64_h1=0.1709, 64_l2=0.0722\n",
      "[19] time=2.34, avg_loss=1.6914, train_err=0.0846, 32_h1=0.0821, 32_l2=0.0426, 64_h1=0.1598, 64_l2=0.0590\n",
      "[20] time=2.36, avg_loss=1.7224, train_err=0.0861, 32_h1=0.0926, 32_l2=0.0511, 64_h1=0.1620, 64_l2=0.0659\n",
      "[21] time=2.35, avg_loss=1.6805, train_err=0.0840, 32_h1=0.0792, 32_l2=0.0400, 64_h1=0.1663, 64_l2=0.0602\n",
      "[22] time=2.31, avg_loss=1.6482, train_err=0.0824, 32_h1=0.0851, 32_l2=0.0513, 64_h1=0.1709, 64_l2=0.0671\n",
      "[23] time=2.37, avg_loss=1.6348, train_err=0.0817, 32_h1=0.0793, 32_l2=0.0416, 64_h1=0.1596, 64_l2=0.0550\n",
      "[24] time=2.37, avg_loss=1.5903, train_err=0.0795, 32_h1=0.0814, 32_l2=0.0444, 64_h1=0.1639, 64_l2=0.0574\n",
      "[25] time=2.33, avg_loss=1.5951, train_err=0.0798, 32_h1=0.1047, 32_l2=0.0730, 64_h1=0.1650, 64_l2=0.0755\n",
      "[26] time=2.31, avg_loss=1.6326, train_err=0.0816, 32_h1=0.0818, 32_l2=0.0432, 64_h1=0.1607, 64_l2=0.0580\n",
      "[27] time=2.20, avg_loss=1.5780, train_err=0.0789, 32_h1=0.0784, 32_l2=0.0452, 64_h1=0.1567, 64_l2=0.0558\n",
      "[28] time=2.25, avg_loss=1.5697, train_err=0.0785, 32_h1=0.0817, 32_l2=0.0456, 64_h1=0.1581, 64_l2=0.0601\n",
      "[29] time=2.19, avg_loss=1.5371, train_err=0.0769, 32_h1=0.0777, 32_l2=0.0405, 64_h1=0.1566, 64_l2=0.0580\n",
      "[30] time=2.22, avg_loss=1.6069, train_err=0.0803, 32_h1=0.0755, 32_l2=0.0391, 64_h1=0.1615, 64_l2=0.0556\n",
      "[31] time=2.22, avg_loss=1.5070, train_err=0.0753, 32_h1=0.0736, 32_l2=0.0347, 64_h1=0.1565, 64_l2=0.0522\n",
      "[32] time=2.17, avg_loss=1.5313, train_err=0.0766, 32_h1=0.0857, 32_l2=0.0522, 64_h1=0.1598, 64_l2=0.0633\n",
      "[33] time=2.06, avg_loss=1.5316, train_err=0.0766, 32_h1=0.0755, 32_l2=0.0381, 64_h1=0.1523, 64_l2=0.0537\n",
      "[34] time=2.14, avg_loss=1.5356, train_err=0.0768, 32_h1=0.0828, 32_l2=0.0452, 64_h1=0.1574, 64_l2=0.0593\n",
      "[35] time=2.08, avg_loss=1.6447, train_err=0.0822, 32_h1=0.0770, 32_l2=0.0392, 64_h1=0.1572, 64_l2=0.0546\n",
      "[36] time=2.07, avg_loss=1.5422, train_err=0.0771, 32_h1=0.0782, 32_l2=0.0456, 64_h1=0.1562, 64_l2=0.0617\n",
      "[37] time=2.08, avg_loss=1.5020, train_err=0.0751, 32_h1=0.0770, 32_l2=0.0395, 64_h1=0.1504, 64_l2=0.0527\n",
      "[38] time=2.06, avg_loss=1.4917, train_err=0.0746, 32_h1=0.0783, 32_l2=0.0427, 64_h1=0.1597, 64_l2=0.0624\n",
      "[39] time=2.10, avg_loss=1.5151, train_err=0.0758, 32_h1=0.0770, 32_l2=0.0402, 64_h1=0.1557, 64_l2=0.0544\n",
      "[40] time=2.12, avg_loss=1.5311, train_err=0.0766, 32_h1=0.0760, 32_l2=0.0395, 64_h1=0.1494, 64_l2=0.0526\n",
      "[41] time=2.32, avg_loss=1.5052, train_err=0.0753, 32_h1=0.0767, 32_l2=0.0404, 64_h1=0.1604, 64_l2=0.0595\n",
      "[42] time=2.11, avg_loss=1.4445, train_err=0.0722, 32_h1=0.0723, 32_l2=0.0360, 64_h1=0.1532, 64_l2=0.0522\n",
      "[43] time=2.15, avg_loss=1.4440, train_err=0.0722, 32_h1=0.0783, 32_l2=0.0444, 64_h1=0.1531, 64_l2=0.0589\n",
      "[44] time=2.06, avg_loss=1.5271, train_err=0.0764, 32_h1=0.0782, 32_l2=0.0426, 64_h1=0.1519, 64_l2=0.0561\n",
      "[45] time=2.05, avg_loss=1.4545, train_err=0.0727, 32_h1=0.0746, 32_l2=0.0382, 64_h1=0.1512, 64_l2=0.0537\n",
      "[46] time=2.05, avg_loss=1.4635, train_err=0.0732, 32_h1=0.0765, 32_l2=0.0403, 64_h1=0.1550, 64_l2=0.0578\n",
      "[47] time=2.14, avg_loss=1.4340, train_err=0.0717, 32_h1=0.0743, 32_l2=0.0387, 64_h1=0.1491, 64_l2=0.0525\n",
      "[48] time=2.21, avg_loss=1.4313, train_err=0.0716, 32_h1=0.0713, 32_l2=0.0346, 64_h1=0.1561, 64_l2=0.0531\n",
      "[49] time=2.20, avg_loss=1.4697, train_err=0.0735, 32_h1=0.0749, 32_l2=0.0374, 64_h1=0.1585, 64_l2=0.0505\n",
      "[50] time=2.06, avg_loss=1.4645, train_err=0.0732, 32_h1=0.0739, 32_l2=0.0378, 64_h1=0.1587, 64_l2=0.0598\n",
      "[51] time=2.21, avg_loss=1.4224, train_err=0.0711, 32_h1=0.0758, 32_l2=0.0409, 64_h1=0.1575, 64_l2=0.0584\n",
      "[52] time=2.05, avg_loss=1.4498, train_err=0.0725, 32_h1=0.0728, 32_l2=0.0365, 64_h1=0.1559, 64_l2=0.0569\n",
      "[53] time=2.10, avg_loss=1.4090, train_err=0.0704, 32_h1=0.0731, 32_l2=0.0358, 64_h1=0.1542, 64_l2=0.0528\n",
      "[54] time=2.15, avg_loss=1.4729, train_err=0.0736, 32_h1=0.0759, 32_l2=0.0412, 64_h1=0.1538, 64_l2=0.0541\n",
      "[55] time=2.20, avg_loss=1.4197, train_err=0.0710, 32_h1=0.0775, 32_l2=0.0430, 64_h1=0.1489, 64_l2=0.0542\n",
      "[56] time=2.30, avg_loss=1.4088, train_err=0.0704, 32_h1=0.0752, 32_l2=0.0376, 64_h1=0.1501, 64_l2=0.0550\n",
      "[57] time=2.28, avg_loss=1.4119, train_err=0.0706, 32_h1=0.0809, 32_l2=0.0486, 64_h1=0.1621, 64_l2=0.0680\n",
      "[58] time=2.38, avg_loss=1.3944, train_err=0.0697, 32_h1=0.0723, 32_l2=0.0358, 64_h1=0.1465, 64_l2=0.0467\n",
      "[59] time=2.38, avg_loss=1.4277, train_err=0.0714, 32_h1=0.0759, 32_l2=0.0415, 64_h1=0.1470, 64_l2=0.0544\n",
      "[60] time=2.41, avg_loss=1.4050, train_err=0.0702, 32_h1=0.0721, 32_l2=0.0365, 64_h1=0.1546, 64_l2=0.0527\n",
      "[61] time=2.33, avg_loss=1.4110, train_err=0.0705, 32_h1=0.0746, 32_l2=0.0387, 64_h1=0.1470, 64_l2=0.0475\n",
      "[62] time=2.33, avg_loss=1.4138, train_err=0.0707, 32_h1=0.0750, 32_l2=0.0437, 64_h1=0.1516, 64_l2=0.0606\n",
      "[63] time=2.40, avg_loss=1.4228, train_err=0.0711, 32_h1=0.0746, 32_l2=0.0395, 64_h1=0.1524, 64_l2=0.0517\n",
      "[64] time=2.42, avg_loss=1.4167, train_err=0.0708, 32_h1=0.0738, 32_l2=0.0385, 64_h1=0.1513, 64_l2=0.0521\n",
      "[65] time=2.41, avg_loss=1.3902, train_err=0.0695, 32_h1=0.0746, 32_l2=0.0399, 64_h1=0.1559, 64_l2=0.0557\n",
      "[66] time=2.33, avg_loss=1.3558, train_err=0.0678, 32_h1=0.0714, 32_l2=0.0357, 64_h1=0.1538, 64_l2=0.0556\n",
      "[67] time=2.31, avg_loss=1.4044, train_err=0.0702, 32_h1=0.0708, 32_l2=0.0333, 64_h1=0.1588, 64_l2=0.0539\n",
      "[68] time=2.37, avg_loss=1.3690, train_err=0.0684, 32_h1=0.0730, 32_l2=0.0374, 64_h1=0.1619, 64_l2=0.0602\n",
      "[69] time=2.37, avg_loss=1.3330, train_err=0.0666, 32_h1=0.0708, 32_l2=0.0355, 64_h1=0.1501, 64_l2=0.0513\n",
      "[70] time=2.32, avg_loss=1.3857, train_err=0.0693, 32_h1=0.0733, 32_l2=0.0405, 64_h1=0.1566, 64_l2=0.0585\n",
      "[71] time=2.29, avg_loss=1.3778, train_err=0.0689, 32_h1=0.0717, 32_l2=0.0362, 64_h1=0.1480, 64_l2=0.0534\n",
      "[72] time=2.35, avg_loss=1.3897, train_err=0.0695, 32_h1=0.0785, 32_l2=0.0419, 64_h1=0.1538, 64_l2=0.0568\n",
      "[73] time=2.34, avg_loss=1.4055, train_err=0.0703, 32_h1=0.0721, 32_l2=0.0394, 64_h1=0.1513, 64_l2=0.0577\n",
      "[74] time=2.33, avg_loss=1.3809, train_err=0.0690, 32_h1=0.0713, 32_l2=0.0354, 64_h1=0.1589, 64_l2=0.0553\n",
      "[75] time=2.36, avg_loss=1.3491, train_err=0.0675, 32_h1=0.0727, 32_l2=0.0363, 64_h1=0.1476, 64_l2=0.0491\n",
      "[76] time=2.32, avg_loss=1.3554, train_err=0.0678, 32_h1=0.0732, 32_l2=0.0376, 64_h1=0.1510, 64_l2=0.0552\n",
      "[77] time=2.40, avg_loss=1.3627, train_err=0.0681, 32_h1=0.0712, 32_l2=0.0351, 64_h1=0.1500, 64_l2=0.0498\n",
      "[78] time=2.30, avg_loss=1.3555, train_err=0.0678, 32_h1=0.0697, 32_l2=0.0342, 64_h1=0.1517, 64_l2=0.0551\n",
      "[79] time=2.34, avg_loss=1.3484, train_err=0.0674, 32_h1=0.0688, 32_l2=0.0326, 64_h1=0.1493, 64_l2=0.0507\n",
      "[80] time=2.36, avg_loss=1.3243, train_err=0.0662, 32_h1=0.0694, 32_l2=0.0329, 64_h1=0.1515, 64_l2=0.0498\n",
      "[81] time=2.38, avg_loss=1.3149, train_err=0.0657, 32_h1=0.0742, 32_l2=0.0400, 64_h1=0.1619, 64_l2=0.0635\n",
      "[82] time=2.38, avg_loss=1.3176, train_err=0.0659, 32_h1=0.0707, 32_l2=0.0353, 64_h1=0.1458, 64_l2=0.0493\n",
      "[83] time=2.36, avg_loss=1.2985, train_err=0.0649, 32_h1=0.0730, 32_l2=0.0382, 64_h1=0.1532, 64_l2=0.0564\n",
      "[84] time=2.36, avg_loss=1.3191, train_err=0.0660, 32_h1=0.0718, 32_l2=0.0374, 64_h1=0.1543, 64_l2=0.0550\n",
      "[85] time=2.34, avg_loss=1.3546, train_err=0.0677, 32_h1=0.0728, 32_l2=0.0410, 64_h1=0.1597, 64_l2=0.0608\n",
      "[86] time=2.39, avg_loss=1.3324, train_err=0.0666, 32_h1=0.0724, 32_l2=0.0369, 64_h1=0.1479, 64_l2=0.0486\n",
      "[87] time=2.38, avg_loss=1.3206, train_err=0.0660, 32_h1=0.0715, 32_l2=0.0368, 64_h1=0.1534, 64_l2=0.0524\n",
      "[88] time=2.39, avg_loss=1.3321, train_err=0.0666, 32_h1=0.0714, 32_l2=0.0356, 64_h1=0.1513, 64_l2=0.0525\n",
      "[89] time=2.37, avg_loss=1.3143, train_err=0.0657, 32_h1=0.0711, 32_l2=0.0364, 64_h1=0.1540, 64_l2=0.0537\n",
      "[90] time=2.37, avg_loss=1.3160, train_err=0.0658, 32_h1=0.0713, 32_l2=0.0357, 64_h1=0.1510, 64_l2=0.0476\n",
      "[91] time=2.34, avg_loss=1.3126, train_err=0.0656, 32_h1=0.0740, 32_l2=0.0398, 64_h1=0.1534, 64_l2=0.0570\n",
      "[92] time=2.36, avg_loss=1.2774, train_err=0.0639, 32_h1=0.0696, 32_l2=0.0339, 64_h1=0.1533, 64_l2=0.0524\n",
      "[93] time=2.31, avg_loss=1.3288, train_err=0.0664, 32_h1=0.0716, 32_l2=0.0360, 64_h1=0.1507, 64_l2=0.0512\n",
      "[94] time=2.32, avg_loss=1.2871, train_err=0.0644, 32_h1=0.0763, 32_l2=0.0443, 64_h1=0.1583, 64_l2=0.0590\n",
      "[95] time=2.37, avg_loss=1.2848, train_err=0.0642, 32_h1=0.0697, 32_l2=0.0338, 64_h1=0.1534, 64_l2=0.0493\n",
      "[96] time=2.08, avg_loss=1.3031, train_err=0.0652, 32_h1=0.0733, 32_l2=0.0389, 64_h1=0.1544, 64_l2=0.0546\n",
      "[97] time=2.06, avg_loss=1.3344, train_err=0.0667, 32_h1=0.0685, 32_l2=0.0319, 64_h1=0.1522, 64_l2=0.0498\n",
      "[98] time=2.03, avg_loss=1.2531, train_err=0.0627, 32_h1=0.0710, 32_l2=0.0359, 64_h1=0.1505, 64_l2=0.0475\n",
      "[99] time=2.04, avg_loss=1.2640, train_err=0.0632, 32_h1=0.0711, 32_l2=0.0339, 64_h1=0.1546, 64_l2=0.0546\n",
      "[100] time=2.19, avg_loss=1.2648, train_err=0.0632, 32_h1=0.0719, 32_l2=0.0376, 64_h1=0.1540, 64_l2=0.0531\n",
      "[101] time=2.22, avg_loss=1.2292, train_err=0.0615, 32_h1=0.0691, 32_l2=0.0329, 64_h1=0.1501, 64_l2=0.0480\n",
      "[102] time=2.21, avg_loss=1.2592, train_err=0.0630, 32_h1=0.0712, 32_l2=0.0352, 64_h1=0.1550, 64_l2=0.0538\n",
      "[103] time=2.23, avg_loss=1.2454, train_err=0.0623, 32_h1=0.0707, 32_l2=0.0339, 64_h1=0.1558, 64_l2=0.0507\n",
      "[104] time=2.24, avg_loss=1.2544, train_err=0.0627, 32_h1=0.0700, 32_l2=0.0336, 64_h1=0.1574, 64_l2=0.0519\n",
      "[105] time=2.24, avg_loss=1.2378, train_err=0.0619, 32_h1=0.0729, 32_l2=0.0379, 64_h1=0.1523, 64_l2=0.0558\n",
      "[106] time=2.24, avg_loss=1.2908, train_err=0.0645, 32_h1=0.0772, 32_l2=0.0445, 64_h1=0.1598, 64_l2=0.0612\n",
      "[107] time=2.16, avg_loss=1.2544, train_err=0.0627, 32_h1=0.0718, 32_l2=0.0377, 64_h1=0.1575, 64_l2=0.0576\n",
      "[108] time=2.08, avg_loss=1.2475, train_err=0.0624, 32_h1=0.0699, 32_l2=0.0325, 64_h1=0.1587, 64_l2=0.0512\n",
      "[109] time=2.11, avg_loss=1.2282, train_err=0.0614, 32_h1=0.0806, 32_l2=0.0522, 64_h1=0.1662, 64_l2=0.0657\n",
      "[110] time=2.09, avg_loss=1.2326, train_err=0.0616, 32_h1=0.0717, 32_l2=0.0365, 64_h1=0.1563, 64_l2=0.0538\n",
      "[111] time=2.16, avg_loss=1.2287, train_err=0.0614, 32_h1=0.0705, 32_l2=0.0346, 64_h1=0.1518, 64_l2=0.0496\n",
      "[112] time=2.18, avg_loss=1.2149, train_err=0.0607, 32_h1=0.0710, 32_l2=0.0340, 64_h1=0.1610, 64_l2=0.0520\n",
      "[113] time=2.16, avg_loss=1.2102, train_err=0.0605, 32_h1=0.0702, 32_l2=0.0338, 64_h1=0.1577, 64_l2=0.0535\n",
      "[114] time=2.17, avg_loss=1.2373, train_err=0.0619, 32_h1=0.0710, 32_l2=0.0357, 64_h1=0.1517, 64_l2=0.0490\n",
      "[115] time=2.23, avg_loss=1.1899, train_err=0.0595, 32_h1=0.0709, 32_l2=0.0356, 64_h1=0.1595, 64_l2=0.0535\n",
      "[116] time=2.16, avg_loss=1.2012, train_err=0.0601, 32_h1=0.0712, 32_l2=0.0340, 64_h1=0.1550, 64_l2=0.0513\n",
      "[117] time=2.21, avg_loss=1.1870, train_err=0.0594, 32_h1=0.0707, 32_l2=0.0334, 64_h1=0.1578, 64_l2=0.0530\n",
      "[118] time=2.20, avg_loss=1.1865, train_err=0.0593, 32_h1=0.0707, 32_l2=0.0334, 64_h1=0.1602, 64_l2=0.0530\n",
      "[119] time=2.20, avg_loss=1.1878, train_err=0.0594, 32_h1=0.0732, 32_l2=0.0377, 64_h1=0.1517, 64_l2=0.0520\n",
      "[120] time=2.06, avg_loss=1.2174, train_err=0.0609, 32_h1=0.0710, 32_l2=0.0350, 64_h1=0.1533, 64_l2=0.0512\n",
      "[121] time=2.04, avg_loss=1.1686, train_err=0.0584, 32_h1=0.0705, 32_l2=0.0351, 64_h1=0.1571, 64_l2=0.0527\n",
      "[122] time=2.05, avg_loss=1.1926, train_err=0.0596, 32_h1=0.0745, 32_l2=0.0415, 64_h1=0.1603, 64_l2=0.0564\n",
      "[123] time=2.03, avg_loss=1.1696, train_err=0.0585, 32_h1=0.0757, 32_l2=0.0417, 64_h1=0.1623, 64_l2=0.0595\n",
      "[124] time=2.22, avg_loss=1.1732, train_err=0.0587, 32_h1=0.0730, 32_l2=0.0368, 64_h1=0.1555, 64_l2=0.0544\n",
      "[125] time=2.40, avg_loss=1.1665, train_err=0.0583, 32_h1=0.0721, 32_l2=0.0362, 64_h1=0.1605, 64_l2=0.0577\n",
      "[126] time=2.29, avg_loss=1.1596, train_err=0.0580, 32_h1=0.0716, 32_l2=0.0362, 64_h1=0.1590, 64_l2=0.0571\n",
      "[127] time=2.32, avg_loss=1.1555, train_err=0.0578, 32_h1=0.0718, 32_l2=0.0333, 64_h1=0.1641, 64_l2=0.0536\n",
      "[128] time=2.36, avg_loss=1.1381, train_err=0.0569, 32_h1=0.0729, 32_l2=0.0366, 64_h1=0.1571, 64_l2=0.0552\n",
      "[129] time=2.37, avg_loss=1.1377, train_err=0.0569, 32_h1=0.0756, 32_l2=0.0415, 64_h1=0.1559, 64_l2=0.0553\n",
      "[130] time=2.37, avg_loss=1.1648, train_err=0.0582, 32_h1=0.0729, 32_l2=0.0361, 64_h1=0.1588, 64_l2=0.0535\n",
      "[131] time=2.35, avg_loss=1.1407, train_err=0.0570, 32_h1=0.0723, 32_l2=0.0339, 64_h1=0.1583, 64_l2=0.0528\n",
      "[132] time=2.35, avg_loss=1.1259, train_err=0.0563, 32_h1=0.0717, 32_l2=0.0345, 64_h1=0.1590, 64_l2=0.0531\n",
      "[133] time=2.37, avg_loss=1.1176, train_err=0.0559, 32_h1=0.0712, 32_l2=0.0337, 64_h1=0.1574, 64_l2=0.0483\n",
      "[134] time=2.32, avg_loss=1.1197, train_err=0.0560, 32_h1=0.0715, 32_l2=0.0336, 64_h1=0.1568, 64_l2=0.0509\n",
      "[135] time=2.32, avg_loss=1.1162, train_err=0.0558, 32_h1=0.0720, 32_l2=0.0338, 64_h1=0.1638, 64_l2=0.0552\n",
      "[136] time=2.37, avg_loss=1.1131, train_err=0.0557, 32_h1=0.0725, 32_l2=0.0339, 64_h1=0.1614, 64_l2=0.0554\n",
      "[137] time=2.34, avg_loss=1.0963, train_err=0.0548, 32_h1=0.0715, 32_l2=0.0339, 64_h1=0.1587, 64_l2=0.0529\n",
      "[138] time=2.33, avg_loss=1.1028, train_err=0.0551, 32_h1=0.0725, 32_l2=0.0344, 64_h1=0.1641, 64_l2=0.0557\n",
      "[139] time=2.36, avg_loss=1.1130, train_err=0.0556, 32_h1=0.0777, 32_l2=0.0419, 64_h1=0.1562, 64_l2=0.0570\n",
      "[140] time=2.32, avg_loss=1.1081, train_err=0.0554, 32_h1=0.0751, 32_l2=0.0394, 64_h1=0.1586, 64_l2=0.0573\n",
      "[141] time=2.33, avg_loss=1.0957, train_err=0.0548, 32_h1=0.0735, 32_l2=0.0349, 64_h1=0.1561, 64_l2=0.0528\n",
      "[142] time=2.31, avg_loss=1.0860, train_err=0.0543, 32_h1=0.0735, 32_l2=0.0352, 64_h1=0.1580, 64_l2=0.0494\n",
      "[143] time=2.34, avg_loss=1.0919, train_err=0.0546, 32_h1=0.0744, 32_l2=0.0358, 64_h1=0.1626, 64_l2=0.0526\n",
      "[144] time=2.32, avg_loss=1.0809, train_err=0.0540, 32_h1=0.0725, 32_l2=0.0338, 64_h1=0.1594, 64_l2=0.0533\n",
      "[145] time=2.35, avg_loss=1.0703, train_err=0.0535, 32_h1=0.0724, 32_l2=0.0342, 64_h1=0.1601, 64_l2=0.0529\n",
      "[146] time=2.33, avg_loss=1.0767, train_err=0.0538, 32_h1=0.0727, 32_l2=0.0342, 64_h1=0.1601, 64_l2=0.0526\n",
      "[147] time=2.32, avg_loss=1.0741, train_err=0.0537, 32_h1=0.0728, 32_l2=0.0342, 64_h1=0.1623, 64_l2=0.0532\n",
      "[148] time=2.44, avg_loss=1.0636, train_err=0.0532, 32_h1=0.0729, 32_l2=0.0343, 64_h1=0.1637, 64_l2=0.0532\n",
      "[149] time=2.37, avg_loss=1.0675, train_err=0.0534, 32_h1=0.0727, 32_l2=0.0341, 64_h1=0.1606, 64_l2=0.0544\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=18\n",
      "tfno2d.n_modes_width=18\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.2\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 291073\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 9, 9), rank=(21, 21, 6, 6))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 9, 9), rank=(21, 21, 6, 6))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 9, 9), rank=(21, 21, 6, 6))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 9, 9), rank=(21, 21, 6, 6))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 9, 9), rank=(21, 21, 6, 6))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 9, 9), rank=(21, 21, 6, 6))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 9, 9), rank=(21, 21, 6, 6))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 9, 9), rank=(21, 21, 6, 6))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f7761b3c4c0>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f7761b6d610>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f7761b6d610>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f7761b6d6a0>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.31, avg_loss=10.1890, train_err=0.5095, 32_h1=0.3073, 32_l2=0.2178, 64_h1=0.3511, 64_l2=0.2200\n",
      "[1] time=2.35, avg_loss=4.7665, train_err=0.2383, 32_h1=0.2021, 32_l2=0.1368, 64_h1=0.2589, 64_l2=0.1479\n",
      "[2] time=2.35, avg_loss=3.7739, train_err=0.1887, 32_h1=0.1796, 32_l2=0.1269, 64_h1=0.2535, 64_l2=0.1407\n",
      "[3] time=2.41, avg_loss=3.2009, train_err=0.1600, 32_h1=0.1435, 32_l2=0.0940, 64_h1=0.2031, 64_l2=0.1013\n",
      "[4] time=2.36, avg_loss=2.9110, train_err=0.1456, 32_h1=0.1423, 32_l2=0.0972, 64_h1=0.2139, 64_l2=0.1128\n",
      "[5] time=2.35, avg_loss=2.5099, train_err=0.1255, 32_h1=0.1261, 32_l2=0.0762, 64_h1=0.1952, 64_l2=0.0936\n",
      "[6] time=2.34, avg_loss=2.3823, train_err=0.1191, 32_h1=0.1262, 32_l2=0.0931, 64_h1=0.1834, 64_l2=0.0958\n",
      "[7] time=2.34, avg_loss=2.2234, train_err=0.1112, 32_h1=0.1093, 32_l2=0.0667, 64_h1=0.1807, 64_l2=0.0767\n",
      "[8] time=2.32, avg_loss=2.0450, train_err=0.1023, 32_h1=0.1356, 32_l2=0.0989, 64_h1=0.1833, 64_l2=0.1000\n",
      "[9] time=2.39, avg_loss=2.0907, train_err=0.1045, 32_h1=0.0995, 32_l2=0.0601, 64_h1=0.1703, 64_l2=0.0760\n",
      "[10] time=2.43, avg_loss=1.9370, train_err=0.0968, 32_h1=0.0918, 32_l2=0.0517, 64_h1=0.1721, 64_l2=0.0719\n",
      "[11] time=2.41, avg_loss=1.9101, train_err=0.0955, 32_h1=0.1054, 32_l2=0.0693, 64_h1=0.1908, 64_l2=0.0863\n",
      "[12] time=2.36, avg_loss=1.8711, train_err=0.0936, 32_h1=0.0904, 32_l2=0.0524, 64_h1=0.1683, 64_l2=0.0670\n",
      "[13] time=2.38, avg_loss=1.7663, train_err=0.0883, 32_h1=0.1117, 32_l2=0.0761, 64_h1=0.1829, 64_l2=0.0875\n",
      "[14] time=2.18, avg_loss=1.8731, train_err=0.0937, 32_h1=0.0931, 32_l2=0.0526, 64_h1=0.1684, 64_l2=0.0617\n",
      "[15] time=2.08, avg_loss=1.7636, train_err=0.0882, 32_h1=0.1063, 32_l2=0.0734, 64_h1=0.1647, 64_l2=0.0826\n",
      "[16] time=2.10, avg_loss=1.6896, train_err=0.0845, 32_h1=0.0876, 32_l2=0.0506, 64_h1=0.1621, 64_l2=0.0675\n",
      "[17] time=2.04, avg_loss=1.7532, train_err=0.0877, 32_h1=0.0832, 32_l2=0.0463, 64_h1=0.1614, 64_l2=0.0604\n",
      "[18] time=2.15, avg_loss=1.6558, train_err=0.0828, 32_h1=0.0877, 32_l2=0.0549, 64_h1=0.1591, 64_l2=0.0648\n",
      "[19] time=2.08, avg_loss=1.7277, train_err=0.0864, 32_h1=0.0853, 32_l2=0.0501, 64_h1=0.1683, 64_l2=0.0669\n",
      "[20] time=2.23, avg_loss=1.6434, train_err=0.0822, 32_h1=0.0933, 32_l2=0.0590, 64_h1=0.1722, 64_l2=0.0713\n",
      "[21] time=2.23, avg_loss=1.6310, train_err=0.0816, 32_h1=0.0783, 32_l2=0.0407, 64_h1=0.1509, 64_l2=0.0526\n",
      "[22] time=2.17, avg_loss=1.6196, train_err=0.0810, 32_h1=0.0824, 32_l2=0.0460, 64_h1=0.1594, 64_l2=0.0606\n",
      "[23] time=2.20, avg_loss=1.5864, train_err=0.0793, 32_h1=0.0829, 32_l2=0.0492, 64_h1=0.1546, 64_l2=0.0548\n",
      "[24] time=2.21, avg_loss=1.6364, train_err=0.0818, 32_h1=0.0798, 32_l2=0.0436, 64_h1=0.1566, 64_l2=0.0559\n",
      "[25] time=2.16, avg_loss=1.5652, train_err=0.0783, 32_h1=0.0825, 32_l2=0.0442, 64_h1=0.1633, 64_l2=0.0631\n",
      "[26] time=2.16, avg_loss=1.5815, train_err=0.0791, 32_h1=0.0769, 32_l2=0.0391, 64_h1=0.1554, 64_l2=0.0570\n",
      "[27] time=2.09, avg_loss=1.5270, train_err=0.0764, 32_h1=0.0777, 32_l2=0.0401, 64_h1=0.1613, 64_l2=0.0574\n",
      "[28] time=2.07, avg_loss=1.5527, train_err=0.0776, 32_h1=0.0780, 32_l2=0.0408, 64_h1=0.1579, 64_l2=0.0595\n",
      "[29] time=2.09, avg_loss=1.5528, train_err=0.0776, 32_h1=0.0792, 32_l2=0.0414, 64_h1=0.1550, 64_l2=0.0594\n",
      "[30] time=2.15, avg_loss=1.5091, train_err=0.0755, 32_h1=0.0803, 32_l2=0.0486, 64_h1=0.1578, 64_l2=0.0637\n",
      "[31] time=2.24, avg_loss=1.5251, train_err=0.0763, 32_h1=0.0751, 32_l2=0.0383, 64_h1=0.1600, 64_l2=0.0558\n",
      "[32] time=2.15, avg_loss=1.5317, train_err=0.0766, 32_h1=0.0781, 32_l2=0.0421, 64_h1=0.1565, 64_l2=0.0591\n",
      "[33] time=2.15, avg_loss=1.4880, train_err=0.0744, 32_h1=0.0768, 32_l2=0.0419, 64_h1=0.1526, 64_l2=0.0591\n",
      "[34] time=2.15, avg_loss=1.5134, train_err=0.0757, 32_h1=0.0778, 32_l2=0.0424, 64_h1=0.1622, 64_l2=0.0653\n",
      "[35] time=2.10, avg_loss=1.5449, train_err=0.0772, 32_h1=0.0886, 32_l2=0.0551, 64_h1=0.1636, 64_l2=0.0696\n",
      "[36] time=2.05, avg_loss=1.5100, train_err=0.0755, 32_h1=0.0734, 32_l2=0.0380, 64_h1=0.1497, 64_l2=0.0485\n",
      "[37] time=2.05, avg_loss=1.4698, train_err=0.0735, 32_h1=0.0767, 32_l2=0.0421, 64_h1=0.1555, 64_l2=0.0573\n",
      "[38] time=2.11, avg_loss=1.4575, train_err=0.0729, 32_h1=0.0728, 32_l2=0.0370, 64_h1=0.1513, 64_l2=0.0536\n",
      "[39] time=2.17, avg_loss=1.4219, train_err=0.0711, 32_h1=0.0850, 32_l2=0.0548, 64_h1=0.1533, 64_l2=0.0676\n",
      "[40] time=2.18, avg_loss=1.4696, train_err=0.0735, 32_h1=0.0747, 32_l2=0.0392, 64_h1=0.1512, 64_l2=0.0528\n",
      "[41] time=2.19, avg_loss=1.4937, train_err=0.0747, 32_h1=0.0754, 32_l2=0.0397, 64_h1=0.1588, 64_l2=0.0566\n",
      "[42] time=2.31, avg_loss=1.4355, train_err=0.0718, 32_h1=0.0733, 32_l2=0.0369, 64_h1=0.1522, 64_l2=0.0509\n",
      "[43] time=2.33, avg_loss=1.4506, train_err=0.0725, 32_h1=0.0751, 32_l2=0.0387, 64_h1=0.1491, 64_l2=0.0528\n",
      "[44] time=2.34, avg_loss=1.4531, train_err=0.0727, 32_h1=0.0790, 32_l2=0.0460, 64_h1=0.1522, 64_l2=0.0610\n",
      "[45] time=2.33, avg_loss=1.4612, train_err=0.0731, 32_h1=0.0762, 32_l2=0.0410, 64_h1=0.1594, 64_l2=0.0595\n",
      "[46] time=2.38, avg_loss=1.4202, train_err=0.0710, 32_h1=0.0829, 32_l2=0.0509, 64_h1=0.1575, 64_l2=0.0623\n",
      "[47] time=2.32, avg_loss=1.4488, train_err=0.0724, 32_h1=0.0767, 32_l2=0.0422, 64_h1=0.1463, 64_l2=0.0524\n",
      "[48] time=2.34, avg_loss=1.4346, train_err=0.0717, 32_h1=0.0735, 32_l2=0.0390, 64_h1=0.1556, 64_l2=0.0545\n",
      "[49] time=2.34, avg_loss=1.4263, train_err=0.0713, 32_h1=0.0807, 32_l2=0.0462, 64_h1=0.1543, 64_l2=0.0523\n",
      "[50] time=2.38, avg_loss=1.4393, train_err=0.0720, 32_h1=0.0751, 32_l2=0.0396, 64_h1=0.1590, 64_l2=0.0607\n",
      "[51] time=2.38, avg_loss=1.4344, train_err=0.0717, 32_h1=0.0767, 32_l2=0.0404, 64_h1=0.1488, 64_l2=0.0573\n",
      "[52] time=2.35, avg_loss=1.4354, train_err=0.0718, 32_h1=0.0716, 32_l2=0.0355, 64_h1=0.1517, 64_l2=0.0520\n",
      "[53] time=2.35, avg_loss=1.3880, train_err=0.0694, 32_h1=0.0723, 32_l2=0.0353, 64_h1=0.1568, 64_l2=0.0514\n",
      "[54] time=2.35, avg_loss=1.3732, train_err=0.0687, 32_h1=0.0755, 32_l2=0.0429, 64_h1=0.1494, 64_l2=0.0550\n",
      "[55] time=2.35, avg_loss=1.4342, train_err=0.0717, 32_h1=0.0697, 32_l2=0.0329, 64_h1=0.1436, 64_l2=0.0495\n",
      "[56] time=2.33, avg_loss=1.4164, train_err=0.0708, 32_h1=0.0755, 32_l2=0.0395, 64_h1=0.1468, 64_l2=0.0519\n",
      "[57] time=2.34, avg_loss=1.3960, train_err=0.0698, 32_h1=0.0716, 32_l2=0.0353, 64_h1=0.1505, 64_l2=0.0484\n",
      "[58] time=2.44, avg_loss=1.3562, train_err=0.0678, 32_h1=0.0713, 32_l2=0.0361, 64_h1=0.1483, 64_l2=0.0513\n",
      "[59] time=2.34, avg_loss=1.3676, train_err=0.0684, 32_h1=0.0776, 32_l2=0.0461, 64_h1=0.1561, 64_l2=0.0654\n",
      "[60] time=2.36, avg_loss=1.3920, train_err=0.0696, 32_h1=0.0730, 32_l2=0.0385, 64_h1=0.1502, 64_l2=0.0507\n",
      "[61] time=2.39, avg_loss=1.3636, train_err=0.0682, 32_h1=0.0690, 32_l2=0.0326, 64_h1=0.1484, 64_l2=0.0492\n",
      "[62] time=2.36, avg_loss=1.3842, train_err=0.0692, 32_h1=0.0762, 32_l2=0.0405, 64_h1=0.1607, 64_l2=0.0614\n",
      "[63] time=2.34, avg_loss=1.3951, train_err=0.0698, 32_h1=0.0845, 32_l2=0.0532, 64_h1=0.1586, 64_l2=0.0644\n",
      "[64] time=2.35, avg_loss=1.4266, train_err=0.0713, 32_h1=0.0718, 32_l2=0.0365, 64_h1=0.1532, 64_l2=0.0514\n",
      "[65] time=2.34, avg_loss=1.3501, train_err=0.0675, 32_h1=0.0698, 32_l2=0.0336, 64_h1=0.1430, 64_l2=0.0492\n",
      "[66] time=2.32, avg_loss=1.3852, train_err=0.0693, 32_h1=0.0695, 32_l2=0.0330, 64_h1=0.1514, 64_l2=0.0511\n",
      "[67] time=2.33, avg_loss=1.3472, train_err=0.0674, 32_h1=0.0709, 32_l2=0.0357, 64_h1=0.1512, 64_l2=0.0519\n",
      "[68] time=2.36, avg_loss=1.3759, train_err=0.0688, 32_h1=0.0728, 32_l2=0.0369, 64_h1=0.1545, 64_l2=0.0551\n",
      "[69] time=2.37, avg_loss=1.3356, train_err=0.0668, 32_h1=0.0740, 32_l2=0.0385, 64_h1=0.1544, 64_l2=0.0485\n",
      "[70] time=2.37, avg_loss=1.3221, train_err=0.0661, 32_h1=0.0699, 32_l2=0.0361, 64_h1=0.1514, 64_l2=0.0533\n",
      "[71] time=2.35, avg_loss=1.3413, train_err=0.0671, 32_h1=0.0751, 32_l2=0.0387, 64_h1=0.1522, 64_l2=0.0525\n",
      "[72] time=2.31, avg_loss=1.3362, train_err=0.0668, 32_h1=0.0713, 32_l2=0.0352, 64_h1=0.1509, 64_l2=0.0529\n",
      "[73] time=2.39, avg_loss=1.3257, train_err=0.0663, 32_h1=0.0716, 32_l2=0.0361, 64_h1=0.1493, 64_l2=0.0522\n",
      "[74] time=2.35, avg_loss=1.3396, train_err=0.0670, 32_h1=0.0711, 32_l2=0.0349, 64_h1=0.1573, 64_l2=0.0509\n",
      "[75] time=2.36, avg_loss=1.3179, train_err=0.0659, 32_h1=0.0710, 32_l2=0.0347, 64_h1=0.1507, 64_l2=0.0493\n",
      "[76] time=2.34, avg_loss=1.3176, train_err=0.0659, 32_h1=0.0697, 32_l2=0.0338, 64_h1=0.1551, 64_l2=0.0552\n",
      "[77] time=2.34, avg_loss=1.3406, train_err=0.0670, 32_h1=0.0711, 32_l2=0.0365, 64_h1=0.1486, 64_l2=0.0482\n",
      "[78] time=2.37, avg_loss=1.2759, train_err=0.0638, 32_h1=0.0740, 32_l2=0.0389, 64_h1=0.1521, 64_l2=0.0474\n",
      "[79] time=2.33, avg_loss=1.2982, train_err=0.0649, 32_h1=0.0715, 32_l2=0.0366, 64_h1=0.1479, 64_l2=0.0475\n",
      "[80] time=2.37, avg_loss=1.3196, train_err=0.0660, 32_h1=0.0733, 32_l2=0.0358, 64_h1=0.1612, 64_l2=0.0553\n",
      "[81] time=2.21, avg_loss=1.3012, train_err=0.0651, 32_h1=0.0755, 32_l2=0.0415, 64_h1=0.1517, 64_l2=0.0525\n",
      "[82] time=2.11, avg_loss=1.3103, train_err=0.0655, 32_h1=0.0723, 32_l2=0.0364, 64_h1=0.1523, 64_l2=0.0468\n",
      "[83] time=2.10, avg_loss=1.3170, train_err=0.0659, 32_h1=0.0729, 32_l2=0.0407, 64_h1=0.1602, 64_l2=0.0576\n",
      "[84] time=2.06, avg_loss=1.2838, train_err=0.0642, 32_h1=0.0738, 32_l2=0.0378, 64_h1=0.1544, 64_l2=0.0532\n",
      "[85] time=2.07, avg_loss=1.2885, train_err=0.0644, 32_h1=0.0690, 32_l2=0.0328, 64_h1=0.1527, 64_l2=0.0485\n",
      "[86] time=2.11, avg_loss=1.2559, train_err=0.0628, 32_h1=0.0705, 32_l2=0.0348, 64_h1=0.1472, 64_l2=0.0489\n",
      "[87] time=2.19, avg_loss=1.2560, train_err=0.0628, 32_h1=0.0722, 32_l2=0.0385, 64_h1=0.1508, 64_l2=0.0530\n",
      "[88] time=2.09, avg_loss=1.2546, train_err=0.0627, 32_h1=0.0731, 32_l2=0.0381, 64_h1=0.1575, 64_l2=0.0566\n",
      "[89] time=2.06, avg_loss=1.2752, train_err=0.0638, 32_h1=0.0718, 32_l2=0.0352, 64_h1=0.1559, 64_l2=0.0492\n",
      "[90] time=2.17, avg_loss=1.2584, train_err=0.0629, 32_h1=0.0702, 32_l2=0.0330, 64_h1=0.1481, 64_l2=0.0482\n",
      "[91] time=2.23, avg_loss=1.2633, train_err=0.0632, 32_h1=0.0722, 32_l2=0.0366, 64_h1=0.1472, 64_l2=0.0478\n",
      "[92] time=2.22, avg_loss=1.2772, train_err=0.0639, 32_h1=0.0720, 32_l2=0.0363, 64_h1=0.1476, 64_l2=0.0516\n",
      "[93] time=2.22, avg_loss=1.2461, train_err=0.0623, 32_h1=0.0724, 32_l2=0.0356, 64_h1=0.1476, 64_l2=0.0518\n",
      "[94] time=2.20, avg_loss=1.2422, train_err=0.0621, 32_h1=0.0705, 32_l2=0.0347, 64_h1=0.1490, 64_l2=0.0488\n",
      "[95] time=2.25, avg_loss=1.2582, train_err=0.0629, 32_h1=0.0722, 32_l2=0.0364, 64_h1=0.1548, 64_l2=0.0523\n",
      "[96] time=2.18, avg_loss=1.2508, train_err=0.0625, 32_h1=0.0759, 32_l2=0.0403, 64_h1=0.1564, 64_l2=0.0539\n",
      "[97] time=2.24, avg_loss=1.2354, train_err=0.0618, 32_h1=0.0763, 32_l2=0.0418, 64_h1=0.1500, 64_l2=0.0500\n",
      "[98] time=2.25, avg_loss=1.2471, train_err=0.0624, 32_h1=0.0720, 32_l2=0.0362, 64_h1=0.1570, 64_l2=0.0482\n",
      "[99] time=2.21, avg_loss=1.2313, train_err=0.0616, 32_h1=0.0711, 32_l2=0.0345, 64_h1=0.1528, 64_l2=0.0513\n",
      "[100] time=2.23, avg_loss=1.2027, train_err=0.0601, 32_h1=0.0724, 32_l2=0.0348, 64_h1=0.1511, 64_l2=0.0530\n",
      "[101] time=2.25, avg_loss=1.2243, train_err=0.0612, 32_h1=0.0719, 32_l2=0.0341, 64_h1=0.1499, 64_l2=0.0475\n",
      "[102] time=2.24, avg_loss=1.1956, train_err=0.0598, 32_h1=0.0722, 32_l2=0.0355, 64_h1=0.1494, 64_l2=0.0460\n",
      "[103] time=2.12, avg_loss=1.1823, train_err=0.0591, 32_h1=0.0725, 32_l2=0.0352, 64_h1=0.1481, 64_l2=0.0476\n",
      "[104] time=2.15, avg_loss=1.2035, train_err=0.0602, 32_h1=0.0785, 32_l2=0.0445, 64_h1=0.1509, 64_l2=0.0570\n",
      "[105] time=2.21, avg_loss=1.2179, train_err=0.0609, 32_h1=0.0722, 32_l2=0.0354, 64_h1=0.1476, 64_l2=0.0460\n",
      "[106] time=2.19, avg_loss=1.1738, train_err=0.0587, 32_h1=0.0737, 32_l2=0.0367, 64_h1=0.1471, 64_l2=0.0485\n",
      "[107] time=2.22, avg_loss=1.1750, train_err=0.0587, 32_h1=0.0712, 32_l2=0.0333, 64_h1=0.1565, 64_l2=0.0517\n",
      "[108] time=2.11, avg_loss=1.1596, train_err=0.0580, 32_h1=0.0729, 32_l2=0.0350, 64_h1=0.1479, 64_l2=0.0469\n",
      "[109] time=2.16, avg_loss=1.1652, train_err=0.0583, 32_h1=0.0729, 32_l2=0.0354, 64_h1=0.1529, 64_l2=0.0522\n",
      "[110] time=2.38, avg_loss=1.1841, train_err=0.0592, 32_h1=0.0794, 32_l2=0.0427, 64_h1=0.1666, 64_l2=0.0594\n",
      "[111] time=2.35, avg_loss=1.1579, train_err=0.0579, 32_h1=0.0717, 32_l2=0.0336, 64_h1=0.1569, 64_l2=0.0501\n",
      "[112] time=2.35, avg_loss=1.1536, train_err=0.0577, 32_h1=0.0721, 32_l2=0.0348, 64_h1=0.1562, 64_l2=0.0522\n",
      "[113] time=2.35, avg_loss=1.1353, train_err=0.0568, 32_h1=0.0756, 32_l2=0.0382, 64_h1=0.1558, 64_l2=0.0543\n",
      "[114] time=2.33, avg_loss=1.1479, train_err=0.0574, 32_h1=0.0726, 32_l2=0.0346, 64_h1=0.1525, 64_l2=0.0499\n",
      "[115] time=2.32, avg_loss=1.1465, train_err=0.0573, 32_h1=0.0732, 32_l2=0.0356, 64_h1=0.1524, 64_l2=0.0504\n",
      "[116] time=2.36, avg_loss=1.1292, train_err=0.0565, 32_h1=0.0739, 32_l2=0.0370, 64_h1=0.1522, 64_l2=0.0493\n",
      "[117] time=2.37, avg_loss=1.1470, train_err=0.0573, 32_h1=0.0731, 32_l2=0.0356, 64_h1=0.1533, 64_l2=0.0517\n",
      "[118] time=2.33, avg_loss=1.1148, train_err=0.0557, 32_h1=0.0732, 32_l2=0.0343, 64_h1=0.1521, 64_l2=0.0482\n",
      "[119] time=2.37, avg_loss=1.1202, train_err=0.0560, 32_h1=0.0741, 32_l2=0.0357, 64_h1=0.1575, 64_l2=0.0542\n",
      "[120] time=2.39, avg_loss=1.1446, train_err=0.0572, 32_h1=0.0745, 32_l2=0.0382, 64_h1=0.1512, 64_l2=0.0540\n",
      "[121] time=2.39, avg_loss=1.0883, train_err=0.0544, 32_h1=0.0755, 32_l2=0.0364, 64_h1=0.1593, 64_l2=0.0535\n",
      "[122] time=2.39, avg_loss=1.0893, train_err=0.0545, 32_h1=0.0742, 32_l2=0.0360, 64_h1=0.1464, 64_l2=0.0457\n",
      "[123] time=2.37, avg_loss=1.1116, train_err=0.0556, 32_h1=0.0741, 32_l2=0.0356, 64_h1=0.1536, 64_l2=0.0506\n",
      "[124] time=2.36, avg_loss=1.0990, train_err=0.0549, 32_h1=0.0803, 32_l2=0.0440, 64_h1=0.1566, 64_l2=0.0564\n",
      "[125] time=2.36, avg_loss=1.1145, train_err=0.0557, 32_h1=0.0725, 32_l2=0.0334, 64_h1=0.1562, 64_l2=0.0486\n",
      "[126] time=2.33, avg_loss=1.0801, train_err=0.0540, 32_h1=0.0754, 32_l2=0.0370, 64_h1=0.1497, 64_l2=0.0514\n",
      "[127] time=2.34, avg_loss=1.0814, train_err=0.0541, 32_h1=0.0729, 32_l2=0.0339, 64_h1=0.1520, 64_l2=0.0488\n",
      "[128] time=2.38, avg_loss=1.0693, train_err=0.0535, 32_h1=0.0739, 32_l2=0.0349, 64_h1=0.1519, 64_l2=0.0510\n",
      "[129] time=2.44, avg_loss=1.0499, train_err=0.0525, 32_h1=0.0734, 32_l2=0.0348, 64_h1=0.1532, 64_l2=0.0473\n",
      "[130] time=2.36, avg_loss=1.0256, train_err=0.0513, 32_h1=0.0750, 32_l2=0.0353, 64_h1=0.1583, 64_l2=0.0543\n",
      "[131] time=2.35, avg_loss=1.0293, train_err=0.0515, 32_h1=0.0741, 32_l2=0.0348, 64_h1=0.1544, 64_l2=0.0515\n",
      "[132] time=2.36, avg_loss=1.0299, train_err=0.0515, 32_h1=0.0749, 32_l2=0.0355, 64_h1=0.1621, 64_l2=0.0550\n",
      "[133] time=2.38, avg_loss=1.0399, train_err=0.0520, 32_h1=0.0742, 32_l2=0.0354, 64_h1=0.1560, 64_l2=0.0495\n",
      "[134] time=2.42, avg_loss=1.0240, train_err=0.0512, 32_h1=0.0762, 32_l2=0.0385, 64_h1=0.1557, 64_l2=0.0531\n",
      "[135] time=2.36, avg_loss=1.0287, train_err=0.0514, 32_h1=0.0747, 32_l2=0.0356, 64_h1=0.1520, 64_l2=0.0505\n",
      "[136] time=2.37, avg_loss=1.0082, train_err=0.0504, 32_h1=0.0745, 32_l2=0.0363, 64_h1=0.1531, 64_l2=0.0524\n",
      "[137] time=2.30, avg_loss=1.0320, train_err=0.0516, 32_h1=0.0778, 32_l2=0.0416, 64_h1=0.1565, 64_l2=0.0538\n",
      "[138] time=2.32, avg_loss=1.0104, train_err=0.0505, 32_h1=0.0750, 32_l2=0.0350, 64_h1=0.1536, 64_l2=0.0509\n",
      "[139] time=2.29, avg_loss=1.0094, train_err=0.0505, 32_h1=0.0745, 32_l2=0.0346, 64_h1=0.1538, 64_l2=0.0506\n",
      "[140] time=2.38, avg_loss=1.0104, train_err=0.0505, 32_h1=0.0761, 32_l2=0.0366, 64_h1=0.1564, 64_l2=0.0513\n",
      "[141] time=2.29, avg_loss=1.0549, train_err=0.0527, 32_h1=0.0755, 32_l2=0.0358, 64_h1=0.1540, 64_l2=0.0487\n",
      "[142] time=2.32, avg_loss=1.0070, train_err=0.0503, 32_h1=0.0746, 32_l2=0.0348, 64_h1=0.1557, 64_l2=0.0506\n",
      "[143] time=2.37, avg_loss=0.9758, train_err=0.0488, 32_h1=0.0762, 32_l2=0.0380, 64_h1=0.1581, 64_l2=0.0524\n",
      "[144] time=2.40, avg_loss=1.0139, train_err=0.0507, 32_h1=0.0752, 32_l2=0.0352, 64_h1=0.1527, 64_l2=0.0475\n",
      "[145] time=2.35, avg_loss=1.0024, train_err=0.0501, 32_h1=0.0796, 32_l2=0.0401, 64_h1=0.1580, 64_l2=0.0506\n",
      "[146] time=2.34, avg_loss=0.9732, train_err=0.0487, 32_h1=0.0754, 32_l2=0.0348, 64_h1=0.1592, 64_l2=0.0510\n",
      "[147] time=2.41, avg_loss=0.9529, train_err=0.0476, 32_h1=0.0753, 32_l2=0.0355, 64_h1=0.1577, 64_l2=0.0503\n",
      "[148] time=2.32, avg_loss=0.9547, train_err=0.0477, 32_h1=0.0757, 32_l2=0.0352, 64_h1=0.1544, 64_l2=0.0493\n",
      "[149] time=2.09, avg_loss=0.9603, train_err=0.0480, 32_h1=0.0769, 32_l2=0.0386, 64_h1=0.1594, 64_l2=0.0527\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=20\n",
      "tfno2d.n_modes_width=20\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.2\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 383313\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 10, 10), rank=(21, 21, 7, 7))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 10, 10), rank=(21, 21, 7, 7))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 10, 10), rank=(21, 21, 7, 7))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 10, 10), rank=(21, 21, 7, 7))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 10, 10), rank=(21, 21, 7, 7))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 10, 10), rank=(21, 21, 7, 7))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 10, 10), rank=(21, 21, 7, 7))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 10, 10), rank=(21, 21, 7, 7))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f787f0a9f10>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f7761b3c4c0>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f7761b3c4c0>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f787f0a93a0>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.08, avg_loss=9.9327, train_err=0.4966, 32_h1=0.3134, 32_l2=0.2166, 64_h1=0.3715, 64_l2=0.2227\n",
      "[1] time=2.17, avg_loss=5.0601, train_err=0.2530, 32_h1=0.2547, 32_l2=0.1852, 64_h1=0.3210, 64_l2=0.2024\n",
      "[2] time=2.35, avg_loss=3.8746, train_err=0.1937, 32_h1=0.1740, 32_l2=0.1169, 64_h1=0.2264, 64_l2=0.1229\n",
      "[3] time=2.24, avg_loss=3.4641, train_err=0.1732, 32_h1=0.1739, 32_l2=0.1321, 64_h1=0.2327, 64_l2=0.1371\n",
      "[4] time=2.07, avg_loss=2.9022, train_err=0.1451, 32_h1=0.1508, 32_l2=0.1096, 64_h1=0.2202, 64_l2=0.1249\n",
      "[5] time=2.11, avg_loss=2.7907, train_err=0.1395, 32_h1=0.1427, 32_l2=0.1023, 64_h1=0.1930, 64_l2=0.1041\n",
      "[6] time=2.05, avg_loss=2.5586, train_err=0.1279, 32_h1=0.1209, 32_l2=0.0816, 64_h1=0.1999, 64_l2=0.0925\n",
      "[7] time=2.06, avg_loss=2.4935, train_err=0.1247, 32_h1=0.1196, 32_l2=0.0801, 64_h1=0.1829, 64_l2=0.0842\n",
      "[8] time=2.15, avg_loss=2.2926, train_err=0.1146, 32_h1=0.1158, 32_l2=0.0848, 64_h1=0.1875, 64_l2=0.0953\n",
      "[9] time=2.21, avg_loss=2.1620, train_err=0.1081, 32_h1=0.1053, 32_l2=0.0697, 64_h1=0.1760, 64_l2=0.0783\n",
      "[10] time=2.20, avg_loss=2.1085, train_err=0.1054, 32_h1=0.1138, 32_l2=0.0849, 64_h1=0.1882, 64_l2=0.0946\n",
      "[11] time=2.21, avg_loss=2.0896, train_err=0.1045, 32_h1=0.1075, 32_l2=0.0685, 64_h1=0.1917, 64_l2=0.0833\n",
      "[12] time=2.23, avg_loss=1.9803, train_err=0.0990, 32_h1=0.0965, 32_l2=0.0563, 64_h1=0.1656, 64_l2=0.0655\n",
      "[13] time=2.09, avg_loss=1.8532, train_err=0.0927, 32_h1=0.0946, 32_l2=0.0566, 64_h1=0.1741, 64_l2=0.0720\n",
      "[14] time=2.16, avg_loss=1.8206, train_err=0.0910, 32_h1=0.0893, 32_l2=0.0507, 64_h1=0.1564, 64_l2=0.0584\n",
      "[15] time=2.13, avg_loss=1.8393, train_err=0.0920, 32_h1=0.0875, 32_l2=0.0487, 64_h1=0.1674, 64_l2=0.0629\n",
      "[16] time=2.08, avg_loss=1.8231, train_err=0.0912, 32_h1=0.0905, 32_l2=0.0509, 64_h1=0.1599, 64_l2=0.0590\n",
      "[17] time=2.14, avg_loss=1.8371, train_err=0.0919, 32_h1=0.0893, 32_l2=0.0513, 64_h1=0.1693, 64_l2=0.0706\n",
      "[18] time=2.19, avg_loss=1.7581, train_err=0.0879, 32_h1=0.0890, 32_l2=0.0519, 64_h1=0.1711, 64_l2=0.0691\n",
      "[19] time=2.29, avg_loss=1.7100, train_err=0.0855, 32_h1=0.0950, 32_l2=0.0613, 64_h1=0.1701, 64_l2=0.0704\n",
      "[20] time=2.23, avg_loss=1.6992, train_err=0.0850, 32_h1=0.0852, 32_l2=0.0503, 64_h1=0.1600, 64_l2=0.0637\n",
      "[21] time=2.22, avg_loss=1.6629, train_err=0.0831, 32_h1=0.0874, 32_l2=0.0525, 64_h1=0.1666, 64_l2=0.0659\n",
      "[22] time=2.24, avg_loss=1.7542, train_err=0.0877, 32_h1=0.0898, 32_l2=0.0558, 64_h1=0.1618, 64_l2=0.0656\n",
      "[23] time=2.16, avg_loss=1.6995, train_err=0.0850, 32_h1=0.0860, 32_l2=0.0516, 64_h1=0.1552, 64_l2=0.0654\n",
      "[24] time=2.21, avg_loss=1.5646, train_err=0.0782, 32_h1=0.0773, 32_l2=0.0392, 64_h1=0.1579, 64_l2=0.0585\n",
      "[25] time=2.24, avg_loss=1.7534, train_err=0.0877, 32_h1=0.0838, 32_l2=0.0482, 64_h1=0.1567, 64_l2=0.0617\n",
      "[26] time=2.18, avg_loss=1.6174, train_err=0.0809, 32_h1=0.0790, 32_l2=0.0427, 64_h1=0.1537, 64_l2=0.0555\n",
      "[27] time=2.46, avg_loss=1.5637, train_err=0.0782, 32_h1=0.0801, 32_l2=0.0468, 64_h1=0.1564, 64_l2=0.0651\n",
      "[28] time=2.33, avg_loss=1.5356, train_err=0.0768, 32_h1=0.0789, 32_l2=0.0426, 64_h1=0.1523, 64_l2=0.0574\n",
      "[29] time=2.33, avg_loss=1.5176, train_err=0.0759, 32_h1=0.0885, 32_l2=0.0584, 64_h1=0.1552, 64_l2=0.0670\n",
      "[30] time=2.37, avg_loss=1.5622, train_err=0.0781, 32_h1=0.0803, 32_l2=0.0468, 64_h1=0.1467, 64_l2=0.0588\n",
      "[31] time=2.35, avg_loss=1.5577, train_err=0.0779, 32_h1=0.0761, 32_l2=0.0399, 64_h1=0.1487, 64_l2=0.0510\n",
      "[32] time=2.36, avg_loss=1.4943, train_err=0.0747, 32_h1=0.0862, 32_l2=0.0578, 64_h1=0.1471, 64_l2=0.0543\n",
      "[33] time=2.34, avg_loss=1.5543, train_err=0.0777, 32_h1=0.0776, 32_l2=0.0438, 64_h1=0.1529, 64_l2=0.0566\n",
      "[34] time=2.36, avg_loss=1.4796, train_err=0.0740, 32_h1=0.0817, 32_l2=0.0468, 64_h1=0.1547, 64_l2=0.0565\n",
      "[35] time=2.34, avg_loss=1.6116, train_err=0.0806, 32_h1=0.0775, 32_l2=0.0417, 64_h1=0.1584, 64_l2=0.0594\n",
      "[36] time=2.33, avg_loss=1.4680, train_err=0.0734, 32_h1=0.0760, 32_l2=0.0414, 64_h1=0.1581, 64_l2=0.0600\n",
      "[37] time=2.32, avg_loss=1.5139, train_err=0.0757, 32_h1=0.0771, 32_l2=0.0427, 64_h1=0.1570, 64_l2=0.0624\n",
      "[38] time=2.35, avg_loss=1.4712, train_err=0.0736, 32_h1=0.0743, 32_l2=0.0396, 64_h1=0.1579, 64_l2=0.0547\n",
      "[39] time=2.35, avg_loss=1.4673, train_err=0.0734, 32_h1=0.0737, 32_l2=0.0383, 64_h1=0.1469, 64_l2=0.0521\n",
      "[40] time=2.32, avg_loss=1.4774, train_err=0.0739, 32_h1=0.0756, 32_l2=0.0409, 64_h1=0.1567, 64_l2=0.0566\n",
      "[41] time=2.36, avg_loss=1.4471, train_err=0.0724, 32_h1=0.0802, 32_l2=0.0442, 64_h1=0.1559, 64_l2=0.0634\n",
      "[42] time=2.35, avg_loss=1.4624, train_err=0.0731, 32_h1=0.0723, 32_l2=0.0362, 64_h1=0.1481, 64_l2=0.0528\n",
      "[43] time=2.39, avg_loss=1.4759, train_err=0.0738, 32_h1=0.0722, 32_l2=0.0361, 64_h1=0.1524, 64_l2=0.0511\n",
      "[44] time=2.33, avg_loss=1.4466, train_err=0.0723, 32_h1=0.0725, 32_l2=0.0365, 64_h1=0.1487, 64_l2=0.0538\n",
      "[45] time=2.39, avg_loss=1.4836, train_err=0.0742, 32_h1=0.0771, 32_l2=0.0418, 64_h1=0.1485, 64_l2=0.0568\n",
      "[46] time=2.37, avg_loss=1.4073, train_err=0.0704, 32_h1=0.0702, 32_l2=0.0338, 64_h1=0.1479, 64_l2=0.0488\n",
      "[47] time=2.33, avg_loss=1.4161, train_err=0.0708, 32_h1=0.0791, 32_l2=0.0462, 64_h1=0.1427, 64_l2=0.0527\n",
      "[48] time=2.32, avg_loss=1.4542, train_err=0.0727, 32_h1=0.0756, 32_l2=0.0390, 64_h1=0.1537, 64_l2=0.0532\n",
      "[49] time=2.38, avg_loss=1.4154, train_err=0.0708, 32_h1=0.0753, 32_l2=0.0388, 64_h1=0.1532, 64_l2=0.0545\n",
      "[50] time=2.40, avg_loss=1.4459, train_err=0.0723, 32_h1=0.0787, 32_l2=0.0454, 64_h1=0.1525, 64_l2=0.0589\n",
      "[51] time=2.36, avg_loss=1.4137, train_err=0.0707, 32_h1=0.0705, 32_l2=0.0347, 64_h1=0.1488, 64_l2=0.0524\n",
      "[52] time=2.33, avg_loss=1.4078, train_err=0.0704, 32_h1=0.0817, 32_l2=0.0485, 64_h1=0.1477, 64_l2=0.0522\n",
      "[53] time=2.34, avg_loss=1.4570, train_err=0.0729, 32_h1=0.1104, 32_l2=0.0832, 64_h1=0.1665, 64_l2=0.0941\n",
      "[54] time=2.37, avg_loss=1.4898, train_err=0.0745, 32_h1=0.0738, 32_l2=0.0403, 64_h1=0.1526, 64_l2=0.0551\n",
      "[55] time=2.39, avg_loss=1.3739, train_err=0.0687, 32_h1=0.0754, 32_l2=0.0433, 64_h1=0.1487, 64_l2=0.0566\n",
      "[56] time=2.36, avg_loss=1.3551, train_err=0.0678, 32_h1=0.0743, 32_l2=0.0408, 64_h1=0.1519, 64_l2=0.0551\n",
      "[57] time=2.37, avg_loss=1.3834, train_err=0.0692, 32_h1=0.0905, 32_l2=0.0585, 64_h1=0.1594, 64_l2=0.0739\n",
      "[58] time=2.32, avg_loss=1.4346, train_err=0.0717, 32_h1=0.0751, 32_l2=0.0418, 64_h1=0.1488, 64_l2=0.0529\n",
      "[59] time=2.38, avg_loss=1.3871, train_err=0.0694, 32_h1=0.0735, 32_l2=0.0408, 64_h1=0.1503, 64_l2=0.0526\n",
      "[60] time=2.37, avg_loss=1.4773, train_err=0.0739, 32_h1=0.0740, 32_l2=0.0436, 64_h1=0.1540, 64_l2=0.0596\n",
      "[61] time=2.37, avg_loss=1.3523, train_err=0.0676, 32_h1=0.0699, 32_l2=0.0343, 64_h1=0.1520, 64_l2=0.0538\n",
      "[62] time=2.31, avg_loss=1.3582, train_err=0.0679, 32_h1=0.0709, 32_l2=0.0359, 64_h1=0.1499, 64_l2=0.0521\n",
      "[63] time=2.37, avg_loss=1.3741, train_err=0.0687, 32_h1=0.0724, 32_l2=0.0363, 64_h1=0.1495, 64_l2=0.0476\n",
      "[64] time=2.36, avg_loss=1.3722, train_err=0.0686, 32_h1=0.0711, 32_l2=0.0352, 64_h1=0.1504, 64_l2=0.0512\n",
      "[65] time=2.42, avg_loss=1.4156, train_err=0.0708, 32_h1=0.0731, 32_l2=0.0401, 64_h1=0.1563, 64_l2=0.0558\n",
      "[66] time=2.26, avg_loss=1.3325, train_err=0.0666, 32_h1=0.0719, 32_l2=0.0365, 64_h1=0.1504, 64_l2=0.0546\n",
      "[67] time=2.10, avg_loss=1.3256, train_err=0.0663, 32_h1=0.0704, 32_l2=0.0349, 64_h1=0.1515, 64_l2=0.0524\n",
      "[68] time=2.08, avg_loss=1.3287, train_err=0.0664, 32_h1=0.0781, 32_l2=0.0459, 64_h1=0.1529, 64_l2=0.0569\n",
      "[69] time=2.26, avg_loss=1.3434, train_err=0.0672, 32_h1=0.0775, 32_l2=0.0415, 64_h1=0.1677, 64_l2=0.0656\n",
      "[70] time=2.14, avg_loss=1.3062, train_err=0.0653, 32_h1=0.0703, 32_l2=0.0344, 64_h1=0.1513, 64_l2=0.0502\n",
      "[71] time=2.19, avg_loss=1.3181, train_err=0.0659, 32_h1=0.0731, 32_l2=0.0366, 64_h1=0.1526, 64_l2=0.0547\n",
      "[72] time=2.10, avg_loss=1.3561, train_err=0.0678, 32_h1=0.0745, 32_l2=0.0394, 64_h1=0.1510, 64_l2=0.0495\n",
      "[73] time=2.18, avg_loss=1.3414, train_err=0.0671, 32_h1=0.0747, 32_l2=0.0399, 64_h1=0.1549, 64_l2=0.0584\n",
      "[74] time=2.11, avg_loss=1.2951, train_err=0.0648, 32_h1=0.0713, 32_l2=0.0363, 64_h1=0.1470, 64_l2=0.0524\n",
      "[75] time=2.07, avg_loss=1.3071, train_err=0.0654, 32_h1=0.0729, 32_l2=0.0419, 64_h1=0.1472, 64_l2=0.0578\n",
      "[76] time=2.06, avg_loss=1.2910, train_err=0.0645, 32_h1=0.0695, 32_l2=0.0337, 64_h1=0.1504, 64_l2=0.0536\n",
      "[77] time=2.07, avg_loss=1.2848, train_err=0.0642, 32_h1=0.0734, 32_l2=0.0386, 64_h1=0.1449, 64_l2=0.0521\n",
      "[78] time=2.11, avg_loss=1.3357, train_err=0.0668, 32_h1=0.0711, 32_l2=0.0365, 64_h1=0.1546, 64_l2=0.0558\n",
      "[79] time=2.11, avg_loss=1.2988, train_err=0.0649, 32_h1=0.0721, 32_l2=0.0364, 64_h1=0.1437, 64_l2=0.0477\n",
      "[80] time=2.13, avg_loss=1.2669, train_err=0.0633, 32_h1=0.0708, 32_l2=0.0344, 64_h1=0.1472, 64_l2=0.0535\n",
      "[81] time=2.18, avg_loss=1.3350, train_err=0.0667, 32_h1=0.0777, 32_l2=0.0438, 64_h1=0.1545, 64_l2=0.0598\n",
      "[82] time=2.07, avg_loss=1.3784, train_err=0.0689, 32_h1=0.0711, 32_l2=0.0343, 64_h1=0.1542, 64_l2=0.0556\n",
      "[83] time=2.23, avg_loss=1.2674, train_err=0.0634, 32_h1=0.0700, 32_l2=0.0336, 64_h1=0.1542, 64_l2=0.0515\n",
      "[84] time=2.21, avg_loss=1.2495, train_err=0.0625, 32_h1=0.0738, 32_l2=0.0392, 64_h1=0.1572, 64_l2=0.0528\n",
      "[85] time=2.17, avg_loss=1.2470, train_err=0.0623, 32_h1=0.0751, 32_l2=0.0405, 64_h1=0.1494, 64_l2=0.0531\n",
      "[86] time=2.29, avg_loss=1.2534, train_err=0.0627, 32_h1=0.0747, 32_l2=0.0384, 64_h1=0.1543, 64_l2=0.0538\n",
      "[87] time=2.20, avg_loss=1.2796, train_err=0.0640, 32_h1=0.0716, 32_l2=0.0360, 64_h1=0.1466, 64_l2=0.0536\n",
      "[88] time=2.21, avg_loss=1.2228, train_err=0.0611, 32_h1=0.0722, 32_l2=0.0357, 64_h1=0.1541, 64_l2=0.0576\n",
      "[89] time=2.09, avg_loss=1.2309, train_err=0.0615, 32_h1=0.0760, 32_l2=0.0435, 64_h1=0.1546, 64_l2=0.0592\n",
      "[90] time=2.11, avg_loss=1.2221, train_err=0.0611, 32_h1=0.0791, 32_l2=0.0459, 64_h1=0.1543, 64_l2=0.0603\n",
      "[91] time=2.13, avg_loss=1.2854, train_err=0.0643, 32_h1=0.0799, 32_l2=0.0448, 64_h1=0.1609, 64_l2=0.0613\n",
      "[92] time=2.18, avg_loss=1.2393, train_err=0.0620, 32_h1=0.0726, 32_l2=0.0373, 64_h1=0.1503, 64_l2=0.0527\n",
      "[93] time=2.23, avg_loss=1.1976, train_err=0.0599, 32_h1=0.0735, 32_l2=0.0376, 64_h1=0.1504, 64_l2=0.0512\n",
      "[94] time=2.34, avg_loss=1.2477, train_err=0.0624, 32_h1=0.0716, 32_l2=0.0352, 64_h1=0.1487, 64_l2=0.0514\n",
      "[95] time=2.39, avg_loss=1.2142, train_err=0.0607, 32_h1=0.0775, 32_l2=0.0450, 64_h1=0.1468, 64_l2=0.0554\n",
      "[96] time=2.36, avg_loss=1.2350, train_err=0.0618, 32_h1=0.0776, 32_l2=0.0434, 64_h1=0.1513, 64_l2=0.0594\n",
      "[97] time=2.38, avg_loss=1.1904, train_err=0.0595, 32_h1=0.0760, 32_l2=0.0419, 64_h1=0.1539, 64_l2=0.0606\n",
      "[98] time=2.39, avg_loss=1.1642, train_err=0.0582, 32_h1=0.0735, 32_l2=0.0372, 64_h1=0.1526, 64_l2=0.0539\n",
      "[99] time=2.38, avg_loss=1.2220, train_err=0.0611, 32_h1=0.0761, 32_l2=0.0426, 64_h1=0.1553, 64_l2=0.0601\n",
      "[100] time=2.35, avg_loss=1.1789, train_err=0.0589, 32_h1=0.0732, 32_l2=0.0351, 64_h1=0.1507, 64_l2=0.0529\n",
      "[101] time=2.35, avg_loss=1.2034, train_err=0.0602, 32_h1=0.0769, 32_l2=0.0407, 64_h1=0.1502, 64_l2=0.0527\n",
      "[102] time=2.40, avg_loss=1.1917, train_err=0.0596, 32_h1=0.0741, 32_l2=0.0371, 64_h1=0.1531, 64_l2=0.0562\n",
      "[103] time=2.39, avg_loss=1.1314, train_err=0.0566, 32_h1=0.0735, 32_l2=0.0362, 64_h1=0.1523, 64_l2=0.0487\n",
      "[104] time=2.46, avg_loss=1.1428, train_err=0.0571, 32_h1=0.0725, 32_l2=0.0350, 64_h1=0.1537, 64_l2=0.0524\n",
      "[105] time=2.36, avg_loss=1.1558, train_err=0.0578, 32_h1=0.0732, 32_l2=0.0351, 64_h1=0.1495, 64_l2=0.0484\n",
      "[106] time=2.33, avg_loss=1.1244, train_err=0.0562, 32_h1=0.0721, 32_l2=0.0337, 64_h1=0.1558, 64_l2=0.0541\n",
      "[107] time=2.36, avg_loss=1.1336, train_err=0.0567, 32_h1=0.0779, 32_l2=0.0411, 64_h1=0.1599, 64_l2=0.0558\n",
      "[108] time=2.36, avg_loss=1.1259, train_err=0.0563, 32_h1=0.0731, 32_l2=0.0350, 64_h1=0.1525, 64_l2=0.0534\n",
      "[109] time=2.44, avg_loss=1.1141, train_err=0.0557, 32_h1=0.0732, 32_l2=0.0345, 64_h1=0.1508, 64_l2=0.0520\n",
      "[110] time=2.33, avg_loss=1.0839, train_err=0.0542, 32_h1=0.0732, 32_l2=0.0350, 64_h1=0.1503, 64_l2=0.0508\n",
      "[111] time=2.35, avg_loss=1.1093, train_err=0.0555, 32_h1=0.0737, 32_l2=0.0353, 64_h1=0.1518, 64_l2=0.0528\n",
      "[112] time=2.36, avg_loss=1.0823, train_err=0.0541, 32_h1=0.0755, 32_l2=0.0370, 64_h1=0.1496, 64_l2=0.0500\n",
      "[113] time=2.36, avg_loss=1.1156, train_err=0.0558, 32_h1=0.0765, 32_l2=0.0389, 64_h1=0.1588, 64_l2=0.0564\n",
      "[114] time=2.38, avg_loss=1.1096, train_err=0.0555, 32_h1=0.0748, 32_l2=0.0356, 64_h1=0.1547, 64_l2=0.0530\n",
      "[115] time=2.39, avg_loss=1.0664, train_err=0.0533, 32_h1=0.0736, 32_l2=0.0345, 64_h1=0.1554, 64_l2=0.0531\n",
      "[116] time=2.38, avg_loss=1.0487, train_err=0.0524, 32_h1=0.0784, 32_l2=0.0431, 64_h1=0.1500, 64_l2=0.0566\n",
      "[117] time=2.36, avg_loss=1.0606, train_err=0.0530, 32_h1=0.0746, 32_l2=0.0367, 64_h1=0.1564, 64_l2=0.0528\n",
      "[118] time=2.36, avg_loss=1.0485, train_err=0.0524, 32_h1=0.0757, 32_l2=0.0361, 64_h1=0.1481, 64_l2=0.0510\n",
      "[119] time=2.38, avg_loss=1.0939, train_err=0.0547, 32_h1=0.0780, 32_l2=0.0400, 64_h1=0.1532, 64_l2=0.0532\n",
      "[120] time=2.36, avg_loss=1.0662, train_err=0.0533, 32_h1=0.0753, 32_l2=0.0372, 64_h1=0.1548, 64_l2=0.0565\n",
      "[121] time=2.42, avg_loss=1.0353, train_err=0.0518, 32_h1=0.0745, 32_l2=0.0354, 64_h1=0.1526, 64_l2=0.0523\n",
      "[122] time=2.33, avg_loss=1.0257, train_err=0.0513, 32_h1=0.0765, 32_l2=0.0377, 64_h1=0.1568, 64_l2=0.0550\n",
      "[123] time=2.35, avg_loss=1.0430, train_err=0.0521, 32_h1=0.0782, 32_l2=0.0407, 64_h1=0.1526, 64_l2=0.0554\n",
      "[124] time=2.36, avg_loss=1.0435, train_err=0.0522, 32_h1=0.0766, 32_l2=0.0365, 64_h1=0.1596, 64_l2=0.0561\n",
      "[125] time=2.33, avg_loss=1.0003, train_err=0.0500, 32_h1=0.0766, 32_l2=0.0383, 64_h1=0.1543, 64_l2=0.0540\n",
      "[126] time=2.38, avg_loss=0.9890, train_err=0.0495, 32_h1=0.0769, 32_l2=0.0385, 64_h1=0.1555, 64_l2=0.0555\n",
      "[127] time=2.33, avg_loss=0.9943, train_err=0.0497, 32_h1=0.0743, 32_l2=0.0344, 64_h1=0.1552, 64_l2=0.0534\n",
      "[128] time=2.39, avg_loss=0.9780, train_err=0.0489, 32_h1=0.0750, 32_l2=0.0353, 64_h1=0.1493, 64_l2=0.0514\n",
      "[129] time=2.33, avg_loss=0.9777, train_err=0.0489, 32_h1=0.0752, 32_l2=0.0354, 64_h1=0.1542, 64_l2=0.0524\n",
      "[130] time=2.34, avg_loss=0.9888, train_err=0.0494, 32_h1=0.0757, 32_l2=0.0354, 64_h1=0.1510, 64_l2=0.0511\n",
      "[131] time=2.33, avg_loss=0.9805, train_err=0.0490, 32_h1=0.0755, 32_l2=0.0351, 64_h1=0.1533, 64_l2=0.0495\n",
      "[132] time=2.39, avg_loss=0.9803, train_err=0.0490, 32_h1=0.0776, 32_l2=0.0389, 64_h1=0.1509, 64_l2=0.0520\n",
      "[133] time=2.22, avg_loss=0.9779, train_err=0.0489, 32_h1=0.0768, 32_l2=0.0371, 64_h1=0.1555, 64_l2=0.0554\n",
      "[134] time=2.11, avg_loss=0.9809, train_err=0.0490, 32_h1=0.0760, 32_l2=0.0360, 64_h1=0.1566, 64_l2=0.0555\n",
      "[135] time=2.15, avg_loss=0.9578, train_err=0.0479, 32_h1=0.0763, 32_l2=0.0359, 64_h1=0.1546, 64_l2=0.0534\n",
      "[136] time=2.24, avg_loss=0.9819, train_err=0.0491, 32_h1=0.0769, 32_l2=0.0375, 64_h1=0.1537, 64_l2=0.0558\n",
      "[137] time=2.09, avg_loss=0.9450, train_err=0.0473, 32_h1=0.0764, 32_l2=0.0365, 64_h1=0.1532, 64_l2=0.0525\n",
      "[138] time=2.10, avg_loss=0.9256, train_err=0.0463, 32_h1=0.0780, 32_l2=0.0394, 64_h1=0.1544, 64_l2=0.0540\n",
      "[139] time=2.10, avg_loss=0.9284, train_err=0.0464, 32_h1=0.0766, 32_l2=0.0367, 64_h1=0.1567, 64_l2=0.0557\n",
      "[140] time=2.08, avg_loss=0.9305, train_err=0.0465, 32_h1=0.0776, 32_l2=0.0368, 64_h1=0.1537, 64_l2=0.0524\n",
      "[141] time=2.14, avg_loss=0.9273, train_err=0.0464, 32_h1=0.0766, 32_l2=0.0363, 64_h1=0.1530, 64_l2=0.0510\n",
      "[142] time=2.09, avg_loss=0.9332, train_err=0.0467, 32_h1=0.0761, 32_l2=0.0356, 64_h1=0.1546, 64_l2=0.0538\n",
      "[143] time=2.11, avg_loss=0.9203, train_err=0.0460, 32_h1=0.0778, 32_l2=0.0374, 64_h1=0.1514, 64_l2=0.0517\n",
      "[144] time=2.21, avg_loss=0.9167, train_err=0.0458, 32_h1=0.0779, 32_l2=0.0383, 64_h1=0.1518, 64_l2=0.0495\n",
      "[145] time=2.22, avg_loss=0.9114, train_err=0.0456, 32_h1=0.0771, 32_l2=0.0362, 64_h1=0.1527, 64_l2=0.0501\n",
      "[146] time=2.07, avg_loss=0.9043, train_err=0.0452, 32_h1=0.0772, 32_l2=0.0363, 64_h1=0.1545, 64_l2=0.0508\n",
      "[147] time=2.09, avg_loss=0.9045, train_err=0.0452, 32_h1=0.0762, 32_l2=0.0354, 64_h1=0.1549, 64_l2=0.0535\n",
      "[148] time=2.14, avg_loss=0.9022, train_err=0.0451, 32_h1=0.0779, 32_l2=0.0368, 64_h1=0.1541, 64_l2=0.0512\n",
      "[149] time=2.18, avg_loss=0.8817, train_err=0.0441, 32_h1=0.0797, 32_l2=0.0413, 64_h1=0.1560, 64_l2=0.0533\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=22\n",
      "tfno2d.n_modes_width=22\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.2\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 383537\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 11, 11), rank=(21, 21, 7, 7))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 11, 11), rank=(21, 21, 7, 7))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 11, 11), rank=(21, 21, 7, 7))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 11, 11), rank=(21, 21, 7, 7))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 11, 11), rank=(21, 21, 7, 7))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 11, 11), rank=(21, 21, 7, 7))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 11, 11), rank=(21, 21, 7, 7))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 11, 11), rank=(21, 21, 7, 7))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f776fd8cd00>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f776fd8cbb0>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f776fd8cbb0>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f787f0a9f10>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.11, avg_loss=10.1823, train_err=0.5091, 32_h1=0.3600, 32_l2=0.2587, 64_h1=0.3935, 64_l2=0.2570\n",
      "[1] time=2.10, avg_loss=4.9060, train_err=0.2453, 32_h1=0.1965, 32_l2=0.1352, 64_h1=0.2648, 64_l2=0.1483\n",
      "[2] time=2.13, avg_loss=3.7397, train_err=0.1870, 32_h1=0.2007, 32_l2=0.1684, 64_h1=0.2689, 64_l2=0.1796\n",
      "[3] time=2.24, avg_loss=3.1762, train_err=0.1588, 32_h1=0.1572, 32_l2=0.1151, 64_h1=0.2344, 64_l2=0.1281\n",
      "[4] time=2.06, avg_loss=2.8093, train_err=0.1405, 32_h1=0.1413, 32_l2=0.0957, 64_h1=0.2009, 64_l2=0.1040\n",
      "[5] time=2.08, avg_loss=2.6117, train_err=0.1306, 32_h1=0.1266, 32_l2=0.0870, 64_h1=0.2010, 64_l2=0.0931\n",
      "[6] time=2.06, avg_loss=2.4252, train_err=0.1213, 32_h1=0.1164, 32_l2=0.0740, 64_h1=0.1971, 64_l2=0.0837\n",
      "[7] time=2.15, avg_loss=2.2192, train_err=0.1110, 32_h1=0.1099, 32_l2=0.0698, 64_h1=0.1970, 64_l2=0.0849\n",
      "[8] time=2.06, avg_loss=2.1575, train_err=0.1079, 32_h1=0.1271, 32_l2=0.0909, 64_h1=0.1873, 64_l2=0.0978\n",
      "[9] time=2.21, avg_loss=2.1956, train_err=0.1098, 32_h1=0.1089, 32_l2=0.0671, 64_h1=0.1771, 64_l2=0.0795\n",
      "[10] time=2.08, avg_loss=2.0619, train_err=0.1031, 32_h1=0.1079, 32_l2=0.0650, 64_h1=0.1840, 64_l2=0.0798\n",
      "[11] time=2.26, avg_loss=1.9637, train_err=0.0982, 32_h1=0.1032, 32_l2=0.0648, 64_h1=0.1717, 64_l2=0.0730\n",
      "[12] time=2.37, avg_loss=1.9010, train_err=0.0950, 32_h1=0.0915, 32_l2=0.0518, 64_h1=0.1728, 64_l2=0.0691\n",
      "[13] time=2.44, avg_loss=1.8988, train_err=0.0949, 32_h1=0.1302, 32_l2=0.0970, 64_h1=0.1912, 64_l2=0.1074\n",
      "[14] time=2.37, avg_loss=1.8579, train_err=0.0929, 32_h1=0.0888, 32_l2=0.0482, 64_h1=0.1684, 64_l2=0.0677\n",
      "[15] time=2.44, avg_loss=1.8240, train_err=0.0912, 32_h1=0.0991, 32_l2=0.0668, 64_h1=0.1729, 64_l2=0.0850\n",
      "[16] time=2.36, avg_loss=1.8065, train_err=0.0903, 32_h1=0.0929, 32_l2=0.0585, 64_h1=0.1665, 64_l2=0.0744\n",
      "[17] time=2.38, avg_loss=1.7751, train_err=0.0888, 32_h1=0.1054, 32_l2=0.0778, 64_h1=0.1688, 64_l2=0.0893\n",
      "[18] time=2.37, avg_loss=1.7289, train_err=0.0864, 32_h1=0.0842, 32_l2=0.0474, 64_h1=0.1596, 64_l2=0.0621\n",
      "[19] time=2.43, avg_loss=1.7811, train_err=0.0891, 32_h1=0.0875, 32_l2=0.0513, 64_h1=0.1720, 64_l2=0.0720\n",
      "[20] time=2.32, avg_loss=1.6883, train_err=0.0844, 32_h1=0.0905, 32_l2=0.0539, 64_h1=0.1581, 64_l2=0.0717\n",
      "[21] time=2.37, avg_loss=1.6482, train_err=0.0824, 32_h1=0.0871, 32_l2=0.0500, 64_h1=0.1678, 64_l2=0.0703\n",
      "[22] time=2.38, avg_loss=1.6016, train_err=0.0801, 32_h1=0.0915, 32_l2=0.0635, 64_h1=0.1620, 64_l2=0.0745\n",
      "[23] time=2.37, avg_loss=1.6352, train_err=0.0818, 32_h1=0.0810, 32_l2=0.0439, 64_h1=0.1512, 64_l2=0.0554\n",
      "[24] time=2.36, avg_loss=1.6878, train_err=0.0844, 32_h1=0.0856, 32_l2=0.0458, 64_h1=0.1641, 64_l2=0.0591\n",
      "[25] time=2.34, avg_loss=1.5887, train_err=0.0794, 32_h1=0.0781, 32_l2=0.0411, 64_h1=0.1596, 64_l2=0.0596\n",
      "[26] time=2.31, avg_loss=1.5753, train_err=0.0788, 32_h1=0.0965, 32_l2=0.0640, 64_h1=0.1685, 64_l2=0.0762\n",
      "[27] time=2.41, avg_loss=1.5633, train_err=0.0782, 32_h1=0.0795, 32_l2=0.0430, 64_h1=0.1655, 64_l2=0.0619\n",
      "[28] time=2.36, avg_loss=1.5398, train_err=0.0770, 32_h1=0.0777, 32_l2=0.0425, 64_h1=0.1547, 64_l2=0.0561\n",
      "[29] time=2.33, avg_loss=1.5726, train_err=0.0786, 32_h1=0.0805, 32_l2=0.0437, 64_h1=0.1621, 64_l2=0.0575\n",
      "[30] time=2.34, avg_loss=1.5450, train_err=0.0773, 32_h1=0.0805, 32_l2=0.0457, 64_h1=0.1587, 64_l2=0.0631\n",
      "[31] time=2.39, avg_loss=1.5307, train_err=0.0765, 32_h1=0.0780, 32_l2=0.0433, 64_h1=0.1595, 64_l2=0.0624\n",
      "[32] time=2.35, avg_loss=1.5687, train_err=0.0784, 32_h1=0.0845, 32_l2=0.0502, 64_h1=0.1701, 64_l2=0.0674\n",
      "[33] time=2.41, avg_loss=1.4903, train_err=0.0745, 32_h1=0.0771, 32_l2=0.0410, 64_h1=0.1548, 64_l2=0.0550\n",
      "[34] time=2.38, avg_loss=1.4932, train_err=0.0747, 32_h1=0.0773, 32_l2=0.0403, 64_h1=0.1534, 64_l2=0.0551\n",
      "[35] time=2.37, avg_loss=1.5194, train_err=0.0760, 32_h1=0.0789, 32_l2=0.0445, 64_h1=0.1611, 64_l2=0.0630\n",
      "[36] time=2.37, avg_loss=1.4779, train_err=0.0739, 32_h1=0.0762, 32_l2=0.0395, 64_h1=0.1525, 64_l2=0.0517\n",
      "[37] time=2.35, avg_loss=1.4759, train_err=0.0738, 32_h1=0.0778, 32_l2=0.0423, 64_h1=0.1558, 64_l2=0.0558\n",
      "[38] time=2.38, avg_loss=1.4728, train_err=0.0736, 32_h1=0.0784, 32_l2=0.0431, 64_h1=0.1636, 64_l2=0.0604\n",
      "[39] time=2.39, avg_loss=1.4465, train_err=0.0723, 32_h1=0.0762, 32_l2=0.0407, 64_h1=0.1527, 64_l2=0.0549\n",
      "[40] time=2.34, avg_loss=1.4566, train_err=0.0728, 32_h1=0.0792, 32_l2=0.0426, 64_h1=0.1551, 64_l2=0.0588\n",
      "[41] time=2.37, avg_loss=1.4501, train_err=0.0725, 32_h1=0.0751, 32_l2=0.0389, 64_h1=0.1598, 64_l2=0.0565\n",
      "[42] time=2.40, avg_loss=1.4345, train_err=0.0717, 32_h1=0.0753, 32_l2=0.0392, 64_h1=0.1512, 64_l2=0.0563\n",
      "[43] time=2.34, avg_loss=1.4611, train_err=0.0731, 32_h1=0.0758, 32_l2=0.0407, 64_h1=0.1558, 64_l2=0.0566\n",
      "[44] time=2.34, avg_loss=1.4561, train_err=0.0728, 32_h1=0.0750, 32_l2=0.0393, 64_h1=0.1502, 64_l2=0.0520\n",
      "[45] time=2.34, avg_loss=1.4240, train_err=0.0712, 32_h1=0.0853, 32_l2=0.0547, 64_h1=0.1649, 64_l2=0.0690\n",
      "[46] time=2.38, avg_loss=1.4837, train_err=0.0742, 32_h1=0.0796, 32_l2=0.0444, 64_h1=0.1522, 64_l2=0.0486\n",
      "[47] time=2.34, avg_loss=1.4233, train_err=0.0712, 32_h1=0.0778, 32_l2=0.0443, 64_h1=0.1554, 64_l2=0.0647\n",
      "[48] time=2.39, avg_loss=1.4431, train_err=0.0722, 32_h1=0.0757, 32_l2=0.0405, 64_h1=0.1570, 64_l2=0.0593\n",
      "[49] time=2.30, avg_loss=1.3723, train_err=0.0686, 32_h1=0.0791, 32_l2=0.0450, 64_h1=0.1579, 64_l2=0.0636\n",
      "[50] time=2.39, avg_loss=1.3890, train_err=0.0695, 32_h1=0.0757, 32_l2=0.0403, 64_h1=0.1518, 64_l2=0.0498\n",
      "[51] time=2.10, avg_loss=1.3998, train_err=0.0700, 32_h1=0.0749, 32_l2=0.0389, 64_h1=0.1610, 64_l2=0.0603\n",
      "[52] time=2.06, avg_loss=1.4447, train_err=0.0722, 32_h1=0.0757, 32_l2=0.0387, 64_h1=0.1486, 64_l2=0.0544\n",
      "[53] time=2.07, avg_loss=1.3980, train_err=0.0699, 32_h1=0.0774, 32_l2=0.0448, 64_h1=0.1504, 64_l2=0.0567\n",
      "[54] time=2.25, avg_loss=1.3845, train_err=0.0692, 32_h1=0.0740, 32_l2=0.0372, 64_h1=0.1524, 64_l2=0.0536\n",
      "[55] time=2.12, avg_loss=1.3640, train_err=0.0682, 32_h1=0.0727, 32_l2=0.0367, 64_h1=0.1488, 64_l2=0.0500\n",
      "[56] time=2.24, avg_loss=1.3749, train_err=0.0687, 32_h1=0.0721, 32_l2=0.0359, 64_h1=0.1564, 64_l2=0.0583\n",
      "[57] time=2.20, avg_loss=1.3697, train_err=0.0685, 32_h1=0.0783, 32_l2=0.0454, 64_h1=0.1579, 64_l2=0.0615\n",
      "[58] time=2.11, avg_loss=1.3722, train_err=0.0686, 32_h1=0.0735, 32_l2=0.0370, 64_h1=0.1559, 64_l2=0.0543\n",
      "[59] time=2.22, avg_loss=1.3712, train_err=0.0686, 32_h1=0.0722, 32_l2=0.0359, 64_h1=0.1528, 64_l2=0.0540\n",
      "[60] time=2.14, avg_loss=1.3970, train_err=0.0698, 32_h1=0.0789, 32_l2=0.0453, 64_h1=0.1598, 64_l2=0.0621\n",
      "[61] time=2.16, avg_loss=1.3414, train_err=0.0671, 32_h1=0.0729, 32_l2=0.0379, 64_h1=0.1575, 64_l2=0.0587\n",
      "[62] time=2.25, avg_loss=1.3416, train_err=0.0671, 32_h1=0.0714, 32_l2=0.0353, 64_h1=0.1573, 64_l2=0.0544\n",
      "[63] time=2.24, avg_loss=1.3410, train_err=0.0670, 32_h1=0.0741, 32_l2=0.0394, 64_h1=0.1538, 64_l2=0.0535\n",
      "[64] time=2.23, avg_loss=1.3383, train_err=0.0669, 32_h1=0.0738, 32_l2=0.0406, 64_h1=0.1585, 64_l2=0.0632\n",
      "[65] time=2.24, avg_loss=1.3641, train_err=0.0682, 32_h1=0.0739, 32_l2=0.0390, 64_h1=0.1526, 64_l2=0.0507\n",
      "[66] time=2.31, avg_loss=1.3113, train_err=0.0656, 32_h1=0.0710, 32_l2=0.0347, 64_h1=0.1554, 64_l2=0.0549\n",
      "[67] time=2.20, avg_loss=1.3019, train_err=0.0651, 32_h1=0.0736, 32_l2=0.0377, 64_h1=0.1554, 64_l2=0.0574\n",
      "[68] time=2.06, avg_loss=1.3201, train_err=0.0660, 32_h1=0.0733, 32_l2=0.0381, 64_h1=0.1511, 64_l2=0.0523\n",
      "[69] time=2.26, avg_loss=1.3939, train_err=0.0697, 32_h1=0.0761, 32_l2=0.0421, 64_h1=0.1438, 64_l2=0.0508\n",
      "[70] time=2.26, avg_loss=1.3312, train_err=0.0666, 32_h1=0.0754, 32_l2=0.0409, 64_h1=0.1470, 64_l2=0.0535\n",
      "[71] time=2.10, avg_loss=1.2812, train_err=0.0641, 32_h1=0.0758, 32_l2=0.0411, 64_h1=0.1541, 64_l2=0.0575\n",
      "[72] time=2.22, avg_loss=1.3151, train_err=0.0658, 32_h1=0.0841, 32_l2=0.0569, 64_h1=0.1606, 64_l2=0.0769\n",
      "[73] time=2.07, avg_loss=1.3259, train_err=0.0663, 32_h1=0.0743, 32_l2=0.0382, 64_h1=0.1578, 64_l2=0.0566\n",
      "[74] time=2.23, avg_loss=1.2801, train_err=0.0640, 32_h1=0.0758, 32_l2=0.0398, 64_h1=0.1564, 64_l2=0.0554\n",
      "[75] time=2.24, avg_loss=1.3018, train_err=0.0651, 32_h1=0.0743, 32_l2=0.0373, 64_h1=0.1487, 64_l2=0.0525\n",
      "[76] time=2.18, avg_loss=1.2733, train_err=0.0637, 32_h1=0.0739, 32_l2=0.0413, 64_h1=0.1480, 64_l2=0.0577\n",
      "[77] time=2.18, avg_loss=1.2524, train_err=0.0626, 32_h1=0.0742, 32_l2=0.0387, 64_h1=0.1606, 64_l2=0.0625\n",
      "[78] time=2.17, avg_loss=1.3051, train_err=0.0653, 32_h1=0.0757, 32_l2=0.0405, 64_h1=0.1537, 64_l2=0.0577\n",
      "[79] time=2.35, avg_loss=1.3605, train_err=0.0680, 32_h1=0.0743, 32_l2=0.0391, 64_h1=0.1532, 64_l2=0.0578\n",
      "[80] time=2.33, avg_loss=1.2531, train_err=0.0627, 32_h1=0.0717, 32_l2=0.0348, 64_h1=0.1550, 64_l2=0.0528\n",
      "[81] time=2.34, avg_loss=1.2355, train_err=0.0618, 32_h1=0.0708, 32_l2=0.0345, 64_h1=0.1490, 64_l2=0.0516\n",
      "[82] time=2.39, avg_loss=1.2417, train_err=0.0621, 32_h1=0.0710, 32_l2=0.0351, 64_h1=0.1499, 64_l2=0.0527\n",
      "[83] time=2.38, avg_loss=1.2145, train_err=0.0607, 32_h1=0.0737, 32_l2=0.0376, 64_h1=0.1536, 64_l2=0.0561\n",
      "[84] time=2.41, avg_loss=1.2661, train_err=0.0633, 32_h1=0.0728, 32_l2=0.0376, 64_h1=0.1512, 64_l2=0.0536\n",
      "[85] time=2.38, avg_loss=1.2155, train_err=0.0608, 32_h1=0.0745, 32_l2=0.0388, 64_h1=0.1554, 64_l2=0.0538\n",
      "[86] time=2.36, avg_loss=1.2394, train_err=0.0620, 32_h1=0.0729, 32_l2=0.0358, 64_h1=0.1494, 64_l2=0.0498\n",
      "[87] time=2.34, avg_loss=1.2239, train_err=0.0612, 32_h1=0.0730, 32_l2=0.0373, 64_h1=0.1530, 64_l2=0.0575\n",
      "[88] time=2.33, avg_loss=1.2095, train_err=0.0605, 32_h1=0.0737, 32_l2=0.0392, 64_h1=0.1559, 64_l2=0.0613\n",
      "[89] time=2.37, avg_loss=1.2973, train_err=0.0649, 32_h1=0.0759, 32_l2=0.0406, 64_h1=0.1544, 64_l2=0.0515\n",
      "[90] time=2.44, avg_loss=1.2046, train_err=0.0602, 32_h1=0.0729, 32_l2=0.0350, 64_h1=0.1600, 64_l2=0.0549\n",
      "[91] time=2.38, avg_loss=1.1726, train_err=0.0586, 32_h1=0.0714, 32_l2=0.0350, 64_h1=0.1555, 64_l2=0.0577\n",
      "[92] time=2.36, avg_loss=1.1934, train_err=0.0597, 32_h1=0.0781, 32_l2=0.0413, 64_h1=0.1533, 64_l2=0.0560\n",
      "[93] time=2.36, avg_loss=1.2165, train_err=0.0608, 32_h1=0.0755, 32_l2=0.0374, 64_h1=0.1638, 64_l2=0.0588\n",
      "[94] time=2.34, avg_loss=1.2351, train_err=0.0618, 32_h1=0.0739, 32_l2=0.0372, 64_h1=0.1518, 64_l2=0.0516\n",
      "[95] time=2.37, avg_loss=1.1642, train_err=0.0582, 32_h1=0.0748, 32_l2=0.0388, 64_h1=0.1563, 64_l2=0.0583\n",
      "[96] time=2.33, avg_loss=1.1745, train_err=0.0587, 32_h1=0.0760, 32_l2=0.0386, 64_h1=0.1592, 64_l2=0.0526\n",
      "[97] time=2.36, avg_loss=1.1774, train_err=0.0589, 32_h1=0.0749, 32_l2=0.0379, 64_h1=0.1608, 64_l2=0.0557\n",
      "[98] time=2.35, avg_loss=1.1659, train_err=0.0583, 32_h1=0.0722, 32_l2=0.0344, 64_h1=0.1486, 64_l2=0.0497\n",
      "[99] time=2.40, avg_loss=1.1534, train_err=0.0577, 32_h1=0.0735, 32_l2=0.0355, 64_h1=0.1496, 64_l2=0.0515\n",
      "[100] time=2.33, avg_loss=1.1726, train_err=0.0586, 32_h1=0.0744, 32_l2=0.0361, 64_h1=0.1551, 64_l2=0.0538\n",
      "[101] time=2.38, avg_loss=1.1665, train_err=0.0583, 32_h1=0.0759, 32_l2=0.0379, 64_h1=0.1610, 64_l2=0.0583\n",
      "[102] time=2.34, avg_loss=1.1381, train_err=0.0569, 32_h1=0.0745, 32_l2=0.0382, 64_h1=0.1487, 64_l2=0.0537\n",
      "[103] time=2.36, avg_loss=1.1348, train_err=0.0567, 32_h1=0.0743, 32_l2=0.0354, 64_h1=0.1507, 64_l2=0.0548\n",
      "[104] time=2.36, avg_loss=1.1083, train_err=0.0554, 32_h1=0.0736, 32_l2=0.0350, 64_h1=0.1544, 64_l2=0.0541\n",
      "[105] time=2.35, avg_loss=1.1228, train_err=0.0561, 32_h1=0.0749, 32_l2=0.0367, 64_h1=0.1559, 64_l2=0.0534\n",
      "[106] time=2.37, avg_loss=1.1341, train_err=0.0567, 32_h1=0.0738, 32_l2=0.0356, 64_h1=0.1630, 64_l2=0.0577\n",
      "[107] time=2.36, avg_loss=1.1190, train_err=0.0559, 32_h1=0.0751, 32_l2=0.0373, 64_h1=0.1590, 64_l2=0.0603\n",
      "[108] time=2.43, avg_loss=1.1181, train_err=0.0559, 32_h1=0.0795, 32_l2=0.0432, 64_h1=0.1542, 64_l2=0.0565\n",
      "[109] time=2.36, avg_loss=1.1263, train_err=0.0563, 32_h1=0.0739, 32_l2=0.0350, 64_h1=0.1575, 64_l2=0.0568\n",
      "[110] time=2.36, avg_loss=1.0861, train_err=0.0543, 32_h1=0.0733, 32_l2=0.0343, 64_h1=0.1565, 64_l2=0.0561\n",
      "[111] time=2.31, avg_loss=1.0527, train_err=0.0526, 32_h1=0.0741, 32_l2=0.0352, 64_h1=0.1560, 64_l2=0.0535\n",
      "[112] time=2.37, avg_loss=1.0654, train_err=0.0533, 32_h1=0.0764, 32_l2=0.0361, 64_h1=0.1666, 64_l2=0.0593\n",
      "[113] time=2.42, avg_loss=1.0595, train_err=0.0530, 32_h1=0.0749, 32_l2=0.0356, 64_h1=0.1554, 64_l2=0.0542\n",
      "[114] time=2.34, avg_loss=1.0616, train_err=0.0531, 32_h1=0.0755, 32_l2=0.0369, 64_h1=0.1584, 64_l2=0.0554\n",
      "[115] time=2.37, avg_loss=1.0680, train_err=0.0534, 32_h1=0.0758, 32_l2=0.0378, 64_h1=0.1590, 64_l2=0.0559\n",
      "[116] time=2.33, avg_loss=1.0298, train_err=0.0515, 32_h1=0.0748, 32_l2=0.0360, 64_h1=0.1593, 64_l2=0.0540\n",
      "[117] time=2.33, avg_loss=1.0174, train_err=0.0509, 32_h1=0.0756, 32_l2=0.0352, 64_h1=0.1563, 64_l2=0.0502\n",
      "[118] time=2.24, avg_loss=1.0256, train_err=0.0513, 32_h1=0.0745, 32_l2=0.0351, 64_h1=0.1606, 64_l2=0.0556\n",
      "[119] time=2.06, avg_loss=1.0322, train_err=0.0516, 32_h1=0.0758, 32_l2=0.0378, 64_h1=0.1571, 64_l2=0.0521\n",
      "[120] time=2.13, avg_loss=1.0239, train_err=0.0512, 32_h1=0.0759, 32_l2=0.0369, 64_h1=0.1609, 64_l2=0.0584\n",
      "[121] time=2.17, avg_loss=1.0418, train_err=0.0521, 32_h1=0.0761, 32_l2=0.0392, 64_h1=0.1573, 64_l2=0.0553\n",
      "[122] time=2.05, avg_loss=1.0058, train_err=0.0503, 32_h1=0.0757, 32_l2=0.0370, 64_h1=0.1599, 64_l2=0.0556\n",
      "[123] time=2.18, avg_loss=1.0019, train_err=0.0501, 32_h1=0.0762, 32_l2=0.0367, 64_h1=0.1569, 64_l2=0.0556\n",
      "[124] time=2.27, avg_loss=0.9826, train_err=0.0491, 32_h1=0.0804, 32_l2=0.0454, 64_h1=0.1572, 64_l2=0.0633\n",
      "[125] time=2.27, avg_loss=0.9712, train_err=0.0486, 32_h1=0.0755, 32_l2=0.0366, 64_h1=0.1564, 64_l2=0.0525\n",
      "[126] time=2.19, avg_loss=0.9841, train_err=0.0492, 32_h1=0.0748, 32_l2=0.0348, 64_h1=0.1567, 64_l2=0.0513\n",
      "[127] time=2.24, avg_loss=0.9907, train_err=0.0495, 32_h1=0.0761, 32_l2=0.0368, 64_h1=0.1572, 64_l2=0.0542\n",
      "[128] time=2.24, avg_loss=0.9808, train_err=0.0490, 32_h1=0.0757, 32_l2=0.0360, 64_h1=0.1589, 64_l2=0.0566\n",
      "[129] time=2.21, avg_loss=0.9995, train_err=0.0500, 32_h1=0.0776, 32_l2=0.0380, 64_h1=0.1578, 64_l2=0.0548\n",
      "[130] time=2.07, avg_loss=0.9651, train_err=0.0483, 32_h1=0.0757, 32_l2=0.0357, 64_h1=0.1603, 64_l2=0.0569\n",
      "[131] time=2.07, avg_loss=0.9651, train_err=0.0483, 32_h1=0.0759, 32_l2=0.0360, 64_h1=0.1558, 64_l2=0.0534\n",
      "[132] time=2.15, avg_loss=0.9449, train_err=0.0472, 32_h1=0.0770, 32_l2=0.0386, 64_h1=0.1589, 64_l2=0.0513\n",
      "[133] time=2.07, avg_loss=0.9640, train_err=0.0482, 32_h1=0.0765, 32_l2=0.0355, 64_h1=0.1621, 64_l2=0.0514\n",
      "[134] time=2.07, avg_loss=0.9376, train_err=0.0469, 32_h1=0.0769, 32_l2=0.0377, 64_h1=0.1530, 64_l2=0.0527\n",
      "[135] time=2.08, avg_loss=0.9219, train_err=0.0461, 32_h1=0.0764, 32_l2=0.0353, 64_h1=0.1619, 64_l2=0.0546\n",
      "[136] time=2.14, avg_loss=0.9245, train_err=0.0462, 32_h1=0.0760, 32_l2=0.0356, 64_h1=0.1604, 64_l2=0.0539\n",
      "[137] time=2.25, avg_loss=0.9350, train_err=0.0467, 32_h1=0.0767, 32_l2=0.0368, 64_h1=0.1610, 64_l2=0.0563\n",
      "[138] time=2.24, avg_loss=0.9209, train_err=0.0460, 32_h1=0.0776, 32_l2=0.0380, 64_h1=0.1546, 64_l2=0.0547\n",
      "[139] time=2.25, avg_loss=0.8984, train_err=0.0449, 32_h1=0.0761, 32_l2=0.0354, 64_h1=0.1601, 64_l2=0.0512\n",
      "[140] time=2.24, avg_loss=0.9276, train_err=0.0464, 32_h1=0.0766, 32_l2=0.0353, 64_h1=0.1588, 64_l2=0.0534\n",
      "[141] time=2.07, avg_loss=0.9042, train_err=0.0452, 32_h1=0.0764, 32_l2=0.0359, 64_h1=0.1583, 64_l2=0.0535\n",
      "[142] time=2.23, avg_loss=0.8844, train_err=0.0442, 32_h1=0.0767, 32_l2=0.0369, 64_h1=0.1608, 64_l2=0.0570\n",
      "[143] time=2.23, avg_loss=0.8676, train_err=0.0434, 32_h1=0.0760, 32_l2=0.0348, 64_h1=0.1634, 64_l2=0.0543\n",
      "[144] time=2.19, avg_loss=0.8597, train_err=0.0430, 32_h1=0.0762, 32_l2=0.0355, 64_h1=0.1618, 64_l2=0.0546\n",
      "[145] time=2.22, avg_loss=0.8595, train_err=0.0430, 32_h1=0.0772, 32_l2=0.0374, 64_h1=0.1618, 64_l2=0.0537\n",
      "[146] time=2.27, avg_loss=0.8798, train_err=0.0440, 32_h1=0.0771, 32_l2=0.0359, 64_h1=0.1576, 64_l2=0.0506\n",
      "[147] time=2.45, avg_loss=0.8847, train_err=0.0442, 32_h1=0.0773, 32_l2=0.0365, 64_h1=0.1591, 64_l2=0.0530\n",
      "[148] time=2.38, avg_loss=0.8684, train_err=0.0434, 32_h1=0.0772, 32_l2=0.0355, 64_h1=0.1590, 64_l2=0.0509\n",
      "[149] time=2.43, avg_loss=0.8709, train_err=0.0435, 32_h1=0.0803, 32_l2=0.0406, 64_h1=0.1589, 64_l2=0.0573\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=24\n",
      "tfno2d.n_modes_width=24\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.2\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 489985\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 12, 12), rank=(21, 21, 8, 8))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 12, 12), rank=(21, 21, 8, 8))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 12, 12), rank=(21, 21, 8, 8))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 12, 12), rank=(21, 21, 8, 8))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 12, 12), rank=(21, 21, 8, 8))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 12, 12), rank=(21, 21, 8, 8))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 12, 12), rank=(21, 21, 8, 8))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 12, 12), rank=(21, 21, 8, 8))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f7761b37ca0>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f776fd8ca60>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f776fd8ca60>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f776fd8cd00>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.33, avg_loss=10.0229, train_err=0.5011, 32_h1=0.2705, 32_l2=0.1892, 64_h1=0.3211, 64_l2=0.1894\n",
      "[1] time=2.30, avg_loss=4.8555, train_err=0.2428, 32_h1=0.2008, 32_l2=0.1347, 64_h1=0.2569, 64_l2=0.1388\n",
      "[2] time=2.35, avg_loss=3.6110, train_err=0.1805, 32_h1=0.1718, 32_l2=0.1230, 64_h1=0.2160, 64_l2=0.1186\n",
      "[3] time=2.36, avg_loss=3.0772, train_err=0.1539, 32_h1=0.1384, 32_l2=0.0899, 64_h1=0.1939, 64_l2=0.0975\n",
      "[4] time=2.39, avg_loss=2.7802, train_err=0.1390, 32_h1=0.1626, 32_l2=0.1108, 64_h1=0.2295, 64_l2=0.1243\n",
      "[5] time=2.35, avg_loss=2.5733, train_err=0.1287, 32_h1=0.1261, 32_l2=0.0830, 64_h1=0.1877, 64_l2=0.0946\n",
      "[6] time=2.33, avg_loss=2.3618, train_err=0.1181, 32_h1=0.1111, 32_l2=0.0685, 64_h1=0.1763, 64_l2=0.0797\n",
      "[7] time=2.32, avg_loss=2.1879, train_err=0.1094, 32_h1=0.1103, 32_l2=0.0699, 64_h1=0.1828, 64_l2=0.0770\n",
      "[8] time=2.36, avg_loss=2.1006, train_err=0.1050, 32_h1=0.1074, 32_l2=0.0646, 64_h1=0.1699, 64_l2=0.0710\n",
      "[9] time=2.38, avg_loss=2.0367, train_err=0.1018, 32_h1=0.0916, 32_l2=0.0497, 64_h1=0.1720, 64_l2=0.0661\n",
      "[10] time=2.45, avg_loss=1.9061, train_err=0.0953, 32_h1=0.1008, 32_l2=0.0653, 64_h1=0.1822, 64_l2=0.0770\n",
      "[11] time=2.44, avg_loss=2.0209, train_err=0.1010, 32_h1=0.1077, 32_l2=0.0681, 64_h1=0.1739, 64_l2=0.0781\n",
      "[12] time=2.45, avg_loss=1.8782, train_err=0.0939, 32_h1=0.0934, 32_l2=0.0565, 64_h1=0.1687, 64_l2=0.0726\n",
      "[13] time=2.40, avg_loss=1.7797, train_err=0.0890, 32_h1=0.0954, 32_l2=0.0563, 64_h1=0.1810, 64_l2=0.0784\n",
      "[14] time=2.39, avg_loss=1.7854, train_err=0.0893, 32_h1=0.0840, 32_l2=0.0461, 64_h1=0.1588, 64_l2=0.0618\n",
      "[15] time=2.47, avg_loss=1.7042, train_err=0.0852, 32_h1=0.0863, 32_l2=0.0494, 64_h1=0.1692, 64_l2=0.0677\n",
      "[16] time=2.44, avg_loss=1.7285, train_err=0.0864, 32_h1=0.1028, 32_l2=0.0725, 64_h1=0.1651, 64_l2=0.0798\n",
      "[17] time=2.37, avg_loss=1.7012, train_err=0.0851, 32_h1=0.0790, 32_l2=0.0414, 64_h1=0.1609, 64_l2=0.0567\n",
      "[18] time=2.43, avg_loss=1.6720, train_err=0.0836, 32_h1=0.0838, 32_l2=0.0475, 64_h1=0.1644, 64_l2=0.0611\n",
      "[19] time=2.33, avg_loss=1.5959, train_err=0.0798, 32_h1=0.0810, 32_l2=0.0440, 64_h1=0.1644, 64_l2=0.0627\n",
      "[20] time=2.40, avg_loss=1.6351, train_err=0.0818, 32_h1=0.0810, 32_l2=0.0466, 64_h1=0.1651, 64_l2=0.0607\n",
      "[21] time=2.39, avg_loss=1.6536, train_err=0.0827, 32_h1=0.0806, 32_l2=0.0445, 64_h1=0.1596, 64_l2=0.0654\n",
      "[22] time=2.42, avg_loss=1.5731, train_err=0.0787, 32_h1=0.0806, 32_l2=0.0451, 64_h1=0.1585, 64_l2=0.0649\n",
      "[23] time=2.36, avg_loss=1.6116, train_err=0.0806, 32_h1=0.0823, 32_l2=0.0529, 64_h1=0.1595, 64_l2=0.0665\n",
      "[24] time=2.43, avg_loss=1.5763, train_err=0.0788, 32_h1=0.0779, 32_l2=0.0425, 64_h1=0.1538, 64_l2=0.0620\n",
      "[25] time=2.45, avg_loss=1.5776, train_err=0.0789, 32_h1=0.0822, 32_l2=0.0480, 64_h1=0.1604, 64_l2=0.0680\n",
      "[26] time=2.36, avg_loss=1.5884, train_err=0.0794, 32_h1=0.0796, 32_l2=0.0444, 64_h1=0.1631, 64_l2=0.0624\n",
      "[27] time=2.43, avg_loss=1.5877, train_err=0.0794, 32_h1=0.0856, 32_l2=0.0523, 64_h1=0.1642, 64_l2=0.0709\n",
      "[28] time=2.42, avg_loss=1.5489, train_err=0.0774, 32_h1=0.0754, 32_l2=0.0396, 64_h1=0.1585, 64_l2=0.0555\n",
      "[29] time=2.42, avg_loss=1.4907, train_err=0.0745, 32_h1=0.0817, 32_l2=0.0475, 64_h1=0.1642, 64_l2=0.0611\n",
      "[30] time=2.39, avg_loss=1.5056, train_err=0.0753, 32_h1=0.0828, 32_l2=0.0513, 64_h1=0.1595, 64_l2=0.0627\n",
      "[31] time=2.36, avg_loss=1.5311, train_err=0.0766, 32_h1=0.0913, 32_l2=0.0595, 64_h1=0.1629, 64_l2=0.0697\n",
      "[32] time=2.38, avg_loss=1.5324, train_err=0.0766, 32_h1=0.0797, 32_l2=0.0431, 64_h1=0.1508, 64_l2=0.0584\n",
      "[33] time=2.51, avg_loss=1.4763, train_err=0.0738, 32_h1=0.0750, 32_l2=0.0403, 64_h1=0.1549, 64_l2=0.0559\n",
      "[34] time=2.38, avg_loss=1.4588, train_err=0.0729, 32_h1=0.0763, 32_l2=0.0411, 64_h1=0.1559, 64_l2=0.0549\n",
      "[35] time=2.24, avg_loss=1.5163, train_err=0.0758, 32_h1=0.0798, 32_l2=0.0433, 64_h1=0.1646, 64_l2=0.0647\n",
      "[36] time=2.07, avg_loss=1.4987, train_err=0.0749, 32_h1=0.0777, 32_l2=0.0412, 64_h1=0.1523, 64_l2=0.0531\n",
      "[37] time=2.18, avg_loss=1.4471, train_err=0.0724, 32_h1=0.0775, 32_l2=0.0430, 64_h1=0.1546, 64_l2=0.0608\n",
      "[38] time=2.11, avg_loss=1.4412, train_err=0.0721, 32_h1=0.0744, 32_l2=0.0387, 64_h1=0.1520, 64_l2=0.0544\n",
      "[39] time=2.17, avg_loss=1.5719, train_err=0.0786, 32_h1=0.0775, 32_l2=0.0415, 64_h1=0.1610, 64_l2=0.0596\n",
      "[40] time=2.14, avg_loss=1.4439, train_err=0.0722, 32_h1=0.0765, 32_l2=0.0424, 64_h1=0.1588, 64_l2=0.0635\n",
      "[41] time=2.23, avg_loss=1.4265, train_err=0.0713, 32_h1=0.0759, 32_l2=0.0394, 64_h1=0.1533, 64_l2=0.0551\n",
      "[42] time=2.32, avg_loss=1.4732, train_err=0.0737, 32_h1=0.0717, 32_l2=0.0360, 64_h1=0.1496, 64_l2=0.0504\n",
      "[43] time=2.24, avg_loss=1.4331, train_err=0.0717, 32_h1=0.0714, 32_l2=0.0353, 64_h1=0.1513, 64_l2=0.0517\n",
      "[44] time=2.14, avg_loss=1.4548, train_err=0.0727, 32_h1=0.0812, 32_l2=0.0487, 64_h1=0.1532, 64_l2=0.0587\n",
      "[45] time=2.19, avg_loss=1.4323, train_err=0.0716, 32_h1=0.0721, 32_l2=0.0370, 64_h1=0.1540, 64_l2=0.0537\n",
      "[46] time=2.12, avg_loss=1.3796, train_err=0.0690, 32_h1=0.0761, 32_l2=0.0436, 64_h1=0.1596, 64_l2=0.0561\n",
      "[47] time=2.05, avg_loss=1.3920, train_err=0.0696, 32_h1=0.0759, 32_l2=0.0388, 64_h1=0.1512, 64_l2=0.0476\n",
      "[48] time=2.06, avg_loss=1.4310, train_err=0.0716, 32_h1=0.0713, 32_l2=0.0350, 64_h1=0.1566, 64_l2=0.0550\n",
      "[49] time=2.16, avg_loss=1.4028, train_err=0.0701, 32_h1=0.0722, 32_l2=0.0382, 64_h1=0.1493, 64_l2=0.0556\n",
      "[50] time=2.25, avg_loss=1.4198, train_err=0.0710, 32_h1=0.0803, 32_l2=0.0444, 64_h1=0.1534, 64_l2=0.0557\n",
      "[51] time=2.11, avg_loss=1.4335, train_err=0.0717, 32_h1=0.0749, 32_l2=0.0405, 64_h1=0.1578, 64_l2=0.0563\n",
      "[52] time=2.11, avg_loss=1.3825, train_err=0.0691, 32_h1=0.0730, 32_l2=0.0372, 64_h1=0.1563, 64_l2=0.0487\n",
      "[53] time=2.12, avg_loss=1.3898, train_err=0.0695, 32_h1=0.0726, 32_l2=0.0379, 64_h1=0.1545, 64_l2=0.0574\n",
      "[54] time=2.18, avg_loss=1.3684, train_err=0.0684, 32_h1=0.0699, 32_l2=0.0339, 64_h1=0.1558, 64_l2=0.0546\n",
      "[55] time=2.18, avg_loss=1.3412, train_err=0.0671, 32_h1=0.0713, 32_l2=0.0359, 64_h1=0.1509, 64_l2=0.0507\n",
      "[56] time=2.24, avg_loss=1.3357, train_err=0.0668, 32_h1=0.0721, 32_l2=0.0369, 64_h1=0.1529, 64_l2=0.0546\n",
      "[57] time=2.24, avg_loss=1.3768, train_err=0.0688, 32_h1=0.0734, 32_l2=0.0380, 64_h1=0.1533, 64_l2=0.0537\n",
      "[58] time=2.14, avg_loss=1.3417, train_err=0.0671, 32_h1=0.0751, 32_l2=0.0396, 64_h1=0.1464, 64_l2=0.0470\n",
      "[59] time=2.24, avg_loss=1.3370, train_err=0.0668, 32_h1=0.0757, 32_l2=0.0420, 64_h1=0.1604, 64_l2=0.0629\n",
      "[60] time=2.12, avg_loss=1.3226, train_err=0.0661, 32_h1=0.0729, 32_l2=0.0389, 64_h1=0.1451, 64_l2=0.0480\n",
      "[61] time=2.08, avg_loss=1.3475, train_err=0.0674, 32_h1=0.0717, 32_l2=0.0361, 64_h1=0.1502, 64_l2=0.0492\n",
      "[62] time=2.15, avg_loss=1.3521, train_err=0.0676, 32_h1=0.0717, 32_l2=0.0357, 64_h1=0.1486, 64_l2=0.0510\n",
      "[63] time=2.40, avg_loss=1.3074, train_err=0.0654, 32_h1=0.0724, 32_l2=0.0367, 64_h1=0.1587, 64_l2=0.0519\n",
      "[64] time=2.39, avg_loss=1.3651, train_err=0.0683, 32_h1=0.0718, 32_l2=0.0362, 64_h1=0.1479, 64_l2=0.0460\n",
      "[65] time=2.37, avg_loss=1.2934, train_err=0.0647, 32_h1=0.0738, 32_l2=0.0404, 64_h1=0.1526, 64_l2=0.0557\n",
      "[66] time=2.40, avg_loss=1.3196, train_err=0.0660, 32_h1=0.0759, 32_l2=0.0412, 64_h1=0.1580, 64_l2=0.0594\n",
      "[67] time=2.36, avg_loss=1.3285, train_err=0.0664, 32_h1=0.0745, 32_l2=0.0387, 64_h1=0.1529, 64_l2=0.0507\n",
      "[68] time=2.39, avg_loss=1.3315, train_err=0.0666, 32_h1=0.0737, 32_l2=0.0377, 64_h1=0.1482, 64_l2=0.0467\n",
      "[69] time=2.43, avg_loss=1.2665, train_err=0.0633, 32_h1=0.0709, 32_l2=0.0360, 64_h1=0.1536, 64_l2=0.0528\n",
      "[70] time=2.38, avg_loss=1.3129, train_err=0.0656, 32_h1=0.0716, 32_l2=0.0352, 64_h1=0.1527, 64_l2=0.0534\n",
      "[71] time=2.39, avg_loss=1.3422, train_err=0.0671, 32_h1=0.0753, 32_l2=0.0398, 64_h1=0.1494, 64_l2=0.0504\n",
      "[72] time=2.40, avg_loss=1.2983, train_err=0.0649, 32_h1=0.0739, 32_l2=0.0384, 64_h1=0.1590, 64_l2=0.0564\n",
      "[73] time=2.43, avg_loss=1.2375, train_err=0.0619, 32_h1=0.0713, 32_l2=0.0354, 64_h1=0.1526, 64_l2=0.0538\n",
      "[74] time=2.39, avg_loss=1.2530, train_err=0.0627, 32_h1=0.0718, 32_l2=0.0359, 64_h1=0.1521, 64_l2=0.0538\n",
      "[75] time=2.41, avg_loss=1.2526, train_err=0.0626, 32_h1=0.0708, 32_l2=0.0337, 64_h1=0.1553, 64_l2=0.0479\n",
      "[76] time=2.35, avg_loss=1.2929, train_err=0.0646, 32_h1=0.0741, 32_l2=0.0371, 64_h1=0.1560, 64_l2=0.0564\n",
      "[77] time=2.37, avg_loss=1.2573, train_err=0.0629, 32_h1=0.0753, 32_l2=0.0399, 64_h1=0.1525, 64_l2=0.0550\n",
      "[78] time=2.39, avg_loss=1.2616, train_err=0.0631, 32_h1=0.0717, 32_l2=0.0358, 64_h1=0.1600, 64_l2=0.0534\n",
      "[79] time=2.42, avg_loss=1.2331, train_err=0.0617, 32_h1=0.0716, 32_l2=0.0339, 64_h1=0.1548, 64_l2=0.0535\n",
      "[80] time=2.47, avg_loss=1.2240, train_err=0.0612, 32_h1=0.0741, 32_l2=0.0376, 64_h1=0.1506, 64_l2=0.0499\n",
      "[81] time=2.47, avg_loss=1.1884, train_err=0.0594, 32_h1=0.0753, 32_l2=0.0399, 64_h1=0.1562, 64_l2=0.0585\n",
      "[82] time=2.42, avg_loss=1.1769, train_err=0.0588, 32_h1=0.0775, 32_l2=0.0427, 64_h1=0.1559, 64_l2=0.0598\n",
      "[83] time=2.42, avg_loss=1.1742, train_err=0.0587, 32_h1=0.0758, 32_l2=0.0391, 64_h1=0.1516, 64_l2=0.0498\n",
      "[84] time=2.34, avg_loss=1.1854, train_err=0.0593, 32_h1=0.0743, 32_l2=0.0381, 64_h1=0.1547, 64_l2=0.0546\n",
      "[85] time=2.35, avg_loss=1.1901, train_err=0.0595, 32_h1=0.0795, 32_l2=0.0454, 64_h1=0.1635, 64_l2=0.0581\n",
      "[86] time=2.38, avg_loss=1.2375, train_err=0.0619, 32_h1=0.0747, 32_l2=0.0378, 64_h1=0.1572, 64_l2=0.0583\n",
      "[87] time=2.40, avg_loss=1.1682, train_err=0.0584, 32_h1=0.0758, 32_l2=0.0385, 64_h1=0.1585, 64_l2=0.0570\n",
      "[88] time=2.43, avg_loss=1.1378, train_err=0.0569, 32_h1=0.0737, 32_l2=0.0363, 64_h1=0.1548, 64_l2=0.0523\n",
      "[89] time=2.40, avg_loss=1.1458, train_err=0.0573, 32_h1=0.0802, 32_l2=0.0478, 64_h1=0.1650, 64_l2=0.0642\n",
      "[90] time=2.38, avg_loss=1.1336, train_err=0.0567, 32_h1=0.0738, 32_l2=0.0361, 64_h1=0.1562, 64_l2=0.0541\n",
      "[91] time=2.38, avg_loss=1.1577, train_err=0.0579, 32_h1=0.0769, 32_l2=0.0417, 64_h1=0.1550, 64_l2=0.0548\n",
      "[92] time=2.42, avg_loss=1.1294, train_err=0.0565, 32_h1=0.0739, 32_l2=0.0369, 64_h1=0.1565, 64_l2=0.0567\n",
      "[93] time=2.36, avg_loss=1.0822, train_err=0.0541, 32_h1=0.0775, 32_l2=0.0405, 64_h1=0.1652, 64_l2=0.0608\n",
      "[94] time=2.40, avg_loss=1.0772, train_err=0.0539, 32_h1=0.0752, 32_l2=0.0378, 64_h1=0.1521, 64_l2=0.0520\n",
      "[95] time=2.38, avg_loss=1.0789, train_err=0.0539, 32_h1=0.0759, 32_l2=0.0375, 64_h1=0.1592, 64_l2=0.0550\n",
      "[96] time=2.35, avg_loss=1.0494, train_err=0.0525, 32_h1=0.0758, 32_l2=0.0378, 64_h1=0.1564, 64_l2=0.0552\n",
      "[97] time=2.40, avg_loss=1.0481, train_err=0.0524, 32_h1=0.0745, 32_l2=0.0357, 64_h1=0.1617, 64_l2=0.0555\n",
      "[98] time=2.39, avg_loss=1.0709, train_err=0.0535, 32_h1=0.0760, 32_l2=0.0375, 64_h1=0.1586, 64_l2=0.0563\n",
      "[99] time=2.37, avg_loss=1.1084, train_err=0.0554, 32_h1=0.0785, 32_l2=0.0423, 64_h1=0.1616, 64_l2=0.0603\n",
      "[100] time=2.41, avg_loss=1.0590, train_err=0.0529, 32_h1=0.0758, 32_l2=0.0375, 64_h1=0.1533, 64_l2=0.0517\n",
      "[101] time=2.20, avg_loss=1.1261, train_err=0.0563, 32_h1=0.0778, 32_l2=0.0411, 64_h1=0.1597, 64_l2=0.0560\n",
      "[102] time=2.06, avg_loss=1.0460, train_err=0.0523, 32_h1=0.0781, 32_l2=0.0414, 64_h1=0.1607, 64_l2=0.0579\n",
      "[103] time=2.15, avg_loss=1.0073, train_err=0.0504, 32_h1=0.0750, 32_l2=0.0355, 64_h1=0.1599, 64_l2=0.0527\n",
      "[104] time=2.26, avg_loss=0.9803, train_err=0.0490, 32_h1=0.0764, 32_l2=0.0372, 64_h1=0.1603, 64_l2=0.0549\n",
      "[105] time=2.22, avg_loss=0.9643, train_err=0.0482, 32_h1=0.0764, 32_l2=0.0375, 64_h1=0.1562, 64_l2=0.0566\n",
      "[106] time=2.20, avg_loss=0.9882, train_err=0.0494, 32_h1=0.0759, 32_l2=0.0361, 64_h1=0.1584, 64_l2=0.0531\n",
      "[107] time=2.23, avg_loss=1.0045, train_err=0.0502, 32_h1=0.0772, 32_l2=0.0381, 64_h1=0.1628, 64_l2=0.0555\n",
      "[108] time=2.24, avg_loss=0.9752, train_err=0.0488, 32_h1=0.0764, 32_l2=0.0374, 64_h1=0.1581, 64_l2=0.0519\n",
      "[109] time=2.19, avg_loss=0.9613, train_err=0.0481, 32_h1=0.0764, 32_l2=0.0364, 64_h1=0.1609, 64_l2=0.0584\n",
      "[110] time=2.09, avg_loss=0.9878, train_err=0.0494, 32_h1=0.0794, 32_l2=0.0397, 64_h1=0.1534, 64_l2=0.0481\n",
      "[111] time=2.05, avg_loss=0.9890, train_err=0.0495, 32_h1=0.0761, 32_l2=0.0370, 64_h1=0.1617, 64_l2=0.0559\n",
      "[112] time=2.05, avg_loss=0.9461, train_err=0.0473, 32_h1=0.0764, 32_l2=0.0372, 64_h1=0.1622, 64_l2=0.0565\n",
      "[113] time=2.09, avg_loss=0.9343, train_err=0.0467, 32_h1=0.0767, 32_l2=0.0375, 64_h1=0.1578, 64_l2=0.0583\n",
      "[114] time=2.22, avg_loss=0.9507, train_err=0.0475, 32_h1=0.0769, 32_l2=0.0369, 64_h1=0.1558, 64_l2=0.0504\n",
      "[115] time=2.12, avg_loss=0.9324, train_err=0.0466, 32_h1=0.0778, 32_l2=0.0375, 64_h1=0.1600, 64_l2=0.0540\n",
      "[116] time=2.31, avg_loss=0.9453, train_err=0.0473, 32_h1=0.0767, 32_l2=0.0362, 64_h1=0.1674, 64_l2=0.0577\n",
      "[117] time=2.24, avg_loss=0.9437, train_err=0.0472, 32_h1=0.0763, 32_l2=0.0361, 64_h1=0.1639, 64_l2=0.0562\n",
      "[118] time=2.07, avg_loss=0.9118, train_err=0.0456, 32_h1=0.0757, 32_l2=0.0357, 64_h1=0.1594, 64_l2=0.0550\n",
      "[119] time=2.17, avg_loss=0.9096, train_err=0.0455, 32_h1=0.0773, 32_l2=0.0377, 64_h1=0.1596, 64_l2=0.0547\n",
      "[120] time=2.24, avg_loss=0.9373, train_err=0.0469, 32_h1=0.0761, 32_l2=0.0356, 64_h1=0.1600, 64_l2=0.0534\n",
      "[121] time=2.09, avg_loss=0.9079, train_err=0.0454, 32_h1=0.0755, 32_l2=0.0357, 64_h1=0.1585, 64_l2=0.0531\n",
      "[122] time=2.07, avg_loss=0.8877, train_err=0.0444, 32_h1=0.0769, 32_l2=0.0371, 64_h1=0.1547, 64_l2=0.0517\n",
      "[123] time=2.10, avg_loss=0.8650, train_err=0.0433, 32_h1=0.0762, 32_l2=0.0349, 64_h1=0.1553, 64_l2=0.0508\n",
      "[124] time=2.09, avg_loss=0.8818, train_err=0.0441, 32_h1=0.0762, 32_l2=0.0356, 64_h1=0.1565, 64_l2=0.0540\n",
      "[125] time=2.17, avg_loss=0.8862, train_err=0.0443, 32_h1=0.0757, 32_l2=0.0350, 64_h1=0.1566, 64_l2=0.0508\n",
      "[126] time=2.08, avg_loss=0.8708, train_err=0.0435, 32_h1=0.0773, 32_l2=0.0365, 64_h1=0.1616, 64_l2=0.0557\n",
      "[127] time=2.08, avg_loss=0.9010, train_err=0.0450, 32_h1=0.0784, 32_l2=0.0375, 64_h1=0.1628, 64_l2=0.0564\n",
      "[128] time=2.16, avg_loss=0.8638, train_err=0.0432, 32_h1=0.0770, 32_l2=0.0373, 64_h1=0.1603, 64_l2=0.0563\n",
      "[129] time=2.31, avg_loss=0.8510, train_err=0.0426, 32_h1=0.0778, 32_l2=0.0387, 64_h1=0.1582, 64_l2=0.0530\n",
      "[130] time=2.43, avg_loss=0.8428, train_err=0.0421, 32_h1=0.0783, 32_l2=0.0396, 64_h1=0.1603, 64_l2=0.0573\n",
      "[131] time=2.35, avg_loss=0.8562, train_err=0.0428, 32_h1=0.0771, 32_l2=0.0368, 64_h1=0.1630, 64_l2=0.0574\n",
      "[132] time=2.39, avg_loss=0.8372, train_err=0.0419, 32_h1=0.0786, 32_l2=0.0397, 64_h1=0.1588, 64_l2=0.0572\n",
      "[133] time=2.39, avg_loss=0.8435, train_err=0.0422, 32_h1=0.0770, 32_l2=0.0363, 64_h1=0.1594, 64_l2=0.0556\n",
      "[134] time=2.38, avg_loss=0.8268, train_err=0.0413, 32_h1=0.0764, 32_l2=0.0357, 64_h1=0.1600, 64_l2=0.0547\n",
      "[135] time=2.36, avg_loss=0.8206, train_err=0.0410, 32_h1=0.0776, 32_l2=0.0372, 64_h1=0.1619, 64_l2=0.0519\n",
      "[136] time=2.39, avg_loss=0.8159, train_err=0.0408, 32_h1=0.0768, 32_l2=0.0354, 64_h1=0.1570, 64_l2=0.0525\n",
      "[137] time=2.36, avg_loss=0.8408, train_err=0.0420, 32_h1=0.0779, 32_l2=0.0362, 64_h1=0.1651, 64_l2=0.0551\n",
      "[138] time=2.39, avg_loss=0.8010, train_err=0.0400, 32_h1=0.0786, 32_l2=0.0395, 64_h1=0.1538, 64_l2=0.0533\n",
      "[139] time=2.36, avg_loss=0.7995, train_err=0.0400, 32_h1=0.0767, 32_l2=0.0349, 64_h1=0.1575, 64_l2=0.0521\n",
      "[140] time=2.46, avg_loss=0.7978, train_err=0.0399, 32_h1=0.0767, 32_l2=0.0359, 64_h1=0.1591, 64_l2=0.0527\n",
      "[141] time=2.34, avg_loss=0.8048, train_err=0.0402, 32_h1=0.0771, 32_l2=0.0366, 64_h1=0.1625, 64_l2=0.0548\n",
      "[142] time=2.40, avg_loss=0.8016, train_err=0.0401, 32_h1=0.0779, 32_l2=0.0366, 64_h1=0.1614, 64_l2=0.0544\n",
      "[143] time=2.42, avg_loss=0.8007, train_err=0.0400, 32_h1=0.0780, 32_l2=0.0373, 64_h1=0.1593, 64_l2=0.0550\n",
      "[144] time=2.44, avg_loss=0.7752, train_err=0.0388, 32_h1=0.0784, 32_l2=0.0366, 64_h1=0.1585, 64_l2=0.0506\n",
      "[145] time=2.37, avg_loss=0.7825, train_err=0.0391, 32_h1=0.0766, 32_l2=0.0353, 64_h1=0.1618, 64_l2=0.0536\n",
      "[146] time=2.35, avg_loss=0.7665, train_err=0.0383, 32_h1=0.0777, 32_l2=0.0363, 64_h1=0.1568, 64_l2=0.0527\n",
      "[147] time=2.40, avg_loss=0.7687, train_err=0.0384, 32_h1=0.0778, 32_l2=0.0360, 64_h1=0.1603, 64_l2=0.0532\n",
      "[148] time=2.39, avg_loss=0.7699, train_err=0.0385, 32_h1=0.0783, 32_l2=0.0386, 64_h1=0.1632, 64_l2=0.0559\n",
      "[149] time=2.36, avg_loss=0.7681, train_err=0.0384, 32_h1=0.0776, 32_l2=0.0354, 64_h1=0.1622, 64_l2=0.0528\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=26\n",
      "tfno2d.n_modes_width=26\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.2\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 610609\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 13, 13), rank=(21, 21, 9, 9))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 13, 13), rank=(21, 21, 9, 9))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 13, 13), rank=(21, 21, 9, 9))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 13, 13), rank=(21, 21, 9, 9))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 13, 13), rank=(21, 21, 9, 9))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 13, 13), rank=(21, 21, 9, 9))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 13, 13), rank=(21, 21, 9, 9))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 13, 13), rank=(21, 21, 9, 9))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f7761b3c040>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f7761b3ca60>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f7761b3ca60>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f7761b3c550>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.39, avg_loss=9.8197, train_err=0.4910, 32_h1=0.2855, 32_l2=0.1982, 64_h1=0.3510, 64_l2=0.2024\n",
      "[1] time=2.43, avg_loss=4.7147, train_err=0.2357, 32_h1=0.2256, 32_l2=0.1603, 64_h1=0.2706, 64_l2=0.1626\n",
      "[2] time=2.33, avg_loss=3.5929, train_err=0.1796, 32_h1=0.1903, 32_l2=0.1327, 64_h1=0.2662, 64_l2=0.1519\n",
      "[3] time=2.36, avg_loss=3.2340, train_err=0.1617, 32_h1=0.1457, 32_l2=0.0982, 64_h1=0.1998, 64_l2=0.0984\n",
      "[4] time=2.32, avg_loss=2.8961, train_err=0.1448, 32_h1=0.1395, 32_l2=0.0947, 64_h1=0.2061, 64_l2=0.1053\n",
      "[5] time=2.35, avg_loss=2.6947, train_err=0.1347, 32_h1=0.1311, 32_l2=0.0870, 64_h1=0.1900, 64_l2=0.0935\n",
      "[6] time=2.38, avg_loss=2.6177, train_err=0.1309, 32_h1=0.1215, 32_l2=0.0763, 64_h1=0.2073, 64_l2=0.0948\n",
      "[7] time=2.37, avg_loss=2.4116, train_err=0.1206, 32_h1=0.1167, 32_l2=0.0713, 64_h1=0.1787, 64_l2=0.0842\n",
      "[8] time=2.34, avg_loss=2.2674, train_err=0.1134, 32_h1=0.1325, 32_l2=0.0955, 64_h1=0.1907, 64_l2=0.1015\n",
      "[9] time=2.37, avg_loss=2.2051, train_err=0.1103, 32_h1=0.1032, 32_l2=0.0607, 64_h1=0.1775, 64_l2=0.0738\n",
      "[10] time=2.33, avg_loss=2.1451, train_err=0.1073, 32_h1=0.1048, 32_l2=0.0614, 64_h1=0.1602, 64_l2=0.0659\n",
      "[11] time=2.40, avg_loss=2.0488, train_err=0.1024, 32_h1=0.0994, 32_l2=0.0615, 64_h1=0.1744, 64_l2=0.0720\n",
      "[12] time=2.49, avg_loss=2.0213, train_err=0.1011, 32_h1=0.0997, 32_l2=0.0647, 64_h1=0.1704, 64_l2=0.0738\n",
      "[13] time=2.38, avg_loss=2.0240, train_err=0.1012, 32_h1=0.1088, 32_l2=0.0743, 64_h1=0.1838, 64_l2=0.0845\n",
      "[14] time=2.37, avg_loss=1.9846, train_err=0.0992, 32_h1=0.1120, 32_l2=0.0761, 64_h1=0.1713, 64_l2=0.0767\n",
      "[15] time=2.32, avg_loss=1.8904, train_err=0.0945, 32_h1=0.0927, 32_l2=0.0539, 64_h1=0.1588, 64_l2=0.0627\n",
      "[16] time=2.41, avg_loss=1.8697, train_err=0.0935, 32_h1=0.0925, 32_l2=0.0566, 64_h1=0.1653, 64_l2=0.0720\n",
      "[17] time=2.41, avg_loss=1.7728, train_err=0.0886, 32_h1=0.0874, 32_l2=0.0493, 64_h1=0.1640, 64_l2=0.0580\n",
      "[18] time=2.20, avg_loss=1.7663, train_err=0.0883, 32_h1=0.0916, 32_l2=0.0558, 64_h1=0.1680, 64_l2=0.0696\n",
      "[19] time=2.12, avg_loss=1.7649, train_err=0.0882, 32_h1=0.1082, 32_l2=0.0779, 64_h1=0.1799, 64_l2=0.0886\n",
      "[20] time=2.07, avg_loss=1.7439, train_err=0.0872, 32_h1=0.0829, 32_l2=0.0452, 64_h1=0.1599, 64_l2=0.0539\n",
      "[21] time=2.25, avg_loss=1.7859, train_err=0.0893, 32_h1=0.0808, 32_l2=0.0425, 64_h1=0.1589, 64_l2=0.0551\n",
      "[22] time=2.18, avg_loss=1.5958, train_err=0.0798, 32_h1=0.0827, 32_l2=0.0462, 64_h1=0.1554, 64_l2=0.0538\n",
      "[23] time=2.11, avg_loss=1.6345, train_err=0.0817, 32_h1=0.0835, 32_l2=0.0487, 64_h1=0.1501, 64_l2=0.0548\n",
      "[24] time=2.15, avg_loss=1.6218, train_err=0.0811, 32_h1=0.0777, 32_l2=0.0401, 64_h1=0.1544, 64_l2=0.0526\n",
      "[25] time=2.10, avg_loss=1.6542, train_err=0.0827, 32_h1=0.0802, 32_l2=0.0433, 64_h1=0.1580, 64_l2=0.0512\n",
      "[26] time=2.07, avg_loss=1.5931, train_err=0.0797, 32_h1=0.0886, 32_l2=0.0579, 64_h1=0.1632, 64_l2=0.0720\n",
      "[27] time=2.10, avg_loss=1.6199, train_err=0.0810, 32_h1=0.0843, 32_l2=0.0491, 64_h1=0.1589, 64_l2=0.0584\n",
      "[28] time=2.12, avg_loss=1.6089, train_err=0.0804, 32_h1=0.0860, 32_l2=0.0499, 64_h1=0.1557, 64_l2=0.0582\n",
      "[29] time=2.10, avg_loss=1.6023, train_err=0.0801, 32_h1=0.0834, 32_l2=0.0460, 64_h1=0.1500, 64_l2=0.0508\n",
      "[30] time=2.10, avg_loss=1.5453, train_err=0.0773, 32_h1=0.0781, 32_l2=0.0429, 64_h1=0.1563, 64_l2=0.0534\n",
      "[31] time=2.06, avg_loss=1.5809, train_err=0.0790, 32_h1=0.0803, 32_l2=0.0456, 64_h1=0.1533, 64_l2=0.0530\n",
      "[32] time=2.08, avg_loss=1.5038, train_err=0.0752, 32_h1=0.0800, 32_l2=0.0451, 64_h1=0.1595, 64_l2=0.0570\n",
      "[33] time=2.12, avg_loss=1.5143, train_err=0.0757, 32_h1=0.0776, 32_l2=0.0421, 64_h1=0.1585, 64_l2=0.0564\n",
      "[34] time=2.11, avg_loss=1.5053, train_err=0.0753, 32_h1=0.0758, 32_l2=0.0396, 64_h1=0.1626, 64_l2=0.0569\n",
      "[35] time=2.09, avg_loss=1.5096, train_err=0.0755, 32_h1=0.0789, 32_l2=0.0421, 64_h1=0.1627, 64_l2=0.0613\n",
      "[36] time=2.07, avg_loss=1.4725, train_err=0.0736, 32_h1=0.0825, 32_l2=0.0470, 64_h1=0.1613, 64_l2=0.0633\n",
      "[37] time=2.20, avg_loss=1.4522, train_err=0.0726, 32_h1=0.0760, 32_l2=0.0382, 64_h1=0.1559, 64_l2=0.0498\n",
      "[38] time=2.06, avg_loss=1.4690, train_err=0.0735, 32_h1=0.0967, 32_l2=0.0710, 64_h1=0.1728, 64_l2=0.0761\n",
      "[39] time=2.23, avg_loss=1.5620, train_err=0.0781, 32_h1=0.0758, 32_l2=0.0408, 64_h1=0.1541, 64_l2=0.0550\n",
      "[40] time=2.06, avg_loss=1.4749, train_err=0.0737, 32_h1=0.0742, 32_l2=0.0396, 64_h1=0.1519, 64_l2=0.0532\n",
      "[41] time=2.09, avg_loss=1.4009, train_err=0.0700, 32_h1=0.0746, 32_l2=0.0407, 64_h1=0.1522, 64_l2=0.0556\n",
      "[42] time=2.21, avg_loss=1.4502, train_err=0.0725, 32_h1=0.0754, 32_l2=0.0408, 64_h1=0.1617, 64_l2=0.0584\n",
      "[43] time=2.08, avg_loss=1.3822, train_err=0.0691, 32_h1=0.0748, 32_l2=0.0401, 64_h1=0.1480, 64_l2=0.0505\n",
      "[44] time=2.13, avg_loss=1.4251, train_err=0.0713, 32_h1=0.0746, 32_l2=0.0394, 64_h1=0.1549, 64_l2=0.0535\n",
      "[45] time=2.21, avg_loss=1.3856, train_err=0.0693, 32_h1=0.0829, 32_l2=0.0500, 64_h1=0.1577, 64_l2=0.0630\n",
      "[46] time=2.19, avg_loss=1.4000, train_err=0.0700, 32_h1=0.0736, 32_l2=0.0378, 64_h1=0.1601, 64_l2=0.0584\n",
      "[47] time=2.30, avg_loss=1.3708, train_err=0.0685, 32_h1=0.0723, 32_l2=0.0361, 64_h1=0.1577, 64_l2=0.0534\n",
      "[48] time=2.38, avg_loss=1.3514, train_err=0.0676, 32_h1=0.0741, 32_l2=0.0377, 64_h1=0.1571, 64_l2=0.0568\n",
      "[49] time=2.41, avg_loss=1.3673, train_err=0.0684, 32_h1=0.0724, 32_l2=0.0362, 64_h1=0.1583, 64_l2=0.0543\n",
      "[50] time=2.42, avg_loss=1.3644, train_err=0.0682, 32_h1=0.0722, 32_l2=0.0370, 64_h1=0.1618, 64_l2=0.0573\n",
      "[51] time=2.34, avg_loss=1.4409, train_err=0.0720, 32_h1=0.0763, 32_l2=0.0411, 64_h1=0.1640, 64_l2=0.0623\n",
      "[52] time=2.34, avg_loss=1.3055, train_err=0.0653, 32_h1=0.0769, 32_l2=0.0402, 64_h1=0.1608, 64_l2=0.0564\n",
      "[53] time=2.35, avg_loss=1.3591, train_err=0.0680, 32_h1=0.0799, 32_l2=0.0455, 64_h1=0.1708, 64_l2=0.0657\n",
      "[54] time=2.36, avg_loss=1.4242, train_err=0.0712, 32_h1=0.0744, 32_l2=0.0379, 64_h1=0.1612, 64_l2=0.0535\n",
      "[55] time=2.34, avg_loss=1.2851, train_err=0.0643, 32_h1=0.0754, 32_l2=0.0407, 64_h1=0.1514, 64_l2=0.0515\n",
      "[56] time=2.37, avg_loss=1.3019, train_err=0.0651, 32_h1=0.0768, 32_l2=0.0423, 64_h1=0.1596, 64_l2=0.0587\n",
      "[57] time=2.35, avg_loss=1.3110, train_err=0.0655, 32_h1=0.0795, 32_l2=0.0465, 64_h1=0.1534, 64_l2=0.0525\n",
      "[58] time=2.35, avg_loss=1.4699, train_err=0.0735, 32_h1=0.0748, 32_l2=0.0386, 64_h1=0.1545, 64_l2=0.0562\n",
      "[59] time=2.32, avg_loss=1.2939, train_err=0.0647, 32_h1=0.0744, 32_l2=0.0389, 64_h1=0.1554, 64_l2=0.0551\n",
      "[60] time=2.33, avg_loss=1.3099, train_err=0.0655, 32_h1=0.0728, 32_l2=0.0360, 64_h1=0.1577, 64_l2=0.0537\n",
      "[61] time=2.41, avg_loss=1.2244, train_err=0.0612, 32_h1=0.0733, 32_l2=0.0376, 64_h1=0.1557, 64_l2=0.0550\n",
      "[62] time=2.36, avg_loss=1.2244, train_err=0.0612, 32_h1=0.0715, 32_l2=0.0347, 64_h1=0.1544, 64_l2=0.0515\n",
      "[63] time=2.36, avg_loss=1.2458, train_err=0.0623, 32_h1=0.0791, 32_l2=0.0462, 64_h1=0.1634, 64_l2=0.0659\n",
      "[64] time=2.35, avg_loss=1.2674, train_err=0.0634, 32_h1=0.0767, 32_l2=0.0415, 64_h1=0.1497, 64_l2=0.0541\n",
      "[65] time=2.37, avg_loss=1.2744, train_err=0.0637, 32_h1=0.0762, 32_l2=0.0430, 64_h1=0.1557, 64_l2=0.0601\n",
      "[66] time=2.37, avg_loss=1.3186, train_err=0.0659, 32_h1=0.0749, 32_l2=0.0394, 64_h1=0.1582, 64_l2=0.0559\n",
      "[67] time=2.38, avg_loss=1.2080, train_err=0.0604, 32_h1=0.0742, 32_l2=0.0373, 64_h1=0.1522, 64_l2=0.0502\n",
      "[68] time=2.35, avg_loss=1.2001, train_err=0.0600, 32_h1=0.0739, 32_l2=0.0373, 64_h1=0.1581, 64_l2=0.0523\n",
      "[69] time=2.40, avg_loss=1.2024, train_err=0.0601, 32_h1=0.0740, 32_l2=0.0364, 64_h1=0.1573, 64_l2=0.0540\n",
      "[70] time=2.35, avg_loss=1.2046, train_err=0.0602, 32_h1=0.0749, 32_l2=0.0379, 64_h1=0.1556, 64_l2=0.0518\n",
      "[71] time=2.39, avg_loss=1.1955, train_err=0.0598, 32_h1=0.0781, 32_l2=0.0423, 64_h1=0.1565, 64_l2=0.0547\n",
      "[72] time=2.44, avg_loss=1.2451, train_err=0.0623, 32_h1=0.0757, 32_l2=0.0385, 64_h1=0.1618, 64_l2=0.0584\n",
      "[73] time=2.39, avg_loss=1.2514, train_err=0.0626, 32_h1=0.0789, 32_l2=0.0416, 64_h1=0.1538, 64_l2=0.0523\n",
      "[74] time=2.39, avg_loss=1.2147, train_err=0.0607, 32_h1=0.0763, 32_l2=0.0384, 64_h1=0.1629, 64_l2=0.0588\n",
      "[75] time=2.43, avg_loss=1.1396, train_err=0.0570, 32_h1=0.0752, 32_l2=0.0368, 64_h1=0.1629, 64_l2=0.0577\n",
      "[76] time=2.42, avg_loss=1.1280, train_err=0.0564, 32_h1=0.0745, 32_l2=0.0364, 64_h1=0.1590, 64_l2=0.0532\n",
      "[77] time=2.35, avg_loss=1.1244, train_err=0.0562, 32_h1=0.0765, 32_l2=0.0384, 64_h1=0.1612, 64_l2=0.0497\n",
      "[78] time=2.38, avg_loss=1.1327, train_err=0.0566, 32_h1=0.0752, 32_l2=0.0362, 64_h1=0.1570, 64_l2=0.0503\n",
      "[79] time=2.32, avg_loss=1.1106, train_err=0.0555, 32_h1=0.0746, 32_l2=0.0361, 64_h1=0.1571, 64_l2=0.0530\n",
      "[80] time=2.34, avg_loss=1.1171, train_err=0.0559, 32_h1=0.0769, 32_l2=0.0391, 64_h1=0.1574, 64_l2=0.0525\n",
      "[81] time=2.37, avg_loss=1.1051, train_err=0.0553, 32_h1=0.0763, 32_l2=0.0391, 64_h1=0.1537, 64_l2=0.0550\n",
      "[82] time=2.33, avg_loss=1.0863, train_err=0.0543, 32_h1=0.0771, 32_l2=0.0399, 64_h1=0.1576, 64_l2=0.0546\n",
      "[83] time=2.37, avg_loss=1.0686, train_err=0.0534, 32_h1=0.0751, 32_l2=0.0363, 64_h1=0.1619, 64_l2=0.0548\n",
      "[84] time=2.41, avg_loss=1.0893, train_err=0.0545, 32_h1=0.0783, 32_l2=0.0392, 64_h1=0.1559, 64_l2=0.0517\n",
      "[85] time=2.29, avg_loss=1.0972, train_err=0.0549, 32_h1=0.0809, 32_l2=0.0424, 64_h1=0.1523, 64_l2=0.0509\n",
      "[86] time=2.06, avg_loss=1.0827, train_err=0.0541, 32_h1=0.0767, 32_l2=0.0391, 64_h1=0.1606, 64_l2=0.0542\n",
      "[87] time=2.07, avg_loss=1.0508, train_err=0.0525, 32_h1=0.0763, 32_l2=0.0364, 64_h1=0.1615, 64_l2=0.0552\n",
      "[88] time=2.10, avg_loss=1.0436, train_err=0.0522, 32_h1=0.0761, 32_l2=0.0361, 64_h1=0.1606, 64_l2=0.0538\n",
      "[89] time=2.17, avg_loss=1.0279, train_err=0.0514, 32_h1=0.0794, 32_l2=0.0451, 64_h1=0.1636, 64_l2=0.0608\n",
      "[90] time=2.22, avg_loss=1.0104, train_err=0.0505, 32_h1=0.0780, 32_l2=0.0383, 64_h1=0.1563, 64_l2=0.0520\n",
      "[91] time=2.12, avg_loss=1.0424, train_err=0.0521, 32_h1=0.0778, 32_l2=0.0386, 64_h1=0.1548, 64_l2=0.0500\n",
      "[92] time=2.23, avg_loss=1.0263, train_err=0.0513, 32_h1=0.0772, 32_l2=0.0373, 64_h1=0.1574, 64_l2=0.0537\n",
      "[93] time=2.26, avg_loss=1.0422, train_err=0.0521, 32_h1=0.0782, 32_l2=0.0394, 64_h1=0.1601, 64_l2=0.0571\n",
      "[94] time=2.13, avg_loss=1.0333, train_err=0.0517, 32_h1=0.0785, 32_l2=0.0387, 64_h1=0.1656, 64_l2=0.0579\n",
      "[95] time=2.26, avg_loss=1.0304, train_err=0.0515, 32_h1=0.0777, 32_l2=0.0379, 64_h1=0.1600, 64_l2=0.0533\n",
      "[96] time=2.28, avg_loss=0.9738, train_err=0.0487, 32_h1=0.0773, 32_l2=0.0365, 64_h1=0.1642, 64_l2=0.0579\n",
      "[97] time=2.07, avg_loss=0.9928, train_err=0.0496, 32_h1=0.0812, 32_l2=0.0431, 64_h1=0.1612, 64_l2=0.0596\n",
      "[98] time=2.18, avg_loss=0.9883, train_err=0.0494, 32_h1=0.0766, 32_l2=0.0365, 64_h1=0.1616, 64_l2=0.0568\n",
      "[99] time=2.17, avg_loss=1.0263, train_err=0.0513, 32_h1=0.0870, 32_l2=0.0492, 64_h1=0.1585, 64_l2=0.0622\n",
      "[100] time=2.24, avg_loss=1.0148, train_err=0.0507, 32_h1=0.0770, 32_l2=0.0375, 64_h1=0.1637, 64_l2=0.0543\n",
      "[101] time=2.24, avg_loss=0.9469, train_err=0.0473, 32_h1=0.0764, 32_l2=0.0361, 64_h1=0.1611, 64_l2=0.0550\n",
      "[102] time=2.22, avg_loss=0.9222, train_err=0.0461, 32_h1=0.0779, 32_l2=0.0379, 64_h1=0.1649, 64_l2=0.0574\n",
      "[103] time=2.06, avg_loss=0.9607, train_err=0.0480, 32_h1=0.0783, 32_l2=0.0379, 64_h1=0.1608, 64_l2=0.0534\n",
      "[104] time=2.11, avg_loss=0.9403, train_err=0.0470, 32_h1=0.0770, 32_l2=0.0367, 64_h1=0.1617, 64_l2=0.0574\n",
      "[105] time=2.20, avg_loss=0.9275, train_err=0.0464, 32_h1=0.0781, 32_l2=0.0387, 64_h1=0.1583, 64_l2=0.0530\n",
      "[106] time=2.19, avg_loss=0.9224, train_err=0.0461, 32_h1=0.0778, 32_l2=0.0376, 64_h1=0.1608, 64_l2=0.0581\n",
      "[107] time=2.14, avg_loss=0.9172, train_err=0.0459, 32_h1=0.0791, 32_l2=0.0386, 64_h1=0.1628, 64_l2=0.0534\n",
      "[108] time=2.24, avg_loss=0.9309, train_err=0.0465, 32_h1=0.0764, 32_l2=0.0363, 64_h1=0.1626, 64_l2=0.0540\n",
      "[109] time=2.22, avg_loss=0.9154, train_err=0.0458, 32_h1=0.0815, 32_l2=0.0427, 64_h1=0.1613, 64_l2=0.0622\n",
      "[110] time=2.22, avg_loss=0.9323, train_err=0.0466, 32_h1=0.0806, 32_l2=0.0411, 64_h1=0.1660, 64_l2=0.0596\n",
      "[111] time=2.25, avg_loss=0.9244, train_err=0.0462, 32_h1=0.0765, 32_l2=0.0359, 64_h1=0.1595, 64_l2=0.0544\n",
      "[112] time=2.23, avg_loss=0.8931, train_err=0.0447, 32_h1=0.0796, 32_l2=0.0409, 64_h1=0.1597, 64_l2=0.0570\n",
      "[113] time=2.15, avg_loss=0.8902, train_err=0.0445, 32_h1=0.0783, 32_l2=0.0385, 64_h1=0.1619, 64_l2=0.0570\n",
      "[114] time=2.47, avg_loss=0.9088, train_err=0.0454, 32_h1=0.0778, 32_l2=0.0364, 64_h1=0.1623, 64_l2=0.0572\n",
      "[115] time=2.39, avg_loss=0.8836, train_err=0.0442, 32_h1=0.0777, 32_l2=0.0360, 64_h1=0.1602, 64_l2=0.0562\n",
      "[116] time=2.38, avg_loss=0.8740, train_err=0.0437, 32_h1=0.0792, 32_l2=0.0375, 64_h1=0.1606, 64_l2=0.0527\n",
      "[117] time=2.35, avg_loss=0.8816, train_err=0.0441, 32_h1=0.0789, 32_l2=0.0383, 64_h1=0.1624, 64_l2=0.0565\n",
      "[118] time=2.38, avg_loss=0.8681, train_err=0.0434, 32_h1=0.0798, 32_l2=0.0397, 64_h1=0.1628, 64_l2=0.0589\n",
      "[119] time=2.35, avg_loss=0.8823, train_err=0.0441, 32_h1=0.0776, 32_l2=0.0355, 64_h1=0.1654, 64_l2=0.0556\n",
      "[120] time=2.44, avg_loss=0.8396, train_err=0.0420, 32_h1=0.0779, 32_l2=0.0371, 64_h1=0.1587, 64_l2=0.0529\n",
      "[121] time=2.35, avg_loss=0.8663, train_err=0.0433, 32_h1=0.0795, 32_l2=0.0378, 64_h1=0.1610, 64_l2=0.0556\n",
      "[122] time=2.36, avg_loss=0.8566, train_err=0.0428, 32_h1=0.0793, 32_l2=0.0392, 64_h1=0.1562, 64_l2=0.0513\n",
      "[123] time=2.36, avg_loss=0.8648, train_err=0.0432, 32_h1=0.0793, 32_l2=0.0390, 64_h1=0.1614, 64_l2=0.0542\n",
      "[124] time=2.37, avg_loss=0.8420, train_err=0.0421, 32_h1=0.0774, 32_l2=0.0360, 64_h1=0.1610, 64_l2=0.0523\n",
      "[125] time=2.41, avg_loss=0.8392, train_err=0.0420, 32_h1=0.0780, 32_l2=0.0371, 64_h1=0.1623, 64_l2=0.0556\n",
      "[126] time=2.35, avg_loss=0.8208, train_err=0.0410, 32_h1=0.0781, 32_l2=0.0362, 64_h1=0.1647, 64_l2=0.0554\n",
      "[127] time=2.33, avg_loss=0.8183, train_err=0.0409, 32_h1=0.0782, 32_l2=0.0372, 64_h1=0.1624, 64_l2=0.0577\n",
      "[128] time=2.36, avg_loss=0.8096, train_err=0.0405, 32_h1=0.0776, 32_l2=0.0368, 64_h1=0.1633, 64_l2=0.0567\n",
      "[129] time=2.32, avg_loss=0.8198, train_err=0.0410, 32_h1=0.0793, 32_l2=0.0372, 64_h1=0.1635, 64_l2=0.0559\n",
      "[130] time=2.38, avg_loss=0.8127, train_err=0.0406, 32_h1=0.0778, 32_l2=0.0363, 64_h1=0.1620, 64_l2=0.0536\n",
      "[131] time=2.39, avg_loss=0.7946, train_err=0.0397, 32_h1=0.0782, 32_l2=0.0372, 64_h1=0.1632, 64_l2=0.0563\n",
      "[132] time=2.48, avg_loss=0.7853, train_err=0.0393, 32_h1=0.0786, 32_l2=0.0363, 64_h1=0.1652, 64_l2=0.0592\n",
      "[133] time=2.37, avg_loss=0.8217, train_err=0.0411, 32_h1=0.0782, 32_l2=0.0373, 64_h1=0.1611, 64_l2=0.0552\n",
      "[134] time=2.39, avg_loss=0.8128, train_err=0.0406, 32_h1=0.0787, 32_l2=0.0374, 64_h1=0.1583, 64_l2=0.0541\n",
      "[135] time=2.35, avg_loss=0.8180, train_err=0.0409, 32_h1=0.0819, 32_l2=0.0433, 64_h1=0.1703, 64_l2=0.0648\n",
      "[136] time=2.40, avg_loss=0.8340, train_err=0.0417, 32_h1=0.0793, 32_l2=0.0383, 64_h1=0.1645, 64_l2=0.0575\n",
      "[137] time=2.35, avg_loss=0.7980, train_err=0.0399, 32_h1=0.0778, 32_l2=0.0366, 64_h1=0.1610, 64_l2=0.0552\n",
      "[138] time=2.32, avg_loss=0.7696, train_err=0.0385, 32_h1=0.0787, 32_l2=0.0373, 64_h1=0.1626, 64_l2=0.0561\n",
      "[139] time=2.38, avg_loss=0.7698, train_err=0.0385, 32_h1=0.0787, 32_l2=0.0360, 64_h1=0.1645, 64_l2=0.0563\n",
      "[140] time=2.41, avg_loss=0.7572, train_err=0.0379, 32_h1=0.0793, 32_l2=0.0379, 64_h1=0.1593, 64_l2=0.0559\n",
      "[141] time=2.37, avg_loss=0.7578, train_err=0.0379, 32_h1=0.0785, 32_l2=0.0366, 64_h1=0.1616, 64_l2=0.0521\n",
      "[142] time=2.32, avg_loss=0.7577, train_err=0.0379, 32_h1=0.0793, 32_l2=0.0376, 64_h1=0.1620, 64_l2=0.0570\n",
      "[143] time=2.42, avg_loss=0.7629, train_err=0.0381, 32_h1=0.0784, 32_l2=0.0362, 64_h1=0.1635, 64_l2=0.0551\n",
      "[144] time=2.33, avg_loss=0.7273, train_err=0.0364, 32_h1=0.0775, 32_l2=0.0352, 64_h1=0.1619, 64_l2=0.0544\n",
      "[145] time=2.37, avg_loss=0.7391, train_err=0.0370, 32_h1=0.0803, 32_l2=0.0391, 64_h1=0.1635, 64_l2=0.0566\n",
      "[146] time=2.36, avg_loss=0.7521, train_err=0.0376, 32_h1=0.0782, 32_l2=0.0365, 64_h1=0.1606, 64_l2=0.0534\n",
      "[147] time=2.39, avg_loss=0.7506, train_err=0.0375, 32_h1=0.0806, 32_l2=0.0399, 64_h1=0.1646, 64_l2=0.0594\n",
      "[148] time=2.43, avg_loss=0.7536, train_err=0.0377, 32_h1=0.0793, 32_l2=0.0374, 64_h1=0.1642, 64_l2=0.0564\n",
      "[149] time=2.37, avg_loss=0.7287, train_err=0.0364, 32_h1=0.0777, 32_l2=0.0355, 64_h1=0.1626, 64_l2=0.0530\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=28\n",
      "tfno2d.n_modes_width=28\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.2\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 610897\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 14, 14), rank=(21, 21, 9, 9))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 14, 14), rank=(21, 21, 9, 9))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 14, 14), rank=(21, 21, 9, 9))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 14, 14), rank=(21, 21, 9, 9))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 14, 14), rank=(21, 21, 9, 9))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 14, 14), rank=(21, 21, 9, 9))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 14, 14), rank=(21, 21, 9, 9))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 14, 14), rank=(21, 21, 9, 9))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f776fdbba30>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f776fd8cac0>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f776fd8cac0>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f7761b37760>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.34, avg_loss=10.0036, train_err=0.5002, 32_h1=0.2722, 32_l2=0.1920, 64_h1=0.3469, 64_l2=0.1985\n",
      "[1] time=2.36, avg_loss=4.4013, train_err=0.2201, 32_h1=0.1986, 32_l2=0.1424, 64_h1=0.2687, 64_l2=0.1482\n",
      "[2] time=2.28, avg_loss=3.3295, train_err=0.1665, 32_h1=0.1511, 32_l2=0.1028, 64_h1=0.2208, 64_l2=0.1070\n",
      "[3] time=2.18, avg_loss=2.9388, train_err=0.1469, 32_h1=0.1545, 32_l2=0.1049, 64_h1=0.2119, 64_l2=0.1119\n",
      "[4] time=2.26, avg_loss=2.5209, train_err=0.1260, 32_h1=0.1364, 32_l2=0.0942, 64_h1=0.2063, 64_l2=0.1011\n",
      "[5] time=2.23, avg_loss=2.4109, train_err=0.1205, 32_h1=0.1049, 32_l2=0.0584, 64_h1=0.1803, 64_l2=0.0694\n",
      "[6] time=2.21, avg_loss=2.1497, train_err=0.1075, 32_h1=0.1024, 32_l2=0.0587, 64_h1=0.1844, 64_l2=0.0723\n",
      "[7] time=2.21, avg_loss=2.1110, train_err=0.1056, 32_h1=0.1018, 32_l2=0.0598, 64_h1=0.1851, 64_l2=0.0759\n",
      "[8] time=2.23, avg_loss=2.0966, train_err=0.1048, 32_h1=0.1184, 32_l2=0.0921, 64_h1=0.1994, 64_l2=0.1037\n",
      "[9] time=2.24, avg_loss=2.0009, train_err=0.1000, 32_h1=0.0944, 32_l2=0.0572, 64_h1=0.1664, 64_l2=0.0710\n",
      "[10] time=2.26, avg_loss=1.9189, train_err=0.0959, 32_h1=0.0905, 32_l2=0.0516, 64_h1=0.1722, 64_l2=0.0650\n",
      "[11] time=2.26, avg_loss=1.8281, train_err=0.0914, 32_h1=0.0923, 32_l2=0.0548, 64_h1=0.1750, 64_l2=0.0725\n",
      "[12] time=2.26, avg_loss=1.8043, train_err=0.0902, 32_h1=0.0908, 32_l2=0.0547, 64_h1=0.1723, 64_l2=0.0667\n",
      "[13] time=2.14, avg_loss=1.9649, train_err=0.0982, 32_h1=0.1034, 32_l2=0.0737, 64_h1=0.1868, 64_l2=0.0844\n",
      "[14] time=2.24, avg_loss=1.8359, train_err=0.0918, 32_h1=0.0936, 32_l2=0.0561, 64_h1=0.1621, 64_l2=0.0632\n",
      "[15] time=2.24, avg_loss=1.8034, train_err=0.0902, 32_h1=0.0962, 32_l2=0.0574, 64_h1=0.1774, 64_l2=0.0697\n",
      "[16] time=2.12, avg_loss=1.7584, train_err=0.0879, 32_h1=0.0969, 32_l2=0.0643, 64_h1=0.1787, 64_l2=0.0777\n",
      "[17] time=2.10, avg_loss=1.7678, train_err=0.0884, 32_h1=0.0855, 32_l2=0.0507, 64_h1=0.1734, 64_l2=0.0702\n",
      "[18] time=2.21, avg_loss=1.6864, train_err=0.0843, 32_h1=0.0876, 32_l2=0.0506, 64_h1=0.1662, 64_l2=0.0645\n",
      "[19] time=2.20, avg_loss=1.6767, train_err=0.0838, 32_h1=0.0827, 32_l2=0.0467, 64_h1=0.1679, 64_l2=0.0642\n",
      "[20] time=2.16, avg_loss=1.6089, train_err=0.0804, 32_h1=0.0868, 32_l2=0.0563, 64_h1=0.1714, 64_l2=0.0685\n",
      "[21] time=2.21, avg_loss=1.6389, train_err=0.0819, 32_h1=0.0830, 32_l2=0.0459, 64_h1=0.1610, 64_l2=0.0604\n",
      "[22] time=2.12, avg_loss=1.5475, train_err=0.0774, 32_h1=0.0827, 32_l2=0.0477, 64_h1=0.1567, 64_l2=0.0566\n",
      "[23] time=2.19, avg_loss=1.6002, train_err=0.0800, 32_h1=0.0890, 32_l2=0.0589, 64_h1=0.1631, 64_l2=0.0685\n",
      "[24] time=2.10, avg_loss=1.5576, train_err=0.0779, 32_h1=0.0765, 32_l2=0.0417, 64_h1=0.1604, 64_l2=0.0597\n",
      "[25] time=2.15, avg_loss=1.5989, train_err=0.0799, 32_h1=0.0944, 32_l2=0.0558, 64_h1=0.1729, 64_l2=0.0710\n",
      "[26] time=2.22, avg_loss=1.5676, train_err=0.0784, 32_h1=0.0864, 32_l2=0.0549, 64_h1=0.1649, 64_l2=0.0652\n",
      "[27] time=2.22, avg_loss=1.6319, train_err=0.0816, 32_h1=0.0790, 32_l2=0.0426, 64_h1=0.1619, 64_l2=0.0604\n",
      "[28] time=2.22, avg_loss=1.5511, train_err=0.0776, 32_h1=0.0909, 32_l2=0.0558, 64_h1=0.1583, 64_l2=0.0638\n",
      "[29] time=2.28, avg_loss=1.5019, train_err=0.0751, 32_h1=0.0789, 32_l2=0.0448, 64_h1=0.1490, 64_l2=0.0536\n",
      "[30] time=2.23, avg_loss=1.5022, train_err=0.0751, 32_h1=0.0772, 32_l2=0.0432, 64_h1=0.1556, 64_l2=0.0554\n",
      "[31] time=2.44, avg_loss=1.4776, train_err=0.0739, 32_h1=0.0736, 32_l2=0.0386, 64_h1=0.1542, 64_l2=0.0563\n",
      "[32] time=2.35, avg_loss=1.4932, train_err=0.0747, 32_h1=0.0913, 32_l2=0.0600, 64_h1=0.1666, 64_l2=0.0712\n",
      "[33] time=2.40, avg_loss=1.5431, train_err=0.0772, 32_h1=0.0766, 32_l2=0.0415, 64_h1=0.1578, 64_l2=0.0553\n",
      "[34] time=2.35, avg_loss=1.4741, train_err=0.0737, 32_h1=0.0826, 32_l2=0.0472, 64_h1=0.1585, 64_l2=0.0586\n",
      "[35] time=2.38, avg_loss=1.4585, train_err=0.0729, 32_h1=0.0762, 32_l2=0.0430, 64_h1=0.1539, 64_l2=0.0559\n",
      "[36] time=2.40, avg_loss=1.4533, train_err=0.0727, 32_h1=0.0806, 32_l2=0.0472, 64_h1=0.1550, 64_l2=0.0590\n",
      "[37] time=2.35, avg_loss=1.5117, train_err=0.0756, 32_h1=0.0775, 32_l2=0.0407, 64_h1=0.1590, 64_l2=0.0570\n",
      "[38] time=2.36, avg_loss=1.5169, train_err=0.0758, 32_h1=0.0949, 32_l2=0.0644, 64_h1=0.1605, 64_l2=0.0723\n",
      "[39] time=2.36, avg_loss=1.4726, train_err=0.0736, 32_h1=0.0753, 32_l2=0.0392, 64_h1=0.1613, 64_l2=0.0617\n",
      "[40] time=2.42, avg_loss=1.4221, train_err=0.0711, 32_h1=0.0795, 32_l2=0.0493, 64_h1=0.1526, 64_l2=0.0595\n",
      "[41] time=2.36, avg_loss=1.4241, train_err=0.0712, 32_h1=0.0806, 32_l2=0.0459, 64_h1=0.1540, 64_l2=0.0577\n",
      "[42] time=2.33, avg_loss=1.4022, train_err=0.0701, 32_h1=0.0765, 32_l2=0.0444, 64_h1=0.1529, 64_l2=0.0564\n",
      "[43] time=2.35, avg_loss=1.3988, train_err=0.0699, 32_h1=0.0752, 32_l2=0.0430, 64_h1=0.1515, 64_l2=0.0544\n",
      "[44] time=2.34, avg_loss=1.4446, train_err=0.0722, 32_h1=0.0730, 32_l2=0.0383, 64_h1=0.1599, 64_l2=0.0569\n",
      "[45] time=2.35, avg_loss=1.4172, train_err=0.0709, 32_h1=0.0759, 32_l2=0.0414, 64_h1=0.1563, 64_l2=0.0594\n",
      "[46] time=2.35, avg_loss=1.3778, train_err=0.0689, 32_h1=0.0729, 32_l2=0.0367, 64_h1=0.1621, 64_l2=0.0560\n",
      "[47] time=2.36, avg_loss=1.3818, train_err=0.0691, 32_h1=0.0756, 32_l2=0.0447, 64_h1=0.1610, 64_l2=0.0634\n",
      "[48] time=2.35, avg_loss=1.4361, train_err=0.0718, 32_h1=0.0723, 32_l2=0.0370, 64_h1=0.1472, 64_l2=0.0527\n",
      "[49] time=2.33, avg_loss=1.3902, train_err=0.0695, 32_h1=0.0737, 32_l2=0.0398, 64_h1=0.1566, 64_l2=0.0556\n",
      "[50] time=2.32, avg_loss=1.3415, train_err=0.0671, 32_h1=0.0734, 32_l2=0.0401, 64_h1=0.1519, 64_l2=0.0542\n",
      "[51] time=2.33, avg_loss=1.3794, train_err=0.0690, 32_h1=0.0727, 32_l2=0.0376, 64_h1=0.1548, 64_l2=0.0561\n",
      "[52] time=2.40, avg_loss=1.3553, train_err=0.0678, 32_h1=0.0746, 32_l2=0.0427, 64_h1=0.1578, 64_l2=0.0556\n",
      "[53] time=2.37, avg_loss=1.3504, train_err=0.0675, 32_h1=0.0731, 32_l2=0.0384, 64_h1=0.1496, 64_l2=0.0493\n",
      "[54] time=2.32, avg_loss=1.3528, train_err=0.0676, 32_h1=0.0739, 32_l2=0.0396, 64_h1=0.1553, 64_l2=0.0546\n",
      "[55] time=2.42, avg_loss=1.3653, train_err=0.0683, 32_h1=0.0719, 32_l2=0.0377, 64_h1=0.1493, 64_l2=0.0531\n",
      "[56] time=2.35, avg_loss=1.3805, train_err=0.0690, 32_h1=0.0706, 32_l2=0.0351, 64_h1=0.1512, 64_l2=0.0492\n",
      "[57] time=2.36, avg_loss=1.3691, train_err=0.0685, 32_h1=0.0736, 32_l2=0.0384, 64_h1=0.1561, 64_l2=0.0533\n",
      "[58] time=2.36, avg_loss=1.3164, train_err=0.0658, 32_h1=0.0699, 32_l2=0.0338, 64_h1=0.1517, 64_l2=0.0494\n",
      "[59] time=2.38, avg_loss=1.3159, train_err=0.0658, 32_h1=0.0750, 32_l2=0.0394, 64_h1=0.1483, 64_l2=0.0478\n",
      "[60] time=2.38, avg_loss=1.3223, train_err=0.0661, 32_h1=0.0752, 32_l2=0.0453, 64_h1=0.1657, 64_l2=0.0659\n",
      "[61] time=2.35, avg_loss=1.3055, train_err=0.0653, 32_h1=0.0794, 32_l2=0.0464, 64_h1=0.1582, 64_l2=0.0596\n",
      "[62] time=2.36, avg_loss=1.3353, train_err=0.0668, 32_h1=0.0778, 32_l2=0.0436, 64_h1=0.1590, 64_l2=0.0604\n",
      "[63] time=2.40, avg_loss=1.3022, train_err=0.0651, 32_h1=0.0718, 32_l2=0.0351, 64_h1=0.1535, 64_l2=0.0511\n",
      "[64] time=2.35, avg_loss=1.3200, train_err=0.0660, 32_h1=0.0841, 32_l2=0.0530, 64_h1=0.1643, 64_l2=0.0673\n",
      "[65] time=2.38, avg_loss=1.3025, train_err=0.0651, 32_h1=0.0728, 32_l2=0.0388, 64_h1=0.1476, 64_l2=0.0504\n",
      "[66] time=2.35, avg_loss=1.3005, train_err=0.0650, 32_h1=0.0736, 32_l2=0.0373, 64_h1=0.1567, 64_l2=0.0549\n",
      "[67] time=2.39, avg_loss=1.2646, train_err=0.0632, 32_h1=0.0727, 32_l2=0.0361, 64_h1=0.1502, 64_l2=0.0472\n",
      "[68] time=2.37, avg_loss=1.2531, train_err=0.0627, 32_h1=0.0714, 32_l2=0.0348, 64_h1=0.1550, 64_l2=0.0511\n",
      "[69] time=2.19, avg_loss=1.2185, train_err=0.0609, 32_h1=0.0720, 32_l2=0.0351, 64_h1=0.1585, 64_l2=0.0539\n",
      "[70] time=2.15, avg_loss=1.2277, train_err=0.0614, 32_h1=0.0771, 32_l2=0.0442, 64_h1=0.1606, 64_l2=0.0608\n",
      "[71] time=2.09, avg_loss=1.2411, train_err=0.0621, 32_h1=0.0762, 32_l2=0.0405, 64_h1=0.1542, 64_l2=0.0510\n",
      "[72] time=2.08, avg_loss=1.2154, train_err=0.0608, 32_h1=0.0730, 32_l2=0.0380, 64_h1=0.1523, 64_l2=0.0499\n",
      "[73] time=2.22, avg_loss=1.2207, train_err=0.0610, 32_h1=0.0728, 32_l2=0.0355, 64_h1=0.1561, 64_l2=0.0523\n",
      "[74] time=2.09, avg_loss=1.1775, train_err=0.0589, 32_h1=0.0722, 32_l2=0.0348, 64_h1=0.1565, 64_l2=0.0545\n",
      "[75] time=2.24, avg_loss=1.1777, train_err=0.0589, 32_h1=0.0746, 32_l2=0.0391, 64_h1=0.1506, 64_l2=0.0512\n",
      "[76] time=2.12, avg_loss=1.1563, train_err=0.0578, 32_h1=0.0732, 32_l2=0.0356, 64_h1=0.1538, 64_l2=0.0494\n",
      "[77] time=2.10, avg_loss=1.1633, train_err=0.0582, 32_h1=0.0733, 32_l2=0.0361, 64_h1=0.1574, 64_l2=0.0538\n",
      "[78] time=2.25, avg_loss=1.2047, train_err=0.0602, 32_h1=0.0787, 32_l2=0.0425, 64_h1=0.1548, 64_l2=0.0559\n",
      "[79] time=2.22, avg_loss=1.1946, train_err=0.0597, 32_h1=0.0759, 32_l2=0.0396, 64_h1=0.1500, 64_l2=0.0495\n",
      "[80] time=2.20, avg_loss=1.1473, train_err=0.0574, 32_h1=0.0749, 32_l2=0.0370, 64_h1=0.1552, 64_l2=0.0518\n",
      "[81] time=2.15, avg_loss=1.1048, train_err=0.0552, 32_h1=0.0732, 32_l2=0.0353, 64_h1=0.1499, 64_l2=0.0471\n",
      "[82] time=2.26, avg_loss=1.1378, train_err=0.0569, 32_h1=0.0751, 32_l2=0.0364, 64_h1=0.1588, 64_l2=0.0546\n",
      "[83] time=2.08, avg_loss=1.1227, train_err=0.0561, 32_h1=0.0787, 32_l2=0.0418, 64_h1=0.1524, 64_l2=0.0535\n",
      "[84] time=2.19, avg_loss=1.0897, train_err=0.0545, 32_h1=0.0747, 32_l2=0.0357, 64_h1=0.1592, 64_l2=0.0541\n",
      "[85] time=2.23, avg_loss=1.0645, train_err=0.0532, 32_h1=0.0750, 32_l2=0.0373, 64_h1=0.1537, 64_l2=0.0530\n",
      "[86] time=2.16, avg_loss=1.0697, train_err=0.0535, 32_h1=0.0762, 32_l2=0.0391, 64_h1=0.1570, 64_l2=0.0572\n",
      "[87] time=2.14, avg_loss=1.0806, train_err=0.0540, 32_h1=0.0797, 32_l2=0.0427, 64_h1=0.1541, 64_l2=0.0553\n",
      "[88] time=2.19, avg_loss=1.0593, train_err=0.0530, 32_h1=0.0773, 32_l2=0.0411, 64_h1=0.1526, 64_l2=0.0517\n",
      "[89] time=2.21, avg_loss=1.0562, train_err=0.0528, 32_h1=0.0756, 32_l2=0.0365, 64_h1=0.1499, 64_l2=0.0486\n",
      "[90] time=2.25, avg_loss=1.0435, train_err=0.0522, 32_h1=0.0767, 32_l2=0.0374, 64_h1=0.1503, 64_l2=0.0498\n",
      "[91] time=2.24, avg_loss=1.0128, train_err=0.0506, 32_h1=0.0755, 32_l2=0.0361, 64_h1=0.1510, 64_l2=0.0495\n",
      "[92] time=2.25, avg_loss=0.9908, train_err=0.0495, 32_h1=0.0762, 32_l2=0.0371, 64_h1=0.1615, 64_l2=0.0547\n",
      "[93] time=2.17, avg_loss=1.0235, train_err=0.0512, 32_h1=0.0787, 32_l2=0.0408, 64_h1=0.1584, 64_l2=0.0607\n",
      "[94] time=2.15, avg_loss=1.0604, train_err=0.0530, 32_h1=0.0766, 32_l2=0.0375, 64_h1=0.1579, 64_l2=0.0533\n",
      "[95] time=2.16, avg_loss=0.9803, train_err=0.0490, 32_h1=0.0749, 32_l2=0.0347, 64_h1=0.1594, 64_l2=0.0543\n",
      "[96] time=2.20, avg_loss=0.9727, train_err=0.0486, 32_h1=0.0771, 32_l2=0.0372, 64_h1=0.1612, 64_l2=0.0592\n",
      "[97] time=2.25, avg_loss=1.0365, train_err=0.0518, 32_h1=0.0769, 32_l2=0.0373, 64_h1=0.1544, 64_l2=0.0516\n",
      "[98] time=2.40, avg_loss=0.9522, train_err=0.0476, 32_h1=0.0770, 32_l2=0.0374, 64_h1=0.1545, 64_l2=0.0507\n",
      "[99] time=2.32, avg_loss=0.9369, train_err=0.0468, 32_h1=0.0773, 32_l2=0.0394, 64_h1=0.1503, 64_l2=0.0500\n",
      "[100] time=2.42, avg_loss=0.9670, train_err=0.0484, 32_h1=0.0788, 32_l2=0.0413, 64_h1=0.1570, 64_l2=0.0581\n",
      "[101] time=2.42, avg_loss=0.9361, train_err=0.0468, 32_h1=0.0795, 32_l2=0.0396, 64_h1=0.1623, 64_l2=0.0578\n",
      "[102] time=2.41, avg_loss=0.9568, train_err=0.0478, 32_h1=0.0754, 32_l2=0.0354, 64_h1=0.1536, 64_l2=0.0507\n",
      "[103] time=2.38, avg_loss=0.9269, train_err=0.0463, 32_h1=0.0767, 32_l2=0.0365, 64_h1=0.1497, 64_l2=0.0473\n",
      "[104] time=2.38, avg_loss=0.9088, train_err=0.0454, 32_h1=0.0756, 32_l2=0.0363, 64_h1=0.1552, 64_l2=0.0512\n",
      "[105] time=2.37, avg_loss=0.8969, train_err=0.0448, 32_h1=0.0762, 32_l2=0.0371, 64_h1=0.1538, 64_l2=0.0528\n",
      "[106] time=2.39, avg_loss=0.8986, train_err=0.0449, 32_h1=0.0756, 32_l2=0.0348, 64_h1=0.1543, 64_l2=0.0517\n",
      "[107] time=2.40, avg_loss=0.8835, train_err=0.0442, 32_h1=0.0770, 32_l2=0.0364, 64_h1=0.1573, 64_l2=0.0523\n",
      "[108] time=2.37, avg_loss=0.8993, train_err=0.0450, 32_h1=0.0784, 32_l2=0.0389, 64_h1=0.1587, 64_l2=0.0553\n",
      "[109] time=2.35, avg_loss=0.8884, train_err=0.0444, 32_h1=0.0761, 32_l2=0.0352, 64_h1=0.1507, 64_l2=0.0499\n",
      "[110] time=2.33, avg_loss=0.8593, train_err=0.0430, 32_h1=0.0767, 32_l2=0.0362, 64_h1=0.1595, 64_l2=0.0530\n",
      "[111] time=2.45, avg_loss=0.8905, train_err=0.0445, 32_h1=0.0763, 32_l2=0.0353, 64_h1=0.1559, 64_l2=0.0498\n",
      "[112] time=2.35, avg_loss=0.8829, train_err=0.0441, 32_h1=0.0781, 32_l2=0.0383, 64_h1=0.1571, 64_l2=0.0542\n",
      "[113] time=2.34, avg_loss=0.8633, train_err=0.0432, 32_h1=0.0771, 32_l2=0.0368, 64_h1=0.1573, 64_l2=0.0510\n",
      "[114] time=2.32, avg_loss=0.8420, train_err=0.0421, 32_h1=0.0769, 32_l2=0.0367, 64_h1=0.1527, 64_l2=0.0488\n",
      "[115] time=2.34, avg_loss=0.8293, train_err=0.0415, 32_h1=0.0764, 32_l2=0.0349, 64_h1=0.1567, 64_l2=0.0499\n",
      "[116] time=2.37, avg_loss=0.8430, train_err=0.0421, 32_h1=0.0787, 32_l2=0.0385, 64_h1=0.1531, 64_l2=0.0497\n",
      "[117] time=2.37, avg_loss=0.8371, train_err=0.0419, 32_h1=0.0783, 32_l2=0.0385, 64_h1=0.1577, 64_l2=0.0525\n",
      "[118] time=2.35, avg_loss=0.8587, train_err=0.0429, 32_h1=0.0769, 32_l2=0.0357, 64_h1=0.1510, 64_l2=0.0478\n",
      "[119] time=2.31, avg_loss=0.8553, train_err=0.0428, 32_h1=0.0806, 32_l2=0.0435, 64_h1=0.1552, 64_l2=0.0574\n",
      "[120] time=2.35, avg_loss=0.8720, train_err=0.0436, 32_h1=0.0767, 32_l2=0.0359, 64_h1=0.1548, 64_l2=0.0523\n",
      "[121] time=2.34, avg_loss=0.8936, train_err=0.0447, 32_h1=0.0772, 32_l2=0.0359, 64_h1=0.1602, 64_l2=0.0532\n",
      "[122] time=2.33, avg_loss=0.8060, train_err=0.0403, 32_h1=0.0769, 32_l2=0.0352, 64_h1=0.1579, 64_l2=0.0531\n",
      "[123] time=2.42, avg_loss=0.7785, train_err=0.0389, 32_h1=0.0765, 32_l2=0.0361, 64_h1=0.1549, 64_l2=0.0530\n",
      "[124] time=2.34, avg_loss=0.7754, train_err=0.0388, 32_h1=0.0770, 32_l2=0.0352, 64_h1=0.1563, 64_l2=0.0517\n",
      "[125] time=2.39, avg_loss=0.7952, train_err=0.0398, 32_h1=0.0773, 32_l2=0.0360, 64_h1=0.1583, 64_l2=0.0537\n",
      "[126] time=2.34, avg_loss=0.7850, train_err=0.0392, 32_h1=0.0771, 32_l2=0.0352, 64_h1=0.1562, 64_l2=0.0537\n",
      "[127] time=2.39, avg_loss=0.7800, train_err=0.0390, 32_h1=0.0773, 32_l2=0.0363, 64_h1=0.1582, 64_l2=0.0531\n",
      "[128] time=2.39, avg_loss=0.7793, train_err=0.0390, 32_h1=0.0777, 32_l2=0.0370, 64_h1=0.1557, 64_l2=0.0511\n",
      "[129] time=2.33, avg_loss=0.7733, train_err=0.0387, 32_h1=0.0781, 32_l2=0.0368, 64_h1=0.1513, 64_l2=0.0507\n",
      "[130] time=2.37, avg_loss=0.7573, train_err=0.0379, 32_h1=0.0802, 32_l2=0.0408, 64_h1=0.1586, 64_l2=0.0574\n",
      "[131] time=2.36, avg_loss=0.7746, train_err=0.0387, 32_h1=0.0774, 32_l2=0.0362, 64_h1=0.1531, 64_l2=0.0511\n",
      "[132] time=2.35, avg_loss=0.7589, train_err=0.0379, 32_h1=0.0767, 32_l2=0.0361, 64_h1=0.1494, 64_l2=0.0488\n",
      "[133] time=2.36, avg_loss=0.7382, train_err=0.0369, 32_h1=0.0775, 32_l2=0.0353, 64_h1=0.1558, 64_l2=0.0516\n",
      "[134] time=2.43, avg_loss=0.7364, train_err=0.0368, 32_h1=0.0769, 32_l2=0.0359, 64_h1=0.1534, 64_l2=0.0536\n",
      "[135] time=2.37, avg_loss=0.7166, train_err=0.0358, 32_h1=0.0762, 32_l2=0.0352, 64_h1=0.1510, 64_l2=0.0485\n",
      "[136] time=2.33, avg_loss=0.7521, train_err=0.0376, 32_h1=0.0763, 32_l2=0.0346, 64_h1=0.1531, 64_l2=0.0506\n",
      "[137] time=2.21, avg_loss=0.7420, train_err=0.0371, 32_h1=0.0758, 32_l2=0.0344, 64_h1=0.1516, 64_l2=0.0491\n",
      "[138] time=2.22, avg_loss=0.7285, train_err=0.0364, 32_h1=0.0765, 32_l2=0.0359, 64_h1=0.1530, 64_l2=0.0507\n",
      "[139] time=2.19, avg_loss=0.7027, train_err=0.0351, 32_h1=0.0758, 32_l2=0.0343, 64_h1=0.1534, 64_l2=0.0500\n",
      "[140] time=2.23, avg_loss=0.7014, train_err=0.0351, 32_h1=0.0771, 32_l2=0.0360, 64_h1=0.1516, 64_l2=0.0521\n",
      "[141] time=2.23, avg_loss=0.7045, train_err=0.0352, 32_h1=0.0770, 32_l2=0.0361, 64_h1=0.1544, 64_l2=0.0524\n",
      "[142] time=2.17, avg_loss=0.7360, train_err=0.0368, 32_h1=0.0764, 32_l2=0.0345, 64_h1=0.1543, 64_l2=0.0497\n",
      "[143] time=2.19, avg_loss=0.6994, train_err=0.0350, 32_h1=0.0765, 32_l2=0.0352, 64_h1=0.1505, 64_l2=0.0494\n",
      "[144] time=2.11, avg_loss=0.6826, train_err=0.0341, 32_h1=0.0772, 32_l2=0.0362, 64_h1=0.1543, 64_l2=0.0533\n",
      "[145] time=2.17, avg_loss=0.7708, train_err=0.0385, 32_h1=0.0773, 32_l2=0.0352, 64_h1=0.1549, 64_l2=0.0528\n",
      "[146] time=2.17, avg_loss=0.6944, train_err=0.0347, 32_h1=0.0783, 32_l2=0.0373, 64_h1=0.1562, 64_l2=0.0512\n",
      "[147] time=2.21, avg_loss=0.6936, train_err=0.0347, 32_h1=0.0771, 32_l2=0.0354, 64_h1=0.1510, 64_l2=0.0478\n",
      "[148] time=2.20, avg_loss=0.6776, train_err=0.0339, 32_h1=0.0762, 32_l2=0.0345, 64_h1=0.1572, 64_l2=0.0499\n",
      "[149] time=2.24, avg_loss=0.6600, train_err=0.0330, 32_h1=0.0772, 32_l2=0.0362, 64_h1=0.1497, 64_l2=0.0484\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=30\n",
      "tfno2d.n_modes_width=30\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.2\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 745729\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 15, 15), rank=(21, 21, 10, 10))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 15, 15), rank=(21, 21, 10, 10))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 15, 15), rank=(21, 21, 10, 10))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 15, 15), rank=(21, 21, 10, 10))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 15, 15), rank=(21, 21, 10, 10))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 15, 15), rank=(21, 21, 10, 10))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 15, 15), rank=(21, 21, 10, 10))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 15, 15), rank=(21, 21, 10, 10))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f7761a60430>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f7761a60a90>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f7761a60a90>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f7761a60af0>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.25, avg_loss=9.7435, train_err=0.4872, 32_h1=0.3009, 32_l2=0.2284, 64_h1=0.3617, 64_l2=0.2305\n",
      "[1] time=2.18, avg_loss=4.5103, train_err=0.2255, 32_h1=0.1940, 32_l2=0.1341, 64_h1=0.2833, 64_l2=0.1418\n",
      "[2] time=2.12, avg_loss=3.3762, train_err=0.1688, 32_h1=0.1702, 32_l2=0.1270, 64_h1=0.2470, 64_l2=0.1422\n",
      "[3] time=2.10, avg_loss=2.8523, train_err=0.1426, 32_h1=0.1211, 32_l2=0.0752, 64_h1=0.1959, 64_l2=0.0848\n",
      "[4] time=2.10, avg_loss=2.5351, train_err=0.1268, 32_h1=0.1167, 32_l2=0.0703, 64_h1=0.1972, 64_l2=0.0844\n",
      "[5] time=2.18, avg_loss=2.4124, train_err=0.1206, 32_h1=0.1083, 32_l2=0.0648, 64_h1=0.1935, 64_l2=0.0758\n",
      "[6] time=2.19, avg_loss=2.2528, train_err=0.1126, 32_h1=0.1079, 32_l2=0.0659, 64_h1=0.1923, 64_l2=0.0761\n",
      "[7] time=2.08, avg_loss=2.1423, train_err=0.1071, 32_h1=0.0975, 32_l2=0.0571, 64_h1=0.1948, 64_l2=0.0733\n",
      "[8] time=2.26, avg_loss=2.0191, train_err=0.1010, 32_h1=0.0961, 32_l2=0.0606, 64_h1=0.1816, 64_l2=0.0750\n",
      "[9] time=2.26, avg_loss=2.0137, train_err=0.1007, 32_h1=0.1102, 32_l2=0.0762, 64_h1=0.1871, 64_l2=0.0786\n",
      "[10] time=2.24, avg_loss=1.9920, train_err=0.0996, 32_h1=0.1000, 32_l2=0.0669, 64_h1=0.1938, 64_l2=0.0773\n",
      "[11] time=2.25, avg_loss=1.8265, train_err=0.0913, 32_h1=0.0901, 32_l2=0.0520, 64_h1=0.1692, 64_l2=0.0592\n",
      "[12] time=2.11, avg_loss=1.7939, train_err=0.0897, 32_h1=0.0927, 32_l2=0.0546, 64_h1=0.1830, 64_l2=0.0722\n",
      "[13] time=2.14, avg_loss=1.9058, train_err=0.0953, 32_h1=0.0956, 32_l2=0.0600, 64_h1=0.1732, 64_l2=0.0667\n",
      "[14] time=2.29, avg_loss=1.7435, train_err=0.0872, 32_h1=0.0975, 32_l2=0.0662, 64_h1=0.1778, 64_l2=0.0834\n",
      "[15] time=2.44, avg_loss=1.6996, train_err=0.0850, 32_h1=0.0819, 32_l2=0.0461, 64_h1=0.1726, 64_l2=0.0596\n",
      "[16] time=2.29, avg_loss=1.6704, train_err=0.0835, 32_h1=0.0826, 32_l2=0.0460, 64_h1=0.1894, 64_l2=0.0688\n",
      "[17] time=2.34, avg_loss=1.6670, train_err=0.0833, 32_h1=0.0831, 32_l2=0.0476, 64_h1=0.1844, 64_l2=0.0678\n",
      "[18] time=2.35, avg_loss=1.7020, train_err=0.0851, 32_h1=0.0896, 32_l2=0.0546, 64_h1=0.1867, 64_l2=0.0703\n",
      "[19] time=2.33, avg_loss=1.6470, train_err=0.0824, 32_h1=0.0840, 32_l2=0.0485, 64_h1=0.1891, 64_l2=0.0678\n",
      "[20] time=2.40, avg_loss=1.6141, train_err=0.0807, 32_h1=0.0851, 32_l2=0.0547, 64_h1=0.1868, 64_l2=0.0713\n",
      "[21] time=2.36, avg_loss=1.6620, train_err=0.0831, 32_h1=0.0911, 32_l2=0.0559, 64_h1=0.1832, 64_l2=0.0680\n",
      "[22] time=2.34, avg_loss=1.6221, train_err=0.0811, 32_h1=0.0807, 32_l2=0.0459, 64_h1=0.1714, 64_l2=0.0510\n",
      "[23] time=2.35, avg_loss=1.4976, train_err=0.0749, 32_h1=0.0802, 32_l2=0.0487, 64_h1=0.1875, 64_l2=0.0728\n",
      "[24] time=2.39, avg_loss=1.5285, train_err=0.0764, 32_h1=0.0769, 32_l2=0.0417, 64_h1=0.1612, 64_l2=0.0518\n",
      "[25] time=2.36, avg_loss=1.5069, train_err=0.0753, 32_h1=0.0750, 32_l2=0.0391, 64_h1=0.1709, 64_l2=0.0524\n",
      "[26] time=2.37, avg_loss=1.4839, train_err=0.0742, 32_h1=0.0747, 32_l2=0.0396, 64_h1=0.1697, 64_l2=0.0572\n",
      "[27] time=2.40, avg_loss=1.6189, train_err=0.0809, 32_h1=0.0793, 32_l2=0.0501, 64_h1=0.1771, 64_l2=0.0663\n",
      "[28] time=2.36, avg_loss=1.4663, train_err=0.0733, 32_h1=0.0735, 32_l2=0.0381, 64_h1=0.1709, 64_l2=0.0544\n",
      "[29] time=2.35, avg_loss=1.4606, train_err=0.0730, 32_h1=0.0767, 32_l2=0.0406, 64_h1=0.1710, 64_l2=0.0581\n",
      "[30] time=2.37, avg_loss=1.5386, train_err=0.0769, 32_h1=0.0754, 32_l2=0.0393, 64_h1=0.1828, 64_l2=0.0650\n",
      "[31] time=2.35, avg_loss=1.4351, train_err=0.0718, 32_h1=0.0760, 32_l2=0.0430, 64_h1=0.1775, 64_l2=0.0624\n",
      "[32] time=2.40, avg_loss=1.5041, train_err=0.0752, 32_h1=0.0853, 32_l2=0.0564, 64_h1=0.1816, 64_l2=0.0703\n",
      "[33] time=2.36, avg_loss=1.5030, train_err=0.0752, 32_h1=0.0740, 32_l2=0.0352, 64_h1=0.1633, 64_l2=0.0526\n",
      "[34] time=2.35, avg_loss=1.4485, train_err=0.0724, 32_h1=0.0761, 32_l2=0.0416, 64_h1=0.1724, 64_l2=0.0581\n",
      "[35] time=2.38, avg_loss=1.4170, train_err=0.0708, 32_h1=0.0847, 32_l2=0.0553, 64_h1=0.1780, 64_l2=0.0712\n",
      "[36] time=2.32, avg_loss=1.4754, train_err=0.0738, 32_h1=0.0741, 32_l2=0.0374, 64_h1=0.1634, 64_l2=0.0554\n",
      "[37] time=2.34, avg_loss=1.4074, train_err=0.0704, 32_h1=0.0772, 32_l2=0.0429, 64_h1=0.1658, 64_l2=0.0571\n",
      "[38] time=2.37, avg_loss=1.4184, train_err=0.0709, 32_h1=0.0723, 32_l2=0.0379, 64_h1=0.1662, 64_l2=0.0543\n",
      "[39] time=2.37, avg_loss=1.3796, train_err=0.0690, 32_h1=0.0776, 32_l2=0.0463, 64_h1=0.1728, 64_l2=0.0595\n",
      "[40] time=2.34, avg_loss=1.3969, train_err=0.0698, 32_h1=0.0748, 32_l2=0.0383, 64_h1=0.1761, 64_l2=0.0584\n",
      "[41] time=2.36, avg_loss=1.3782, train_err=0.0689, 32_h1=0.0752, 32_l2=0.0399, 64_h1=0.1720, 64_l2=0.0568\n",
      "[42] time=2.35, avg_loss=1.3921, train_err=0.0696, 32_h1=0.0734, 32_l2=0.0370, 64_h1=0.1667, 64_l2=0.0503\n",
      "[43] time=2.43, avg_loss=1.3431, train_err=0.0672, 32_h1=0.0776, 32_l2=0.0474, 64_h1=0.1777, 64_l2=0.0681\n",
      "[44] time=2.38, avg_loss=1.4227, train_err=0.0711, 32_h1=0.0748, 32_l2=0.0383, 64_h1=0.1679, 64_l2=0.0520\n",
      "[45] time=2.34, avg_loss=1.3563, train_err=0.0678, 32_h1=0.0760, 32_l2=0.0437, 64_h1=0.1693, 64_l2=0.0569\n",
      "[46] time=2.33, avg_loss=1.3031, train_err=0.0652, 32_h1=0.0713, 32_l2=0.0356, 64_h1=0.1708, 64_l2=0.0555\n",
      "[47] time=2.36, avg_loss=1.3213, train_err=0.0661, 32_h1=0.0773, 32_l2=0.0396, 64_h1=0.1702, 64_l2=0.0520\n",
      "[48] time=2.33, avg_loss=1.3906, train_err=0.0695, 32_h1=0.0770, 32_l2=0.0424, 64_h1=0.1667, 64_l2=0.0570\n",
      "[49] time=2.35, avg_loss=1.3816, train_err=0.0691, 32_h1=0.0809, 32_l2=0.0475, 64_h1=0.1710, 64_l2=0.0536\n",
      "[50] time=2.38, avg_loss=1.3271, train_err=0.0664, 32_h1=0.0790, 32_l2=0.0464, 64_h1=0.1735, 64_l2=0.0606\n",
      "[51] time=2.35, avg_loss=1.3263, train_err=0.0663, 32_h1=0.0757, 32_l2=0.0422, 64_h1=0.1752, 64_l2=0.0600\n",
      "[52] time=2.32, avg_loss=1.2693, train_err=0.0635, 32_h1=0.0790, 32_l2=0.0456, 64_h1=0.1693, 64_l2=0.0614\n",
      "[53] time=2.32, avg_loss=1.3023, train_err=0.0651, 32_h1=0.0738, 32_l2=0.0376, 64_h1=0.1767, 64_l2=0.0550\n",
      "[54] time=2.27, avg_loss=1.2831, train_err=0.0642, 32_h1=0.0771, 32_l2=0.0430, 64_h1=0.1775, 64_l2=0.0631\n",
      "[55] time=2.17, avg_loss=1.2887, train_err=0.0644, 32_h1=0.0719, 32_l2=0.0353, 64_h1=0.1703, 64_l2=0.0552\n",
      "[56] time=2.14, avg_loss=1.2469, train_err=0.0623, 32_h1=0.0743, 32_l2=0.0376, 64_h1=0.1623, 64_l2=0.0470\n",
      "[57] time=2.24, avg_loss=1.2568, train_err=0.0628, 32_h1=0.0795, 32_l2=0.0433, 64_h1=0.1732, 64_l2=0.0613\n",
      "[58] time=2.26, avg_loss=1.3820, train_err=0.0691, 32_h1=0.0858, 32_l2=0.0502, 64_h1=0.1720, 64_l2=0.0644\n",
      "[59] time=2.21, avg_loss=1.2524, train_err=0.0626, 32_h1=0.0736, 32_l2=0.0375, 64_h1=0.1769, 64_l2=0.0588\n",
      "[60] time=2.23, avg_loss=1.2074, train_err=0.0604, 32_h1=0.0829, 32_l2=0.0441, 64_h1=0.1722, 64_l2=0.0592\n",
      "[61] time=2.14, avg_loss=1.3052, train_err=0.0653, 32_h1=0.0752, 32_l2=0.0391, 64_h1=0.1685, 64_l2=0.0532\n",
      "[62] time=2.07, avg_loss=1.2117, train_err=0.0606, 32_h1=0.0777, 32_l2=0.0427, 64_h1=0.1718, 64_l2=0.0594\n",
      "[63] time=2.05, avg_loss=1.2703, train_err=0.0635, 32_h1=0.0770, 32_l2=0.0436, 64_h1=0.1783, 64_l2=0.0644\n",
      "[64] time=2.08, avg_loss=1.2032, train_err=0.0602, 32_h1=0.0742, 32_l2=0.0375, 64_h1=0.1722, 64_l2=0.0579\n",
      "[65] time=2.05, avg_loss=1.1426, train_err=0.0571, 32_h1=0.0736, 32_l2=0.0362, 64_h1=0.1695, 64_l2=0.0560\n",
      "[66] time=2.05, avg_loss=1.1318, train_err=0.0566, 32_h1=0.0743, 32_l2=0.0361, 64_h1=0.1658, 64_l2=0.0518\n",
      "[67] time=2.15, avg_loss=1.1521, train_err=0.0576, 32_h1=0.0754, 32_l2=0.0375, 64_h1=0.1717, 64_l2=0.0589\n",
      "[68] time=2.19, avg_loss=1.1889, train_err=0.0594, 32_h1=0.0763, 32_l2=0.0401, 64_h1=0.1702, 64_l2=0.0582\n",
      "[69] time=2.12, avg_loss=1.1233, train_err=0.0562, 32_h1=0.0765, 32_l2=0.0394, 64_h1=0.1716, 64_l2=0.0595\n",
      "[70] time=2.20, avg_loss=1.1706, train_err=0.0585, 32_h1=0.0844, 32_l2=0.0498, 64_h1=0.1662, 64_l2=0.0624\n",
      "[71] time=2.31, avg_loss=1.1325, train_err=0.0566, 32_h1=0.0771, 32_l2=0.0391, 64_h1=0.1745, 64_l2=0.0580\n",
      "[72] time=2.23, avg_loss=1.0816, train_err=0.0541, 32_h1=0.0767, 32_l2=0.0386, 64_h1=0.1720, 64_l2=0.0586\n",
      "[73] time=2.20, avg_loss=1.0605, train_err=0.0530, 32_h1=0.0775, 32_l2=0.0420, 64_h1=0.1676, 64_l2=0.0526\n",
      "[74] time=2.25, avg_loss=1.0488, train_err=0.0524, 32_h1=0.0749, 32_l2=0.0366, 64_h1=0.1669, 64_l2=0.0562\n",
      "[75] time=2.18, avg_loss=1.1038, train_err=0.0552, 32_h1=0.0802, 32_l2=0.0439, 64_h1=0.1640, 64_l2=0.0560\n",
      "[76] time=2.22, avg_loss=1.1205, train_err=0.0560, 32_h1=0.0745, 32_l2=0.0352, 64_h1=0.1679, 64_l2=0.0559\n",
      "[77] time=2.11, avg_loss=1.0329, train_err=0.0516, 32_h1=0.0770, 32_l2=0.0385, 64_h1=0.1719, 64_l2=0.0593\n",
      "[78] time=2.20, avg_loss=1.0673, train_err=0.0534, 32_h1=0.0896, 32_l2=0.0538, 64_h1=0.1800, 64_l2=0.0676\n",
      "[79] time=2.24, avg_loss=1.0807, train_err=0.0540, 32_h1=0.0756, 32_l2=0.0372, 64_h1=0.1735, 64_l2=0.0580\n",
      "[80] time=2.16, avg_loss=0.9903, train_err=0.0495, 32_h1=0.0762, 32_l2=0.0369, 64_h1=0.1645, 64_l2=0.0542\n",
      "[81] time=2.08, avg_loss=1.0130, train_err=0.0506, 32_h1=0.0762, 32_l2=0.0368, 64_h1=0.1723, 64_l2=0.0552\n",
      "[82] time=2.31, avg_loss=0.9914, train_err=0.0496, 32_h1=0.0755, 32_l2=0.0361, 64_h1=0.1672, 64_l2=0.0561\n",
      "[83] time=2.31, avg_loss=0.9723, train_err=0.0486, 32_h1=0.0774, 32_l2=0.0378, 64_h1=0.1697, 64_l2=0.0552\n",
      "[84] time=2.35, avg_loss=1.0366, train_err=0.0518, 32_h1=0.0768, 32_l2=0.0370, 64_h1=0.1695, 64_l2=0.0572\n",
      "[85] time=2.36, avg_loss=0.9638, train_err=0.0482, 32_h1=0.0776, 32_l2=0.0392, 64_h1=0.1721, 64_l2=0.0606\n",
      "[86] time=2.30, avg_loss=0.9792, train_err=0.0490, 32_h1=0.0774, 32_l2=0.0372, 64_h1=0.1654, 64_l2=0.0539\n",
      "[87] time=2.33, avg_loss=1.0111, train_err=0.0506, 32_h1=0.0822, 32_l2=0.0442, 64_h1=0.1735, 64_l2=0.0611\n",
      "[88] time=2.35, avg_loss=1.0722, train_err=0.0536, 32_h1=0.0762, 32_l2=0.0363, 64_h1=0.1670, 64_l2=0.0555\n",
      "[89] time=2.34, avg_loss=0.9550, train_err=0.0478, 32_h1=0.0803, 32_l2=0.0418, 64_h1=0.1676, 64_l2=0.0586\n",
      "[90] time=2.36, avg_loss=0.9255, train_err=0.0463, 32_h1=0.0768, 32_l2=0.0377, 64_h1=0.1644, 64_l2=0.0512\n",
      "[91] time=2.42, avg_loss=0.8940, train_err=0.0447, 32_h1=0.0763, 32_l2=0.0355, 64_h1=0.1676, 64_l2=0.0540\n",
      "[92] time=2.38, avg_loss=0.8981, train_err=0.0449, 32_h1=0.0764, 32_l2=0.0359, 64_h1=0.1687, 64_l2=0.0588\n",
      "[93] time=2.34, avg_loss=0.9314, train_err=0.0466, 32_h1=0.0779, 32_l2=0.0375, 64_h1=0.1712, 64_l2=0.0588\n",
      "[94] time=2.35, avg_loss=0.9228, train_err=0.0461, 32_h1=0.0802, 32_l2=0.0422, 64_h1=0.1756, 64_l2=0.0612\n",
      "[95] time=2.36, avg_loss=0.9164, train_err=0.0458, 32_h1=0.0774, 32_l2=0.0370, 64_h1=0.1629, 64_l2=0.0510\n",
      "[96] time=2.38, avg_loss=0.9234, train_err=0.0462, 32_h1=0.0785, 32_l2=0.0399, 64_h1=0.1667, 64_l2=0.0564\n",
      "[97] time=2.37, avg_loss=0.9242, train_err=0.0462, 32_h1=0.0779, 32_l2=0.0378, 64_h1=0.1680, 64_l2=0.0554\n",
      "[98] time=2.38, avg_loss=0.8897, train_err=0.0445, 32_h1=0.0780, 32_l2=0.0380, 64_h1=0.1714, 64_l2=0.0593\n",
      "[99] time=2.39, avg_loss=0.8869, train_err=0.0443, 32_h1=0.0769, 32_l2=0.0374, 64_h1=0.1636, 64_l2=0.0540\n",
      "[100] time=2.38, avg_loss=0.8736, train_err=0.0437, 32_h1=0.0776, 32_l2=0.0371, 64_h1=0.1664, 64_l2=0.0551\n",
      "[101] time=2.36, avg_loss=0.8925, train_err=0.0446, 32_h1=0.0778, 32_l2=0.0381, 64_h1=0.1695, 64_l2=0.0581\n",
      "[102] time=2.38, avg_loss=0.9203, train_err=0.0460, 32_h1=0.0795, 32_l2=0.0396, 64_h1=0.1696, 64_l2=0.0591\n",
      "[103] time=2.39, avg_loss=0.8729, train_err=0.0436, 32_h1=0.0781, 32_l2=0.0375, 64_h1=0.1693, 64_l2=0.0574\n",
      "[104] time=2.36, avg_loss=0.8515, train_err=0.0426, 32_h1=0.0771, 32_l2=0.0370, 64_h1=0.1641, 64_l2=0.0567\n",
      "[105] time=2.36, avg_loss=0.8566, train_err=0.0428, 32_h1=0.0782, 32_l2=0.0375, 64_h1=0.1617, 64_l2=0.0519\n",
      "[106] time=2.38, avg_loss=0.8317, train_err=0.0416, 32_h1=0.0775, 32_l2=0.0370, 64_h1=0.1632, 64_l2=0.0538\n",
      "[107] time=2.35, avg_loss=0.8532, train_err=0.0427, 32_h1=0.0785, 32_l2=0.0377, 64_h1=0.1628, 64_l2=0.0528\n",
      "[108] time=2.33, avg_loss=0.8740, train_err=0.0437, 32_h1=0.0778, 32_l2=0.0374, 64_h1=0.1668, 64_l2=0.0570\n",
      "[109] time=2.36, avg_loss=0.8380, train_err=0.0419, 32_h1=0.0777, 32_l2=0.0379, 64_h1=0.1642, 64_l2=0.0540\n",
      "[110] time=2.33, avg_loss=0.8063, train_err=0.0403, 32_h1=0.0776, 32_l2=0.0366, 64_h1=0.1650, 64_l2=0.0556\n",
      "[111] time=2.32, avg_loss=0.8280, train_err=0.0414, 32_h1=0.0781, 32_l2=0.0409, 64_h1=0.1683, 64_l2=0.0601\n",
      "[112] time=2.35, avg_loss=0.8864, train_err=0.0443, 32_h1=0.0798, 32_l2=0.0399, 64_h1=0.1678, 64_l2=0.0573\n",
      "[113] time=2.32, avg_loss=0.8635, train_err=0.0432, 32_h1=0.0758, 32_l2=0.0348, 64_h1=0.1670, 64_l2=0.0547\n",
      "[114] time=2.41, avg_loss=0.7867, train_err=0.0393, 32_h1=0.0782, 32_l2=0.0393, 64_h1=0.1672, 64_l2=0.0532\n",
      "[115] time=2.36, avg_loss=0.8025, train_err=0.0401, 32_h1=0.0774, 32_l2=0.0376, 64_h1=0.1643, 64_l2=0.0564\n",
      "[116] time=2.36, avg_loss=0.7788, train_err=0.0389, 32_h1=0.0782, 32_l2=0.0378, 64_h1=0.1654, 64_l2=0.0556\n",
      "[117] time=2.38, avg_loss=0.7952, train_err=0.0398, 32_h1=0.0776, 32_l2=0.0364, 64_h1=0.1657, 64_l2=0.0557\n",
      "[118] time=2.38, avg_loss=0.8378, train_err=0.0419, 32_h1=0.0804, 32_l2=0.0433, 64_h1=0.1670, 64_l2=0.0600\n",
      "[119] time=2.38, avg_loss=0.8425, train_err=0.0421, 32_h1=0.0774, 32_l2=0.0367, 64_h1=0.1625, 64_l2=0.0543\n",
      "[120] time=2.36, avg_loss=0.7940, train_err=0.0397, 32_h1=0.0772, 32_l2=0.0365, 64_h1=0.1656, 64_l2=0.0556\n",
      "[121] time=2.20, avg_loss=0.7660, train_err=0.0383, 32_h1=0.0768, 32_l2=0.0363, 64_h1=0.1669, 64_l2=0.0582\n",
      "[122] time=2.07, avg_loss=0.7570, train_err=0.0378, 32_h1=0.0771, 32_l2=0.0353, 64_h1=0.1693, 64_l2=0.0540\n",
      "[123] time=2.11, avg_loss=0.7951, train_err=0.0398, 32_h1=0.0773, 32_l2=0.0364, 64_h1=0.1640, 64_l2=0.0547\n",
      "[124] time=2.19, avg_loss=0.8151, train_err=0.0408, 32_h1=0.0802, 32_l2=0.0418, 64_h1=0.1631, 64_l2=0.0581\n",
      "[125] time=2.15, avg_loss=0.7714, train_err=0.0386, 32_h1=0.0765, 32_l2=0.0352, 64_h1=0.1652, 64_l2=0.0561\n",
      "[126] time=2.17, avg_loss=0.7305, train_err=0.0365, 32_h1=0.0773, 32_l2=0.0363, 64_h1=0.1661, 64_l2=0.0558\n",
      "[127] time=2.16, avg_loss=0.7177, train_err=0.0359, 32_h1=0.0764, 32_l2=0.0348, 64_h1=0.1662, 64_l2=0.0524\n",
      "[128] time=2.20, avg_loss=0.7176, train_err=0.0359, 32_h1=0.0774, 32_l2=0.0358, 64_h1=0.1676, 64_l2=0.0546\n",
      "[129] time=2.24, avg_loss=0.7405, train_err=0.0370, 32_h1=0.0818, 32_l2=0.0445, 64_h1=0.1637, 64_l2=0.0599\n",
      "[130] time=2.14, avg_loss=0.7577, train_err=0.0379, 32_h1=0.0765, 32_l2=0.0352, 64_h1=0.1676, 64_l2=0.0553\n",
      "[131] time=2.06, avg_loss=0.7099, train_err=0.0355, 32_h1=0.0773, 32_l2=0.0361, 64_h1=0.1677, 64_l2=0.0574\n",
      "[132] time=2.06, avg_loss=0.7204, train_err=0.0360, 32_h1=0.0777, 32_l2=0.0358, 64_h1=0.1701, 64_l2=0.0584\n",
      "[133] time=2.24, avg_loss=0.7186, train_err=0.0359, 32_h1=0.0779, 32_l2=0.0384, 64_h1=0.1635, 64_l2=0.0573\n",
      "[134] time=2.23, avg_loss=0.7342, train_err=0.0367, 32_h1=0.0774, 32_l2=0.0356, 64_h1=0.1650, 64_l2=0.0548\n",
      "[135] time=2.07, avg_loss=0.7275, train_err=0.0364, 32_h1=0.0779, 32_l2=0.0369, 64_h1=0.1686, 64_l2=0.0569\n",
      "[136] time=2.05, avg_loss=0.7003, train_err=0.0350, 32_h1=0.0778, 32_l2=0.0365, 64_h1=0.1662, 64_l2=0.0552\n",
      "[137] time=2.21, avg_loss=0.7200, train_err=0.0360, 32_h1=0.0782, 32_l2=0.0376, 64_h1=0.1699, 64_l2=0.0573\n",
      "[138] time=2.17, avg_loss=0.7133, train_err=0.0357, 32_h1=0.0786, 32_l2=0.0385, 64_h1=0.1634, 64_l2=0.0539\n",
      "[139] time=2.09, avg_loss=0.7219, train_err=0.0361, 32_h1=0.0770, 32_l2=0.0359, 64_h1=0.1662, 64_l2=0.0568\n",
      "[140] time=2.16, avg_loss=0.7042, train_err=0.0352, 32_h1=0.0773, 32_l2=0.0362, 64_h1=0.1671, 64_l2=0.0558\n",
      "[141] time=2.07, avg_loss=0.7619, train_err=0.0381, 32_h1=0.0777, 32_l2=0.0359, 64_h1=0.1647, 64_l2=0.0538\n",
      "[142] time=2.08, avg_loss=0.6976, train_err=0.0349, 32_h1=0.0834, 32_l2=0.0441, 64_h1=0.1707, 64_l2=0.0617\n",
      "[143] time=2.25, avg_loss=0.6904, train_err=0.0345, 32_h1=0.0765, 32_l2=0.0347, 64_h1=0.1672, 64_l2=0.0554\n",
      "[144] time=2.26, avg_loss=0.6785, train_err=0.0339, 32_h1=0.0783, 32_l2=0.0372, 64_h1=0.1667, 64_l2=0.0571\n",
      "[145] time=2.26, avg_loss=0.6686, train_err=0.0334, 32_h1=0.0781, 32_l2=0.0370, 64_h1=0.1661, 64_l2=0.0532\n",
      "[146] time=2.25, avg_loss=0.6718, train_err=0.0336, 32_h1=0.0771, 32_l2=0.0358, 64_h1=0.1658, 64_l2=0.0540\n",
      "[147] time=2.09, avg_loss=0.6690, train_err=0.0334, 32_h1=0.0767, 32_l2=0.0354, 64_h1=0.1649, 64_l2=0.0563\n",
      "[148] time=2.11, avg_loss=0.6462, train_err=0.0323, 32_h1=0.0770, 32_l2=0.0348, 64_h1=0.1665, 64_l2=0.0546\n",
      "[149] time=2.31, avg_loss=0.6391, train_err=0.0320, 32_h1=0.0774, 32_l2=0.0356, 64_h1=0.1647, 64_l2=0.0540\n"
     ]
    }
   ],
   "source": [
    "for i in range(8, 34, 2):\n",
    "    # Read the configuration\n",
    "    config_name = 'default'\n",
    "    pipe = ConfigPipeline([YamlConfig('./tfno_darcy_config.yaml', config_name='default', config_folder='./config'),\n",
    "                          ])\n",
    "    config = pipe.read_conf()\n",
    "    config_name = pipe.steps[-1].config_name\n",
    "    \n",
    "    config.tfno2d.n_modes_height = i\n",
    "    config.tfno2d.n_modes_width = i\n",
    "    \n",
    "    # Set-up distributed communication, if using\n",
    "    device, is_logger = setup(config)\n",
    "    \n",
    "    # Make sure we only print information when needed\n",
    "    config.verbose = config.verbose and is_logger\n",
    "\n",
    "    #Print config to screen\n",
    "    if config.verbose and is_logger:\n",
    "        pipe.log()\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    # Loading the Darcy flow training set in 32x32 resolution, test set in 32x32 and 64x64 resolutions\n",
    "    train_loader, test_loaders, output_encoder = load_darcy_pt(\n",
    "            config.data.folder, train_resolution=config.data.train_resolution, n_train=config.data.n_train, batch_size=config.data.batch_size, \n",
    "            positional_encoding=config.data.positional_encoding,\n",
    "            test_resolutions=config.data.test_resolutions, n_tests=config.data.n_tests, test_batch_sizes=config.data.test_batch_sizes,\n",
    "            encode_input=config.data.encode_input, encode_output=config.data.encode_output,\n",
    "            )\n",
    "    \n",
    "    model = get_model(config)\n",
    "    model = model.to(device)\n",
    "\n",
    "    #Log parameter count\n",
    "    if is_logger:\n",
    "        n_params = count_params(model)\n",
    "\n",
    "        if config.verbose:\n",
    "            print(f'\\nn_params: {n_params}')\n",
    "            sys.stdout.flush()\n",
    "    \n",
    "    #Create the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                    lr=config.opt.learning_rate, \n",
    "                                    weight_decay=config.opt.weight_decay)\n",
    "\n",
    "    if config.opt.scheduler == 'ReduceLROnPlateau':\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=config.opt.gamma, patience=config.opt.scheduler_patience, mode='min')\n",
    "    elif config.opt.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.opt.scheduler_T_max)\n",
    "    elif config.opt.scheduler == 'StepLR':\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n",
    "                                                    step_size=config.opt.step_size,\n",
    "                                                    gamma=config.opt.gamma)\n",
    "    else:\n",
    "        raise ValueError(f'Got {config.opt.scheduler=}')\n",
    "    \n",
    "    # Creating the losses\n",
    "    l2loss = LpLoss(d=2, p=2)\n",
    "    h1loss = H1Loss(d=2)\n",
    "    if config.opt.training_loss == 'l2':\n",
    "        train_loss = l2loss\n",
    "    elif config.opt.training_loss == 'h1':\n",
    "        train_loss = h1loss\n",
    "    else:\n",
    "        raise ValueError(f'Got training_loss={config.opt.training_loss} but expected one of [\"l2\", \"h1\"]')\n",
    "    eval_losses={'h1': h1loss, 'l2': l2loss}\n",
    "    \n",
    "    if config.verbose and is_logger:\n",
    "        print('\\n### MODEL ###\\n', model)\n",
    "        print('\\n### OPTIMIZER ###\\n', optimizer)\n",
    "        print('\\n### SCHEDULER ###\\n', scheduler)\n",
    "        print('\\n### LOSSES ###')\n",
    "        print(f'\\n * Train: {train_loss}')\n",
    "        print(f'\\n * Test: {eval_losses}')\n",
    "        print(f'\\n### Beginning Training...\\n')\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    trainer = Trainer(model, n_epochs=config.opt.n_epochs,\n",
    "                      device=device,\n",
    "                      mg_patching_levels=config.patching.levels,\n",
    "                      mg_patching_padding=config.patching.padding,\n",
    "                      mg_patching_stitching=config.patching.stitching,\n",
    "                      wandb_log=config.wandb.log,\n",
    "                      log_test_interval=config.wandb.log_test_interval,\n",
    "                      log_output=False,\n",
    "                      use_distributed=config.distributed.use_distributed,\n",
    "                      verbose=config.verbose and is_logger)\n",
    "    \n",
    "    trainer.train(train_loader, test_loaders,\n",
    "                  output_encoder,\n",
    "                  model, \n",
    "                  optimizer,\n",
    "                  scheduler, \n",
    "                  regularizer=False, \n",
    "                  training_loss=train_loss,\n",
    "                  eval_losses=eval_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44504280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.01\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 19537\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(5, 5, 1, 1))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(5, 5, 1, 1))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(5, 5, 1, 1))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(5, 5, 1, 1))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(5, 5, 1, 1))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(5, 5, 1, 1))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(5, 5, 1, 1))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(5, 5, 1, 1))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f7761a60f70>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f776fe01b80>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f776fe01b80>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f776fe01850>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.45, avg_loss=12.6224, train_err=0.6311, 32_h1=0.3734, 32_l2=0.2545, 64_h1=0.4262, 64_l2=0.2604\n",
      "[1] time=2.40, avg_loss=6.2108, train_err=0.3105, 32_h1=0.2785, 32_l2=0.1894, 64_h1=0.3316, 64_l2=0.1930\n",
      "[2] time=2.43, avg_loss=5.1103, train_err=0.2555, 32_h1=0.2512, 32_l2=0.1769, 64_h1=0.2978, 64_l2=0.1773\n",
      "[3] time=2.41, avg_loss=4.3947, train_err=0.2197, 32_h1=0.2297, 32_l2=0.1533, 64_h1=0.2954, 64_l2=0.1598\n",
      "[4] time=2.42, avg_loss=4.1038, train_err=0.2052, 32_h1=0.2033, 32_l2=0.1405, 64_h1=0.2683, 64_l2=0.1521\n",
      "[5] time=2.46, avg_loss=3.8644, train_err=0.1932, 32_h1=0.1794, 32_l2=0.1136, 64_h1=0.2447, 64_l2=0.1236\n",
      "[6] time=2.41, avg_loss=3.6592, train_err=0.1830, 32_h1=0.1784, 32_l2=0.1189, 64_h1=0.2453, 64_l2=0.1302\n",
      "[7] time=2.40, avg_loss=3.4713, train_err=0.1736, 32_h1=0.1847, 32_l2=0.1266, 64_h1=0.2432, 64_l2=0.1356\n",
      "[8] time=2.44, avg_loss=3.3057, train_err=0.1653, 32_h1=0.1597, 32_l2=0.1003, 64_h1=0.2284, 64_l2=0.1139\n",
      "[9] time=2.42, avg_loss=3.1717, train_err=0.1586, 32_h1=0.1587, 32_l2=0.1060, 64_h1=0.2179, 64_l2=0.1110\n",
      "[10] time=2.42, avg_loss=3.0261, train_err=0.1513, 32_h1=0.1532, 32_l2=0.0929, 64_h1=0.2277, 64_l2=0.1008\n",
      "[11] time=2.39, avg_loss=2.9532, train_err=0.1477, 32_h1=0.1477, 32_l2=0.0889, 64_h1=0.2193, 64_l2=0.1010\n",
      "[12] time=2.39, avg_loss=2.9274, train_err=0.1464, 32_h1=0.1502, 32_l2=0.0893, 64_h1=0.2154, 64_l2=0.0990\n",
      "[13] time=2.39, avg_loss=2.8722, train_err=0.1436, 32_h1=0.1384, 32_l2=0.0800, 64_h1=0.2195, 64_l2=0.0904\n",
      "[14] time=2.42, avg_loss=2.7250, train_err=0.1363, 32_h1=0.1415, 32_l2=0.0868, 64_h1=0.2153, 64_l2=0.1018\n",
      "[15] time=2.39, avg_loss=2.6595, train_err=0.1330, 32_h1=0.1374, 32_l2=0.0815, 64_h1=0.2141, 64_l2=0.0892\n",
      "[16] time=2.42, avg_loss=2.6053, train_err=0.1303, 32_h1=0.1311, 32_l2=0.0755, 64_h1=0.2061, 64_l2=0.0824\n",
      "[17] time=2.35, avg_loss=2.6565, train_err=0.1328, 32_h1=0.1360, 32_l2=0.0816, 64_h1=0.2094, 64_l2=0.0868\n",
      "[18] time=2.28, avg_loss=2.5804, train_err=0.1290, 32_h1=0.1294, 32_l2=0.0757, 64_h1=0.2010, 64_l2=0.0820\n",
      "[19] time=2.14, avg_loss=2.5277, train_err=0.1264, 32_h1=0.1323, 32_l2=0.0798, 64_h1=0.1977, 64_l2=0.0869\n",
      "[20] time=2.12, avg_loss=2.5057, train_err=0.1253, 32_h1=0.1274, 32_l2=0.0718, 64_h1=0.1904, 64_l2=0.0827\n",
      "[21] time=2.23, avg_loss=2.5228, train_err=0.1261, 32_h1=0.1261, 32_l2=0.0748, 64_h1=0.1985, 64_l2=0.0884\n",
      "[22] time=2.26, avg_loss=2.5891, train_err=0.1295, 32_h1=0.1219, 32_l2=0.0655, 64_h1=0.1982, 64_l2=0.0793\n",
      "[23] time=2.28, avg_loss=2.4241, train_err=0.1212, 32_h1=0.1208, 32_l2=0.0671, 64_h1=0.1941, 64_l2=0.0729\n",
      "[24] time=2.25, avg_loss=2.3926, train_err=0.1196, 32_h1=0.1192, 32_l2=0.0644, 64_h1=0.1897, 64_l2=0.0780\n",
      "[25] time=2.18, avg_loss=2.4317, train_err=0.1216, 32_h1=0.1209, 32_l2=0.0671, 64_h1=0.1931, 64_l2=0.0787\n",
      "[26] time=2.16, avg_loss=2.3912, train_err=0.1196, 32_h1=0.1179, 32_l2=0.0639, 64_h1=0.1927, 64_l2=0.0749\n",
      "[27] time=2.30, avg_loss=2.4057, train_err=0.1203, 32_h1=0.1262, 32_l2=0.0761, 64_h1=0.2033, 64_l2=0.0881\n",
      "[28] time=2.30, avg_loss=2.3818, train_err=0.1191, 32_h1=0.1206, 32_l2=0.0717, 64_h1=0.2002, 64_l2=0.0828\n",
      "[29] time=2.32, avg_loss=2.3035, train_err=0.1152, 32_h1=0.1151, 32_l2=0.0632, 64_h1=0.1983, 64_l2=0.0746\n",
      "[30] time=2.15, avg_loss=2.3160, train_err=0.1158, 32_h1=0.1193, 32_l2=0.0674, 64_h1=0.2005, 64_l2=0.0735\n",
      "[31] time=2.31, avg_loss=2.3157, train_err=0.1158, 32_h1=0.1274, 32_l2=0.0840, 64_h1=0.2025, 64_l2=0.0916\n",
      "[32] time=2.32, avg_loss=2.3338, train_err=0.1167, 32_h1=0.1182, 32_l2=0.0671, 64_h1=0.1938, 64_l2=0.0740\n",
      "[33] time=2.31, avg_loss=2.2591, train_err=0.1130, 32_h1=0.1143, 32_l2=0.0619, 64_h1=0.1937, 64_l2=0.0757\n",
      "[34] time=2.30, avg_loss=2.2927, train_err=0.1146, 32_h1=0.1180, 32_l2=0.0669, 64_h1=0.1985, 64_l2=0.0835\n",
      "[35] time=2.25, avg_loss=2.2472, train_err=0.1124, 32_h1=0.1135, 32_l2=0.0621, 64_h1=0.1836, 64_l2=0.0698\n",
      "[36] time=2.16, avg_loss=2.2389, train_err=0.1119, 32_h1=0.1145, 32_l2=0.0626, 64_h1=0.2017, 64_l2=0.0742\n",
      "[37] time=2.12, avg_loss=2.2482, train_err=0.1124, 32_h1=0.1209, 32_l2=0.0730, 64_h1=0.1894, 64_l2=0.0803\n",
      "[38] time=2.26, avg_loss=2.2123, train_err=0.1106, 32_h1=0.1244, 32_l2=0.0746, 64_h1=0.1988, 64_l2=0.0903\n",
      "[39] time=2.26, avg_loss=2.2476, train_err=0.1124, 32_h1=0.1247, 32_l2=0.0808, 64_h1=0.1904, 64_l2=0.0863\n",
      "[40] time=2.16, avg_loss=2.2111, train_err=0.1106, 32_h1=0.1199, 32_l2=0.0763, 64_h1=0.2017, 64_l2=0.0811\n",
      "[41] time=2.22, avg_loss=2.2062, train_err=0.1103, 32_h1=0.1292, 32_l2=0.0952, 64_h1=0.2115, 64_l2=0.1020\n",
      "[42] time=2.26, avg_loss=2.1853, train_err=0.1093, 32_h1=0.1158, 32_l2=0.0719, 64_h1=0.1944, 64_l2=0.0819\n",
      "[43] time=2.23, avg_loss=2.1741, train_err=0.1087, 32_h1=0.1150, 32_l2=0.0665, 64_h1=0.1867, 64_l2=0.0729\n",
      "[44] time=2.17, avg_loss=2.1860, train_err=0.1093, 32_h1=0.1087, 32_l2=0.0584, 64_h1=0.1860, 64_l2=0.0747\n",
      "[45] time=2.20, avg_loss=2.1261, train_err=0.1063, 32_h1=0.1089, 32_l2=0.0630, 64_h1=0.1944, 64_l2=0.0721\n",
      "[46] time=2.50, avg_loss=2.1110, train_err=0.1055, 32_h1=0.1106, 32_l2=0.0630, 64_h1=0.1887, 64_l2=0.0688\n",
      "[47] time=2.44, avg_loss=2.1373, train_err=0.1069, 32_h1=0.1054, 32_l2=0.0553, 64_h1=0.1864, 64_l2=0.0672\n",
      "[48] time=2.46, avg_loss=2.1192, train_err=0.1060, 32_h1=0.1162, 32_l2=0.0654, 64_h1=0.2112, 64_l2=0.0816\n",
      "[49] time=2.42, avg_loss=2.1066, train_err=0.1053, 32_h1=0.1092, 32_l2=0.0613, 64_h1=0.1928, 64_l2=0.0751\n",
      "[50] time=2.41, avg_loss=2.1282, train_err=0.1064, 32_h1=0.1068, 32_l2=0.0610, 64_h1=0.1823, 64_l2=0.0700\n",
      "[51] time=2.40, avg_loss=2.0933, train_err=0.1047, 32_h1=0.1055, 32_l2=0.0564, 64_h1=0.1818, 64_l2=0.0642\n",
      "[52] time=2.52, avg_loss=2.0708, train_err=0.1035, 32_h1=0.1079, 32_l2=0.0612, 64_h1=0.1845, 64_l2=0.0718\n",
      "[53] time=2.44, avg_loss=2.0964, train_err=0.1048, 32_h1=0.1087, 32_l2=0.0598, 64_h1=0.1877, 64_l2=0.0686\n",
      "[54] time=2.41, avg_loss=2.0497, train_err=0.1025, 32_h1=0.1034, 32_l2=0.0552, 64_h1=0.1880, 64_l2=0.0678\n",
      "[55] time=2.43, avg_loss=2.0984, train_err=0.1049, 32_h1=0.1039, 32_l2=0.0585, 64_h1=0.1837, 64_l2=0.0692\n",
      "[56] time=2.39, avg_loss=2.0649, train_err=0.1032, 32_h1=0.1012, 32_l2=0.0520, 64_h1=0.1842, 64_l2=0.0649\n",
      "[57] time=2.42, avg_loss=2.0918, train_err=0.1046, 32_h1=0.1092, 32_l2=0.0660, 64_h1=0.1824, 64_l2=0.0772\n",
      "[58] time=2.42, avg_loss=2.0427, train_err=0.1021, 32_h1=0.1007, 32_l2=0.0524, 64_h1=0.1853, 64_l2=0.0664\n",
      "[59] time=2.40, avg_loss=2.0111, train_err=0.1006, 32_h1=0.1021, 32_l2=0.0556, 64_h1=0.1836, 64_l2=0.0669\n",
      "[60] time=2.42, avg_loss=2.0094, train_err=0.1005, 32_h1=0.1012, 32_l2=0.0551, 64_h1=0.1861, 64_l2=0.0698\n",
      "[61] time=2.37, avg_loss=2.0678, train_err=0.1034, 32_h1=0.1030, 32_l2=0.0558, 64_h1=0.1832, 64_l2=0.0666\n",
      "[62] time=2.40, avg_loss=1.9651, train_err=0.0983, 32_h1=0.1022, 32_l2=0.0562, 64_h1=0.1884, 64_l2=0.0700\n",
      "[63] time=2.46, avg_loss=2.0110, train_err=0.1006, 32_h1=0.1078, 32_l2=0.0639, 64_h1=0.1903, 64_l2=0.0721\n",
      "[64] time=2.41, avg_loss=1.9786, train_err=0.0989, 32_h1=0.1061, 32_l2=0.0607, 64_h1=0.1934, 64_l2=0.0713\n",
      "[65] time=2.40, avg_loss=1.9776, train_err=0.0989, 32_h1=0.1059, 32_l2=0.0597, 64_h1=0.1912, 64_l2=0.0743\n",
      "[66] time=2.39, avg_loss=1.9694, train_err=0.0985, 32_h1=0.1016, 32_l2=0.0562, 64_h1=0.1871, 64_l2=0.0729\n",
      "[67] time=2.41, avg_loss=2.0086, train_err=0.1004, 32_h1=0.1013, 32_l2=0.0581, 64_h1=0.1813, 64_l2=0.0689\n",
      "[68] time=2.46, avg_loss=1.9629, train_err=0.0981, 32_h1=0.1020, 32_l2=0.0540, 64_h1=0.1820, 64_l2=0.0700\n",
      "[69] time=2.41, avg_loss=1.9406, train_err=0.0970, 32_h1=0.0983, 32_l2=0.0515, 64_h1=0.1860, 64_l2=0.0649\n",
      "[70] time=2.46, avg_loss=1.9466, train_err=0.0973, 32_h1=0.1062, 32_l2=0.0649, 64_h1=0.1835, 64_l2=0.0745\n",
      "[71] time=2.42, avg_loss=1.9332, train_err=0.0967, 32_h1=0.0971, 32_l2=0.0501, 64_h1=0.1779, 64_l2=0.0635\n",
      "[72] time=2.40, avg_loss=1.9559, train_err=0.0978, 32_h1=0.0999, 32_l2=0.0544, 64_h1=0.1843, 64_l2=0.0680\n",
      "[73] time=2.44, avg_loss=1.9719, train_err=0.0986, 32_h1=0.1035, 32_l2=0.0572, 64_h1=0.1784, 64_l2=0.0651\n",
      "[74] time=2.50, avg_loss=1.9238, train_err=0.0962, 32_h1=0.1042, 32_l2=0.0621, 64_h1=0.1819, 64_l2=0.0744\n",
      "[75] time=2.36, avg_loss=1.9223, train_err=0.0961, 32_h1=0.0971, 32_l2=0.0509, 64_h1=0.1805, 64_l2=0.0671\n",
      "[76] time=2.37, avg_loss=1.9055, train_err=0.0953, 32_h1=0.1095, 32_l2=0.0690, 64_h1=0.1911, 64_l2=0.0821\n",
      "[77] time=2.42, avg_loss=1.9159, train_err=0.0958, 32_h1=0.0979, 32_l2=0.0533, 64_h1=0.1789, 64_l2=0.0652\n",
      "[78] time=2.44, avg_loss=1.8864, train_err=0.0943, 32_h1=0.0966, 32_l2=0.0513, 64_h1=0.1802, 64_l2=0.0663\n",
      "[79] time=2.38, avg_loss=1.9317, train_err=0.0966, 32_h1=0.0955, 32_l2=0.0492, 64_h1=0.1823, 64_l2=0.0630\n",
      "[80] time=2.38, avg_loss=1.9061, train_err=0.0953, 32_h1=0.0975, 32_l2=0.0522, 64_h1=0.1689, 64_l2=0.0639\n",
      "[81] time=2.40, avg_loss=1.8903, train_err=0.0945, 32_h1=0.0991, 32_l2=0.0542, 64_h1=0.1716, 64_l2=0.0576\n",
      "[82] time=2.39, avg_loss=1.9010, train_err=0.0950, 32_h1=0.0977, 32_l2=0.0527, 64_h1=0.1803, 64_l2=0.0665\n",
      "[83] time=2.34, avg_loss=1.9069, train_err=0.0953, 32_h1=0.1026, 32_l2=0.0570, 64_h1=0.1783, 64_l2=0.0680\n",
      "[84] time=2.11, avg_loss=1.8902, train_err=0.0945, 32_h1=0.0959, 32_l2=0.0517, 64_h1=0.1804, 64_l2=0.0640\n",
      "[85] time=2.25, avg_loss=1.8669, train_err=0.0933, 32_h1=0.0946, 32_l2=0.0513, 64_h1=0.1818, 64_l2=0.0663\n",
      "[86] time=2.33, avg_loss=1.8563, train_err=0.0928, 32_h1=0.0967, 32_l2=0.0523, 64_h1=0.1844, 64_l2=0.0613\n",
      "[87] time=2.26, avg_loss=1.8815, train_err=0.0941, 32_h1=0.0930, 32_l2=0.0463, 64_h1=0.1878, 64_l2=0.0626\n",
      "[88] time=2.17, avg_loss=1.8371, train_err=0.0919, 32_h1=0.0939, 32_l2=0.0487, 64_h1=0.1737, 64_l2=0.0636\n",
      "[89] time=2.26, avg_loss=1.8532, train_err=0.0927, 32_h1=0.0934, 32_l2=0.0476, 64_h1=0.1750, 64_l2=0.0609\n",
      "[90] time=2.28, avg_loss=1.8566, train_err=0.0928, 32_h1=0.1013, 32_l2=0.0608, 64_h1=0.1800, 64_l2=0.0685\n",
      "[91] time=2.21, avg_loss=1.8679, train_err=0.0934, 32_h1=0.0990, 32_l2=0.0535, 64_h1=0.1972, 64_l2=0.0694\n",
      "[92] time=2.12, avg_loss=1.8466, train_err=0.0923, 32_h1=0.0978, 32_l2=0.0544, 64_h1=0.1751, 64_l2=0.0683\n",
      "[93] time=2.24, avg_loss=1.8339, train_err=0.0917, 32_h1=0.0948, 32_l2=0.0497, 64_h1=0.1774, 64_l2=0.0664\n",
      "[94] time=2.29, avg_loss=1.8116, train_err=0.0906, 32_h1=0.0951, 32_l2=0.0508, 64_h1=0.1788, 64_l2=0.0650\n",
      "[95] time=2.18, avg_loss=1.8352, train_err=0.0918, 32_h1=0.0976, 32_l2=0.0537, 64_h1=0.1841, 64_l2=0.0687\n",
      "[96] time=2.25, avg_loss=1.8254, train_err=0.0913, 32_h1=0.0926, 32_l2=0.0496, 64_h1=0.1778, 64_l2=0.0633\n",
      "[97] time=2.28, avg_loss=1.8296, train_err=0.0915, 32_h1=0.1005, 32_l2=0.0629, 64_h1=0.1840, 64_l2=0.0726\n",
      "[98] time=2.36, avg_loss=1.8412, train_err=0.0921, 32_h1=0.0939, 32_l2=0.0497, 64_h1=0.1753, 64_l2=0.0628\n",
      "[99] time=2.28, avg_loss=1.8093, train_err=0.0905, 32_h1=0.0953, 32_l2=0.0537, 64_h1=0.1757, 64_l2=0.0678\n",
      "[100] time=2.25, avg_loss=1.7927, train_err=0.0896, 32_h1=0.0924, 32_l2=0.0488, 64_h1=0.1814, 64_l2=0.0632\n",
      "[101] time=2.27, avg_loss=1.8082, train_err=0.0904, 32_h1=0.0993, 32_l2=0.0626, 64_h1=0.1877, 64_l2=0.0718\n",
      "[102] time=2.29, avg_loss=1.8286, train_err=0.0914, 32_h1=0.0946, 32_l2=0.0517, 64_h1=0.1792, 64_l2=0.0651\n",
      "[103] time=2.38, avg_loss=1.8089, train_err=0.0904, 32_h1=0.0916, 32_l2=0.0471, 64_h1=0.1771, 64_l2=0.0642\n",
      "[104] time=2.24, avg_loss=1.7893, train_err=0.0895, 32_h1=0.0981, 32_l2=0.0555, 64_h1=0.1886, 64_l2=0.0682\n",
      "[105] time=2.09, avg_loss=1.7926, train_err=0.0896, 32_h1=0.0971, 32_l2=0.0558, 64_h1=0.1770, 64_l2=0.0700\n",
      "[106] time=2.22, avg_loss=1.7952, train_err=0.0898, 32_h1=0.0991, 32_l2=0.0570, 64_h1=0.1834, 64_l2=0.0697\n",
      "[107] time=2.19, avg_loss=1.7948, train_err=0.0897, 32_h1=0.0918, 32_l2=0.0468, 64_h1=0.1745, 64_l2=0.0624\n",
      "[108] time=2.26, avg_loss=1.7782, train_err=0.0889, 32_h1=0.0925, 32_l2=0.0509, 64_h1=0.1739, 64_l2=0.0611\n",
      "[109] time=2.11, avg_loss=1.7873, train_err=0.0894, 32_h1=0.0934, 32_l2=0.0500, 64_h1=0.1728, 64_l2=0.0611\n",
      "[110] time=2.20, avg_loss=1.7724, train_err=0.0886, 32_h1=0.0938, 32_l2=0.0525, 64_h1=0.1791, 64_l2=0.0655\n",
      "[111] time=2.36, avg_loss=1.7895, train_err=0.0895, 32_h1=0.0963, 32_l2=0.0547, 64_h1=0.1806, 64_l2=0.0664\n",
      "[112] time=2.40, avg_loss=1.7980, train_err=0.0899, 32_h1=0.0933, 32_l2=0.0500, 64_h1=0.1813, 64_l2=0.0617\n",
      "[113] time=2.43, avg_loss=1.7955, train_err=0.0898, 32_h1=0.0907, 32_l2=0.0475, 64_h1=0.1824, 64_l2=0.0604\n",
      "[114] time=2.46, avg_loss=1.7483, train_err=0.0874, 32_h1=0.0904, 32_l2=0.0468, 64_h1=0.1768, 64_l2=0.0580\n",
      "[115] time=2.47, avg_loss=1.7584, train_err=0.0879, 32_h1=0.0927, 32_l2=0.0506, 64_h1=0.1733, 64_l2=0.0647\n",
      "[116] time=2.44, avg_loss=1.7690, train_err=0.0884, 32_h1=0.0925, 32_l2=0.0495, 64_h1=0.1747, 64_l2=0.0649\n",
      "[117] time=2.38, avg_loss=1.7466, train_err=0.0873, 32_h1=0.0936, 32_l2=0.0539, 64_h1=0.1793, 64_l2=0.0642\n",
      "[118] time=2.40, avg_loss=1.7616, train_err=0.0881, 32_h1=0.0904, 32_l2=0.0468, 64_h1=0.1755, 64_l2=0.0591\n",
      "[119] time=2.37, avg_loss=1.7556, train_err=0.0878, 32_h1=0.0924, 32_l2=0.0496, 64_h1=0.1793, 64_l2=0.0662\n",
      "[120] time=2.43, avg_loss=1.7968, train_err=0.0898, 32_h1=0.0969, 32_l2=0.0539, 64_h1=0.1853, 64_l2=0.0671\n",
      "[121] time=2.50, avg_loss=1.7971, train_err=0.0899, 32_h1=0.0918, 32_l2=0.0488, 64_h1=0.1809, 64_l2=0.0646\n",
      "[122] time=2.44, avg_loss=1.7336, train_err=0.0867, 32_h1=0.0892, 32_l2=0.0450, 64_h1=0.1801, 64_l2=0.0638\n",
      "[123] time=2.42, avg_loss=1.7586, train_err=0.0879, 32_h1=0.0900, 32_l2=0.0464, 64_h1=0.1815, 64_l2=0.0612\n",
      "[124] time=2.41, avg_loss=1.7659, train_err=0.0883, 32_h1=0.0897, 32_l2=0.0466, 64_h1=0.1757, 64_l2=0.0634\n",
      "[125] time=2.38, avg_loss=1.7370, train_err=0.0869, 32_h1=0.0907, 32_l2=0.0489, 64_h1=0.1783, 64_l2=0.0634\n",
      "[126] time=2.41, avg_loss=1.7312, train_err=0.0866, 32_h1=0.0886, 32_l2=0.0447, 64_h1=0.1720, 64_l2=0.0564\n",
      "[127] time=2.38, avg_loss=1.7361, train_err=0.0868, 32_h1=0.0910, 32_l2=0.0478, 64_h1=0.1727, 64_l2=0.0613\n",
      "[128] time=2.37, avg_loss=1.7143, train_err=0.0857, 32_h1=0.0915, 32_l2=0.0491, 64_h1=0.1778, 64_l2=0.0597\n",
      "[129] time=2.37, avg_loss=1.7272, train_err=0.0864, 32_h1=0.0882, 32_l2=0.0442, 64_h1=0.1733, 64_l2=0.0574\n",
      "[130] time=2.40, avg_loss=1.7222, train_err=0.0861, 32_h1=0.0882, 32_l2=0.0441, 64_h1=0.1781, 64_l2=0.0606\n",
      "[131] time=2.36, avg_loss=1.7313, train_err=0.0866, 32_h1=0.0919, 32_l2=0.0486, 64_h1=0.1829, 64_l2=0.0650\n",
      "[132] time=2.48, avg_loss=1.7361, train_err=0.0868, 32_h1=0.0901, 32_l2=0.0482, 64_h1=0.1779, 64_l2=0.0561\n",
      "[133] time=2.39, avg_loss=1.7126, train_err=0.0856, 32_h1=0.0894, 32_l2=0.0464, 64_h1=0.1804, 64_l2=0.0668\n",
      "[134] time=2.39, avg_loss=1.7030, train_err=0.0851, 32_h1=0.0911, 32_l2=0.0496, 64_h1=0.1790, 64_l2=0.0663\n",
      "[135] time=2.38, avg_loss=1.7112, train_err=0.0856, 32_h1=0.0903, 32_l2=0.0486, 64_h1=0.1690, 64_l2=0.0606\n",
      "[136] time=2.43, avg_loss=1.7326, train_err=0.0866, 32_h1=0.0906, 32_l2=0.0492, 64_h1=0.1757, 64_l2=0.0617\n",
      "[137] time=2.40, avg_loss=1.6960, train_err=0.0848, 32_h1=0.0896, 32_l2=0.0469, 64_h1=0.1779, 64_l2=0.0616\n",
      "[138] time=2.42, avg_loss=1.7463, train_err=0.0873, 32_h1=0.0888, 32_l2=0.0477, 64_h1=0.1747, 64_l2=0.0635\n",
      "[139] time=2.39, avg_loss=1.7154, train_err=0.0858, 32_h1=0.0900, 32_l2=0.0469, 64_h1=0.1720, 64_l2=0.0599\n",
      "[140] time=2.42, avg_loss=1.6858, train_err=0.0843, 32_h1=0.0886, 32_l2=0.0464, 64_h1=0.1732, 64_l2=0.0603\n",
      "[141] time=2.37, avg_loss=1.6766, train_err=0.0838, 32_h1=0.0872, 32_l2=0.0441, 64_h1=0.1800, 64_l2=0.0596\n",
      "[142] time=2.37, avg_loss=1.6929, train_err=0.0846, 32_h1=0.0929, 32_l2=0.0544, 64_h1=0.1787, 64_l2=0.0645\n",
      "[143] time=2.41, avg_loss=1.7023, train_err=0.0851, 32_h1=0.0888, 32_l2=0.0459, 64_h1=0.1790, 64_l2=0.0625\n",
      "[144] time=2.43, avg_loss=1.6726, train_err=0.0836, 32_h1=0.0898, 32_l2=0.0460, 64_h1=0.1693, 64_l2=0.0615\n",
      "[145] time=2.40, avg_loss=1.7068, train_err=0.0853, 32_h1=0.0868, 32_l2=0.0434, 64_h1=0.1722, 64_l2=0.0615\n",
      "[146] time=2.37, avg_loss=1.6900, train_err=0.0845, 32_h1=0.0891, 32_l2=0.0493, 64_h1=0.1764, 64_l2=0.0657\n",
      "[147] time=2.38, avg_loss=1.6585, train_err=0.0829, 32_h1=0.0865, 32_l2=0.0439, 64_h1=0.1722, 64_l2=0.0577\n",
      "[148] time=2.37, avg_loss=1.6614, train_err=0.0831, 32_h1=0.0900, 32_l2=0.0484, 64_h1=0.1787, 64_l2=0.0616\n",
      "[149] time=2.27, avg_loss=1.6823, train_err=0.0841, 32_h1=0.0875, 32_l2=0.0441, 64_h1=0.1798, 64_l2=0.0581\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.02\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 26497\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(8, 8, 2, 2))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(8, 8, 2, 2))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(8, 8, 2, 2))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(8, 8, 2, 2))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(8, 8, 2, 2))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(8, 8, 2, 2))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(8, 8, 2, 2))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(8, 8, 2, 2))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f7760c75910>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f7761a60fa0>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f7761a60fa0>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f7761a60f70>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.19, avg_loss=11.6618, train_err=0.5831, 32_h1=0.3747, 32_l2=0.2593, 64_h1=0.4150, 64_l2=0.2595\n",
      "[1] time=2.20, avg_loss=5.6370, train_err=0.2819, 32_h1=0.2722, 32_l2=0.1976, 64_h1=0.3297, 64_l2=0.2083\n",
      "[2] time=2.19, avg_loss=4.4701, train_err=0.2235, 32_h1=0.2069, 32_l2=0.1350, 64_h1=0.2683, 64_l2=0.1372\n",
      "[3] time=2.13, avg_loss=3.8303, train_err=0.1915, 32_h1=0.1760, 32_l2=0.1121, 64_h1=0.2444, 64_l2=0.1186\n",
      "[4] time=2.07, avg_loss=3.4767, train_err=0.1738, 32_h1=0.1721, 32_l2=0.1116, 64_h1=0.2412, 64_l2=0.1229\n",
      "[5] time=2.09, avg_loss=3.3669, train_err=0.1683, 32_h1=0.1851, 32_l2=0.1369, 64_h1=0.2477, 64_l2=0.1453\n",
      "[6] time=2.10, avg_loss=3.1121, train_err=0.1556, 32_h1=0.1475, 32_l2=0.0926, 64_h1=0.2238, 64_l2=0.1004\n",
      "[7] time=2.09, avg_loss=2.8955, train_err=0.1448, 32_h1=0.1568, 32_l2=0.1040, 64_h1=0.2341, 64_l2=0.1213\n",
      "[8] time=2.13, avg_loss=2.7805, train_err=0.1390, 32_h1=0.1361, 32_l2=0.0844, 64_h1=0.2056, 64_l2=0.0895\n",
      "[9] time=2.06, avg_loss=2.7069, train_err=0.1353, 32_h1=0.1448, 32_l2=0.1041, 64_h1=0.2281, 64_l2=0.1164\n",
      "[10] time=2.12, avg_loss=2.6214, train_err=0.1311, 32_h1=0.1260, 32_l2=0.0761, 64_h1=0.2059, 64_l2=0.0838\n",
      "[11] time=2.20, avg_loss=2.4823, train_err=0.1241, 32_h1=0.1237, 32_l2=0.0744, 64_h1=0.1970, 64_l2=0.0849\n",
      "[12] time=2.13, avg_loss=2.3706, train_err=0.1185, 32_h1=0.1193, 32_l2=0.0727, 64_h1=0.1963, 64_l2=0.0832\n",
      "[13] time=2.11, avg_loss=2.3102, train_err=0.1155, 32_h1=0.1160, 32_l2=0.0716, 64_h1=0.2005, 64_l2=0.0870\n",
      "[14] time=2.13, avg_loss=2.2755, train_err=0.1138, 32_h1=0.1165, 32_l2=0.0716, 64_h1=0.1933, 64_l2=0.0817\n",
      "[15] time=2.08, avg_loss=2.2273, train_err=0.1114, 32_h1=0.1133, 32_l2=0.0684, 64_h1=0.1829, 64_l2=0.0708\n",
      "[16] time=2.07, avg_loss=2.1797, train_err=0.1090, 32_h1=0.1083, 32_l2=0.0639, 64_h1=0.1904, 64_l2=0.0761\n",
      "[17] time=2.04, avg_loss=2.0905, train_err=0.1045, 32_h1=0.1031, 32_l2=0.0553, 64_h1=0.1791, 64_l2=0.0674\n",
      "[18] time=2.13, avg_loss=2.1240, train_err=0.1062, 32_h1=0.1044, 32_l2=0.0564, 64_h1=0.1847, 64_l2=0.0709\n",
      "[19] time=2.04, avg_loss=2.0384, train_err=0.1019, 32_h1=0.1081, 32_l2=0.0613, 64_h1=0.1923, 64_l2=0.0730\n",
      "[20] time=2.22, avg_loss=2.0414, train_err=0.1021, 32_h1=0.1000, 32_l2=0.0541, 64_h1=0.1818, 64_l2=0.0648\n",
      "[21] time=2.20, avg_loss=2.0455, train_err=0.1023, 32_h1=0.1062, 32_l2=0.0629, 64_h1=0.1929, 64_l2=0.0802\n",
      "[22] time=2.12, avg_loss=2.0386, train_err=0.1019, 32_h1=0.1049, 32_l2=0.0591, 64_h1=0.1888, 64_l2=0.0747\n",
      "[23] time=2.19, avg_loss=1.9640, train_err=0.0982, 32_h1=0.0991, 32_l2=0.0557, 64_h1=0.1792, 64_l2=0.0689\n",
      "[24] time=2.07, avg_loss=1.9079, train_err=0.0954, 32_h1=0.0934, 32_l2=0.0492, 64_h1=0.1766, 64_l2=0.0647\n",
      "[25] time=2.04, avg_loss=1.9318, train_err=0.0966, 32_h1=0.1053, 32_l2=0.0667, 64_h1=0.1894, 64_l2=0.0804\n",
      "[26] time=2.05, avg_loss=1.9174, train_err=0.0959, 32_h1=0.0951, 32_l2=0.0507, 64_h1=0.1801, 64_l2=0.0650\n",
      "[27] time=2.08, avg_loss=1.8657, train_err=0.0933, 32_h1=0.0932, 32_l2=0.0493, 64_h1=0.1797, 64_l2=0.0661\n",
      "[28] time=2.32, avg_loss=1.8767, train_err=0.0938, 32_h1=0.0959, 32_l2=0.0556, 64_h1=0.1805, 64_l2=0.0663\n",
      "[29] time=2.35, avg_loss=1.8501, train_err=0.0925, 32_h1=0.0955, 32_l2=0.0544, 64_h1=0.1822, 64_l2=0.0684\n",
      "[30] time=2.36, avg_loss=1.8344, train_err=0.0917, 32_h1=0.1008, 32_l2=0.0611, 64_h1=0.1734, 64_l2=0.0727\n",
      "[31] time=2.40, avg_loss=1.8561, train_err=0.0928, 32_h1=0.0901, 32_l2=0.0468, 64_h1=0.1713, 64_l2=0.0602\n",
      "[32] time=2.34, avg_loss=1.8090, train_err=0.0904, 32_h1=0.0993, 32_l2=0.0553, 64_h1=0.1834, 64_l2=0.0709\n",
      "[33] time=2.34, avg_loss=1.8322, train_err=0.0916, 32_h1=0.0934, 32_l2=0.0524, 64_h1=0.1732, 64_l2=0.0668\n",
      "[34] time=2.35, avg_loss=1.8898, train_err=0.0945, 32_h1=0.0892, 32_l2=0.0462, 64_h1=0.1746, 64_l2=0.0597\n",
      "[35] time=2.37, avg_loss=1.7811, train_err=0.0891, 32_h1=0.0951, 32_l2=0.0532, 64_h1=0.1817, 64_l2=0.0672\n",
      "[36] time=2.38, avg_loss=1.8263, train_err=0.0913, 32_h1=0.0878, 32_l2=0.0463, 64_h1=0.1679, 64_l2=0.0579\n",
      "[37] time=2.38, avg_loss=1.7590, train_err=0.0879, 32_h1=0.0867, 32_l2=0.0442, 64_h1=0.1724, 64_l2=0.0571\n",
      "[38] time=2.37, avg_loss=1.7938, train_err=0.0897, 32_h1=0.0935, 32_l2=0.0574, 64_h1=0.1676, 64_l2=0.0678\n",
      "[39] time=2.37, avg_loss=1.7413, train_err=0.0871, 32_h1=0.0885, 32_l2=0.0489, 64_h1=0.1710, 64_l2=0.0633\n",
      "[40] time=2.36, avg_loss=1.7356, train_err=0.0868, 32_h1=0.0888, 32_l2=0.0475, 64_h1=0.1742, 64_l2=0.0629\n",
      "[41] time=2.33, avg_loss=1.7426, train_err=0.0871, 32_h1=0.0917, 32_l2=0.0533, 64_h1=0.1699, 64_l2=0.0646\n",
      "[42] time=2.48, avg_loss=1.7219, train_err=0.0861, 32_h1=0.0872, 32_l2=0.0469, 64_h1=0.1703, 64_l2=0.0635\n",
      "[43] time=2.34, avg_loss=1.7446, train_err=0.0872, 32_h1=0.0915, 32_l2=0.0497, 64_h1=0.1704, 64_l2=0.0633\n",
      "[44] time=2.39, avg_loss=1.6965, train_err=0.0848, 32_h1=0.0903, 32_l2=0.0521, 64_h1=0.1796, 64_l2=0.0656\n",
      "[45] time=2.36, avg_loss=1.6769, train_err=0.0838, 32_h1=0.0918, 32_l2=0.0522, 64_h1=0.1802, 64_l2=0.0664\n",
      "[46] time=2.35, avg_loss=1.7446, train_err=0.0872, 32_h1=0.0892, 32_l2=0.0499, 64_h1=0.1696, 64_l2=0.0645\n",
      "[47] time=2.34, avg_loss=1.6908, train_err=0.0845, 32_h1=0.0859, 32_l2=0.0471, 64_h1=0.1763, 64_l2=0.0622\n",
      "[48] time=2.37, avg_loss=1.7361, train_err=0.0868, 32_h1=0.0853, 32_l2=0.0436, 64_h1=0.1718, 64_l2=0.0576\n",
      "[49] time=2.32, avg_loss=1.6583, train_err=0.0829, 32_h1=0.0863, 32_l2=0.0474, 64_h1=0.1698, 64_l2=0.0625\n",
      "[50] time=2.34, avg_loss=1.6466, train_err=0.0823, 32_h1=0.0836, 32_l2=0.0429, 64_h1=0.1723, 64_l2=0.0580\n",
      "[51] time=2.34, avg_loss=1.6794, train_err=0.0840, 32_h1=0.0851, 32_l2=0.0444, 64_h1=0.1706, 64_l2=0.0554\n",
      "[52] time=2.33, avg_loss=1.6759, train_err=0.0838, 32_h1=0.0838, 32_l2=0.0432, 64_h1=0.1709, 64_l2=0.0534\n",
      "[53] time=2.37, avg_loss=1.6066, train_err=0.0803, 32_h1=0.0833, 32_l2=0.0442, 64_h1=0.1647, 64_l2=0.0593\n",
      "[54] time=2.35, avg_loss=1.6509, train_err=0.0825, 32_h1=0.0863, 32_l2=0.0465, 64_h1=0.1762, 64_l2=0.0611\n",
      "[55] time=2.37, avg_loss=1.6316, train_err=0.0816, 32_h1=0.0827, 32_l2=0.0427, 64_h1=0.1718, 64_l2=0.0549\n",
      "[56] time=2.36, avg_loss=1.6140, train_err=0.0807, 32_h1=0.0829, 32_l2=0.0423, 64_h1=0.1704, 64_l2=0.0530\n",
      "[57] time=2.33, avg_loss=1.6265, train_err=0.0813, 32_h1=0.0847, 32_l2=0.0450, 64_h1=0.1730, 64_l2=0.0664\n",
      "[58] time=2.34, avg_loss=1.6086, train_err=0.0804, 32_h1=0.0857, 32_l2=0.0482, 64_h1=0.1763, 64_l2=0.0648\n",
      "[59] time=2.40, avg_loss=1.6440, train_err=0.0822, 32_h1=0.0828, 32_l2=0.0424, 64_h1=0.1642, 64_l2=0.0574\n",
      "[60] time=2.34, avg_loss=1.6135, train_err=0.0807, 32_h1=0.0824, 32_l2=0.0432, 64_h1=0.1735, 64_l2=0.0664\n",
      "[61] time=2.38, avg_loss=1.6229, train_err=0.0811, 32_h1=0.0820, 32_l2=0.0409, 64_h1=0.1656, 64_l2=0.0574\n",
      "[62] time=2.33, avg_loss=1.6124, train_err=0.0806, 32_h1=0.0828, 32_l2=0.0423, 64_h1=0.1740, 64_l2=0.0536\n",
      "[63] time=2.35, avg_loss=1.5998, train_err=0.0800, 32_h1=0.0819, 32_l2=0.0432, 64_h1=0.1708, 64_l2=0.0591\n",
      "[64] time=2.35, avg_loss=1.6040, train_err=0.0802, 32_h1=0.0804, 32_l2=0.0396, 64_h1=0.1672, 64_l2=0.0561\n",
      "[65] time=2.46, avg_loss=1.6130, train_err=0.0806, 32_h1=0.0906, 32_l2=0.0495, 64_h1=0.1749, 64_l2=0.0635\n",
      "[66] time=2.36, avg_loss=1.5830, train_err=0.0791, 32_h1=0.0823, 32_l2=0.0434, 64_h1=0.1675, 64_l2=0.0564\n",
      "[67] time=2.10, avg_loss=1.5767, train_err=0.0788, 32_h1=0.0833, 32_l2=0.0475, 64_h1=0.1675, 64_l2=0.0611\n",
      "[68] time=2.07, avg_loss=1.5819, train_err=0.0791, 32_h1=0.0844, 32_l2=0.0447, 64_h1=0.1665, 64_l2=0.0551\n",
      "[69] time=2.05, avg_loss=1.5770, train_err=0.0788, 32_h1=0.0813, 32_l2=0.0401, 64_h1=0.1718, 64_l2=0.0567\n",
      "[70] time=2.05, avg_loss=1.5862, train_err=0.0793, 32_h1=0.0817, 32_l2=0.0452, 64_h1=0.1711, 64_l2=0.0640\n",
      "[71] time=2.05, avg_loss=1.5491, train_err=0.0775, 32_h1=0.0790, 32_l2=0.0382, 64_h1=0.1707, 64_l2=0.0585\n",
      "[72] time=2.12, avg_loss=1.5560, train_err=0.0778, 32_h1=0.0822, 32_l2=0.0449, 64_h1=0.1672, 64_l2=0.0580\n",
      "[73] time=2.05, avg_loss=1.5924, train_err=0.0796, 32_h1=0.0805, 32_l2=0.0413, 64_h1=0.1663, 64_l2=0.0579\n",
      "[74] time=2.04, avg_loss=1.5560, train_err=0.0778, 32_h1=0.0831, 32_l2=0.0435, 64_h1=0.1658, 64_l2=0.0571\n",
      "[75] time=2.05, avg_loss=1.5733, train_err=0.0787, 32_h1=0.0793, 32_l2=0.0403, 64_h1=0.1655, 64_l2=0.0513\n",
      "[76] time=2.04, avg_loss=1.5376, train_err=0.0769, 32_h1=0.0808, 32_l2=0.0458, 64_h1=0.1740, 64_l2=0.0635\n",
      "[77] time=2.04, avg_loss=1.5522, train_err=0.0776, 32_h1=0.0856, 32_l2=0.0488, 64_h1=0.1784, 64_l2=0.0645\n",
      "[78] time=2.12, avg_loss=1.5621, train_err=0.0781, 32_h1=0.0788, 32_l2=0.0396, 64_h1=0.1639, 64_l2=0.0549\n",
      "[79] time=2.04, avg_loss=1.5388, train_err=0.0769, 32_h1=0.0821, 32_l2=0.0440, 64_h1=0.1680, 64_l2=0.0528\n",
      "[80] time=2.04, avg_loss=1.5408, train_err=0.0770, 32_h1=0.0796, 32_l2=0.0396, 64_h1=0.1653, 64_l2=0.0593\n",
      "[81] time=2.06, avg_loss=1.5358, train_err=0.0768, 32_h1=0.0771, 32_l2=0.0372, 64_h1=0.1668, 64_l2=0.0543\n",
      "[82] time=2.13, avg_loss=1.5283, train_err=0.0764, 32_h1=0.0817, 32_l2=0.0437, 64_h1=0.1678, 64_l2=0.0587\n",
      "[83] time=2.10, avg_loss=1.5227, train_err=0.0761, 32_h1=0.0799, 32_l2=0.0396, 64_h1=0.1663, 64_l2=0.0545\n",
      "[84] time=2.07, avg_loss=1.5048, train_err=0.0752, 32_h1=0.0783, 32_l2=0.0399, 64_h1=0.1686, 64_l2=0.0564\n",
      "[85] time=2.09, avg_loss=1.5020, train_err=0.0751, 32_h1=0.0781, 32_l2=0.0394, 64_h1=0.1673, 64_l2=0.0587\n",
      "[86] time=2.17, avg_loss=1.5125, train_err=0.0756, 32_h1=0.0788, 32_l2=0.0404, 64_h1=0.1638, 64_l2=0.0543\n",
      "[87] time=2.09, avg_loss=1.5441, train_err=0.0772, 32_h1=0.0802, 32_l2=0.0428, 64_h1=0.1694, 64_l2=0.0578\n",
      "[88] time=2.14, avg_loss=1.5239, train_err=0.0762, 32_h1=0.0777, 32_l2=0.0394, 64_h1=0.1697, 64_l2=0.0561\n",
      "[89] time=2.24, avg_loss=1.4928, train_err=0.0746, 32_h1=0.0794, 32_l2=0.0418, 64_h1=0.1656, 64_l2=0.0548\n",
      "[90] time=2.24, avg_loss=1.5314, train_err=0.0766, 32_h1=0.0785, 32_l2=0.0389, 64_h1=0.1727, 64_l2=0.0542\n",
      "[91] time=2.20, avg_loss=1.4965, train_err=0.0748, 32_h1=0.0789, 32_l2=0.0405, 64_h1=0.1629, 64_l2=0.0546\n",
      "[92] time=2.05, avg_loss=1.5049, train_err=0.0752, 32_h1=0.0783, 32_l2=0.0404, 64_h1=0.1695, 64_l2=0.0549\n",
      "[93] time=2.06, avg_loss=1.4802, train_err=0.0740, 32_h1=0.0806, 32_l2=0.0449, 64_h1=0.1665, 64_l2=0.0596\n",
      "[94] time=2.09, avg_loss=1.4868, train_err=0.0743, 32_h1=0.0795, 32_l2=0.0416, 64_h1=0.1664, 64_l2=0.0585\n",
      "[95] time=2.08, avg_loss=1.4767, train_err=0.0738, 32_h1=0.0769, 32_l2=0.0375, 64_h1=0.1662, 64_l2=0.0547\n",
      "[96] time=2.34, avg_loss=1.5085, train_err=0.0754, 32_h1=0.0775, 32_l2=0.0380, 64_h1=0.1616, 64_l2=0.0495\n",
      "[97] time=2.37, avg_loss=1.4841, train_err=0.0742, 32_h1=0.0780, 32_l2=0.0395, 64_h1=0.1701, 64_l2=0.0590\n",
      "[98] time=2.35, avg_loss=1.4887, train_err=0.0744, 32_h1=0.0779, 32_l2=0.0406, 64_h1=0.1656, 64_l2=0.0545\n",
      "[99] time=2.33, avg_loss=1.5136, train_err=0.0757, 32_h1=0.0765, 32_l2=0.0370, 64_h1=0.1631, 64_l2=0.0504\n",
      "[100] time=2.33, avg_loss=1.4602, train_err=0.0730, 32_h1=0.0759, 32_l2=0.0363, 64_h1=0.1641, 64_l2=0.0522\n",
      "[101] time=2.34, avg_loss=1.4925, train_err=0.0746, 32_h1=0.0788, 32_l2=0.0414, 64_h1=0.1665, 64_l2=0.0574\n",
      "[102] time=2.35, avg_loss=1.4875, train_err=0.0744, 32_h1=0.0774, 32_l2=0.0387, 64_h1=0.1668, 64_l2=0.0512\n",
      "[103] time=2.38, avg_loss=1.4533, train_err=0.0727, 32_h1=0.0785, 32_l2=0.0400, 64_h1=0.1637, 64_l2=0.0503\n",
      "[104] time=2.33, avg_loss=1.4618, train_err=0.0731, 32_h1=0.0781, 32_l2=0.0418, 64_h1=0.1692, 64_l2=0.0563\n",
      "[105] time=2.29, avg_loss=1.4575, train_err=0.0729, 32_h1=0.0756, 32_l2=0.0369, 64_h1=0.1658, 64_l2=0.0525\n",
      "[106] time=2.37, avg_loss=1.4555, train_err=0.0728, 32_h1=0.0786, 32_l2=0.0444, 64_h1=0.1613, 64_l2=0.0564\n",
      "[107] time=2.39, avg_loss=1.5004, train_err=0.0750, 32_h1=0.0783, 32_l2=0.0386, 64_h1=0.1726, 64_l2=0.0541\n",
      "[108] time=2.41, avg_loss=1.4967, train_err=0.0748, 32_h1=0.0788, 32_l2=0.0399, 64_h1=0.1621, 64_l2=0.0542\n",
      "[109] time=2.34, avg_loss=1.4927, train_err=0.0746, 32_h1=0.0761, 32_l2=0.0373, 64_h1=0.1679, 64_l2=0.0540\n",
      "[110] time=2.36, avg_loss=1.4386, train_err=0.0719, 32_h1=0.0782, 32_l2=0.0404, 64_h1=0.1642, 64_l2=0.0549\n",
      "[111] time=2.43, avg_loss=1.4392, train_err=0.0720, 32_h1=0.0780, 32_l2=0.0404, 64_h1=0.1648, 64_l2=0.0509\n",
      "[112] time=2.36, avg_loss=1.4697, train_err=0.0735, 32_h1=0.0784, 32_l2=0.0402, 64_h1=0.1705, 64_l2=0.0558\n",
      "[113] time=2.34, avg_loss=1.4502, train_err=0.0725, 32_h1=0.0772, 32_l2=0.0386, 64_h1=0.1611, 64_l2=0.0493\n",
      "[114] time=2.41, avg_loss=1.4412, train_err=0.0721, 32_h1=0.0760, 32_l2=0.0381, 64_h1=0.1644, 64_l2=0.0534\n",
      "[115] time=2.35, avg_loss=1.4361, train_err=0.0718, 32_h1=0.0769, 32_l2=0.0402, 64_h1=0.1658, 64_l2=0.0553\n",
      "[116] time=2.33, avg_loss=1.4706, train_err=0.0735, 32_h1=0.0767, 32_l2=0.0381, 64_h1=0.1645, 64_l2=0.0509\n",
      "[117] time=2.35, avg_loss=1.4331, train_err=0.0717, 32_h1=0.0744, 32_l2=0.0359, 64_h1=0.1660, 64_l2=0.0546\n",
      "[118] time=2.33, avg_loss=1.4430, train_err=0.0722, 32_h1=0.0757, 32_l2=0.0369, 64_h1=0.1646, 64_l2=0.0505\n",
      "[119] time=2.32, avg_loss=1.4304, train_err=0.0715, 32_h1=0.0757, 32_l2=0.0372, 64_h1=0.1714, 64_l2=0.0580\n",
      "[120] time=2.37, avg_loss=1.4218, train_err=0.0711, 32_h1=0.0757, 32_l2=0.0384, 64_h1=0.1681, 64_l2=0.0561\n",
      "[121] time=2.35, avg_loss=1.4214, train_err=0.0711, 32_h1=0.0771, 32_l2=0.0405, 64_h1=0.1714, 64_l2=0.0566\n",
      "[122] time=2.32, avg_loss=1.4305, train_err=0.0715, 32_h1=0.0752, 32_l2=0.0366, 64_h1=0.1666, 64_l2=0.0517\n",
      "[123] time=2.35, avg_loss=1.4492, train_err=0.0725, 32_h1=0.0769, 32_l2=0.0389, 64_h1=0.1686, 64_l2=0.0536\n",
      "[124] time=2.36, avg_loss=1.4179, train_err=0.0709, 32_h1=0.0742, 32_l2=0.0358, 64_h1=0.1714, 64_l2=0.0552\n",
      "[125] time=2.37, avg_loss=1.4118, train_err=0.0706, 32_h1=0.0752, 32_l2=0.0378, 64_h1=0.1626, 64_l2=0.0536\n",
      "[126] time=2.37, avg_loss=1.4340, train_err=0.0717, 32_h1=0.0757, 32_l2=0.0374, 64_h1=0.1656, 64_l2=0.0553\n",
      "[127] time=2.37, avg_loss=1.4166, train_err=0.0708, 32_h1=0.0744, 32_l2=0.0353, 64_h1=0.1685, 64_l2=0.0528\n",
      "[128] time=2.38, avg_loss=1.4077, train_err=0.0704, 32_h1=0.0747, 32_l2=0.0357, 64_h1=0.1694, 64_l2=0.0548\n",
      "[129] time=2.34, avg_loss=1.4065, train_err=0.0703, 32_h1=0.0752, 32_l2=0.0357, 64_h1=0.1671, 64_l2=0.0490\n",
      "[130] time=2.40, avg_loss=1.4239, train_err=0.0712, 32_h1=0.0751, 32_l2=0.0367, 64_h1=0.1627, 64_l2=0.0505\n",
      "[131] time=2.35, avg_loss=1.4152, train_err=0.0708, 32_h1=0.0756, 32_l2=0.0366, 64_h1=0.1689, 64_l2=0.0549\n",
      "[132] time=2.36, avg_loss=1.4047, train_err=0.0702, 32_h1=0.0761, 32_l2=0.0395, 64_h1=0.1660, 64_l2=0.0536\n",
      "[133] time=2.36, avg_loss=1.4013, train_err=0.0701, 32_h1=0.0737, 32_l2=0.0351, 64_h1=0.1673, 64_l2=0.0531\n",
      "[134] time=2.39, avg_loss=1.3933, train_err=0.0697, 32_h1=0.0771, 32_l2=0.0388, 64_h1=0.1640, 64_l2=0.0529\n",
      "[135] time=2.15, avg_loss=1.3841, train_err=0.0692, 32_h1=0.0733, 32_l2=0.0349, 64_h1=0.1640, 64_l2=0.0509\n",
      "[136] time=2.23, avg_loss=1.4042, train_err=0.0702, 32_h1=0.0783, 32_l2=0.0409, 64_h1=0.1712, 64_l2=0.0594\n",
      "[137] time=2.30, avg_loss=1.4092, train_err=0.0705, 32_h1=0.0755, 32_l2=0.0375, 64_h1=0.1659, 64_l2=0.0520\n",
      "[138] time=2.17, avg_loss=1.3886, train_err=0.0694, 32_h1=0.0742, 32_l2=0.0370, 64_h1=0.1627, 64_l2=0.0512\n",
      "[139] time=2.23, avg_loss=1.4172, train_err=0.0709, 32_h1=0.0749, 32_l2=0.0365, 64_h1=0.1721, 64_l2=0.0578\n",
      "[140] time=2.23, avg_loss=1.3816, train_err=0.0691, 32_h1=0.0761, 32_l2=0.0383, 64_h1=0.1634, 64_l2=0.0543\n",
      "[141] time=2.23, avg_loss=1.3898, train_err=0.0695, 32_h1=0.0760, 32_l2=0.0392, 64_h1=0.1574, 64_l2=0.0539\n",
      "[142] time=2.23, avg_loss=1.3850, train_err=0.0692, 32_h1=0.0744, 32_l2=0.0372, 64_h1=0.1638, 64_l2=0.0507\n",
      "[143] time=2.22, avg_loss=1.3925, train_err=0.0696, 32_h1=0.0730, 32_l2=0.0345, 64_h1=0.1654, 64_l2=0.0545\n",
      "[144] time=2.07, avg_loss=1.4032, train_err=0.0702, 32_h1=0.0769, 32_l2=0.0401, 64_h1=0.1690, 64_l2=0.0582\n",
      "[145] time=2.09, avg_loss=1.3837, train_err=0.0692, 32_h1=0.0750, 32_l2=0.0380, 64_h1=0.1668, 64_l2=0.0545\n",
      "[146] time=2.07, avg_loss=1.3751, train_err=0.0688, 32_h1=0.0739, 32_l2=0.0359, 64_h1=0.1620, 64_l2=0.0488\n",
      "[147] time=2.07, avg_loss=1.3793, train_err=0.0690, 32_h1=0.0744, 32_l2=0.0367, 64_h1=0.1668, 64_l2=0.0530\n",
      "[148] time=2.20, avg_loss=1.3801, train_err=0.0690, 32_h1=0.0732, 32_l2=0.0352, 64_h1=0.1651, 64_l2=0.0537\n",
      "[149] time=2.26, avg_loss=1.3806, train_err=0.0690, 32_h1=0.0754, 32_l2=0.0370, 64_h1=0.1623, 64_l2=0.0572\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.03\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 30849\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(10, 10, 2, 2))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(10, 10, 2, 2))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(10, 10, 2, 2))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(10, 10, 2, 2))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(10, 10, 2, 2))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(10, 10, 2, 2))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(10, 10, 2, 2))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(10, 10, 2, 2))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f7761ae4610>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f7760c757c0>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f7760c757c0>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f7761a57130>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.24, avg_loss=12.2464, train_err=0.6123, 32_h1=0.3899, 32_l2=0.2588, 64_h1=0.4315, 64_l2=0.2554\n",
      "[1] time=2.16, avg_loss=6.0517, train_err=0.3026, 32_h1=0.2485, 32_l2=0.1669, 64_h1=0.3076, 64_l2=0.1742\n",
      "[2] time=2.08, avg_loss=4.5610, train_err=0.2280, 32_h1=0.2062, 32_l2=0.1336, 64_h1=0.2703, 64_l2=0.1403\n",
      "[3] time=2.08, avg_loss=4.0581, train_err=0.2029, 32_h1=0.2161, 32_l2=0.1507, 64_h1=0.2569, 64_l2=0.1466\n",
      "[4] time=2.10, avg_loss=3.7157, train_err=0.1858, 32_h1=0.1783, 32_l2=0.1167, 64_h1=0.2432, 64_l2=0.1171\n",
      "[5] time=2.12, avg_loss=3.4845, train_err=0.1742, 32_h1=0.1622, 32_l2=0.1020, 64_h1=0.2279, 64_l2=0.1119\n",
      "[6] time=2.20, avg_loss=3.2318, train_err=0.1616, 32_h1=0.1485, 32_l2=0.0897, 64_h1=0.2160, 64_l2=0.0979\n",
      "[7] time=2.13, avg_loss=3.0249, train_err=0.1512, 32_h1=0.1499, 32_l2=0.0958, 64_h1=0.2189, 64_l2=0.1073\n",
      "[8] time=2.24, avg_loss=2.9089, train_err=0.1454, 32_h1=0.1438, 32_l2=0.0880, 64_h1=0.2019, 64_l2=0.0938\n",
      "[9] time=2.12, avg_loss=2.7066, train_err=0.1353, 32_h1=0.1348, 32_l2=0.0806, 64_h1=0.2045, 64_l2=0.0860\n",
      "[10] time=2.05, avg_loss=2.6310, train_err=0.1316, 32_h1=0.1261, 32_l2=0.0725, 64_h1=0.1977, 64_l2=0.0854\n",
      "[11] time=2.18, avg_loss=2.5823, train_err=0.1291, 32_h1=0.1362, 32_l2=0.0857, 64_h1=0.2047, 64_l2=0.0915\n",
      "[12] time=2.15, avg_loss=2.4982, train_err=0.1249, 32_h1=0.1174, 32_l2=0.0668, 64_h1=0.1946, 64_l2=0.0816\n",
      "[13] time=2.29, avg_loss=2.5199, train_err=0.1260, 32_h1=0.1233, 32_l2=0.0729, 64_h1=0.1859, 64_l2=0.0778\n",
      "[14] time=2.34, avg_loss=2.3563, train_err=0.1178, 32_h1=0.1211, 32_l2=0.0757, 64_h1=0.1928, 64_l2=0.0850\n",
      "[15] time=2.38, avg_loss=2.2775, train_err=0.1139, 32_h1=0.1250, 32_l2=0.0768, 64_h1=0.2026, 64_l2=0.0828\n",
      "[16] time=2.41, avg_loss=2.2827, train_err=0.1141, 32_h1=0.1125, 32_l2=0.0639, 64_h1=0.1857, 64_l2=0.0746\n",
      "[17] time=2.35, avg_loss=2.1883, train_err=0.1094, 32_h1=0.1111, 32_l2=0.0691, 64_h1=0.1938, 64_l2=0.0818\n",
      "[18] time=2.32, avg_loss=2.1701, train_err=0.1085, 32_h1=0.1038, 32_l2=0.0561, 64_h1=0.1823, 64_l2=0.0695\n",
      "[19] time=2.36, avg_loss=2.0669, train_err=0.1033, 32_h1=0.1092, 32_l2=0.0635, 64_h1=0.1849, 64_l2=0.0732\n",
      "[20] time=2.32, avg_loss=2.0388, train_err=0.1019, 32_h1=0.1013, 32_l2=0.0539, 64_h1=0.1821, 64_l2=0.0687\n",
      "[21] time=2.38, avg_loss=2.0484, train_err=0.1024, 32_h1=0.0999, 32_l2=0.0552, 64_h1=0.1785, 64_l2=0.0614\n",
      "[22] time=2.38, avg_loss=1.9573, train_err=0.0979, 32_h1=0.1002, 32_l2=0.0561, 64_h1=0.1760, 64_l2=0.0686\n",
      "[23] time=2.32, avg_loss=2.0948, train_err=0.1047, 32_h1=0.0974, 32_l2=0.0511, 64_h1=0.1721, 64_l2=0.0595\n",
      "[24] time=2.34, avg_loss=1.9466, train_err=0.0973, 32_h1=0.0962, 32_l2=0.0538, 64_h1=0.1734, 64_l2=0.0636\n",
      "[25] time=2.36, avg_loss=1.9798, train_err=0.0990, 32_h1=0.1135, 32_l2=0.0761, 64_h1=0.1890, 64_l2=0.0866\n",
      "[26] time=2.37, avg_loss=1.9930, train_err=0.0996, 32_h1=0.0958, 32_l2=0.0516, 64_h1=0.1768, 64_l2=0.0670\n",
      "[27] time=2.35, avg_loss=1.9454, train_err=0.0973, 32_h1=0.0961, 32_l2=0.0522, 64_h1=0.1696, 64_l2=0.0628\n",
      "[28] time=2.35, avg_loss=1.8510, train_err=0.0925, 32_h1=0.0916, 32_l2=0.0478, 64_h1=0.1696, 64_l2=0.0615\n",
      "[29] time=2.37, avg_loss=1.8409, train_err=0.0920, 32_h1=0.1011, 32_l2=0.0601, 64_h1=0.1866, 64_l2=0.0712\n",
      "[30] time=2.35, avg_loss=1.8327, train_err=0.0916, 32_h1=0.0914, 32_l2=0.0485, 64_h1=0.1698, 64_l2=0.0574\n",
      "[31] time=2.40, avg_loss=1.8614, train_err=0.0931, 32_h1=0.0896, 32_l2=0.0468, 64_h1=0.1692, 64_l2=0.0614\n",
      "[32] time=2.36, avg_loss=1.7919, train_err=0.0896, 32_h1=0.0928, 32_l2=0.0513, 64_h1=0.1758, 64_l2=0.0618\n",
      "[33] time=2.35, avg_loss=1.7875, train_err=0.0894, 32_h1=0.0888, 32_l2=0.0463, 64_h1=0.1733, 64_l2=0.0661\n",
      "[34] time=2.40, avg_loss=1.8190, train_err=0.0910, 32_h1=0.0985, 32_l2=0.0575, 64_h1=0.1744, 64_l2=0.0673\n",
      "[35] time=2.40, avg_loss=1.7686, train_err=0.0884, 32_h1=0.0871, 32_l2=0.0453, 64_h1=0.1663, 64_l2=0.0616\n",
      "[36] time=2.46, avg_loss=1.7276, train_err=0.0864, 32_h1=0.0896, 32_l2=0.0507, 64_h1=0.1692, 64_l2=0.0652\n",
      "[37] time=2.35, avg_loss=1.7653, train_err=0.0883, 32_h1=0.0866, 32_l2=0.0447, 64_h1=0.1723, 64_l2=0.0605\n",
      "[38] time=2.38, avg_loss=1.7289, train_err=0.0864, 32_h1=0.0879, 32_l2=0.0461, 64_h1=0.1643, 64_l2=0.0579\n",
      "[39] time=2.37, avg_loss=1.7493, train_err=0.0875, 32_h1=0.1011, 32_l2=0.0653, 64_h1=0.1650, 64_l2=0.0732\n",
      "[40] time=2.32, avg_loss=1.7673, train_err=0.0884, 32_h1=0.0876, 32_l2=0.0454, 64_h1=0.1642, 64_l2=0.0582\n",
      "[41] time=2.37, avg_loss=1.7132, train_err=0.0857, 32_h1=0.0874, 32_l2=0.0465, 64_h1=0.1688, 64_l2=0.0630\n",
      "[42] time=2.31, avg_loss=1.7773, train_err=0.0889, 32_h1=0.0909, 32_l2=0.0513, 64_h1=0.1670, 64_l2=0.0614\n",
      "[43] time=2.45, avg_loss=1.7201, train_err=0.0860, 32_h1=0.0911, 32_l2=0.0530, 64_h1=0.1728, 64_l2=0.0699\n",
      "[44] time=2.36, avg_loss=1.6611, train_err=0.0831, 32_h1=0.0844, 32_l2=0.0434, 64_h1=0.1663, 64_l2=0.0590\n",
      "[45] time=2.37, avg_loss=1.6729, train_err=0.0836, 32_h1=0.0850, 32_l2=0.0432, 64_h1=0.1552, 64_l2=0.0548\n",
      "[46] time=2.41, avg_loss=1.6759, train_err=0.0838, 32_h1=0.0853, 32_l2=0.0433, 64_h1=0.1745, 64_l2=0.0580\n",
      "[47] time=2.35, avg_loss=1.6662, train_err=0.0833, 32_h1=0.0857, 32_l2=0.0441, 64_h1=0.1694, 64_l2=0.0653\n",
      "[48] time=2.33, avg_loss=1.6876, train_err=0.0844, 32_h1=0.0822, 32_l2=0.0414, 64_h1=0.1666, 64_l2=0.0589\n",
      "[49] time=2.36, avg_loss=1.6559, train_err=0.0828, 32_h1=0.0821, 32_l2=0.0409, 64_h1=0.1672, 64_l2=0.0577\n",
      "[50] time=2.38, avg_loss=1.6610, train_err=0.0830, 32_h1=0.0850, 32_l2=0.0451, 64_h1=0.1600, 64_l2=0.0603\n",
      "[51] time=2.31, avg_loss=1.6689, train_err=0.0834, 32_h1=0.0856, 32_l2=0.0460, 64_h1=0.1629, 64_l2=0.0576\n",
      "[52] time=2.23, avg_loss=1.6259, train_err=0.0813, 32_h1=0.0831, 32_l2=0.0416, 64_h1=0.1662, 64_l2=0.0578\n",
      "[53] time=2.15, avg_loss=1.6019, train_err=0.0801, 32_h1=0.0817, 32_l2=0.0413, 64_h1=0.1679, 64_l2=0.0602\n",
      "[54] time=2.11, avg_loss=1.6206, train_err=0.0810, 32_h1=0.0802, 32_l2=0.0391, 64_h1=0.1634, 64_l2=0.0560\n",
      "[55] time=2.23, avg_loss=1.6337, train_err=0.0817, 32_h1=0.0833, 32_l2=0.0435, 64_h1=0.1623, 64_l2=0.0535\n",
      "[56] time=2.21, avg_loss=1.5843, train_err=0.0792, 32_h1=0.0835, 32_l2=0.0460, 64_h1=0.1655, 64_l2=0.0613\n",
      "[57] time=2.23, avg_loss=1.5932, train_err=0.0797, 32_h1=0.0815, 32_l2=0.0427, 64_h1=0.1632, 64_l2=0.0567\n",
      "[58] time=2.28, avg_loss=1.6171, train_err=0.0809, 32_h1=0.0795, 32_l2=0.0389, 64_h1=0.1611, 64_l2=0.0522\n",
      "[59] time=2.19, avg_loss=1.5982, train_err=0.0799, 32_h1=0.0978, 32_l2=0.0625, 64_h1=0.1636, 64_l2=0.0679\n",
      "[60] time=2.06, avg_loss=1.6189, train_err=0.0809, 32_h1=0.0790, 32_l2=0.0384, 64_h1=0.1650, 64_l2=0.0567\n",
      "[61] time=2.06, avg_loss=1.6274, train_err=0.0814, 32_h1=0.0824, 32_l2=0.0426, 64_h1=0.1660, 64_l2=0.0623\n",
      "[62] time=2.08, avg_loss=1.5898, train_err=0.0795, 32_h1=0.0800, 32_l2=0.0408, 64_h1=0.1615, 64_l2=0.0566\n",
      "[63] time=2.09, avg_loss=1.6051, train_err=0.0803, 32_h1=0.0834, 32_l2=0.0455, 64_h1=0.1613, 64_l2=0.0580\n",
      "[64] time=2.07, avg_loss=1.5772, train_err=0.0789, 32_h1=0.0799, 32_l2=0.0402, 64_h1=0.1641, 64_l2=0.0590\n",
      "[65] time=2.08, avg_loss=1.5894, train_err=0.0795, 32_h1=0.0974, 32_l2=0.0611, 64_h1=0.1702, 64_l2=0.0724\n",
      "[66] time=2.13, avg_loss=1.5965, train_err=0.0798, 32_h1=0.0912, 32_l2=0.0557, 64_h1=0.1722, 64_l2=0.0661\n",
      "[67] time=2.09, avg_loss=1.5856, train_err=0.0793, 32_h1=0.0786, 32_l2=0.0388, 64_h1=0.1608, 64_l2=0.0565\n",
      "[68] time=2.03, avg_loss=1.5646, train_err=0.0782, 32_h1=0.0829, 32_l2=0.0457, 64_h1=0.1657, 64_l2=0.0583\n",
      "[69] time=2.06, avg_loss=1.5731, train_err=0.0787, 32_h1=0.0871, 32_l2=0.0510, 64_h1=0.1670, 64_l2=0.0641\n",
      "[70] time=2.14, avg_loss=1.5769, train_err=0.0788, 32_h1=0.0931, 32_l2=0.0630, 64_h1=0.1712, 64_l2=0.0733\n",
      "[71] time=2.12, avg_loss=1.5991, train_err=0.0800, 32_h1=0.0779, 32_l2=0.0380, 64_h1=0.1625, 64_l2=0.0540\n",
      "[72] time=2.17, avg_loss=1.5276, train_err=0.0764, 32_h1=0.0788, 32_l2=0.0387, 64_h1=0.1651, 64_l2=0.0529\n",
      "[73] time=2.10, avg_loss=1.5428, train_err=0.0771, 32_h1=0.0776, 32_l2=0.0378, 64_h1=0.1577, 64_l2=0.0528\n",
      "[74] time=2.23, avg_loss=1.5335, train_err=0.0767, 32_h1=0.0796, 32_l2=0.0409, 64_h1=0.1646, 64_l2=0.0558\n",
      "[75] time=2.25, avg_loss=1.5495, train_err=0.0775, 32_h1=0.0798, 32_l2=0.0435, 64_h1=0.1635, 64_l2=0.0589\n",
      "[76] time=2.09, avg_loss=1.5177, train_err=0.0759, 32_h1=0.0824, 32_l2=0.0447, 64_h1=0.1632, 64_l2=0.0559\n",
      "[77] time=2.13, avg_loss=1.5269, train_err=0.0763, 32_h1=0.0806, 32_l2=0.0415, 64_h1=0.1649, 64_l2=0.0560\n",
      "[78] time=2.09, avg_loss=1.5600, train_err=0.0780, 32_h1=0.0800, 32_l2=0.0423, 64_h1=0.1643, 64_l2=0.0568\n",
      "[79] time=2.19, avg_loss=1.5261, train_err=0.0763, 32_h1=0.0774, 32_l2=0.0374, 64_h1=0.1658, 64_l2=0.0548\n",
      "[80] time=2.25, avg_loss=1.5631, train_err=0.0782, 32_h1=0.0785, 32_l2=0.0398, 64_h1=0.1625, 64_l2=0.0553\n",
      "[81] time=2.34, avg_loss=1.5062, train_err=0.0753, 32_h1=0.0822, 32_l2=0.0457, 64_h1=0.1562, 64_l2=0.0576\n",
      "[82] time=2.40, avg_loss=1.5294, train_err=0.0765, 32_h1=0.0898, 32_l2=0.0543, 64_h1=0.1749, 64_l2=0.0679\n",
      "[83] time=2.46, avg_loss=1.5138, train_err=0.0757, 32_h1=0.0770, 32_l2=0.0373, 64_h1=0.1594, 64_l2=0.0534\n",
      "[84] time=2.41, avg_loss=1.5268, train_err=0.0763, 32_h1=0.0816, 32_l2=0.0429, 64_h1=0.1654, 64_l2=0.0627\n",
      "[85] time=2.34, avg_loss=1.5147, train_err=0.0757, 32_h1=0.0817, 32_l2=0.0438, 64_h1=0.1595, 64_l2=0.0600\n",
      "[86] time=2.37, avg_loss=1.5227, train_err=0.0761, 32_h1=0.0799, 32_l2=0.0422, 64_h1=0.1677, 64_l2=0.0603\n",
      "[87] time=2.36, avg_loss=1.4877, train_err=0.0744, 32_h1=0.0784, 32_l2=0.0399, 64_h1=0.1639, 64_l2=0.0548\n",
      "[88] time=2.35, avg_loss=1.5164, train_err=0.0758, 32_h1=0.0787, 32_l2=0.0391, 64_h1=0.1678, 64_l2=0.0608\n",
      "[89] time=2.34, avg_loss=1.5191, train_err=0.0760, 32_h1=0.0782, 32_l2=0.0383, 64_h1=0.1599, 64_l2=0.0551\n",
      "[90] time=2.37, avg_loss=1.4875, train_err=0.0744, 32_h1=0.0763, 32_l2=0.0360, 64_h1=0.1664, 64_l2=0.0516\n",
      "[91] time=2.35, avg_loss=1.4961, train_err=0.0748, 32_h1=0.0765, 32_l2=0.0376, 64_h1=0.1631, 64_l2=0.0556\n",
      "[92] time=2.30, avg_loss=1.4851, train_err=0.0743, 32_h1=0.0790, 32_l2=0.0425, 64_h1=0.1602, 64_l2=0.0541\n",
      "[93] time=2.35, avg_loss=1.4966, train_err=0.0748, 32_h1=0.0774, 32_l2=0.0376, 64_h1=0.1559, 64_l2=0.0507\n",
      "[94] time=2.38, avg_loss=1.4930, train_err=0.0746, 32_h1=0.0840, 32_l2=0.0485, 64_h1=0.1695, 64_l2=0.0612\n",
      "[95] time=2.42, avg_loss=1.5030, train_err=0.0752, 32_h1=0.0765, 32_l2=0.0372, 64_h1=0.1581, 64_l2=0.0530\n",
      "[96] time=2.38, avg_loss=1.4858, train_err=0.0743, 32_h1=0.0769, 32_l2=0.0385, 64_h1=0.1602, 64_l2=0.0552\n",
      "[97] time=2.38, avg_loss=1.4716, train_err=0.0736, 32_h1=0.0801, 32_l2=0.0430, 64_h1=0.1612, 64_l2=0.0596\n",
      "[98] time=2.36, avg_loss=1.4783, train_err=0.0739, 32_h1=0.0764, 32_l2=0.0383, 64_h1=0.1593, 64_l2=0.0536\n",
      "[99] time=2.34, avg_loss=1.4662, train_err=0.0733, 32_h1=0.0792, 32_l2=0.0405, 64_h1=0.1619, 64_l2=0.0539\n",
      "[100] time=2.35, avg_loss=1.4609, train_err=0.0730, 32_h1=0.0784, 32_l2=0.0395, 64_h1=0.1610, 64_l2=0.0544\n",
      "[101] time=2.40, avg_loss=1.4880, train_err=0.0744, 32_h1=0.0771, 32_l2=0.0386, 64_h1=0.1576, 64_l2=0.0538\n",
      "[102] time=2.44, avg_loss=1.4537, train_err=0.0727, 32_h1=0.0758, 32_l2=0.0383, 64_h1=0.1584, 64_l2=0.0522\n",
      "[103] time=2.33, avg_loss=1.4442, train_err=0.0722, 32_h1=0.0756, 32_l2=0.0368, 64_h1=0.1613, 64_l2=0.0541\n",
      "[104] time=2.38, avg_loss=1.4827, train_err=0.0741, 32_h1=0.0756, 32_l2=0.0362, 64_h1=0.1612, 64_l2=0.0530\n",
      "[105] time=2.32, avg_loss=1.4396, train_err=0.0720, 32_h1=0.0783, 32_l2=0.0401, 64_h1=0.1561, 64_l2=0.0509\n",
      "[106] time=2.43, avg_loss=1.4827, train_err=0.0741, 32_h1=0.0776, 32_l2=0.0392, 64_h1=0.1571, 64_l2=0.0523\n",
      "[107] time=2.31, avg_loss=1.4559, train_err=0.0728, 32_h1=0.0759, 32_l2=0.0371, 64_h1=0.1593, 64_l2=0.0510\n",
      "[108] time=2.33, avg_loss=1.4460, train_err=0.0723, 32_h1=0.0810, 32_l2=0.0450, 64_h1=0.1653, 64_l2=0.0587\n",
      "[109] time=2.33, avg_loss=1.4507, train_err=0.0725, 32_h1=0.0788, 32_l2=0.0413, 64_h1=0.1612, 64_l2=0.0597\n",
      "[110] time=2.31, avg_loss=1.4777, train_err=0.0739, 32_h1=0.0757, 32_l2=0.0357, 64_h1=0.1579, 64_l2=0.0520\n",
      "[111] time=2.36, avg_loss=1.4223, train_err=0.0711, 32_h1=0.0750, 32_l2=0.0370, 64_h1=0.1556, 64_l2=0.0520\n",
      "[112] time=2.35, avg_loss=1.4444, train_err=0.0722, 32_h1=0.0752, 32_l2=0.0366, 64_h1=0.1649, 64_l2=0.0540\n",
      "[113] time=2.32, avg_loss=1.4444, train_err=0.0722, 32_h1=0.0757, 32_l2=0.0364, 64_h1=0.1514, 64_l2=0.0486\n",
      "[114] time=2.32, avg_loss=1.4207, train_err=0.0710, 32_h1=0.0778, 32_l2=0.0408, 64_h1=0.1663, 64_l2=0.0567\n",
      "[115] time=2.31, avg_loss=1.4318, train_err=0.0716, 32_h1=0.0740, 32_l2=0.0352, 64_h1=0.1576, 64_l2=0.0522\n",
      "[116] time=2.35, avg_loss=1.4499, train_err=0.0725, 32_h1=0.0779, 32_l2=0.0413, 64_h1=0.1595, 64_l2=0.0547\n",
      "[117] time=2.33, avg_loss=1.4522, train_err=0.0726, 32_h1=0.0752, 32_l2=0.0370, 64_h1=0.1575, 64_l2=0.0529\n",
      "[118] time=2.37, avg_loss=1.4361, train_err=0.0718, 32_h1=0.0753, 32_l2=0.0369, 64_h1=0.1621, 64_l2=0.0539\n",
      "[119] time=2.36, avg_loss=1.4409, train_err=0.0720, 32_h1=0.0748, 32_l2=0.0373, 64_h1=0.1640, 64_l2=0.0537\n",
      "[120] time=2.24, avg_loss=1.4207, train_err=0.0710, 32_h1=0.0740, 32_l2=0.0350, 64_h1=0.1600, 64_l2=0.0513\n",
      "[121] time=2.12, avg_loss=1.4461, train_err=0.0723, 32_h1=0.0774, 32_l2=0.0382, 64_h1=0.1547, 64_l2=0.0519\n",
      "[122] time=2.25, avg_loss=1.4249, train_err=0.0712, 32_h1=0.0755, 32_l2=0.0363, 64_h1=0.1648, 64_l2=0.0535\n",
      "[123] time=2.22, avg_loss=1.4242, train_err=0.0712, 32_h1=0.0787, 32_l2=0.0410, 64_h1=0.1626, 64_l2=0.0574\n",
      "[124] time=2.10, avg_loss=1.4102, train_err=0.0705, 32_h1=0.0740, 32_l2=0.0357, 64_h1=0.1557, 64_l2=0.0500\n",
      "[125] time=2.07, avg_loss=1.4084, train_err=0.0704, 32_h1=0.0767, 32_l2=0.0398, 64_h1=0.1606, 64_l2=0.0574\n",
      "[126] time=2.19, avg_loss=1.4171, train_err=0.0709, 32_h1=0.0747, 32_l2=0.0366, 64_h1=0.1583, 64_l2=0.0514\n",
      "[127] time=2.12, avg_loss=1.4396, train_err=0.0720, 32_h1=0.0796, 32_l2=0.0424, 64_h1=0.1682, 64_l2=0.0564\n",
      "[128] time=2.17, avg_loss=1.4070, train_err=0.0703, 32_h1=0.0739, 32_l2=0.0346, 64_h1=0.1568, 64_l2=0.0516\n",
      "[129] time=2.22, avg_loss=1.4039, train_err=0.0702, 32_h1=0.0749, 32_l2=0.0365, 64_h1=0.1559, 64_l2=0.0462\n",
      "[130] time=2.29, avg_loss=1.4197, train_err=0.0710, 32_h1=0.0734, 32_l2=0.0349, 64_h1=0.1623, 64_l2=0.0538\n",
      "[131] time=2.23, avg_loss=1.4154, train_err=0.0708, 32_h1=0.0773, 32_l2=0.0391, 64_h1=0.1561, 64_l2=0.0545\n",
      "[132] time=2.18, avg_loss=1.4063, train_err=0.0703, 32_h1=0.0739, 32_l2=0.0354, 64_h1=0.1561, 64_l2=0.0479\n",
      "[133] time=2.20, avg_loss=1.3942, train_err=0.0697, 32_h1=0.0742, 32_l2=0.0357, 64_h1=0.1532, 64_l2=0.0500\n",
      "[134] time=2.23, avg_loss=1.4098, train_err=0.0705, 32_h1=0.0762, 32_l2=0.0392, 64_h1=0.1549, 64_l2=0.0523\n",
      "[135] time=2.16, avg_loss=1.4036, train_err=0.0702, 32_h1=0.0726, 32_l2=0.0338, 64_h1=0.1542, 64_l2=0.0490\n",
      "[136] time=2.20, avg_loss=1.4003, train_err=0.0700, 32_h1=0.0731, 32_l2=0.0347, 64_h1=0.1521, 64_l2=0.0502\n",
      "[137] time=2.21, avg_loss=1.3823, train_err=0.0691, 32_h1=0.0728, 32_l2=0.0341, 64_h1=0.1556, 64_l2=0.0490\n",
      "[138] time=2.10, avg_loss=1.3837, train_err=0.0692, 32_h1=0.0755, 32_l2=0.0389, 64_h1=0.1597, 64_l2=0.0579\n",
      "[139] time=2.09, avg_loss=1.4062, train_err=0.0703, 32_h1=0.0748, 32_l2=0.0362, 64_h1=0.1566, 64_l2=0.0496\n",
      "[140] time=2.03, avg_loss=1.4225, train_err=0.0711, 32_h1=0.0736, 32_l2=0.0358, 64_h1=0.1533, 64_l2=0.0485\n",
      "[141] time=2.04, avg_loss=1.3864, train_err=0.0693, 32_h1=0.0734, 32_l2=0.0345, 64_h1=0.1610, 64_l2=0.0516\n",
      "[142] time=2.26, avg_loss=1.3913, train_err=0.0696, 32_h1=0.0749, 32_l2=0.0374, 64_h1=0.1584, 64_l2=0.0521\n",
      "[143] time=2.24, avg_loss=1.3855, train_err=0.0693, 32_h1=0.0763, 32_l2=0.0408, 64_h1=0.1649, 64_l2=0.0573\n",
      "[144] time=2.19, avg_loss=1.3792, train_err=0.0690, 32_h1=0.0745, 32_l2=0.0366, 64_h1=0.1592, 64_l2=0.0535\n",
      "[145] time=2.21, avg_loss=1.4102, train_err=0.0705, 32_h1=0.0741, 32_l2=0.0357, 64_h1=0.1654, 64_l2=0.0540\n",
      "[146] time=2.24, avg_loss=1.3758, train_err=0.0688, 32_h1=0.0724, 32_l2=0.0338, 64_h1=0.1566, 64_l2=0.0512\n",
      "[147] time=2.17, avg_loss=1.3613, train_err=0.0681, 32_h1=0.0754, 32_l2=0.0387, 64_h1=0.1578, 64_l2=0.0537\n",
      "[148] time=2.35, avg_loss=1.3762, train_err=0.0688, 32_h1=0.0732, 32_l2=0.0350, 64_h1=0.1535, 64_l2=0.0498\n",
      "[149] time=2.42, avg_loss=1.3812, train_err=0.0691, 32_h1=0.0773, 32_l2=0.0396, 64_h1=0.1570, 64_l2=0.0493\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.04\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 35713\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(12, 12, 2, 2))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(12, 12, 2, 2))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(12, 12, 2, 2))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(12, 12, 2, 2))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(12, 12, 2, 2))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(12, 12, 2, 2))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(12, 12, 2, 2))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(12, 12, 2, 2))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f78870e48e0>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f7761a60d30>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f7761a60d30>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f7761ae4610>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.38, avg_loss=11.3655, train_err=0.5683, 32_h1=0.3494, 32_l2=0.2443, 64_h1=0.4032, 64_l2=0.2499\n",
      "[1] time=2.32, avg_loss=5.8806, train_err=0.2940, 32_h1=0.2454, 32_l2=0.1713, 64_h1=0.3036, 64_l2=0.1771\n",
      "[2] time=2.37, avg_loss=4.6802, train_err=0.2340, 32_h1=0.2219, 32_l2=0.1574, 64_h1=0.2686, 64_l2=0.1554\n",
      "[3] time=2.33, avg_loss=4.2343, train_err=0.2117, 32_h1=0.2022, 32_l2=0.1385, 64_h1=0.2667, 64_l2=0.1433\n",
      "[4] time=2.41, avg_loss=3.7032, train_err=0.1852, 32_h1=0.1737, 32_l2=0.1139, 64_h1=0.2366, 64_l2=0.1223\n",
      "[5] time=2.37, avg_loss=3.5525, train_err=0.1776, 32_h1=0.1709, 32_l2=0.1194, 64_h1=0.2382, 64_l2=0.1242\n",
      "[6] time=2.35, avg_loss=3.2136, train_err=0.1607, 32_h1=0.1690, 32_l2=0.1181, 64_h1=0.2202, 64_l2=0.1230\n",
      "[7] time=2.30, avg_loss=3.0981, train_err=0.1549, 32_h1=0.1474, 32_l2=0.0939, 64_h1=0.2177, 64_l2=0.1059\n",
      "[8] time=2.32, avg_loss=2.8870, train_err=0.1443, 32_h1=0.1492, 32_l2=0.1037, 64_h1=0.2199, 64_l2=0.1109\n",
      "[9] time=2.33, avg_loss=2.7734, train_err=0.1387, 32_h1=0.1351, 32_l2=0.0833, 64_h1=0.1988, 64_l2=0.0925\n",
      "[10] time=2.32, avg_loss=2.6298, train_err=0.1315, 32_h1=0.1495, 32_l2=0.1090, 64_h1=0.2114, 64_l2=0.1137\n",
      "[11] time=2.34, avg_loss=2.4984, train_err=0.1249, 32_h1=0.1214, 32_l2=0.0725, 64_h1=0.1937, 64_l2=0.0862\n",
      "[12] time=2.34, avg_loss=2.5070, train_err=0.1253, 32_h1=0.1224, 32_l2=0.0709, 64_h1=0.1840, 64_l2=0.0764\n",
      "[13] time=2.32, avg_loss=2.3713, train_err=0.1186, 32_h1=0.1326, 32_l2=0.0929, 64_h1=0.1984, 64_l2=0.1041\n",
      "[14] time=2.43, avg_loss=2.3490, train_err=0.1175, 32_h1=0.1207, 32_l2=0.0743, 64_h1=0.1789, 64_l2=0.0724\n",
      "[15] time=2.37, avg_loss=2.2925, train_err=0.1146, 32_h1=0.1100, 32_l2=0.0626, 64_h1=0.1815, 64_l2=0.0695\n",
      "[16] time=2.36, avg_loss=2.2753, train_err=0.1138, 32_h1=0.1263, 32_l2=0.0802, 64_h1=0.1962, 64_l2=0.0921\n",
      "[17] time=2.38, avg_loss=2.1792, train_err=0.1090, 32_h1=0.1050, 32_l2=0.0588, 64_h1=0.1787, 64_l2=0.0675\n",
      "[18] time=2.36, avg_loss=2.1416, train_err=0.1071, 32_h1=0.1059, 32_l2=0.0603, 64_h1=0.1814, 64_l2=0.0733\n",
      "[19] time=2.33, avg_loss=2.1597, train_err=0.1080, 32_h1=0.1099, 32_l2=0.0691, 64_h1=0.1846, 64_l2=0.0743\n",
      "[20] time=2.37, avg_loss=2.0987, train_err=0.1049, 32_h1=0.1120, 32_l2=0.0665, 64_h1=0.1866, 64_l2=0.0812\n",
      "[21] time=2.40, avg_loss=2.1441, train_err=0.1072, 32_h1=0.1059, 32_l2=0.0609, 64_h1=0.1813, 64_l2=0.0769\n",
      "[22] time=2.35, avg_loss=2.0392, train_err=0.1020, 32_h1=0.1025, 32_l2=0.0585, 64_h1=0.1765, 64_l2=0.0696\n",
      "[23] time=2.34, avg_loss=1.9763, train_err=0.0988, 32_h1=0.1015, 32_l2=0.0608, 64_h1=0.1801, 64_l2=0.0714\n",
      "[24] time=2.37, avg_loss=2.0032, train_err=0.1002, 32_h1=0.1005, 32_l2=0.0558, 64_h1=0.1799, 64_l2=0.0705\n",
      "[25] time=2.34, avg_loss=1.9680, train_err=0.0984, 32_h1=0.0953, 32_l2=0.0513, 64_h1=0.1712, 64_l2=0.0614\n",
      "[26] time=2.36, avg_loss=1.9311, train_err=0.0966, 32_h1=0.1051, 32_l2=0.0676, 64_h1=0.1732, 64_l2=0.0742\n",
      "[27] time=2.40, avg_loss=1.9025, train_err=0.0951, 32_h1=0.1060, 32_l2=0.0638, 64_h1=0.1725, 64_l2=0.0718\n",
      "[28] time=2.35, avg_loss=1.9512, train_err=0.0976, 32_h1=0.0971, 32_l2=0.0540, 64_h1=0.1788, 64_l2=0.0680\n",
      "[29] time=2.34, avg_loss=1.9285, train_err=0.0964, 32_h1=0.0943, 32_l2=0.0523, 64_h1=0.1648, 64_l2=0.0607\n",
      "[30] time=2.37, avg_loss=1.8733, train_err=0.0937, 32_h1=0.1053, 32_l2=0.0645, 64_h1=0.1751, 64_l2=0.0775\n",
      "[31] time=2.35, avg_loss=1.8934, train_err=0.0947, 32_h1=0.0997, 32_l2=0.0609, 64_h1=0.1656, 64_l2=0.0690\n",
      "[32] time=2.32, avg_loss=1.8810, train_err=0.0941, 32_h1=0.0916, 32_l2=0.0502, 64_h1=0.1659, 64_l2=0.0587\n",
      "[33] time=2.36, avg_loss=1.8404, train_err=0.0920, 32_h1=0.0933, 32_l2=0.0501, 64_h1=0.1678, 64_l2=0.0616\n",
      "[34] time=2.35, avg_loss=1.8389, train_err=0.0919, 32_h1=0.0932, 32_l2=0.0537, 64_h1=0.1682, 64_l2=0.0627\n",
      "[35] time=2.32, avg_loss=1.8032, train_err=0.0902, 32_h1=0.0926, 32_l2=0.0510, 64_h1=0.1649, 64_l2=0.0603\n",
      "[36] time=2.37, avg_loss=1.7756, train_err=0.0888, 32_h1=0.0902, 32_l2=0.0478, 64_h1=0.1649, 64_l2=0.0588\n",
      "[37] time=2.08, avg_loss=1.8076, train_err=0.0904, 32_h1=0.0909, 32_l2=0.0492, 64_h1=0.1628, 64_l2=0.0554\n",
      "[38] time=2.16, avg_loss=1.8231, train_err=0.0912, 32_h1=0.0901, 32_l2=0.0490, 64_h1=0.1684, 64_l2=0.0607\n",
      "[39] time=2.25, avg_loss=1.7486, train_err=0.0874, 32_h1=0.0895, 32_l2=0.0475, 64_h1=0.1656, 64_l2=0.0570\n",
      "[40] time=2.07, avg_loss=1.7373, train_err=0.0869, 32_h1=0.0948, 32_l2=0.0568, 64_h1=0.1660, 64_l2=0.0691\n",
      "[41] time=2.04, avg_loss=1.8593, train_err=0.0930, 32_h1=0.0909, 32_l2=0.0490, 64_h1=0.1684, 64_l2=0.0576\n",
      "[42] time=2.22, avg_loss=1.7218, train_err=0.0861, 32_h1=0.0898, 32_l2=0.0497, 64_h1=0.1691, 64_l2=0.0640\n",
      "[43] time=2.19, avg_loss=1.7773, train_err=0.0889, 32_h1=0.0884, 32_l2=0.0486, 64_h1=0.1637, 64_l2=0.0601\n",
      "[44] time=2.22, avg_loss=1.7334, train_err=0.0867, 32_h1=0.0947, 32_l2=0.0623, 64_h1=0.1696, 64_l2=0.0726\n",
      "[45] time=2.14, avg_loss=1.7369, train_err=0.0868, 32_h1=0.0948, 32_l2=0.0555, 64_h1=0.1813, 64_l2=0.0700\n",
      "[46] time=2.12, avg_loss=1.7738, train_err=0.0887, 32_h1=0.0866, 32_l2=0.0463, 64_h1=0.1630, 64_l2=0.0558\n",
      "[47] time=2.10, avg_loss=1.7234, train_err=0.0862, 32_h1=0.0879, 32_l2=0.0496, 64_h1=0.1700, 64_l2=0.0645\n",
      "[48] time=2.07, avg_loss=1.6751, train_err=0.0838, 32_h1=0.0851, 32_l2=0.0465, 64_h1=0.1628, 64_l2=0.0602\n",
      "[49] time=2.10, avg_loss=1.6586, train_err=0.0829, 32_h1=0.0832, 32_l2=0.0423, 64_h1=0.1643, 64_l2=0.0559\n",
      "[50] time=2.20, avg_loss=1.6782, train_err=0.0839, 32_h1=0.0851, 32_l2=0.0457, 64_h1=0.1643, 64_l2=0.0596\n",
      "[51] time=2.13, avg_loss=1.7232, train_err=0.0862, 32_h1=0.0822, 32_l2=0.0404, 64_h1=0.1630, 64_l2=0.0565\n",
      "[52] time=2.15, avg_loss=1.6596, train_err=0.0830, 32_h1=0.0872, 32_l2=0.0499, 64_h1=0.1697, 64_l2=0.0635\n",
      "[53] time=2.13, avg_loss=1.7075, train_err=0.0854, 32_h1=0.0874, 32_l2=0.0478, 64_h1=0.1768, 64_l2=0.0652\n",
      "[54] time=2.12, avg_loss=1.6561, train_err=0.0828, 32_h1=0.0878, 32_l2=0.0499, 64_h1=0.1672, 64_l2=0.0645\n",
      "[55] time=2.11, avg_loss=1.6329, train_err=0.0816, 32_h1=0.0840, 32_l2=0.0453, 64_h1=0.1645, 64_l2=0.0607\n",
      "[56] time=2.13, avg_loss=1.6590, train_err=0.0830, 32_h1=0.0809, 32_l2=0.0404, 64_h1=0.1610, 64_l2=0.0517\n",
      "[57] time=2.17, avg_loss=1.6334, train_err=0.0817, 32_h1=0.0843, 32_l2=0.0444, 64_h1=0.1670, 64_l2=0.0611\n",
      "[58] time=2.19, avg_loss=1.6692, train_err=0.0835, 32_h1=0.0865, 32_l2=0.0460, 64_h1=0.1728, 64_l2=0.0658\n",
      "[59] time=2.04, avg_loss=1.6161, train_err=0.0808, 32_h1=0.0922, 32_l2=0.0594, 64_h1=0.1725, 64_l2=0.0695\n",
      "[60] time=2.14, avg_loss=1.6167, train_err=0.0808, 32_h1=0.0832, 32_l2=0.0435, 64_h1=0.1608, 64_l2=0.0552\n",
      "[61] time=2.12, avg_loss=1.5998, train_err=0.0800, 32_h1=0.0847, 32_l2=0.0451, 64_h1=0.1575, 64_l2=0.0524\n",
      "[62] time=2.22, avg_loss=1.6042, train_err=0.0802, 32_h1=0.0812, 32_l2=0.0410, 64_h1=0.1593, 64_l2=0.0510\n",
      "[63] time=2.06, avg_loss=1.5843, train_err=0.0792, 32_h1=0.0834, 32_l2=0.0426, 64_h1=0.1648, 64_l2=0.0568\n",
      "[64] time=2.12, avg_loss=1.5967, train_err=0.0798, 32_h1=0.0864, 32_l2=0.0493, 64_h1=0.1575, 64_l2=0.0557\n",
      "[65] time=2.22, avg_loss=1.5812, train_err=0.0791, 32_h1=0.0802, 32_l2=0.0417, 64_h1=0.1672, 64_l2=0.0559\n",
      "[66] time=2.28, avg_loss=1.5958, train_err=0.0798, 32_h1=0.0827, 32_l2=0.0469, 64_h1=0.1639, 64_l2=0.0621\n",
      "[67] time=2.34, avg_loss=1.5574, train_err=0.0779, 32_h1=0.0801, 32_l2=0.0400, 64_h1=0.1725, 64_l2=0.0594\n",
      "[68] time=2.38, avg_loss=1.5692, train_err=0.0785, 32_h1=0.0823, 32_l2=0.0454, 64_h1=0.1617, 64_l2=0.0582\n",
      "[69] time=2.36, avg_loss=1.5346, train_err=0.0767, 32_h1=0.0806, 32_l2=0.0422, 64_h1=0.1564, 64_l2=0.0506\n",
      "[70] time=2.35, avg_loss=1.5708, train_err=0.0785, 32_h1=0.0791, 32_l2=0.0389, 64_h1=0.1625, 64_l2=0.0540\n",
      "[71] time=2.36, avg_loss=1.6042, train_err=0.0802, 32_h1=0.0808, 32_l2=0.0425, 64_h1=0.1589, 64_l2=0.0535\n",
      "[72] time=2.37, avg_loss=1.5880, train_err=0.0794, 32_h1=0.0832, 32_l2=0.0451, 64_h1=0.1673, 64_l2=0.0602\n",
      "[73] time=2.38, avg_loss=1.5783, train_err=0.0789, 32_h1=0.0804, 32_l2=0.0421, 64_h1=0.1615, 64_l2=0.0579\n",
      "[74] time=2.34, avg_loss=1.5325, train_err=0.0766, 32_h1=0.0810, 32_l2=0.0421, 64_h1=0.1592, 64_l2=0.0515\n",
      "[75] time=2.37, avg_loss=1.5544, train_err=0.0777, 32_h1=0.0821, 32_l2=0.0449, 64_h1=0.1616, 64_l2=0.0582\n",
      "[76] time=2.45, avg_loss=1.5577, train_err=0.0779, 32_h1=0.0786, 32_l2=0.0394, 64_h1=0.1601, 64_l2=0.0538\n",
      "[77] time=2.31, avg_loss=1.5182, train_err=0.0759, 32_h1=0.0790, 32_l2=0.0432, 64_h1=0.1600, 64_l2=0.0574\n",
      "[78] time=2.35, avg_loss=1.5112, train_err=0.0756, 32_h1=0.0812, 32_l2=0.0446, 64_h1=0.1603, 64_l2=0.0575\n",
      "[79] time=2.36, avg_loss=1.5435, train_err=0.0772, 32_h1=0.0781, 32_l2=0.0389, 64_h1=0.1638, 64_l2=0.0559\n",
      "[80] time=2.34, avg_loss=1.5222, train_err=0.0761, 32_h1=0.0819, 32_l2=0.0446, 64_h1=0.1701, 64_l2=0.0626\n",
      "[81] time=2.34, avg_loss=1.5382, train_err=0.0769, 32_h1=0.0768, 32_l2=0.0383, 64_h1=0.1601, 64_l2=0.0520\n",
      "[82] time=2.34, avg_loss=1.4958, train_err=0.0748, 32_h1=0.0785, 32_l2=0.0398, 64_h1=0.1691, 64_l2=0.0585\n",
      "[83] time=2.35, avg_loss=1.5175, train_err=0.0759, 32_h1=0.0766, 32_l2=0.0376, 64_h1=0.1613, 64_l2=0.0495\n",
      "[84] time=2.36, avg_loss=1.5118, train_err=0.0756, 32_h1=0.0821, 32_l2=0.0471, 64_h1=0.1571, 64_l2=0.0603\n",
      "[85] time=2.34, avg_loss=1.5175, train_err=0.0759, 32_h1=0.0769, 32_l2=0.0395, 64_h1=0.1632, 64_l2=0.0561\n",
      "[86] time=2.33, avg_loss=1.4926, train_err=0.0746, 32_h1=0.0781, 32_l2=0.0384, 64_h1=0.1659, 64_l2=0.0557\n",
      "[87] time=2.40, avg_loss=1.4818, train_err=0.0741, 32_h1=0.0766, 32_l2=0.0377, 64_h1=0.1578, 64_l2=0.0496\n",
      "[88] time=2.34, avg_loss=1.4945, train_err=0.0747, 32_h1=0.0766, 32_l2=0.0394, 64_h1=0.1646, 64_l2=0.0546\n",
      "[89] time=2.38, avg_loss=1.4887, train_err=0.0744, 32_h1=0.0793, 32_l2=0.0435, 64_h1=0.1598, 64_l2=0.0582\n",
      "[90] time=2.37, avg_loss=1.4977, train_err=0.0749, 32_h1=0.0801, 32_l2=0.0414, 64_h1=0.1637, 64_l2=0.0550\n",
      "[91] time=2.38, avg_loss=1.4923, train_err=0.0746, 32_h1=0.0771, 32_l2=0.0390, 64_h1=0.1579, 64_l2=0.0548\n",
      "[92] time=2.38, avg_loss=1.4891, train_err=0.0745, 32_h1=0.0765, 32_l2=0.0377, 64_h1=0.1597, 64_l2=0.0513\n",
      "[93] time=2.37, avg_loss=1.4712, train_err=0.0736, 32_h1=0.0771, 32_l2=0.0386, 64_h1=0.1627, 64_l2=0.0550\n",
      "[94] time=2.34, avg_loss=1.4859, train_err=0.0743, 32_h1=0.0847, 32_l2=0.0533, 64_h1=0.1675, 64_l2=0.0654\n",
      "[95] time=2.39, avg_loss=1.5148, train_err=0.0757, 32_h1=0.0765, 32_l2=0.0376, 64_h1=0.1575, 64_l2=0.0487\n",
      "[96] time=2.33, avg_loss=1.5175, train_err=0.0759, 32_h1=0.0850, 32_l2=0.0521, 64_h1=0.1685, 64_l2=0.0682\n",
      "[97] time=2.36, avg_loss=1.4689, train_err=0.0734, 32_h1=0.0786, 32_l2=0.0420, 64_h1=0.1627, 64_l2=0.0548\n",
      "[98] time=2.36, avg_loss=1.4790, train_err=0.0739, 32_h1=0.0783, 32_l2=0.0395, 64_h1=0.1597, 64_l2=0.0551\n",
      "[99] time=2.39, avg_loss=1.4501, train_err=0.0725, 32_h1=0.0780, 32_l2=0.0428, 64_h1=0.1677, 64_l2=0.0572\n",
      "[100] time=2.36, avg_loss=1.4810, train_err=0.0741, 32_h1=0.0797, 32_l2=0.0449, 64_h1=0.1598, 64_l2=0.0585\n",
      "[101] time=2.34, avg_loss=1.4503, train_err=0.0725, 32_h1=0.0783, 32_l2=0.0420, 64_h1=0.1594, 64_l2=0.0522\n",
      "[102] time=2.37, avg_loss=1.4810, train_err=0.0741, 32_h1=0.0753, 32_l2=0.0375, 64_h1=0.1646, 64_l2=0.0580\n",
      "[103] time=2.32, avg_loss=1.4559, train_err=0.0728, 32_h1=0.0774, 32_l2=0.0400, 64_h1=0.1632, 64_l2=0.0538\n",
      "[104] time=2.25, avg_loss=1.4477, train_err=0.0724, 32_h1=0.0766, 32_l2=0.0397, 64_h1=0.1596, 64_l2=0.0537\n",
      "[105] time=2.17, avg_loss=1.4406, train_err=0.0720, 32_h1=0.0827, 32_l2=0.0489, 64_h1=0.1607, 64_l2=0.0584\n",
      "[106] time=2.25, avg_loss=1.4357, train_err=0.0718, 32_h1=0.0784, 32_l2=0.0413, 64_h1=0.1633, 64_l2=0.0556\n",
      "[107] time=2.22, avg_loss=1.4473, train_err=0.0724, 32_h1=0.0749, 32_l2=0.0373, 64_h1=0.1565, 64_l2=0.0493\n",
      "[108] time=2.22, avg_loss=1.4213, train_err=0.0711, 32_h1=0.0739, 32_l2=0.0352, 64_h1=0.1581, 64_l2=0.0527\n",
      "[109] time=2.22, avg_loss=1.4310, train_err=0.0716, 32_h1=0.0787, 32_l2=0.0407, 64_h1=0.1620, 64_l2=0.0561\n",
      "[110] time=2.26, avg_loss=1.4432, train_err=0.0722, 32_h1=0.0788, 32_l2=0.0422, 64_h1=0.1587, 64_l2=0.0533\n",
      "[111] time=2.21, avg_loss=1.4310, train_err=0.0716, 32_h1=0.0768, 32_l2=0.0390, 64_h1=0.1620, 64_l2=0.0518\n",
      "[112] time=2.20, avg_loss=1.4460, train_err=0.0723, 32_h1=0.0750, 32_l2=0.0359, 64_h1=0.1632, 64_l2=0.0511\n",
      "[113] time=2.23, avg_loss=1.4651, train_err=0.0733, 32_h1=0.0755, 32_l2=0.0377, 64_h1=0.1639, 64_l2=0.0543\n",
      "[114] time=2.25, avg_loss=1.4269, train_err=0.0713, 32_h1=0.0761, 32_l2=0.0378, 64_h1=0.1568, 64_l2=0.0514\n",
      "[115] time=2.24, avg_loss=1.4416, train_err=0.0721, 32_h1=0.0741, 32_l2=0.0360, 64_h1=0.1613, 64_l2=0.0498\n",
      "[116] time=2.23, avg_loss=1.3977, train_err=0.0699, 32_h1=0.0732, 32_l2=0.0351, 64_h1=0.1618, 64_l2=0.0516\n",
      "[117] time=2.15, avg_loss=1.4233, train_err=0.0712, 32_h1=0.0792, 32_l2=0.0416, 64_h1=0.1683, 64_l2=0.0583\n",
      "[118] time=2.12, avg_loss=1.4121, train_err=0.0706, 32_h1=0.0734, 32_l2=0.0357, 64_h1=0.1633, 64_l2=0.0545\n",
      "[119] time=2.07, avg_loss=1.4063, train_err=0.0703, 32_h1=0.0771, 32_l2=0.0406, 64_h1=0.1627, 64_l2=0.0594\n",
      "[120] time=2.16, avg_loss=1.4235, train_err=0.0712, 32_h1=0.0738, 32_l2=0.0355, 64_h1=0.1655, 64_l2=0.0550\n",
      "[121] time=2.18, avg_loss=1.3997, train_err=0.0700, 32_h1=0.0772, 32_l2=0.0402, 64_h1=0.1647, 64_l2=0.0559\n",
      "[122] time=2.05, avg_loss=1.4153, train_err=0.0708, 32_h1=0.0767, 32_l2=0.0397, 64_h1=0.1534, 64_l2=0.0480\n",
      "[123] time=2.14, avg_loss=1.4128, train_err=0.0706, 32_h1=0.0809, 32_l2=0.0478, 64_h1=0.1592, 64_l2=0.0572\n",
      "[124] time=2.14, avg_loss=1.4309, train_err=0.0715, 32_h1=0.0808, 32_l2=0.0463, 64_h1=0.1542, 64_l2=0.0572\n",
      "[125] time=2.16, avg_loss=1.4103, train_err=0.0705, 32_h1=0.0756, 32_l2=0.0404, 64_h1=0.1660, 64_l2=0.0583\n",
      "[126] time=2.23, avg_loss=1.3945, train_err=0.0697, 32_h1=0.0734, 32_l2=0.0354, 64_h1=0.1655, 64_l2=0.0541\n",
      "[127] time=2.23, avg_loss=1.3932, train_err=0.0697, 32_h1=0.0758, 32_l2=0.0380, 64_h1=0.1596, 64_l2=0.0507\n",
      "[128] time=2.08, avg_loss=1.4039, train_err=0.0702, 32_h1=0.0735, 32_l2=0.0356, 64_h1=0.1625, 64_l2=0.0526\n",
      "[129] time=2.18, avg_loss=1.4063, train_err=0.0703, 32_h1=0.0721, 32_l2=0.0339, 64_h1=0.1599, 64_l2=0.0488\n",
      "[130] time=2.09, avg_loss=1.3857, train_err=0.0693, 32_h1=0.0727, 32_l2=0.0354, 64_h1=0.1637, 64_l2=0.0531\n",
      "[131] time=2.16, avg_loss=1.3781, train_err=0.0689, 32_h1=0.0737, 32_l2=0.0362, 64_h1=0.1606, 64_l2=0.0533\n",
      "[132] time=2.14, avg_loss=1.3952, train_err=0.0698, 32_h1=0.0745, 32_l2=0.0365, 64_h1=0.1654, 64_l2=0.0586\n",
      "[133] time=2.30, avg_loss=1.4041, train_err=0.0702, 32_h1=0.0726, 32_l2=0.0352, 64_h1=0.1583, 64_l2=0.0533\n",
      "[134] time=2.33, avg_loss=1.3606, train_err=0.0680, 32_h1=0.0738, 32_l2=0.0388, 64_h1=0.1612, 64_l2=0.0545\n",
      "[135] time=2.42, avg_loss=1.3725, train_err=0.0686, 32_h1=0.0723, 32_l2=0.0346, 64_h1=0.1575, 64_l2=0.0496\n",
      "[136] time=2.46, avg_loss=1.3657, train_err=0.0683, 32_h1=0.0748, 32_l2=0.0393, 64_h1=0.1587, 64_l2=0.0559\n",
      "[137] time=2.32, avg_loss=1.3823, train_err=0.0691, 32_h1=0.0735, 32_l2=0.0361, 64_h1=0.1598, 64_l2=0.0548\n",
      "[138] time=2.34, avg_loss=1.3759, train_err=0.0688, 32_h1=0.0732, 32_l2=0.0360, 64_h1=0.1613, 64_l2=0.0506\n",
      "[139] time=2.40, avg_loss=1.3828, train_err=0.0691, 32_h1=0.0755, 32_l2=0.0382, 64_h1=0.1609, 64_l2=0.0535\n",
      "[140] time=2.39, avg_loss=1.3889, train_err=0.0694, 32_h1=0.0724, 32_l2=0.0345, 64_h1=0.1603, 64_l2=0.0521\n",
      "[141] time=2.34, avg_loss=1.3725, train_err=0.0686, 32_h1=0.0723, 32_l2=0.0347, 64_h1=0.1577, 64_l2=0.0499\n",
      "[142] time=2.41, avg_loss=1.3575, train_err=0.0679, 32_h1=0.0753, 32_l2=0.0383, 64_h1=0.1636, 64_l2=0.0534\n",
      "[143] time=2.38, avg_loss=1.3794, train_err=0.0690, 32_h1=0.0793, 32_l2=0.0452, 64_h1=0.1661, 64_l2=0.0591\n",
      "[144] time=2.39, avg_loss=1.3672, train_err=0.0684, 32_h1=0.0724, 32_l2=0.0350, 64_h1=0.1601, 64_l2=0.0504\n",
      "[145] time=2.36, avg_loss=1.3576, train_err=0.0679, 32_h1=0.0731, 32_l2=0.0362, 64_h1=0.1554, 64_l2=0.0518\n",
      "[146] time=2.34, avg_loss=1.3610, train_err=0.0681, 32_h1=0.0750, 32_l2=0.0375, 64_h1=0.1581, 64_l2=0.0528\n",
      "[147] time=2.37, avg_loss=1.3527, train_err=0.0676, 32_h1=0.0731, 32_l2=0.0375, 64_h1=0.1618, 64_l2=0.0550\n",
      "[148] time=2.33, avg_loss=1.3719, train_err=0.0686, 32_h1=0.0727, 32_l2=0.0360, 64_h1=0.1606, 64_l2=0.0555\n",
      "[149] time=2.36, avg_loss=1.3505, train_err=0.0675, 32_h1=0.0736, 32_l2=0.0373, 64_h1=0.1626, 64_l2=0.0518\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.05\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 38337\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(13, 13, 2, 2))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(13, 13, 2, 2))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(13, 13, 2, 2))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(13, 13, 2, 2))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(13, 13, 2, 2))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(13, 13, 2, 2))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(13, 13, 2, 2))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(13, 13, 2, 2))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f7761b37a00>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f7854f93b20>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f7854f93b20>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f78870e48e0>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.36, avg_loss=10.7311, train_err=0.5366, 32_h1=0.3455, 32_l2=0.2431, 64_h1=0.4056, 64_l2=0.2511\n",
      "[1] time=2.36, avg_loss=5.4273, train_err=0.2714, 32_h1=0.2322, 32_l2=0.1637, 64_h1=0.2888, 64_l2=0.1711\n",
      "[2] time=2.34, avg_loss=4.3428, train_err=0.2171, 32_h1=0.2034, 32_l2=0.1380, 64_h1=0.2396, 64_l2=0.1327\n",
      "[3] time=2.32, avg_loss=3.8989, train_err=0.1949, 32_h1=0.2090, 32_l2=0.1518, 64_h1=0.2569, 64_l2=0.1574\n",
      "[4] time=2.32, avg_loss=3.5479, train_err=0.1774, 32_h1=0.1745, 32_l2=0.1241, 64_h1=0.2196, 64_l2=0.1238\n",
      "[5] time=2.34, avg_loss=3.3813, train_err=0.1691, 32_h1=0.1558, 32_l2=0.1022, 64_h1=0.2122, 64_l2=0.1050\n",
      "[6] time=2.30, avg_loss=3.0782, train_err=0.1539, 32_h1=0.1489, 32_l2=0.0963, 64_h1=0.2248, 64_l2=0.1100\n",
      "[7] time=2.35, avg_loss=2.9640, train_err=0.1482, 32_h1=0.1435, 32_l2=0.0989, 64_h1=0.2039, 64_l2=0.1038\n",
      "[8] time=2.42, avg_loss=2.8760, train_err=0.1438, 32_h1=0.1627, 32_l2=0.1159, 64_h1=0.2201, 64_l2=0.1242\n",
      "[9] time=2.35, avg_loss=2.8262, train_err=0.1413, 32_h1=0.1624, 32_l2=0.1131, 64_h1=0.2280, 64_l2=0.1216\n",
      "[10] time=2.35, avg_loss=2.6239, train_err=0.1312, 32_h1=0.1244, 32_l2=0.0741, 64_h1=0.1949, 64_l2=0.0867\n",
      "[11] time=2.33, avg_loss=2.5649, train_err=0.1282, 32_h1=0.1180, 32_l2=0.0685, 64_h1=0.1862, 64_l2=0.0765\n",
      "[12] time=2.35, avg_loss=2.4654, train_err=0.1233, 32_h1=0.1167, 32_l2=0.0674, 64_h1=0.1787, 64_l2=0.0775\n",
      "[13] time=2.34, avg_loss=2.4137, train_err=0.1207, 32_h1=0.1145, 32_l2=0.0627, 64_h1=0.1961, 64_l2=0.0708\n",
      "[14] time=2.41, avg_loss=2.3565, train_err=0.1178, 32_h1=0.1175, 32_l2=0.0725, 64_h1=0.1821, 64_l2=0.0810\n",
      "[15] time=2.38, avg_loss=2.1864, train_err=0.1093, 32_h1=0.1095, 32_l2=0.0638, 64_h1=0.1865, 64_l2=0.0808\n",
      "[16] time=2.36, avg_loss=2.1687, train_err=0.1084, 32_h1=0.1105, 32_l2=0.0656, 64_h1=0.1771, 64_l2=0.0732\n",
      "[17] time=2.35, avg_loss=2.1215, train_err=0.1061, 32_h1=0.1061, 32_l2=0.0627, 64_h1=0.1793, 64_l2=0.0735\n",
      "[18] time=2.38, avg_loss=2.1847, train_err=0.1092, 32_h1=0.1073, 32_l2=0.0603, 64_h1=0.1815, 64_l2=0.0719\n",
      "[19] time=2.40, avg_loss=2.1090, train_err=0.1055, 32_h1=0.1172, 32_l2=0.0716, 64_h1=0.1780, 64_l2=0.0772\n",
      "[20] time=2.35, avg_loss=2.0418, train_err=0.1021, 32_h1=0.0995, 32_l2=0.0542, 64_h1=0.1741, 64_l2=0.0689\n",
      "[21] time=2.23, avg_loss=2.0831, train_err=0.1042, 32_h1=0.0995, 32_l2=0.0552, 64_h1=0.1841, 64_l2=0.0701\n",
      "[22] time=2.08, avg_loss=2.0104, train_err=0.1005, 32_h1=0.1194, 32_l2=0.0734, 64_h1=0.1892, 64_l2=0.0796\n",
      "[23] time=2.07, avg_loss=2.0600, train_err=0.1030, 32_h1=0.0978, 32_l2=0.0564, 64_h1=0.1710, 64_l2=0.0620\n",
      "[24] time=2.16, avg_loss=1.9660, train_err=0.0983, 32_h1=0.0970, 32_l2=0.0531, 64_h1=0.1715, 64_l2=0.0608\n",
      "[25] time=2.11, avg_loss=1.9617, train_err=0.0981, 32_h1=0.0980, 32_l2=0.0527, 64_h1=0.1775, 64_l2=0.0676\n",
      "[26] time=2.06, avg_loss=1.9536, train_err=0.0977, 32_h1=0.0959, 32_l2=0.0530, 64_h1=0.1677, 64_l2=0.0610\n",
      "[27] time=2.16, avg_loss=1.9348, train_err=0.0967, 32_h1=0.1063, 32_l2=0.0688, 64_h1=0.1766, 64_l2=0.0789\n",
      "[28] time=2.21, avg_loss=1.9222, train_err=0.0961, 32_h1=0.0945, 32_l2=0.0516, 64_h1=0.1756, 64_l2=0.0690\n",
      "[29] time=2.15, avg_loss=1.8914, train_err=0.0946, 32_h1=0.0937, 32_l2=0.0503, 64_h1=0.1752, 64_l2=0.0651\n",
      "[30] time=2.21, avg_loss=1.9240, train_err=0.0962, 32_h1=0.1031, 32_l2=0.0634, 64_h1=0.1732, 64_l2=0.0709\n",
      "[31] time=2.06, avg_loss=1.8743, train_err=0.0937, 32_h1=0.0907, 32_l2=0.0474, 64_h1=0.1690, 64_l2=0.0585\n",
      "[32] time=2.15, avg_loss=1.8067, train_err=0.0903, 32_h1=0.0930, 32_l2=0.0527, 64_h1=0.1694, 64_l2=0.0600\n",
      "[33] time=2.14, avg_loss=1.8870, train_err=0.0943, 32_h1=0.0949, 32_l2=0.0543, 64_h1=0.1795, 64_l2=0.0693\n",
      "[34] time=2.20, avg_loss=1.8397, train_err=0.0920, 32_h1=0.0912, 32_l2=0.0500, 64_h1=0.1661, 64_l2=0.0618\n",
      "[35] time=2.11, avg_loss=1.7814, train_err=0.0891, 32_h1=0.0946, 32_l2=0.0573, 64_h1=0.1643, 64_l2=0.0625\n",
      "[36] time=2.24, avg_loss=1.7357, train_err=0.0868, 32_h1=0.0910, 32_l2=0.0504, 64_h1=0.1731, 64_l2=0.0566\n",
      "[37] time=2.14, avg_loss=1.7799, train_err=0.0890, 32_h1=0.0927, 32_l2=0.0521, 64_h1=0.1741, 64_l2=0.0645\n",
      "[38] time=2.09, avg_loss=1.7894, train_err=0.0895, 32_h1=0.0872, 32_l2=0.0452, 64_h1=0.1686, 64_l2=0.0600\n",
      "[39] time=2.07, avg_loss=1.7738, train_err=0.0887, 32_h1=0.0892, 32_l2=0.0475, 64_h1=0.1739, 64_l2=0.0636\n",
      "[40] time=2.08, avg_loss=1.7392, train_err=0.0870, 32_h1=0.0924, 32_l2=0.0505, 64_h1=0.1634, 64_l2=0.0615\n",
      "[41] time=2.10, avg_loss=1.7561, train_err=0.0878, 32_h1=0.1021, 32_l2=0.0654, 64_h1=0.1773, 64_l2=0.0738\n",
      "[42] time=2.12, avg_loss=1.7260, train_err=0.0863, 32_h1=0.0897, 32_l2=0.0479, 64_h1=0.1771, 64_l2=0.0682\n",
      "[43] time=2.21, avg_loss=1.7135, train_err=0.0857, 32_h1=0.0883, 32_l2=0.0467, 64_h1=0.1644, 64_l2=0.0568\n",
      "[44] time=2.20, avg_loss=1.7174, train_err=0.0859, 32_h1=0.0908, 32_l2=0.0502, 64_h1=0.1685, 64_l2=0.0580\n",
      "[45] time=2.23, avg_loss=1.6854, train_err=0.0843, 32_h1=0.0866, 32_l2=0.0454, 64_h1=0.1705, 64_l2=0.0599\n",
      "[46] time=2.05, avg_loss=1.7027, train_err=0.0851, 32_h1=0.0891, 32_l2=0.0485, 64_h1=0.1692, 64_l2=0.0626\n",
      "[47] time=2.21, avg_loss=1.6707, train_err=0.0835, 32_h1=0.0866, 32_l2=0.0484, 64_h1=0.1655, 64_l2=0.0604\n",
      "[48] time=2.10, avg_loss=1.7540, train_err=0.0877, 32_h1=0.0874, 32_l2=0.0482, 64_h1=0.1636, 64_l2=0.0574\n",
      "[49] time=2.16, avg_loss=1.6956, train_err=0.0848, 32_h1=0.0862, 32_l2=0.0461, 64_h1=0.1693, 64_l2=0.0628\n",
      "[50] time=2.35, avg_loss=1.6582, train_err=0.0829, 32_h1=0.0855, 32_l2=0.0437, 64_h1=0.1570, 64_l2=0.0520\n",
      "[51] time=2.35, avg_loss=1.6249, train_err=0.0812, 32_h1=0.0827, 32_l2=0.0439, 64_h1=0.1639, 64_l2=0.0576\n",
      "[52] time=2.34, avg_loss=1.6716, train_err=0.0836, 32_h1=0.0981, 32_l2=0.0610, 64_h1=0.1719, 64_l2=0.0715\n",
      "[53] time=2.33, avg_loss=1.6349, train_err=0.0817, 32_h1=0.0849, 32_l2=0.0446, 64_h1=0.1671, 64_l2=0.0529\n",
      "[54] time=2.33, avg_loss=1.6283, train_err=0.0814, 32_h1=0.0972, 32_l2=0.0672, 64_h1=0.1658, 64_l2=0.0748\n",
      "[55] time=2.35, avg_loss=1.6392, train_err=0.0820, 32_h1=0.0820, 32_l2=0.0412, 64_h1=0.1702, 64_l2=0.0606\n",
      "[56] time=2.38, avg_loss=1.6409, train_err=0.0820, 32_h1=0.0856, 32_l2=0.0467, 64_h1=0.1707, 64_l2=0.0606\n",
      "[57] time=2.33, avg_loss=1.6466, train_err=0.0823, 32_h1=0.0848, 32_l2=0.0454, 64_h1=0.1644, 64_l2=0.0609\n",
      "[58] time=2.39, avg_loss=1.6245, train_err=0.0812, 32_h1=0.0818, 32_l2=0.0408, 64_h1=0.1589, 64_l2=0.0553\n",
      "[59] time=2.35, avg_loss=1.5991, train_err=0.0800, 32_h1=0.0953, 32_l2=0.0581, 64_h1=0.1832, 64_l2=0.0725\n",
      "[60] time=2.35, avg_loss=1.6282, train_err=0.0814, 32_h1=0.0823, 32_l2=0.0420, 64_h1=0.1603, 64_l2=0.0504\n",
      "[61] time=2.36, avg_loss=1.5928, train_err=0.0796, 32_h1=0.0879, 32_l2=0.0543, 64_h1=0.1712, 64_l2=0.0684\n",
      "[62] time=2.36, avg_loss=1.5965, train_err=0.0798, 32_h1=0.0835, 32_l2=0.0440, 64_h1=0.1678, 64_l2=0.0592\n",
      "[63] time=2.34, avg_loss=1.6279, train_err=0.0814, 32_h1=0.0843, 32_l2=0.0464, 64_h1=0.1635, 64_l2=0.0598\n",
      "[64] time=2.35, avg_loss=1.6025, train_err=0.0801, 32_h1=0.0813, 32_l2=0.0422, 64_h1=0.1634, 64_l2=0.0559\n",
      "[65] time=2.35, avg_loss=1.6122, train_err=0.0806, 32_h1=0.0923, 32_l2=0.0562, 64_h1=0.1685, 64_l2=0.0667\n",
      "[66] time=2.34, avg_loss=1.6201, train_err=0.0810, 32_h1=0.0816, 32_l2=0.0424, 64_h1=0.1679, 64_l2=0.0520\n",
      "[67] time=2.34, avg_loss=1.5417, train_err=0.0771, 32_h1=0.0789, 32_l2=0.0387, 64_h1=0.1660, 64_l2=0.0561\n",
      "[68] time=2.43, avg_loss=1.5573, train_err=0.0779, 32_h1=0.0811, 32_l2=0.0415, 64_h1=0.1587, 64_l2=0.0555\n",
      "[69] time=2.35, avg_loss=1.5450, train_err=0.0773, 32_h1=0.0809, 32_l2=0.0423, 64_h1=0.1697, 64_l2=0.0613\n",
      "[70] time=2.32, avg_loss=1.6271, train_err=0.0814, 32_h1=0.0859, 32_l2=0.0461, 64_h1=0.1654, 64_l2=0.0609\n",
      "[71] time=2.33, avg_loss=1.5832, train_err=0.0792, 32_h1=0.0810, 32_l2=0.0412, 64_h1=0.1606, 64_l2=0.0541\n",
      "[72] time=2.35, avg_loss=1.5641, train_err=0.0782, 32_h1=0.0795, 32_l2=0.0396, 64_h1=0.1698, 64_l2=0.0559\n",
      "[73] time=2.34, avg_loss=1.5979, train_err=0.0799, 32_h1=0.0800, 32_l2=0.0435, 64_h1=0.1668, 64_l2=0.0603\n",
      "[74] time=2.34, avg_loss=1.5385, train_err=0.0769, 32_h1=0.0787, 32_l2=0.0410, 64_h1=0.1603, 64_l2=0.0527\n",
      "[75] time=2.32, avg_loss=1.6096, train_err=0.0805, 32_h1=0.0782, 32_l2=0.0380, 64_h1=0.1635, 64_l2=0.0547\n",
      "[76] time=2.36, avg_loss=1.5183, train_err=0.0759, 32_h1=0.0793, 32_l2=0.0403, 64_h1=0.1677, 64_l2=0.0577\n",
      "[77] time=2.32, avg_loss=1.5329, train_err=0.0766, 32_h1=0.0797, 32_l2=0.0428, 64_h1=0.1568, 64_l2=0.0527\n",
      "[78] time=2.34, avg_loss=1.5484, train_err=0.0774, 32_h1=0.0876, 32_l2=0.0557, 64_h1=0.1623, 64_l2=0.0649\n",
      "[79] time=2.36, avg_loss=1.5482, train_err=0.0774, 32_h1=0.0840, 32_l2=0.0487, 64_h1=0.1737, 64_l2=0.0681\n",
      "[80] time=2.34, avg_loss=1.5331, train_err=0.0767, 32_h1=0.0800, 32_l2=0.0410, 64_h1=0.1707, 64_l2=0.0610\n",
      "[81] time=2.33, avg_loss=1.5262, train_err=0.0763, 32_h1=0.0850, 32_l2=0.0469, 64_h1=0.1792, 64_l2=0.0678\n",
      "[82] time=2.34, avg_loss=1.5287, train_err=0.0764, 32_h1=0.0855, 32_l2=0.0463, 64_h1=0.1671, 64_l2=0.0654\n",
      "[83] time=2.37, avg_loss=1.5259, train_err=0.0763, 32_h1=0.0839, 32_l2=0.0495, 64_h1=0.1701, 64_l2=0.0626\n",
      "[84] time=2.38, avg_loss=1.5236, train_err=0.0762, 32_h1=0.0773, 32_l2=0.0378, 64_h1=0.1647, 64_l2=0.0550\n",
      "[85] time=2.36, avg_loss=1.5044, train_err=0.0752, 32_h1=0.0821, 32_l2=0.0465, 64_h1=0.1616, 64_l2=0.0631\n",
      "[86] time=2.37, avg_loss=1.5124, train_err=0.0756, 32_h1=0.0771, 32_l2=0.0389, 64_h1=0.1640, 64_l2=0.0548\n",
      "[87] time=2.35, avg_loss=1.5047, train_err=0.0752, 32_h1=0.0798, 32_l2=0.0431, 64_h1=0.1640, 64_l2=0.0582\n",
      "[88] time=2.33, avg_loss=1.5188, train_err=0.0759, 32_h1=0.0780, 32_l2=0.0394, 64_h1=0.1688, 64_l2=0.0551\n",
      "[89] time=2.34, avg_loss=1.5291, train_err=0.0765, 32_h1=0.0768, 32_l2=0.0379, 64_h1=0.1663, 64_l2=0.0568\n",
      "[90] time=2.09, avg_loss=1.4824, train_err=0.0741, 32_h1=0.0861, 32_l2=0.0537, 64_h1=0.1627, 64_l2=0.0612\n",
      "[91] time=2.17, avg_loss=1.5008, train_err=0.0750, 32_h1=0.0786, 32_l2=0.0397, 64_h1=0.1703, 64_l2=0.0599\n",
      "[92] time=2.19, avg_loss=1.5015, train_err=0.0751, 32_h1=0.0875, 32_l2=0.0504, 64_h1=0.1689, 64_l2=0.0655\n",
      "[93] time=2.05, avg_loss=1.5111, train_err=0.0756, 32_h1=0.0755, 32_l2=0.0364, 64_h1=0.1592, 64_l2=0.0499\n",
      "[94] time=2.19, avg_loss=1.4829, train_err=0.0741, 32_h1=0.0764, 32_l2=0.0377, 64_h1=0.1594, 64_l2=0.0517\n",
      "[95] time=2.10, avg_loss=1.4957, train_err=0.0748, 32_h1=0.0820, 32_l2=0.0445, 64_h1=0.1703, 64_l2=0.0630\n",
      "[96] time=2.23, avg_loss=1.4790, train_err=0.0740, 32_h1=0.0774, 32_l2=0.0382, 64_h1=0.1616, 64_l2=0.0521\n",
      "[97] time=2.17, avg_loss=1.4784, train_err=0.0739, 32_h1=0.0866, 32_l2=0.0509, 64_h1=0.1641, 64_l2=0.0604\n",
      "[98] time=2.06, avg_loss=1.4873, train_err=0.0744, 32_h1=0.0828, 32_l2=0.0468, 64_h1=0.1593, 64_l2=0.0576\n",
      "[99] time=2.08, avg_loss=1.4770, train_err=0.0738, 32_h1=0.0816, 32_l2=0.0488, 64_h1=0.1692, 64_l2=0.0623\n",
      "[100] time=2.09, avg_loss=1.4685, train_err=0.0734, 32_h1=0.0777, 32_l2=0.0427, 64_h1=0.1602, 64_l2=0.0552\n",
      "[101] time=2.07, avg_loss=1.4604, train_err=0.0730, 32_h1=0.0766, 32_l2=0.0379, 64_h1=0.1603, 64_l2=0.0529\n",
      "[102] time=2.16, avg_loss=1.4672, train_err=0.0734, 32_h1=0.0824, 32_l2=0.0456, 64_h1=0.1664, 64_l2=0.0598\n",
      "[103] time=2.12, avg_loss=1.4804, train_err=0.0740, 32_h1=0.0754, 32_l2=0.0361, 64_h1=0.1628, 64_l2=0.0512\n",
      "[104] time=2.25, avg_loss=1.4560, train_err=0.0728, 32_h1=0.0835, 32_l2=0.0508, 64_h1=0.1559, 64_l2=0.0620\n",
      "[105] time=2.22, avg_loss=1.4590, train_err=0.0730, 32_h1=0.0771, 32_l2=0.0390, 64_h1=0.1659, 64_l2=0.0523\n",
      "[106] time=2.29, avg_loss=1.4419, train_err=0.0721, 32_h1=0.0747, 32_l2=0.0355, 64_h1=0.1615, 64_l2=0.0538\n",
      "[107] time=2.18, avg_loss=1.4284, train_err=0.0714, 32_h1=0.0774, 32_l2=0.0402, 64_h1=0.1645, 64_l2=0.0572\n",
      "[108] time=2.12, avg_loss=1.4364, train_err=0.0718, 32_h1=0.0754, 32_l2=0.0370, 64_h1=0.1586, 64_l2=0.0502\n",
      "[109] time=2.14, avg_loss=1.4341, train_err=0.0717, 32_h1=0.0759, 32_l2=0.0381, 64_h1=0.1645, 64_l2=0.0519\n",
      "[110] time=2.20, avg_loss=1.4680, train_err=0.0734, 32_h1=0.0785, 32_l2=0.0406, 64_h1=0.1623, 64_l2=0.0553\n",
      "[111] time=2.15, avg_loss=1.4717, train_err=0.0736, 32_h1=0.0745, 32_l2=0.0363, 64_h1=0.1555, 64_l2=0.0495\n",
      "[112] time=2.21, avg_loss=1.4472, train_err=0.0724, 32_h1=0.0752, 32_l2=0.0367, 64_h1=0.1612, 64_l2=0.0564\n",
      "[113] time=2.08, avg_loss=1.4201, train_err=0.0710, 32_h1=0.0745, 32_l2=0.0361, 64_h1=0.1662, 64_l2=0.0522\n",
      "[114] time=2.14, avg_loss=1.4312, train_err=0.0716, 32_h1=0.0743, 32_l2=0.0360, 64_h1=0.1556, 64_l2=0.0500\n",
      "[115] time=2.09, avg_loss=1.4038, train_err=0.0702, 32_h1=0.0738, 32_l2=0.0359, 64_h1=0.1586, 64_l2=0.0480\n",
      "[116] time=2.31, avg_loss=1.4186, train_err=0.0709, 32_h1=0.0771, 32_l2=0.0396, 64_h1=0.1674, 64_l2=0.0584\n",
      "[117] time=2.23, avg_loss=1.4286, train_err=0.0714, 32_h1=0.0740, 32_l2=0.0357, 64_h1=0.1622, 64_l2=0.0534\n",
      "[118] time=2.33, avg_loss=1.4565, train_err=0.0728, 32_h1=0.0762, 32_l2=0.0374, 64_h1=0.1580, 64_l2=0.0481\n",
      "[119] time=2.33, avg_loss=1.4446, train_err=0.0722, 32_h1=0.0764, 32_l2=0.0379, 64_h1=0.1656, 64_l2=0.0556\n",
      "[120] time=2.39, avg_loss=1.4005, train_err=0.0700, 32_h1=0.0750, 32_l2=0.0373, 64_h1=0.1637, 64_l2=0.0562\n",
      "[121] time=2.34, avg_loss=1.4394, train_err=0.0720, 32_h1=0.0751, 32_l2=0.0363, 64_h1=0.1622, 64_l2=0.0568\n",
      "[122] time=2.33, avg_loss=1.4181, train_err=0.0709, 32_h1=0.0786, 32_l2=0.0444, 64_h1=0.1586, 64_l2=0.0559\n",
      "[123] time=2.36, avg_loss=1.4050, train_err=0.0703, 32_h1=0.0732, 32_l2=0.0344, 64_h1=0.1655, 64_l2=0.0549\n",
      "[124] time=2.31, avg_loss=1.4101, train_err=0.0705, 32_h1=0.0758, 32_l2=0.0367, 64_h1=0.1658, 64_l2=0.0503\n",
      "[125] time=2.32, avg_loss=1.4100, train_err=0.0705, 32_h1=0.0746, 32_l2=0.0360, 64_h1=0.1638, 64_l2=0.0538\n",
      "[126] time=2.32, avg_loss=1.3954, train_err=0.0698, 32_h1=0.0737, 32_l2=0.0369, 64_h1=0.1648, 64_l2=0.0541\n",
      "[127] time=2.38, avg_loss=1.4090, train_err=0.0705, 32_h1=0.0728, 32_l2=0.0346, 64_h1=0.1567, 64_l2=0.0502\n",
      "[128] time=2.38, avg_loss=1.3891, train_err=0.0695, 32_h1=0.0774, 32_l2=0.0403, 64_h1=0.1601, 64_l2=0.0537\n",
      "[129] time=2.33, avg_loss=1.3977, train_err=0.0699, 32_h1=0.0725, 32_l2=0.0337, 64_h1=0.1576, 64_l2=0.0486\n",
      "[130] time=2.31, avg_loss=1.3973, train_err=0.0699, 32_h1=0.0747, 32_l2=0.0375, 64_h1=0.1609, 64_l2=0.0527\n",
      "[131] time=2.40, avg_loss=1.3937, train_err=0.0697, 32_h1=0.0729, 32_l2=0.0344, 64_h1=0.1663, 64_l2=0.0539\n",
      "[132] time=2.38, avg_loss=1.3930, train_err=0.0697, 32_h1=0.0741, 32_l2=0.0366, 64_h1=0.1625, 64_l2=0.0502\n",
      "[133] time=2.41, avg_loss=1.3882, train_err=0.0694, 32_h1=0.0738, 32_l2=0.0351, 64_h1=0.1616, 64_l2=0.0504\n",
      "[134] time=2.34, avg_loss=1.3853, train_err=0.0693, 32_h1=0.0749, 32_l2=0.0371, 64_h1=0.1677, 64_l2=0.0585\n",
      "[135] time=2.39, avg_loss=1.3831, train_err=0.0692, 32_h1=0.0755, 32_l2=0.0367, 64_h1=0.1610, 64_l2=0.0532\n",
      "[136] time=2.36, avg_loss=1.3769, train_err=0.0688, 32_h1=0.0725, 32_l2=0.0342, 64_h1=0.1609, 64_l2=0.0506\n",
      "[137] time=2.40, avg_loss=1.3892, train_err=0.0695, 32_h1=0.0742, 32_l2=0.0368, 64_h1=0.1590, 64_l2=0.0519\n",
      "[138] time=2.38, avg_loss=1.3870, train_err=0.0693, 32_h1=0.0734, 32_l2=0.0365, 64_h1=0.1644, 64_l2=0.0542\n",
      "[139] time=2.39, avg_loss=1.3949, train_err=0.0697, 32_h1=0.0753, 32_l2=0.0382, 64_h1=0.1670, 64_l2=0.0546\n",
      "[140] time=2.36, avg_loss=1.3624, train_err=0.0681, 32_h1=0.0722, 32_l2=0.0339, 64_h1=0.1625, 64_l2=0.0532\n",
      "[141] time=2.35, avg_loss=1.3715, train_err=0.0686, 32_h1=0.0724, 32_l2=0.0346, 64_h1=0.1634, 64_l2=0.0527\n",
      "[142] time=2.35, avg_loss=1.3740, train_err=0.0687, 32_h1=0.0727, 32_l2=0.0345, 64_h1=0.1678, 64_l2=0.0545\n",
      "[143] time=2.38, avg_loss=1.3652, train_err=0.0683, 32_h1=0.0747, 32_l2=0.0379, 64_h1=0.1663, 64_l2=0.0553\n",
      "[144] time=2.34, avg_loss=1.3587, train_err=0.0679, 32_h1=0.0724, 32_l2=0.0344, 64_h1=0.1637, 64_l2=0.0510\n",
      "[145] time=2.34, avg_loss=1.3584, train_err=0.0679, 32_h1=0.0738, 32_l2=0.0372, 64_h1=0.1620, 64_l2=0.0514\n",
      "[146] time=2.34, avg_loss=1.3620, train_err=0.0681, 32_h1=0.0717, 32_l2=0.0336, 64_h1=0.1641, 64_l2=0.0504\n",
      "[147] time=2.31, avg_loss=1.3595, train_err=0.0680, 32_h1=0.0731, 32_l2=0.0351, 64_h1=0.1594, 64_l2=0.0499\n",
      "[148] time=2.35, avg_loss=1.3889, train_err=0.0694, 32_h1=0.0749, 32_l2=0.0366, 64_h1=0.1664, 64_l2=0.0539\n",
      "[149] time=2.36, avg_loss=1.3547, train_err=0.0677, 32_h1=0.0734, 32_l2=0.0353, 64_h1=0.1628, 64_l2=0.0513\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.060000000000000005\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 56961\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(14, 14, 3, 3))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(14, 14, 3, 3))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(14, 14, 3, 3))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(14, 14, 3, 3))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(14, 14, 3, 3))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(14, 14, 3, 3))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(14, 14, 3, 3))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(14, 14, 3, 3))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f7761ae42b0>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f7761b37670>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f7761b37670>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f787f0a3820>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.36, avg_loss=11.1155, train_err=0.5558, 32_h1=0.3496, 32_l2=0.2383, 64_h1=0.4054, 64_l2=0.2445\n",
      "[1] time=2.36, avg_loss=5.8057, train_err=0.2903, 32_h1=0.2557, 32_l2=0.1936, 64_h1=0.3302, 64_l2=0.2054\n",
      "[2] time=2.35, avg_loss=4.3963, train_err=0.2198, 32_h1=0.2045, 32_l2=0.1415, 64_h1=0.2637, 64_l2=0.1430\n",
      "[3] time=2.35, avg_loss=3.8143, train_err=0.1907, 32_h1=0.1727, 32_l2=0.1126, 64_h1=0.2435, 64_l2=0.1183\n",
      "[4] time=2.34, avg_loss=3.4145, train_err=0.1707, 32_h1=0.1841, 32_l2=0.1420, 64_h1=0.2641, 64_l2=0.1520\n",
      "[5] time=2.34, avg_loss=3.1618, train_err=0.1581, 32_h1=0.1575, 32_l2=0.1080, 64_h1=0.2332, 64_l2=0.1178\n",
      "[6] time=2.43, avg_loss=3.0256, train_err=0.1513, 32_h1=0.1392, 32_l2=0.0870, 64_h1=0.2007, 64_l2=0.0951\n",
      "[7] time=2.08, avg_loss=2.7165, train_err=0.1358, 32_h1=0.1328, 32_l2=0.0837, 64_h1=0.1905, 64_l2=0.0896\n",
      "[8] time=2.07, avg_loss=2.5283, train_err=0.1264, 32_h1=0.1229, 32_l2=0.0720, 64_h1=0.2009, 64_l2=0.0838\n",
      "[9] time=2.06, avg_loss=2.4108, train_err=0.1205, 32_h1=0.1235, 32_l2=0.0754, 64_h1=0.1937, 64_l2=0.0878\n",
      "[10] time=2.12, avg_loss=2.3479, train_err=0.1174, 32_h1=0.1125, 32_l2=0.0660, 64_h1=0.1823, 64_l2=0.0706\n",
      "[11] time=2.08, avg_loss=2.2256, train_err=0.1113, 32_h1=0.1087, 32_l2=0.0604, 64_h1=0.1886, 64_l2=0.0720\n",
      "[12] time=2.21, avg_loss=2.3852, train_err=0.1193, 32_h1=0.1193, 32_l2=0.0739, 64_h1=0.1793, 64_l2=0.0775\n",
      "[13] time=2.10, avg_loss=2.2719, train_err=0.1136, 32_h1=0.1158, 32_l2=0.0784, 64_h1=0.1812, 64_l2=0.0866\n",
      "[14] time=2.21, avg_loss=2.2139, train_err=0.1107, 32_h1=0.1031, 32_l2=0.0573, 64_h1=0.1730, 64_l2=0.0676\n",
      "[15] time=2.09, avg_loss=2.1532, train_err=0.1077, 32_h1=0.1090, 32_l2=0.0609, 64_h1=0.1799, 64_l2=0.0693\n",
      "[16] time=2.09, avg_loss=2.0693, train_err=0.1035, 32_h1=0.1082, 32_l2=0.0643, 64_h1=0.1734, 64_l2=0.0660\n",
      "[17] time=2.08, avg_loss=2.0099, train_err=0.1005, 32_h1=0.1006, 32_l2=0.0575, 64_h1=0.1779, 64_l2=0.0669\n",
      "[18] time=2.08, avg_loss=2.1082, train_err=0.1054, 32_h1=0.0974, 32_l2=0.0508, 64_h1=0.1688, 64_l2=0.0604\n",
      "[19] time=2.11, avg_loss=1.9623, train_err=0.0981, 32_h1=0.1010, 32_l2=0.0616, 64_h1=0.1809, 64_l2=0.0764\n",
      "[20] time=2.15, avg_loss=1.9923, train_err=0.0996, 32_h1=0.0960, 32_l2=0.0515, 64_h1=0.1665, 64_l2=0.0582\n",
      "[21] time=2.06, avg_loss=1.9113, train_err=0.0956, 32_h1=0.0968, 32_l2=0.0537, 64_h1=0.1750, 64_l2=0.0679\n",
      "[22] time=2.06, avg_loss=1.9724, train_err=0.0986, 32_h1=0.0996, 32_l2=0.0601, 64_h1=0.1798, 64_l2=0.0699\n",
      "[23] time=2.04, avg_loss=1.9259, train_err=0.0963, 32_h1=0.1107, 32_l2=0.0728, 64_h1=0.1798, 64_l2=0.0801\n",
      "[24] time=2.04, avg_loss=1.8688, train_err=0.0934, 32_h1=0.0902, 32_l2=0.0482, 64_h1=0.1665, 64_l2=0.0605\n",
      "[25] time=2.08, avg_loss=1.8872, train_err=0.0944, 32_h1=0.1169, 32_l2=0.0791, 64_h1=0.1771, 64_l2=0.0842\n",
      "[26] time=2.12, avg_loss=1.8838, train_err=0.0942, 32_h1=0.0981, 32_l2=0.0649, 64_h1=0.1767, 64_l2=0.0742\n",
      "[27] time=2.18, avg_loss=1.7779, train_err=0.0889, 32_h1=0.0931, 32_l2=0.0495, 64_h1=0.1685, 64_l2=0.0613\n",
      "[28] time=2.14, avg_loss=1.7948, train_err=0.0897, 32_h1=0.0900, 32_l2=0.0482, 64_h1=0.1605, 64_l2=0.0567\n",
      "[29] time=2.09, avg_loss=1.7646, train_err=0.0882, 32_h1=0.0942, 32_l2=0.0576, 64_h1=0.1771, 64_l2=0.0719\n",
      "[30] time=2.15, avg_loss=1.7475, train_err=0.0874, 32_h1=0.0930, 32_l2=0.0566, 64_h1=0.1683, 64_l2=0.0650\n",
      "[31] time=2.22, avg_loss=1.7387, train_err=0.0869, 32_h1=0.0868, 32_l2=0.0449, 64_h1=0.1745, 64_l2=0.0640\n",
      "[32] time=2.22, avg_loss=1.8205, train_err=0.0910, 32_h1=0.0875, 32_l2=0.0473, 64_h1=0.1607, 64_l2=0.0570\n",
      "[33] time=2.24, avg_loss=1.7139, train_err=0.0857, 32_h1=0.0914, 32_l2=0.0536, 64_h1=0.1723, 64_l2=0.0689\n",
      "[34] time=2.23, avg_loss=1.7476, train_err=0.0874, 32_h1=0.0859, 32_l2=0.0449, 64_h1=0.1699, 64_l2=0.0612\n",
      "[35] time=2.31, avg_loss=1.7506, train_err=0.0875, 32_h1=0.0882, 32_l2=0.0477, 64_h1=0.1719, 64_l2=0.0669\n",
      "[36] time=2.31, avg_loss=1.7340, train_err=0.0867, 32_h1=0.0902, 32_l2=0.0495, 64_h1=0.1617, 64_l2=0.0593\n",
      "[37] time=2.37, avg_loss=1.6629, train_err=0.0831, 32_h1=0.0875, 32_l2=0.0503, 64_h1=0.1675, 64_l2=0.0628\n",
      "[38] time=2.37, avg_loss=1.6886, train_err=0.0844, 32_h1=0.0961, 32_l2=0.0590, 64_h1=0.1771, 64_l2=0.0715\n",
      "[39] time=2.35, avg_loss=1.6823, train_err=0.0841, 32_h1=0.0890, 32_l2=0.0462, 64_h1=0.1539, 64_l2=0.0561\n",
      "[40] time=2.35, avg_loss=1.6446, train_err=0.0822, 32_h1=0.0843, 32_l2=0.0427, 64_h1=0.1733, 64_l2=0.0627\n",
      "[41] time=2.33, avg_loss=1.6495, train_err=0.0825, 32_h1=0.0835, 32_l2=0.0481, 64_h1=0.1663, 64_l2=0.0623\n",
      "[42] time=2.36, avg_loss=1.6353, train_err=0.0818, 32_h1=0.0861, 32_l2=0.0467, 64_h1=0.1665, 64_l2=0.0592\n",
      "[43] time=2.34, avg_loss=1.6198, train_err=0.0810, 32_h1=0.0836, 32_l2=0.0433, 64_h1=0.1561, 64_l2=0.0572\n",
      "[44] time=2.35, avg_loss=1.6337, train_err=0.0817, 32_h1=0.0829, 32_l2=0.0430, 64_h1=0.1557, 64_l2=0.0549\n",
      "[45] time=2.35, avg_loss=1.6364, train_err=0.0818, 32_h1=0.0811, 32_l2=0.0416, 64_h1=0.1608, 64_l2=0.0571\n",
      "[46] time=2.33, avg_loss=1.6332, train_err=0.0817, 32_h1=0.0874, 32_l2=0.0494, 64_h1=0.1639, 64_l2=0.0637\n",
      "[47] time=2.35, avg_loss=1.6670, train_err=0.0834, 32_h1=0.0820, 32_l2=0.0424, 64_h1=0.1589, 64_l2=0.0554\n",
      "[48] time=2.32, avg_loss=1.6119, train_err=0.0806, 32_h1=0.0856, 32_l2=0.0455, 64_h1=0.1639, 64_l2=0.0582\n",
      "[49] time=2.39, avg_loss=1.6467, train_err=0.0823, 32_h1=0.0803, 32_l2=0.0408, 64_h1=0.1563, 64_l2=0.0538\n",
      "[50] time=2.34, avg_loss=1.5648, train_err=0.0782, 32_h1=0.0821, 32_l2=0.0421, 64_h1=0.1665, 64_l2=0.0571\n",
      "[51] time=2.33, avg_loss=1.5923, train_err=0.0796, 32_h1=0.0802, 32_l2=0.0402, 64_h1=0.1638, 64_l2=0.0547\n",
      "[52] time=2.34, avg_loss=1.5701, train_err=0.0785, 32_h1=0.0794, 32_l2=0.0408, 64_h1=0.1563, 64_l2=0.0534\n",
      "[53] time=2.37, avg_loss=1.5982, train_err=0.0799, 32_h1=0.0882, 32_l2=0.0504, 64_h1=0.1592, 64_l2=0.0670\n",
      "[54] time=2.36, avg_loss=1.5761, train_err=0.0788, 32_h1=0.0796, 32_l2=0.0421, 64_h1=0.1659, 64_l2=0.0554\n",
      "[55] time=2.35, avg_loss=1.5386, train_err=0.0769, 32_h1=0.0793, 32_l2=0.0391, 64_h1=0.1653, 64_l2=0.0557\n",
      "[56] time=2.37, avg_loss=1.5842, train_err=0.0792, 32_h1=0.0794, 32_l2=0.0410, 64_h1=0.1664, 64_l2=0.0577\n",
      "[57] time=2.38, avg_loss=1.5213, train_err=0.0761, 32_h1=0.0761, 32_l2=0.0362, 64_h1=0.1612, 64_l2=0.0530\n",
      "[58] time=2.35, avg_loss=1.5145, train_err=0.0757, 32_h1=0.0784, 32_l2=0.0393, 64_h1=0.1573, 64_l2=0.0515\n",
      "[59] time=2.36, avg_loss=1.5747, train_err=0.0787, 32_h1=0.0795, 32_l2=0.0396, 64_h1=0.1657, 64_l2=0.0554\n",
      "[60] time=2.34, avg_loss=1.5427, train_err=0.0771, 32_h1=0.0788, 32_l2=0.0396, 64_h1=0.1565, 64_l2=0.0507\n",
      "[61] time=2.44, avg_loss=1.5442, train_err=0.0772, 32_h1=0.0799, 32_l2=0.0408, 64_h1=0.1606, 64_l2=0.0526\n",
      "[62] time=2.37, avg_loss=1.5331, train_err=0.0767, 32_h1=0.0761, 32_l2=0.0373, 64_h1=0.1537, 64_l2=0.0511\n",
      "[63] time=2.38, avg_loss=1.5011, train_err=0.0751, 32_h1=0.0788, 32_l2=0.0404, 64_h1=0.1597, 64_l2=0.0551\n",
      "[64] time=2.32, avg_loss=1.5739, train_err=0.0787, 32_h1=0.0898, 32_l2=0.0516, 64_h1=0.1612, 64_l2=0.0672\n",
      "[65] time=2.36, avg_loss=1.5236, train_err=0.0762, 32_h1=0.0822, 32_l2=0.0475, 64_h1=0.1559, 64_l2=0.0589\n",
      "[66] time=2.31, avg_loss=1.5056, train_err=0.0753, 32_h1=0.0764, 32_l2=0.0374, 64_h1=0.1605, 64_l2=0.0531\n",
      "[67] time=2.31, avg_loss=1.4895, train_err=0.0745, 32_h1=0.0818, 32_l2=0.0454, 64_h1=0.1674, 64_l2=0.0604\n",
      "[68] time=2.34, avg_loss=1.5248, train_err=0.0762, 32_h1=0.0784, 32_l2=0.0406, 64_h1=0.1627, 64_l2=0.0588\n",
      "[69] time=2.34, avg_loss=1.4978, train_err=0.0749, 32_h1=0.0771, 32_l2=0.0388, 64_h1=0.1549, 64_l2=0.0485\n",
      "[70] time=2.31, avg_loss=1.4682, train_err=0.0734, 32_h1=0.0785, 32_l2=0.0403, 64_h1=0.1640, 64_l2=0.0542\n",
      "[71] time=2.36, avg_loss=1.4898, train_err=0.0745, 32_h1=0.0773, 32_l2=0.0388, 64_h1=0.1579, 64_l2=0.0511\n",
      "[72] time=2.42, avg_loss=1.4773, train_err=0.0739, 32_h1=0.0753, 32_l2=0.0361, 64_h1=0.1620, 64_l2=0.0526\n",
      "[73] time=2.35, avg_loss=1.4707, train_err=0.0735, 32_h1=0.0805, 32_l2=0.0426, 64_h1=0.1619, 64_l2=0.0569\n",
      "[74] time=2.29, avg_loss=1.4809, train_err=0.0740, 32_h1=0.0757, 32_l2=0.0379, 64_h1=0.1529, 64_l2=0.0525\n",
      "[75] time=2.20, avg_loss=1.4619, train_err=0.0731, 32_h1=0.0755, 32_l2=0.0365, 64_h1=0.1549, 64_l2=0.0510\n",
      "[76] time=2.32, avg_loss=1.4534, train_err=0.0727, 32_h1=0.0805, 32_l2=0.0424, 64_h1=0.1642, 64_l2=0.0604\n",
      "[77] time=2.34, avg_loss=1.4850, train_err=0.0743, 32_h1=0.0754, 32_l2=0.0364, 64_h1=0.1604, 64_l2=0.0548\n",
      "[78] time=2.18, avg_loss=1.5070, train_err=0.0753, 32_h1=0.0776, 32_l2=0.0416, 64_h1=0.1598, 64_l2=0.0524\n",
      "[79] time=2.10, avg_loss=1.4908, train_err=0.0745, 32_h1=0.0766, 32_l2=0.0389, 64_h1=0.1642, 64_l2=0.0515\n",
      "[80] time=2.12, avg_loss=1.4415, train_err=0.0721, 32_h1=0.0749, 32_l2=0.0356, 64_h1=0.1607, 64_l2=0.0525\n",
      "[81] time=2.10, avg_loss=1.4477, train_err=0.0724, 32_h1=0.0783, 32_l2=0.0406, 64_h1=0.1697, 64_l2=0.0597\n",
      "[82] time=2.12, avg_loss=1.4922, train_err=0.0746, 32_h1=0.0744, 32_l2=0.0356, 64_h1=0.1562, 64_l2=0.0494\n",
      "[83] time=2.27, avg_loss=1.4307, train_err=0.0715, 32_h1=0.0788, 32_l2=0.0406, 64_h1=0.1532, 64_l2=0.0512\n",
      "[84] time=2.22, avg_loss=1.4320, train_err=0.0716, 32_h1=0.0745, 32_l2=0.0364, 64_h1=0.1586, 64_l2=0.0541\n",
      "[85] time=2.06, avg_loss=1.4442, train_err=0.0722, 32_h1=0.0770, 32_l2=0.0390, 64_h1=0.1655, 64_l2=0.0603\n",
      "[86] time=2.08, avg_loss=1.4491, train_err=0.0725, 32_h1=0.0806, 32_l2=0.0428, 64_h1=0.1611, 64_l2=0.0577\n",
      "[87] time=2.17, avg_loss=1.4543, train_err=0.0727, 32_h1=0.0849, 32_l2=0.0479, 64_h1=0.1684, 64_l2=0.0597\n",
      "[88] time=2.06, avg_loss=1.4454, train_err=0.0723, 32_h1=0.0775, 32_l2=0.0410, 64_h1=0.1633, 64_l2=0.0561\n",
      "[89] time=2.07, avg_loss=1.4291, train_err=0.0715, 32_h1=0.0796, 32_l2=0.0434, 64_h1=0.1696, 64_l2=0.0627\n",
      "[90] time=2.05, avg_loss=1.4507, train_err=0.0725, 32_h1=0.0776, 32_l2=0.0434, 64_h1=0.1665, 64_l2=0.0541\n",
      "[91] time=2.15, avg_loss=1.4165, train_err=0.0708, 32_h1=0.0778, 32_l2=0.0397, 64_h1=0.1610, 64_l2=0.0601\n",
      "[92] time=2.22, avg_loss=1.4342, train_err=0.0717, 32_h1=0.0751, 32_l2=0.0370, 64_h1=0.1561, 64_l2=0.0483\n",
      "[93] time=2.21, avg_loss=1.4117, train_err=0.0706, 32_h1=0.0753, 32_l2=0.0382, 64_h1=0.1638, 64_l2=0.0568\n",
      "[94] time=2.15, avg_loss=1.4078, train_err=0.0704, 32_h1=0.0737, 32_l2=0.0366, 64_h1=0.1542, 64_l2=0.0477\n",
      "[95] time=2.22, avg_loss=1.4351, train_err=0.0718, 32_h1=0.0764, 32_l2=0.0390, 64_h1=0.1576, 64_l2=0.0493\n",
      "[96] time=2.22, avg_loss=1.4420, train_err=0.0721, 32_h1=0.0734, 32_l2=0.0353, 64_h1=0.1606, 64_l2=0.0498\n",
      "[97] time=2.29, avg_loss=1.4142, train_err=0.0707, 32_h1=0.0745, 32_l2=0.0365, 64_h1=0.1667, 64_l2=0.0540\n",
      "[98] time=2.21, avg_loss=1.3899, train_err=0.0695, 32_h1=0.0748, 32_l2=0.0383, 64_h1=0.1661, 64_l2=0.0549\n",
      "[99] time=2.16, avg_loss=1.3997, train_err=0.0700, 32_h1=0.0736, 32_l2=0.0352, 64_h1=0.1610, 64_l2=0.0476\n",
      "[100] time=2.13, avg_loss=1.3897, train_err=0.0695, 32_h1=0.0736, 32_l2=0.0361, 64_h1=0.1592, 64_l2=0.0492\n",
      "[101] time=2.09, avg_loss=1.4336, train_err=0.0717, 32_h1=0.0743, 32_l2=0.0361, 64_h1=0.1585, 64_l2=0.0480\n",
      "[102] time=2.07, avg_loss=1.3869, train_err=0.0693, 32_h1=0.0761, 32_l2=0.0380, 64_h1=0.1616, 64_l2=0.0526\n",
      "[103] time=2.49, avg_loss=1.3993, train_err=0.0700, 32_h1=0.0787, 32_l2=0.0423, 64_h1=0.1629, 64_l2=0.0617\n",
      "[104] time=2.35, avg_loss=1.4223, train_err=0.0711, 32_h1=0.0732, 32_l2=0.0365, 64_h1=0.1615, 64_l2=0.0533\n",
      "[105] time=2.37, avg_loss=1.3819, train_err=0.0691, 32_h1=0.0732, 32_l2=0.0357, 64_h1=0.1615, 64_l2=0.0511\n",
      "[106] time=2.36, avg_loss=1.3938, train_err=0.0697, 32_h1=0.0744, 32_l2=0.0369, 64_h1=0.1562, 64_l2=0.0527\n",
      "[107] time=2.33, avg_loss=1.3724, train_err=0.0686, 32_h1=0.0770, 32_l2=0.0401, 64_h1=0.1675, 64_l2=0.0576\n",
      "[108] time=2.35, avg_loss=1.3832, train_err=0.0692, 32_h1=0.0807, 32_l2=0.0470, 64_h1=0.1613, 64_l2=0.0530\n",
      "[109] time=2.39, avg_loss=1.4103, train_err=0.0705, 32_h1=0.0726, 32_l2=0.0350, 64_h1=0.1579, 64_l2=0.0529\n",
      "[110] time=2.33, avg_loss=1.3664, train_err=0.0683, 32_h1=0.0763, 32_l2=0.0401, 64_h1=0.1589, 64_l2=0.0561\n",
      "[111] time=2.38, avg_loss=1.4049, train_err=0.0702, 32_h1=0.0775, 32_l2=0.0451, 64_h1=0.1606, 64_l2=0.0621\n",
      "[112] time=2.36, avg_loss=1.3742, train_err=0.0687, 32_h1=0.0743, 32_l2=0.0363, 64_h1=0.1672, 64_l2=0.0541\n",
      "[113] time=2.35, avg_loss=1.3660, train_err=0.0683, 32_h1=0.0776, 32_l2=0.0417, 64_h1=0.1713, 64_l2=0.0585\n",
      "[114] time=2.37, avg_loss=1.3884, train_err=0.0694, 32_h1=0.0725, 32_l2=0.0344, 64_h1=0.1648, 64_l2=0.0519\n",
      "[115] time=2.35, avg_loss=1.3743, train_err=0.0687, 32_h1=0.0733, 32_l2=0.0359, 64_h1=0.1609, 64_l2=0.0505\n",
      "[116] time=2.32, avg_loss=1.3565, train_err=0.0678, 32_h1=0.0724, 32_l2=0.0353, 64_h1=0.1626, 64_l2=0.0531\n",
      "[117] time=2.36, avg_loss=1.3800, train_err=0.0690, 32_h1=0.0745, 32_l2=0.0393, 64_h1=0.1613, 64_l2=0.0536\n",
      "[118] time=2.32, avg_loss=1.3662, train_err=0.0683, 32_h1=0.0724, 32_l2=0.0345, 64_h1=0.1571, 64_l2=0.0509\n",
      "[119] time=2.33, avg_loss=1.3683, train_err=0.0684, 32_h1=0.0736, 32_l2=0.0383, 64_h1=0.1573, 64_l2=0.0510\n",
      "[120] time=2.39, avg_loss=1.3791, train_err=0.0690, 32_h1=0.0723, 32_l2=0.0349, 64_h1=0.1650, 64_l2=0.0561\n",
      "[121] time=2.33, avg_loss=1.3484, train_err=0.0674, 32_h1=0.0743, 32_l2=0.0387, 64_h1=0.1643, 64_l2=0.0530\n",
      "[122] time=2.37, avg_loss=1.3595, train_err=0.0680, 32_h1=0.0737, 32_l2=0.0369, 64_h1=0.1627, 64_l2=0.0533\n",
      "[123] time=2.33, avg_loss=1.3380, train_err=0.0669, 32_h1=0.0739, 32_l2=0.0363, 64_h1=0.1641, 64_l2=0.0516\n",
      "[124] time=2.36, avg_loss=1.3372, train_err=0.0669, 32_h1=0.0731, 32_l2=0.0364, 64_h1=0.1665, 64_l2=0.0541\n",
      "[125] time=2.34, avg_loss=1.3419, train_err=0.0671, 32_h1=0.0718, 32_l2=0.0339, 64_h1=0.1619, 64_l2=0.0498\n",
      "[126] time=2.37, avg_loss=1.3365, train_err=0.0668, 32_h1=0.0772, 32_l2=0.0444, 64_h1=0.1691, 64_l2=0.0563\n",
      "[127] time=2.34, avg_loss=1.3740, train_err=0.0687, 32_h1=0.0727, 32_l2=0.0355, 64_h1=0.1611, 64_l2=0.0536\n",
      "[128] time=2.35, avg_loss=1.3225, train_err=0.0661, 32_h1=0.0756, 32_l2=0.0377, 64_h1=0.1616, 64_l2=0.0583\n",
      "[129] time=2.34, avg_loss=1.3317, train_err=0.0666, 32_h1=0.0723, 32_l2=0.0357, 64_h1=0.1642, 64_l2=0.0513\n",
      "[130] time=2.36, avg_loss=1.3442, train_err=0.0672, 32_h1=0.0739, 32_l2=0.0378, 64_h1=0.1673, 64_l2=0.0563\n",
      "[131] time=2.39, avg_loss=1.3521, train_err=0.0676, 32_h1=0.0721, 32_l2=0.0342, 64_h1=0.1625, 64_l2=0.0502\n",
      "[132] time=2.39, avg_loss=1.3313, train_err=0.0666, 32_h1=0.0725, 32_l2=0.0361, 64_h1=0.1636, 64_l2=0.0529\n",
      "[133] time=2.37, avg_loss=1.3183, train_err=0.0659, 32_h1=0.0729, 32_l2=0.0356, 64_h1=0.1646, 64_l2=0.0551\n",
      "[134] time=2.36, avg_loss=1.3297, train_err=0.0665, 32_h1=0.0779, 32_l2=0.0464, 64_h1=0.1611, 64_l2=0.0617\n",
      "[135] time=2.34, avg_loss=1.3477, train_err=0.0674, 32_h1=0.0723, 32_l2=0.0363, 64_h1=0.1637, 64_l2=0.0527\n",
      "[136] time=2.35, avg_loss=1.3149, train_err=0.0657, 32_h1=0.0742, 32_l2=0.0382, 64_h1=0.1584, 64_l2=0.0517\n",
      "[137] time=2.36, avg_loss=1.3353, train_err=0.0668, 32_h1=0.0744, 32_l2=0.0375, 64_h1=0.1604, 64_l2=0.0516\n",
      "[138] time=2.36, avg_loss=1.3341, train_err=0.0667, 32_h1=0.0726, 32_l2=0.0360, 64_h1=0.1611, 64_l2=0.0520\n",
      "[139] time=2.34, avg_loss=1.3208, train_err=0.0660, 32_h1=0.0719, 32_l2=0.0340, 64_h1=0.1651, 64_l2=0.0510\n",
      "[140] time=2.36, avg_loss=1.3136, train_err=0.0657, 32_h1=0.0713, 32_l2=0.0348, 64_h1=0.1661, 64_l2=0.0523\n",
      "[141] time=2.25, avg_loss=1.3014, train_err=0.0651, 32_h1=0.0715, 32_l2=0.0345, 64_h1=0.1683, 64_l2=0.0549\n",
      "[142] time=2.12, avg_loss=1.3116, train_err=0.0656, 32_h1=0.0721, 32_l2=0.0358, 64_h1=0.1635, 64_l2=0.0542\n",
      "[143] time=2.25, avg_loss=1.3279, train_err=0.0664, 32_h1=0.0720, 32_l2=0.0351, 64_h1=0.1601, 64_l2=0.0510\n",
      "[144] time=2.22, avg_loss=1.3149, train_err=0.0657, 32_h1=0.0716, 32_l2=0.0352, 64_h1=0.1625, 64_l2=0.0499\n",
      "[145] time=2.22, avg_loss=1.3257, train_err=0.0663, 32_h1=0.0747, 32_l2=0.0387, 64_h1=0.1695, 64_l2=0.0554\n",
      "[146] time=2.23, avg_loss=1.2990, train_err=0.0649, 32_h1=0.0731, 32_l2=0.0370, 64_h1=0.1635, 64_l2=0.0522\n",
      "[147] time=2.22, avg_loss=1.3001, train_err=0.0650, 32_h1=0.0706, 32_l2=0.0331, 64_h1=0.1658, 64_l2=0.0495\n",
      "[148] time=2.24, avg_loss=1.2990, train_err=0.0649, 32_h1=0.0728, 32_l2=0.0369, 64_h1=0.1631, 64_l2=0.0535\n",
      "[149] time=2.23, avg_loss=1.3065, train_err=0.0653, 32_h1=0.0710, 32_l2=0.0338, 64_h1=0.1566, 64_l2=0.0482\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.06999999999999999\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 62161\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f78870e48e0>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f787f0a35b0>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f787f0a35b0>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f7761ae42b0>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.18, avg_loss=10.3810, train_err=0.5191, 32_h1=0.3265, 32_l2=0.2256, 64_h1=0.3908, 64_l2=0.2330\n",
      "[1] time=2.20, avg_loss=5.4096, train_err=0.2705, 32_h1=0.2292, 32_l2=0.1556, 64_h1=0.2792, 64_l2=0.1593\n",
      "[2] time=2.19, avg_loss=4.1731, train_err=0.2087, 32_h1=0.1986, 32_l2=0.1378, 64_h1=0.2523, 64_l2=0.1357\n",
      "[3] time=2.08, avg_loss=3.6804, train_err=0.1840, 32_h1=0.1920, 32_l2=0.1423, 64_h1=0.2521, 64_l2=0.1495\n",
      "[4] time=2.14, avg_loss=3.4003, train_err=0.1700, 32_h1=0.1765, 32_l2=0.1344, 64_h1=0.2406, 64_l2=0.1384\n",
      "[5] time=2.16, avg_loss=3.0634, train_err=0.1532, 32_h1=0.1606, 32_l2=0.1106, 64_h1=0.2241, 64_l2=0.1199\n",
      "[6] time=2.09, avg_loss=2.8811, train_err=0.1441, 32_h1=0.1405, 32_l2=0.0902, 64_h1=0.2107, 64_l2=0.0981\n",
      "[7] time=2.05, avg_loss=2.6534, train_err=0.1327, 32_h1=0.1345, 32_l2=0.0877, 64_h1=0.2064, 64_l2=0.0989\n",
      "[8] time=2.22, avg_loss=2.6187, train_err=0.1309, 32_h1=0.1270, 32_l2=0.0764, 64_h1=0.1981, 64_l2=0.0889\n",
      "[9] time=2.23, avg_loss=2.4232, train_err=0.1212, 32_h1=0.1221, 32_l2=0.0788, 64_h1=0.1940, 64_l2=0.0905\n",
      "[10] time=2.12, avg_loss=2.3620, train_err=0.1181, 32_h1=0.1165, 32_l2=0.0679, 64_h1=0.1897, 64_l2=0.0773\n",
      "[11] time=2.12, avg_loss=2.2489, train_err=0.1124, 32_h1=0.1211, 32_l2=0.0779, 64_h1=0.1954, 64_l2=0.0899\n",
      "[12] time=2.06, avg_loss=2.2433, train_err=0.1122, 32_h1=0.1147, 32_l2=0.0715, 64_h1=0.1949, 64_l2=0.0853\n",
      "[13] time=2.13, avg_loss=2.1577, train_err=0.1079, 32_h1=0.1093, 32_l2=0.0647, 64_h1=0.1682, 64_l2=0.0671\n",
      "[14] time=2.04, avg_loss=2.0867, train_err=0.1043, 32_h1=0.1107, 32_l2=0.0674, 64_h1=0.1838, 64_l2=0.0834\n",
      "[15] time=2.10, avg_loss=2.0914, train_err=0.1046, 32_h1=0.1098, 32_l2=0.0721, 64_h1=0.1822, 64_l2=0.0787\n",
      "[16] time=2.11, avg_loss=2.0137, train_err=0.1007, 32_h1=0.0964, 32_l2=0.0512, 64_h1=0.1673, 64_l2=0.0604\n",
      "[17] time=2.05, avg_loss=2.0133, train_err=0.1007, 32_h1=0.0964, 32_l2=0.0527, 64_h1=0.1753, 64_l2=0.0673\n",
      "[18] time=2.24, avg_loss=1.9080, train_err=0.0954, 32_h1=0.1189, 32_l2=0.0927, 64_h1=0.1785, 64_l2=0.0989\n",
      "[19] time=2.10, avg_loss=1.9766, train_err=0.0988, 32_h1=0.0972, 32_l2=0.0549, 64_h1=0.1747, 64_l2=0.0670\n",
      "[20] time=2.24, avg_loss=1.8625, train_err=0.0931, 32_h1=0.1012, 32_l2=0.0657, 64_h1=0.1784, 64_l2=0.0809\n",
      "[21] time=2.44, avg_loss=1.8782, train_err=0.0939, 32_h1=0.0931, 32_l2=0.0508, 64_h1=0.1747, 64_l2=0.0658\n",
      "[22] time=2.40, avg_loss=1.7955, train_err=0.0898, 32_h1=0.0924, 32_l2=0.0489, 64_h1=0.1608, 64_l2=0.0534\n",
      "[23] time=2.37, avg_loss=1.8025, train_err=0.0901, 32_h1=0.0946, 32_l2=0.0559, 64_h1=0.1724, 64_l2=0.0729\n",
      "[24] time=2.35, avg_loss=1.8389, train_err=0.0919, 32_h1=0.0930, 32_l2=0.0526, 64_h1=0.1704, 64_l2=0.0657\n",
      "[25] time=2.34, avg_loss=1.8765, train_err=0.0938, 32_h1=0.1083, 32_l2=0.0705, 64_h1=0.1852, 64_l2=0.0806\n",
      "[26] time=2.35, avg_loss=1.7794, train_err=0.0890, 32_h1=0.0944, 32_l2=0.0573, 64_h1=0.1749, 64_l2=0.0688\n",
      "[27] time=2.35, avg_loss=1.7204, train_err=0.0860, 32_h1=0.0863, 32_l2=0.0430, 64_h1=0.1707, 64_l2=0.0591\n",
      "[28] time=2.33, avg_loss=1.7521, train_err=0.0876, 32_h1=0.0932, 32_l2=0.0541, 64_h1=0.1675, 64_l2=0.0663\n",
      "[29] time=2.34, avg_loss=1.7079, train_err=0.0854, 32_h1=0.0878, 32_l2=0.0463, 64_h1=0.1672, 64_l2=0.0623\n",
      "[30] time=2.42, avg_loss=1.7169, train_err=0.0858, 32_h1=0.0870, 32_l2=0.0463, 64_h1=0.1623, 64_l2=0.0571\n",
      "[31] time=2.32, avg_loss=1.7605, train_err=0.0880, 32_h1=0.0843, 32_l2=0.0436, 64_h1=0.1675, 64_l2=0.0564\n",
      "[32] time=2.34, avg_loss=1.6805, train_err=0.0840, 32_h1=0.0825, 32_l2=0.0415, 64_h1=0.1719, 64_l2=0.0583\n",
      "[33] time=2.35, avg_loss=1.6760, train_err=0.0838, 32_h1=0.0865, 32_l2=0.0469, 64_h1=0.1695, 64_l2=0.0650\n",
      "[34] time=2.30, avg_loss=1.7053, train_err=0.0853, 32_h1=0.0880, 32_l2=0.0543, 64_h1=0.1724, 64_l2=0.0665\n",
      "[35] time=2.36, avg_loss=1.6601, train_err=0.0830, 32_h1=0.0852, 32_l2=0.0441, 64_h1=0.1643, 64_l2=0.0578\n",
      "[36] time=2.35, avg_loss=1.6581, train_err=0.0829, 32_h1=0.0858, 32_l2=0.0499, 64_h1=0.1686, 64_l2=0.0608\n",
      "[37] time=2.35, avg_loss=1.6307, train_err=0.0815, 32_h1=0.0835, 32_l2=0.0436, 64_h1=0.1675, 64_l2=0.0624\n",
      "[38] time=2.32, avg_loss=1.6470, train_err=0.0824, 32_h1=0.0877, 32_l2=0.0490, 64_h1=0.1695, 64_l2=0.0659\n",
      "[39] time=2.33, avg_loss=1.6370, train_err=0.0818, 32_h1=0.0900, 32_l2=0.0539, 64_h1=0.1744, 64_l2=0.0680\n",
      "[40] time=2.34, avg_loss=1.6603, train_err=0.0830, 32_h1=0.0834, 32_l2=0.0442, 64_h1=0.1710, 64_l2=0.0646\n",
      "[41] time=2.40, avg_loss=1.5976, train_err=0.0799, 32_h1=0.0819, 32_l2=0.0426, 64_h1=0.1567, 64_l2=0.0530\n",
      "[42] time=2.32, avg_loss=1.6641, train_err=0.0832, 32_h1=0.0813, 32_l2=0.0407, 64_h1=0.1621, 64_l2=0.0549\n",
      "[43] time=2.35, avg_loss=1.5957, train_err=0.0798, 32_h1=0.1007, 32_l2=0.0703, 64_h1=0.1801, 64_l2=0.0772\n",
      "[44] time=2.35, avg_loss=1.6290, train_err=0.0814, 32_h1=0.0830, 32_l2=0.0439, 64_h1=0.1702, 64_l2=0.0604\n",
      "[45] time=2.34, avg_loss=1.5722, train_err=0.0786, 32_h1=0.0843, 32_l2=0.0463, 64_h1=0.1625, 64_l2=0.0550\n",
      "[46] time=2.39, avg_loss=1.6598, train_err=0.0830, 32_h1=0.0869, 32_l2=0.0487, 64_h1=0.1669, 64_l2=0.0665\n",
      "[47] time=2.41, avg_loss=1.5701, train_err=0.0785, 32_h1=0.0892, 32_l2=0.0518, 64_h1=0.1638, 64_l2=0.0666\n",
      "[48] time=2.43, avg_loss=1.5583, train_err=0.0779, 32_h1=0.0771, 32_l2=0.0373, 64_h1=0.1606, 64_l2=0.0532\n",
      "[49] time=2.41, avg_loss=1.5598, train_err=0.0780, 32_h1=0.0789, 32_l2=0.0401, 64_h1=0.1628, 64_l2=0.0566\n",
      "[50] time=2.35, avg_loss=1.5661, train_err=0.0783, 32_h1=0.0796, 32_l2=0.0403, 64_h1=0.1626, 64_l2=0.0590\n",
      "[51] time=2.38, avg_loss=1.5380, train_err=0.0769, 32_h1=0.0754, 32_l2=0.0354, 64_h1=0.1623, 64_l2=0.0536\n",
      "[52] time=2.34, avg_loss=1.5454, train_err=0.0773, 32_h1=0.0810, 32_l2=0.0424, 64_h1=0.1640, 64_l2=0.0523\n",
      "[53] time=2.42, avg_loss=1.5574, train_err=0.0779, 32_h1=0.0811, 32_l2=0.0445, 64_h1=0.1648, 64_l2=0.0642\n",
      "[54] time=2.38, avg_loss=1.5169, train_err=0.0758, 32_h1=0.0835, 32_l2=0.0467, 64_h1=0.1646, 64_l2=0.0542\n",
      "[55] time=2.33, avg_loss=1.5497, train_err=0.0775, 32_h1=0.0828, 32_l2=0.0468, 64_h1=0.1666, 64_l2=0.0593\n",
      "[56] time=2.34, avg_loss=1.5407, train_err=0.0770, 32_h1=0.0783, 32_l2=0.0394, 64_h1=0.1628, 64_l2=0.0562\n",
      "[57] time=2.34, avg_loss=1.5035, train_err=0.0752, 32_h1=0.0804, 32_l2=0.0429, 64_h1=0.1656, 64_l2=0.0619\n",
      "[58] time=2.37, avg_loss=1.5237, train_err=0.0762, 32_h1=0.0793, 32_l2=0.0421, 64_h1=0.1653, 64_l2=0.0551\n",
      "[59] time=2.20, avg_loss=1.5107, train_err=0.0755, 32_h1=0.0780, 32_l2=0.0385, 64_h1=0.1694, 64_l2=0.0588\n",
      "[60] time=2.04, avg_loss=1.4900, train_err=0.0745, 32_h1=0.0772, 32_l2=0.0397, 64_h1=0.1645, 64_l2=0.0595\n",
      "[61] time=2.03, avg_loss=1.5279, train_err=0.0764, 32_h1=0.0817, 32_l2=0.0464, 64_h1=0.1719, 64_l2=0.0643\n",
      "[62] time=2.17, avg_loss=1.4950, train_err=0.0748, 32_h1=0.0853, 32_l2=0.0508, 64_h1=0.1638, 64_l2=0.0579\n",
      "[63] time=2.05, avg_loss=1.4745, train_err=0.0737, 32_h1=0.0782, 32_l2=0.0401, 64_h1=0.1619, 64_l2=0.0569\n",
      "[64] time=2.11, avg_loss=1.4892, train_err=0.0745, 32_h1=0.0775, 32_l2=0.0393, 64_h1=0.1647, 64_l2=0.0565\n",
      "[65] time=2.17, avg_loss=1.4986, train_err=0.0749, 32_h1=0.0807, 32_l2=0.0437, 64_h1=0.1674, 64_l2=0.0590\n",
      "[66] time=2.19, avg_loss=1.4724, train_err=0.0736, 32_h1=0.0799, 32_l2=0.0431, 64_h1=0.1644, 64_l2=0.0574\n",
      "[67] time=2.21, avg_loss=1.4848, train_err=0.0742, 32_h1=0.0809, 32_l2=0.0442, 64_h1=0.1678, 64_l2=0.0591\n",
      "[68] time=2.15, avg_loss=1.4979, train_err=0.0749, 32_h1=0.0854, 32_l2=0.0500, 64_h1=0.1678, 64_l2=0.0686\n",
      "[69] time=2.14, avg_loss=1.4652, train_err=0.0733, 32_h1=0.0786, 32_l2=0.0390, 64_h1=0.1693, 64_l2=0.0564\n",
      "[70] time=2.18, avg_loss=1.4938, train_err=0.0747, 32_h1=0.0758, 32_l2=0.0383, 64_h1=0.1646, 64_l2=0.0591\n",
      "[71] time=2.15, avg_loss=1.4429, train_err=0.0721, 32_h1=0.0741, 32_l2=0.0354, 64_h1=0.1653, 64_l2=0.0537\n",
      "[72] time=2.13, avg_loss=1.4620, train_err=0.0731, 32_h1=0.0791, 32_l2=0.0398, 64_h1=0.1668, 64_l2=0.0535\n",
      "[73] time=2.06, avg_loss=1.4791, train_err=0.0740, 32_h1=0.0789, 32_l2=0.0408, 64_h1=0.1636, 64_l2=0.0565\n",
      "[74] time=2.07, avg_loss=1.4758, train_err=0.0738, 32_h1=0.0781, 32_l2=0.0400, 64_h1=0.1760, 64_l2=0.0624\n",
      "[75] time=2.09, avg_loss=1.4812, train_err=0.0741, 32_h1=0.0775, 32_l2=0.0402, 64_h1=0.1680, 64_l2=0.0586\n",
      "[76] time=2.17, avg_loss=1.4397, train_err=0.0720, 32_h1=0.0797, 32_l2=0.0432, 64_h1=0.1688, 64_l2=0.0587\n",
      "[77] time=2.29, avg_loss=1.4556, train_err=0.0728, 32_h1=0.0759, 32_l2=0.0386, 64_h1=0.1644, 64_l2=0.0562\n",
      "[78] time=2.24, avg_loss=1.4418, train_err=0.0721, 32_h1=0.0763, 32_l2=0.0385, 64_h1=0.1726, 64_l2=0.0602\n",
      "[79] time=2.23, avg_loss=1.4257, train_err=0.0713, 32_h1=0.0794, 32_l2=0.0421, 64_h1=0.1590, 64_l2=0.0511\n",
      "[80] time=2.17, avg_loss=1.4436, train_err=0.0722, 32_h1=0.0790, 32_l2=0.0418, 64_h1=0.1579, 64_l2=0.0564\n",
      "[81] time=2.17, avg_loss=1.4750, train_err=0.0737, 32_h1=0.0767, 32_l2=0.0404, 64_h1=0.1676, 64_l2=0.0579\n",
      "[82] time=2.16, avg_loss=1.4272, train_err=0.0714, 32_h1=0.0808, 32_l2=0.0454, 64_h1=0.1663, 64_l2=0.0592\n",
      "[83] time=2.09, avg_loss=1.4244, train_err=0.0712, 32_h1=0.0755, 32_l2=0.0391, 64_h1=0.1599, 64_l2=0.0539\n",
      "[84] time=2.09, avg_loss=1.4175, train_err=0.0709, 32_h1=0.0830, 32_l2=0.0486, 64_h1=0.1649, 64_l2=0.0622\n",
      "[85] time=2.08, avg_loss=1.4254, train_err=0.0713, 32_h1=0.0761, 32_l2=0.0385, 64_h1=0.1613, 64_l2=0.0489\n",
      "[86] time=2.07, avg_loss=1.4126, train_err=0.0706, 32_h1=0.0743, 32_l2=0.0375, 64_h1=0.1623, 64_l2=0.0550\n",
      "[87] time=2.13, avg_loss=1.4313, train_err=0.0716, 32_h1=0.0754, 32_l2=0.0368, 64_h1=0.1620, 64_l2=0.0502\n",
      "[88] time=2.31, avg_loss=1.4044, train_err=0.0702, 32_h1=0.0776, 32_l2=0.0414, 64_h1=0.1735, 64_l2=0.0646\n",
      "[89] time=2.38, avg_loss=1.4350, train_err=0.0718, 32_h1=0.0752, 32_l2=0.0372, 64_h1=0.1665, 64_l2=0.0541\n",
      "[90] time=2.37, avg_loss=1.4000, train_err=0.0700, 32_h1=0.0747, 32_l2=0.0361, 64_h1=0.1606, 64_l2=0.0546\n",
      "[91] time=2.31, avg_loss=1.4116, train_err=0.0706, 32_h1=0.0734, 32_l2=0.0347, 64_h1=0.1644, 64_l2=0.0531\n",
      "[92] time=2.36, avg_loss=1.3864, train_err=0.0693, 32_h1=0.0756, 32_l2=0.0385, 64_h1=0.1630, 64_l2=0.0556\n",
      "[93] time=2.37, avg_loss=1.4066, train_err=0.0703, 32_h1=0.0739, 32_l2=0.0350, 64_h1=0.1687, 64_l2=0.0552\n",
      "[94] time=2.37, avg_loss=1.4136, train_err=0.0707, 32_h1=0.0792, 32_l2=0.0427, 64_h1=0.1691, 64_l2=0.0574\n",
      "[95] time=2.36, avg_loss=1.4225, train_err=0.0711, 32_h1=0.0737, 32_l2=0.0360, 64_h1=0.1617, 64_l2=0.0551\n",
      "[96] time=2.35, avg_loss=1.3817, train_err=0.0691, 32_h1=0.0756, 32_l2=0.0385, 64_h1=0.1690, 64_l2=0.0604\n",
      "[97] time=2.36, avg_loss=1.3843, train_err=0.0692, 32_h1=0.0776, 32_l2=0.0412, 64_h1=0.1620, 64_l2=0.0545\n",
      "[98] time=2.38, avg_loss=1.3930, train_err=0.0696, 32_h1=0.0757, 32_l2=0.0393, 64_h1=0.1649, 64_l2=0.0588\n",
      "[99] time=2.36, avg_loss=1.4262, train_err=0.0713, 32_h1=0.0761, 32_l2=0.0396, 64_h1=0.1645, 64_l2=0.0566\n",
      "[100] time=2.34, avg_loss=1.3868, train_err=0.0693, 32_h1=0.0736, 32_l2=0.0360, 64_h1=0.1630, 64_l2=0.0550\n",
      "[101] time=2.40, avg_loss=1.3786, train_err=0.0689, 32_h1=0.0784, 32_l2=0.0413, 64_h1=0.1658, 64_l2=0.0530\n",
      "[102] time=2.34, avg_loss=1.3894, train_err=0.0695, 32_h1=0.0764, 32_l2=0.0403, 64_h1=0.1676, 64_l2=0.0567\n",
      "[103] time=2.34, avg_loss=1.4019, train_err=0.0701, 32_h1=0.0726, 32_l2=0.0346, 64_h1=0.1621, 64_l2=0.0518\n",
      "[104] time=2.36, avg_loss=1.3539, train_err=0.0677, 32_h1=0.0722, 32_l2=0.0336, 64_h1=0.1603, 64_l2=0.0498\n",
      "[105] time=2.34, avg_loss=1.3726, train_err=0.0686, 32_h1=0.0737, 32_l2=0.0360, 64_h1=0.1672, 64_l2=0.0561\n",
      "[106] time=2.36, avg_loss=1.3614, train_err=0.0681, 32_h1=0.0760, 32_l2=0.0379, 64_h1=0.1613, 64_l2=0.0502\n",
      "[107] time=2.32, avg_loss=1.3623, train_err=0.0681, 32_h1=0.0758, 32_l2=0.0397, 64_h1=0.1623, 64_l2=0.0599\n",
      "[108] time=2.36, avg_loss=1.3468, train_err=0.0673, 32_h1=0.0727, 32_l2=0.0349, 64_h1=0.1661, 64_l2=0.0518\n",
      "[109] time=2.33, avg_loss=1.3740, train_err=0.0687, 32_h1=0.0723, 32_l2=0.0344, 64_h1=0.1649, 64_l2=0.0552\n",
      "[110] time=2.34, avg_loss=1.3560, train_err=0.0678, 32_h1=0.0737, 32_l2=0.0359, 64_h1=0.1632, 64_l2=0.0513\n",
      "[111] time=2.30, avg_loss=1.3882, train_err=0.0694, 32_h1=0.0757, 32_l2=0.0392, 64_h1=0.1697, 64_l2=0.0594\n",
      "[112] time=2.32, avg_loss=1.3530, train_err=0.0677, 32_h1=0.0741, 32_l2=0.0377, 64_h1=0.1588, 64_l2=0.0549\n",
      "[113] time=2.41, avg_loss=1.3557, train_err=0.0678, 32_h1=0.0716, 32_l2=0.0330, 64_h1=0.1649, 64_l2=0.0515\n",
      "[114] time=2.33, avg_loss=1.3559, train_err=0.0678, 32_h1=0.0730, 32_l2=0.0351, 64_h1=0.1587, 64_l2=0.0505\n",
      "[115] time=2.33, avg_loss=1.3430, train_err=0.0672, 32_h1=0.0753, 32_l2=0.0424, 64_h1=0.1606, 64_l2=0.0557\n",
      "[116] time=2.32, avg_loss=1.3498, train_err=0.0675, 32_h1=0.0724, 32_l2=0.0346, 64_h1=0.1642, 64_l2=0.0529\n",
      "[117] time=2.38, avg_loss=1.3587, train_err=0.0679, 32_h1=0.0756, 32_l2=0.0382, 64_h1=0.1675, 64_l2=0.0580\n",
      "[118] time=2.38, avg_loss=1.3442, train_err=0.0672, 32_h1=0.0722, 32_l2=0.0347, 64_h1=0.1653, 64_l2=0.0533\n",
      "[119] time=2.34, avg_loss=1.3245, train_err=0.0662, 32_h1=0.0731, 32_l2=0.0350, 64_h1=0.1635, 64_l2=0.0540\n",
      "[120] time=2.34, avg_loss=1.3618, train_err=0.0681, 32_h1=0.0724, 32_l2=0.0338, 64_h1=0.1591, 64_l2=0.0517\n",
      "[121] time=2.39, avg_loss=1.3293, train_err=0.0665, 32_h1=0.0749, 32_l2=0.0391, 64_h1=0.1600, 64_l2=0.0525\n",
      "[122] time=2.35, avg_loss=1.3159, train_err=0.0658, 32_h1=0.0717, 32_l2=0.0340, 64_h1=0.1657, 64_l2=0.0520\n",
      "[123] time=2.36, avg_loss=1.3245, train_err=0.0662, 32_h1=0.0739, 32_l2=0.0367, 64_h1=0.1632, 64_l2=0.0525\n",
      "[124] time=2.38, avg_loss=1.3348, train_err=0.0667, 32_h1=0.0719, 32_l2=0.0342, 64_h1=0.1608, 64_l2=0.0511\n",
      "[125] time=2.35, avg_loss=1.3130, train_err=0.0656, 32_h1=0.0767, 32_l2=0.0417, 64_h1=0.1651, 64_l2=0.0626\n",
      "[126] time=2.39, avg_loss=1.3765, train_err=0.0688, 32_h1=0.0731, 32_l2=0.0373, 64_h1=0.1639, 64_l2=0.0532\n",
      "[127] time=2.11, avg_loss=1.3291, train_err=0.0665, 32_h1=0.0733, 32_l2=0.0363, 64_h1=0.1662, 64_l2=0.0548\n",
      "[128] time=2.11, avg_loss=1.3185, train_err=0.0659, 32_h1=0.0730, 32_l2=0.0351, 64_h1=0.1661, 64_l2=0.0503\n",
      "[129] time=2.09, avg_loss=1.3192, train_err=0.0660, 32_h1=0.0737, 32_l2=0.0361, 64_h1=0.1608, 64_l2=0.0516\n",
      "[130] time=2.06, avg_loss=1.3194, train_err=0.0660, 32_h1=0.0736, 32_l2=0.0373, 64_h1=0.1680, 64_l2=0.0571\n",
      "[131] time=2.06, avg_loss=1.3063, train_err=0.0653, 32_h1=0.0723, 32_l2=0.0351, 64_h1=0.1631, 64_l2=0.0530\n",
      "[132] time=2.04, avg_loss=1.3258, train_err=0.0663, 32_h1=0.0707, 32_l2=0.0329, 64_h1=0.1661, 64_l2=0.0524\n",
      "[133] time=2.04, avg_loss=1.3073, train_err=0.0654, 32_h1=0.0734, 32_l2=0.0368, 64_h1=0.1619, 64_l2=0.0542\n",
      "[134] time=2.04, avg_loss=1.3323, train_err=0.0666, 32_h1=0.0728, 32_l2=0.0356, 64_h1=0.1631, 64_l2=0.0544\n",
      "[135] time=2.12, avg_loss=1.3170, train_err=0.0658, 32_h1=0.0715, 32_l2=0.0342, 64_h1=0.1626, 64_l2=0.0523\n",
      "[136] time=2.13, avg_loss=1.3105, train_err=0.0655, 32_h1=0.0770, 32_l2=0.0421, 64_h1=0.1643, 64_l2=0.0600\n",
      "[137] time=2.12, avg_loss=1.3242, train_err=0.0662, 32_h1=0.0712, 32_l2=0.0341, 64_h1=0.1644, 64_l2=0.0530\n",
      "[138] time=2.07, avg_loss=1.2910, train_err=0.0645, 32_h1=0.0716, 32_l2=0.0335, 64_h1=0.1638, 64_l2=0.0536\n",
      "[139] time=2.06, avg_loss=1.3107, train_err=0.0655, 32_h1=0.0728, 32_l2=0.0357, 64_h1=0.1644, 64_l2=0.0532\n",
      "[140] time=2.11, avg_loss=1.3013, train_err=0.0651, 32_h1=0.0717, 32_l2=0.0344, 64_h1=0.1694, 64_l2=0.0567\n",
      "[141] time=2.12, avg_loss=1.2887, train_err=0.0644, 32_h1=0.0717, 32_l2=0.0343, 64_h1=0.1654, 64_l2=0.0563\n",
      "[142] time=2.07, avg_loss=1.3075, train_err=0.0654, 32_h1=0.0724, 32_l2=0.0350, 64_h1=0.1649, 64_l2=0.0531\n",
      "[143] time=2.07, avg_loss=1.2848, train_err=0.0642, 32_h1=0.0714, 32_l2=0.0349, 64_h1=0.1704, 64_l2=0.0554\n",
      "[144] time=2.06, avg_loss=1.2960, train_err=0.0648, 32_h1=0.0723, 32_l2=0.0349, 64_h1=0.1614, 64_l2=0.0508\n",
      "[145] time=2.20, avg_loss=1.2973, train_err=0.0649, 32_h1=0.0738, 32_l2=0.0375, 64_h1=0.1687, 64_l2=0.0535\n",
      "[146] time=2.13, avg_loss=1.2893, train_err=0.0645, 32_h1=0.0719, 32_l2=0.0340, 64_h1=0.1677, 64_l2=0.0549\n",
      "[147] time=2.15, avg_loss=1.2847, train_err=0.0642, 32_h1=0.0711, 32_l2=0.0335, 64_h1=0.1654, 64_l2=0.0507\n",
      "[148] time=2.06, avg_loss=1.2720, train_err=0.0636, 32_h1=0.0721, 32_l2=0.0347, 64_h1=0.1630, 64_l2=0.0518\n",
      "[149] time=2.25, avg_loss=1.2752, train_err=0.0638, 32_h1=0.0710, 32_l2=0.0331, 64_h1=0.1665, 64_l2=0.0523\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.08\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 62161\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f7760c6a940>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f7854f93b20>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f7854f93b20>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f78870e48e0>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.14, avg_loss=10.6774, train_err=0.5339, 32_h1=0.3528, 32_l2=0.2394, 64_h1=0.4022, 64_l2=0.2428\n",
      "[1] time=2.08, avg_loss=5.7057, train_err=0.2853, 32_h1=0.2407, 32_l2=0.1576, 64_h1=0.2958, 64_l2=0.1591\n",
      "[2] time=2.08, avg_loss=4.3927, train_err=0.2196, 32_h1=0.1979, 32_l2=0.1303, 64_h1=0.2672, 64_l2=0.1380\n",
      "[3] time=2.06, avg_loss=3.6849, train_err=0.1842, 32_h1=0.1811, 32_l2=0.1211, 64_h1=0.2362, 64_l2=0.1339\n",
      "[4] time=2.21, avg_loss=3.3207, train_err=0.1660, 32_h1=0.1623, 32_l2=0.1055, 64_h1=0.2414, 64_l2=0.1224\n",
      "[5] time=2.18, avg_loss=3.0549, train_err=0.1527, 32_h1=0.1449, 32_l2=0.0953, 64_h1=0.2102, 64_l2=0.1073\n",
      "[6] time=2.33, avg_loss=2.8962, train_err=0.1448, 32_h1=0.1626, 32_l2=0.1260, 64_h1=0.2285, 64_l2=0.1363\n",
      "[7] time=2.41, avg_loss=2.7147, train_err=0.1357, 32_h1=0.1315, 32_l2=0.0791, 64_h1=0.2054, 64_l2=0.0849\n",
      "[8] time=2.34, avg_loss=2.5740, train_err=0.1287, 32_h1=0.1222, 32_l2=0.0724, 64_h1=0.1922, 64_l2=0.0776\n",
      "[9] time=2.38, avg_loss=2.4655, train_err=0.1233, 32_h1=0.1184, 32_l2=0.0690, 64_h1=0.1927, 64_l2=0.0784\n",
      "[10] time=2.32, avg_loss=2.3606, train_err=0.1180, 32_h1=0.1148, 32_l2=0.0658, 64_h1=0.1970, 64_l2=0.0815\n",
      "[11] time=2.34, avg_loss=2.3185, train_err=0.1159, 32_h1=0.1158, 32_l2=0.0688, 64_h1=0.1794, 64_l2=0.0772\n",
      "[12] time=2.39, avg_loss=2.2479, train_err=0.1124, 32_h1=0.1354, 32_l2=0.0996, 64_h1=0.1957, 64_l2=0.1087\n",
      "[13] time=2.35, avg_loss=2.2542, train_err=0.1127, 32_h1=0.1123, 32_l2=0.0655, 64_h1=0.1873, 64_l2=0.0763\n",
      "[14] time=2.35, avg_loss=2.2486, train_err=0.1124, 32_h1=0.1054, 32_l2=0.0584, 64_h1=0.1793, 64_l2=0.0689\n",
      "[15] time=2.32, avg_loss=2.1411, train_err=0.1071, 32_h1=0.1088, 32_l2=0.0613, 64_h1=0.1880, 64_l2=0.0762\n",
      "[16] time=2.37, avg_loss=2.0719, train_err=0.1036, 32_h1=0.1115, 32_l2=0.0701, 64_h1=0.1855, 64_l2=0.0813\n",
      "[17] time=2.37, avg_loss=2.0384, train_err=0.1019, 32_h1=0.1117, 32_l2=0.0725, 64_h1=0.1844, 64_l2=0.0808\n",
      "[18] time=2.37, avg_loss=2.0694, train_err=0.1035, 32_h1=0.1124, 32_l2=0.0789, 64_h1=0.1828, 64_l2=0.0782\n",
      "[19] time=2.36, avg_loss=2.0506, train_err=0.1025, 32_h1=0.1058, 32_l2=0.0607, 64_h1=0.1832, 64_l2=0.0730\n",
      "[20] time=2.41, avg_loss=2.0199, train_err=0.1010, 32_h1=0.1016, 32_l2=0.0579, 64_h1=0.1633, 64_l2=0.0617\n",
      "[21] time=2.38, avg_loss=1.9291, train_err=0.0965, 32_h1=0.1045, 32_l2=0.0626, 64_h1=0.1717, 64_l2=0.0689\n",
      "[22] time=2.36, avg_loss=1.9383, train_err=0.0969, 32_h1=0.0946, 32_l2=0.0498, 64_h1=0.1707, 64_l2=0.0595\n",
      "[23] time=2.44, avg_loss=1.8888, train_err=0.0944, 32_h1=0.1109, 32_l2=0.0660, 64_h1=0.1751, 64_l2=0.0764\n",
      "[24] time=2.37, avg_loss=1.9584, train_err=0.0979, 32_h1=0.0959, 32_l2=0.0547, 64_h1=0.1858, 64_l2=0.0698\n",
      "[25] time=2.36, avg_loss=1.9456, train_err=0.0973, 32_h1=0.0994, 32_l2=0.0579, 64_h1=0.1857, 64_l2=0.0748\n",
      "[26] time=2.38, avg_loss=1.8562, train_err=0.0928, 32_h1=0.0908, 32_l2=0.0488, 64_h1=0.1692, 64_l2=0.0595\n",
      "[27] time=2.35, avg_loss=1.7994, train_err=0.0900, 32_h1=0.1003, 32_l2=0.0575, 64_h1=0.1746, 64_l2=0.0689\n",
      "[28] time=2.35, avg_loss=1.8720, train_err=0.0936, 32_h1=0.0967, 32_l2=0.0538, 64_h1=0.1791, 64_l2=0.0756\n",
      "[29] time=2.34, avg_loss=1.7775, train_err=0.0889, 32_h1=0.0977, 32_l2=0.0596, 64_h1=0.1642, 64_l2=0.0668\n",
      "[30] time=2.38, avg_loss=1.8337, train_err=0.0917, 32_h1=0.1080, 32_l2=0.0689, 64_h1=0.1664, 64_l2=0.0712\n",
      "[31] time=2.30, avg_loss=1.8081, train_err=0.0904, 32_h1=0.0888, 32_l2=0.0470, 64_h1=0.1754, 64_l2=0.0622\n",
      "[32] time=2.35, avg_loss=1.7811, train_err=0.0891, 32_h1=0.0888, 32_l2=0.0472, 64_h1=0.1685, 64_l2=0.0640\n",
      "[33] time=2.35, avg_loss=1.7782, train_err=0.0889, 32_h1=0.0890, 32_l2=0.0472, 64_h1=0.1671, 64_l2=0.0625\n",
      "[34] time=2.36, avg_loss=1.7036, train_err=0.0852, 32_h1=0.0852, 32_l2=0.0441, 64_h1=0.1627, 64_l2=0.0563\n",
      "[35] time=2.38, avg_loss=1.6973, train_err=0.0849, 32_h1=0.0893, 32_l2=0.0501, 64_h1=0.1663, 64_l2=0.0569\n",
      "[36] time=2.33, avg_loss=1.7426, train_err=0.0871, 32_h1=0.0945, 32_l2=0.0550, 64_h1=0.1705, 64_l2=0.0605\n",
      "[37] time=2.35, avg_loss=1.7218, train_err=0.0861, 32_h1=0.0875, 32_l2=0.0459, 64_h1=0.1688, 64_l2=0.0576\n",
      "[38] time=2.35, avg_loss=1.7711, train_err=0.0886, 32_h1=0.0884, 32_l2=0.0522, 64_h1=0.1666, 64_l2=0.0619\n",
      "[39] time=2.36, avg_loss=1.7241, train_err=0.0862, 32_h1=0.0866, 32_l2=0.0444, 64_h1=0.1785, 64_l2=0.0640\n",
      "[40] time=2.40, avg_loss=1.6710, train_err=0.0835, 32_h1=0.0855, 32_l2=0.0449, 64_h1=0.1598, 64_l2=0.0536\n",
      "[41] time=2.35, avg_loss=1.6878, train_err=0.0844, 32_h1=0.0884, 32_l2=0.0489, 64_h1=0.1770, 64_l2=0.0690\n",
      "[42] time=2.34, avg_loss=1.6753, train_err=0.0838, 32_h1=0.0846, 32_l2=0.0481, 64_h1=0.1591, 64_l2=0.0588\n",
      "[43] time=2.39, avg_loss=1.6382, train_err=0.0819, 32_h1=0.0861, 32_l2=0.0461, 64_h1=0.1697, 64_l2=0.0584\n",
      "[44] time=2.36, avg_loss=1.6489, train_err=0.0824, 32_h1=0.0837, 32_l2=0.0444, 64_h1=0.1611, 64_l2=0.0595\n",
      "[45] time=2.30, avg_loss=1.6865, train_err=0.0843, 32_h1=0.0834, 32_l2=0.0418, 64_h1=0.1619, 64_l2=0.0533\n",
      "[46] time=2.17, avg_loss=1.6379, train_err=0.0819, 32_h1=0.0837, 32_l2=0.0437, 64_h1=0.1612, 64_l2=0.0538\n",
      "[47] time=2.06, avg_loss=1.6289, train_err=0.0814, 32_h1=0.0821, 32_l2=0.0417, 64_h1=0.1624, 64_l2=0.0593\n",
      "[48] time=2.11, avg_loss=1.6100, train_err=0.0805, 32_h1=0.0844, 32_l2=0.0445, 64_h1=0.1630, 64_l2=0.0558\n",
      "[49] time=2.23, avg_loss=1.6205, train_err=0.0810, 32_h1=0.0821, 32_l2=0.0423, 64_h1=0.1633, 64_l2=0.0562\n",
      "[50] time=2.23, avg_loss=1.6161, train_err=0.0808, 32_h1=0.0900, 32_l2=0.0546, 64_h1=0.1715, 64_l2=0.0632\n",
      "[51] time=2.20, avg_loss=1.7088, train_err=0.0854, 32_h1=0.0878, 32_l2=0.0491, 64_h1=0.1572, 64_l2=0.0571\n",
      "[52] time=2.23, avg_loss=1.5772, train_err=0.0789, 32_h1=0.0825, 32_l2=0.0442, 64_h1=0.1558, 64_l2=0.0536\n",
      "[53] time=2.21, avg_loss=1.6010, train_err=0.0800, 32_h1=0.0810, 32_l2=0.0417, 64_h1=0.1524, 64_l2=0.0539\n",
      "[54] time=2.19, avg_loss=1.5586, train_err=0.0779, 32_h1=0.0782, 32_l2=0.0394, 64_h1=0.1608, 64_l2=0.0574\n",
      "[55] time=2.15, avg_loss=1.5456, train_err=0.0773, 32_h1=0.0802, 32_l2=0.0405, 64_h1=0.1528, 64_l2=0.0546\n",
      "[56] time=2.14, avg_loss=1.6206, train_err=0.0810, 32_h1=0.0816, 32_l2=0.0426, 64_h1=0.1555, 64_l2=0.0543\n",
      "[57] time=2.19, avg_loss=1.5724, train_err=0.0786, 32_h1=0.0800, 32_l2=0.0407, 64_h1=0.1589, 64_l2=0.0587\n",
      "[58] time=2.27, avg_loss=1.5637, train_err=0.0782, 32_h1=0.0801, 32_l2=0.0415, 64_h1=0.1685, 64_l2=0.0614\n",
      "[59] time=2.22, avg_loss=1.5340, train_err=0.0767, 32_h1=0.0799, 32_l2=0.0408, 64_h1=0.1622, 64_l2=0.0571\n",
      "[60] time=2.22, avg_loss=1.5764, train_err=0.0788, 32_h1=0.0812, 32_l2=0.0398, 64_h1=0.1551, 64_l2=0.0530\n",
      "[61] time=2.15, avg_loss=1.5916, train_err=0.0796, 32_h1=0.0821, 32_l2=0.0434, 64_h1=0.1622, 64_l2=0.0559\n",
      "[62] time=2.07, avg_loss=1.5802, train_err=0.0790, 32_h1=0.0807, 32_l2=0.0436, 64_h1=0.1607, 64_l2=0.0555\n",
      "[63] time=2.25, avg_loss=1.5223, train_err=0.0761, 32_h1=0.0822, 32_l2=0.0448, 64_h1=0.1607, 64_l2=0.0633\n",
      "[64] time=2.24, avg_loss=1.5535, train_err=0.0777, 32_h1=0.0843, 32_l2=0.0490, 64_h1=0.1582, 64_l2=0.0599\n",
      "[65] time=2.12, avg_loss=1.5320, train_err=0.0766, 32_h1=0.0988, 32_l2=0.0749, 64_h1=0.1719, 64_l2=0.0838\n",
      "[66] time=2.08, avg_loss=1.5732, train_err=0.0787, 32_h1=0.0803, 32_l2=0.0419, 64_h1=0.1650, 64_l2=0.0611\n",
      "[67] time=2.11, avg_loss=1.4955, train_err=0.0748, 32_h1=0.0791, 32_l2=0.0423, 64_h1=0.1525, 64_l2=0.0560\n",
      "[68] time=2.05, avg_loss=1.5186, train_err=0.0759, 32_h1=0.0772, 32_l2=0.0371, 64_h1=0.1607, 64_l2=0.0522\n",
      "[69] time=2.08, avg_loss=1.4983, train_err=0.0749, 32_h1=0.0784, 32_l2=0.0396, 64_h1=0.1558, 64_l2=0.0513\n",
      "[70] time=2.11, avg_loss=1.5431, train_err=0.0772, 32_h1=0.0801, 32_l2=0.0426, 64_h1=0.1608, 64_l2=0.0594\n",
      "[71] time=2.29, avg_loss=1.5159, train_err=0.0758, 32_h1=0.0784, 32_l2=0.0398, 64_h1=0.1581, 64_l2=0.0486\n",
      "[72] time=2.19, avg_loss=1.4938, train_err=0.0747, 32_h1=0.0806, 32_l2=0.0420, 64_h1=0.1595, 64_l2=0.0584\n",
      "[73] time=2.26, avg_loss=1.4850, train_err=0.0742, 32_h1=0.0802, 32_l2=0.0427, 64_h1=0.1539, 64_l2=0.0552\n",
      "[74] time=2.44, avg_loss=1.4906, train_err=0.0745, 32_h1=0.0824, 32_l2=0.0476, 64_h1=0.1661, 64_l2=0.0626\n",
      "[75] time=2.38, avg_loss=1.4901, train_err=0.0745, 32_h1=0.0789, 32_l2=0.0422, 64_h1=0.1641, 64_l2=0.0581\n",
      "[76] time=2.44, avg_loss=1.4894, train_err=0.0745, 32_h1=0.0751, 32_l2=0.0364, 64_h1=0.1609, 64_l2=0.0497\n",
      "[77] time=2.44, avg_loss=1.4674, train_err=0.0734, 32_h1=0.0779, 32_l2=0.0397, 64_h1=0.1637, 64_l2=0.0552\n",
      "[78] time=2.43, avg_loss=1.5173, train_err=0.0759, 32_h1=0.0768, 32_l2=0.0388, 64_h1=0.1584, 64_l2=0.0556\n",
      "[79] time=2.42, avg_loss=1.5055, train_err=0.0753, 32_h1=0.0793, 32_l2=0.0415, 64_h1=0.1485, 64_l2=0.0510\n",
      "[80] time=2.41, avg_loss=1.4998, train_err=0.0750, 32_h1=0.0753, 32_l2=0.0366, 64_h1=0.1473, 64_l2=0.0490\n",
      "[81] time=2.41, avg_loss=1.4368, train_err=0.0718, 32_h1=0.0823, 32_l2=0.0450, 64_h1=0.1609, 64_l2=0.0585\n",
      "[82] time=2.49, avg_loss=1.4482, train_err=0.0724, 32_h1=0.0780, 32_l2=0.0404, 64_h1=0.1663, 64_l2=0.0576\n",
      "[83] time=2.36, avg_loss=1.4340, train_err=0.0717, 32_h1=0.0776, 32_l2=0.0407, 64_h1=0.1641, 64_l2=0.0598\n",
      "[84] time=2.39, avg_loss=1.4628, train_err=0.0731, 32_h1=0.0752, 32_l2=0.0394, 64_h1=0.1561, 64_l2=0.0541\n",
      "[85] time=2.41, avg_loss=1.4632, train_err=0.0732, 32_h1=0.0768, 32_l2=0.0392, 64_h1=0.1554, 64_l2=0.0513\n",
      "[86] time=2.42, avg_loss=1.4368, train_err=0.0718, 32_h1=0.0755, 32_l2=0.0363, 64_h1=0.1581, 64_l2=0.0524\n",
      "[87] time=2.37, avg_loss=1.4445, train_err=0.0722, 32_h1=0.0761, 32_l2=0.0398, 64_h1=0.1530, 64_l2=0.0530\n",
      "[88] time=2.38, avg_loss=1.4391, train_err=0.0720, 32_h1=0.0787, 32_l2=0.0437, 64_h1=0.1580, 64_l2=0.0598\n",
      "[89] time=2.37, avg_loss=1.4573, train_err=0.0729, 32_h1=0.0743, 32_l2=0.0365, 64_h1=0.1521, 64_l2=0.0528\n",
      "[90] time=2.41, avg_loss=1.4233, train_err=0.0712, 32_h1=0.0739, 32_l2=0.0358, 64_h1=0.1593, 64_l2=0.0536\n",
      "[91] time=2.42, avg_loss=1.4392, train_err=0.0720, 32_h1=0.0750, 32_l2=0.0396, 64_h1=0.1517, 64_l2=0.0550\n",
      "[92] time=2.42, avg_loss=1.4485, train_err=0.0724, 32_h1=0.0778, 32_l2=0.0378, 64_h1=0.1467, 64_l2=0.0510\n",
      "[93] time=2.40, avg_loss=1.4393, train_err=0.0720, 32_h1=0.0802, 32_l2=0.0459, 64_h1=0.1630, 64_l2=0.0586\n",
      "[94] time=2.41, avg_loss=1.4192, train_err=0.0710, 32_h1=0.0771, 32_l2=0.0406, 64_h1=0.1567, 64_l2=0.0550\n",
      "[95] time=2.42, avg_loss=1.4050, train_err=0.0703, 32_h1=0.0733, 32_l2=0.0350, 64_h1=0.1597, 64_l2=0.0504\n",
      "[96] time=2.39, avg_loss=1.4290, train_err=0.0714, 32_h1=0.0784, 32_l2=0.0410, 64_h1=0.1535, 64_l2=0.0551\n",
      "[97] time=2.37, avg_loss=1.3903, train_err=0.0695, 32_h1=0.0729, 32_l2=0.0344, 64_h1=0.1570, 64_l2=0.0535\n",
      "[98] time=2.37, avg_loss=1.3848, train_err=0.0692, 32_h1=0.0740, 32_l2=0.0355, 64_h1=0.1540, 64_l2=0.0491\n",
      "[99] time=2.42, avg_loss=1.4015, train_err=0.0701, 32_h1=0.0761, 32_l2=0.0395, 64_h1=0.1535, 64_l2=0.0532\n",
      "[100] time=2.40, avg_loss=1.3863, train_err=0.0693, 32_h1=0.0758, 32_l2=0.0402, 64_h1=0.1595, 64_l2=0.0542\n",
      "[101] time=2.40, avg_loss=1.3715, train_err=0.0686, 32_h1=0.0763, 32_l2=0.0390, 64_h1=0.1582, 64_l2=0.0512\n",
      "[102] time=2.42, avg_loss=1.4174, train_err=0.0709, 32_h1=0.0733, 32_l2=0.0354, 64_h1=0.1545, 64_l2=0.0525\n",
      "[103] time=2.39, avg_loss=1.3919, train_err=0.0696, 32_h1=0.0745, 32_l2=0.0365, 64_h1=0.1582, 64_l2=0.0526\n",
      "[104] time=2.37, avg_loss=1.3859, train_err=0.0693, 32_h1=0.0736, 32_l2=0.0362, 64_h1=0.1579, 64_l2=0.0552\n",
      "[105] time=2.45, avg_loss=1.4323, train_err=0.0716, 32_h1=0.0778, 32_l2=0.0414, 64_h1=0.1621, 64_l2=0.0564\n",
      "[106] time=2.36, avg_loss=1.3959, train_err=0.0698, 32_h1=0.0742, 32_l2=0.0374, 64_h1=0.1514, 64_l2=0.0525\n",
      "[107] time=2.41, avg_loss=1.3656, train_err=0.0683, 32_h1=0.0760, 32_l2=0.0382, 64_h1=0.1631, 64_l2=0.0584\n",
      "[108] time=2.40, avg_loss=1.3730, train_err=0.0686, 32_h1=0.0772, 32_l2=0.0399, 64_h1=0.1612, 64_l2=0.0560\n",
      "[109] time=2.43, avg_loss=1.3953, train_err=0.0698, 32_h1=0.0729, 32_l2=0.0349, 64_h1=0.1526, 64_l2=0.0505\n",
      "[110] time=2.38, avg_loss=1.3796, train_err=0.0690, 32_h1=0.0763, 32_l2=0.0399, 64_h1=0.1648, 64_l2=0.0582\n",
      "[111] time=2.10, avg_loss=1.3808, train_err=0.0690, 32_h1=0.0747, 32_l2=0.0387, 64_h1=0.1501, 64_l2=0.0479\n",
      "[112] time=2.09, avg_loss=1.3831, train_err=0.0692, 32_h1=0.0721, 32_l2=0.0342, 64_h1=0.1487, 64_l2=0.0501\n",
      "[113] time=2.22, avg_loss=1.3888, train_err=0.0694, 32_h1=0.0736, 32_l2=0.0377, 64_h1=0.1534, 64_l2=0.0510\n",
      "[114] time=2.10, avg_loss=1.3666, train_err=0.0683, 32_h1=0.0774, 32_l2=0.0429, 64_h1=0.1540, 64_l2=0.0526\n",
      "[115] time=2.23, avg_loss=1.3734, train_err=0.0687, 32_h1=0.0724, 32_l2=0.0341, 64_h1=0.1526, 64_l2=0.0487\n",
      "[116] time=2.22, avg_loss=1.3438, train_err=0.0672, 32_h1=0.0754, 32_l2=0.0396, 64_h1=0.1638, 64_l2=0.0576\n",
      "[117] time=2.13, avg_loss=1.3649, train_err=0.0682, 32_h1=0.0791, 32_l2=0.0419, 64_h1=0.1497, 64_l2=0.0496\n",
      "[118] time=2.11, avg_loss=1.3566, train_err=0.0678, 32_h1=0.0715, 32_l2=0.0335, 64_h1=0.1589, 64_l2=0.0506\n",
      "[119] time=2.07, avg_loss=1.3379, train_err=0.0669, 32_h1=0.0736, 32_l2=0.0365, 64_h1=0.1570, 64_l2=0.0548\n",
      "[120] time=2.06, avg_loss=1.3463, train_err=0.0673, 32_h1=0.0733, 32_l2=0.0358, 64_h1=0.1556, 64_l2=0.0568\n",
      "[121] time=2.05, avg_loss=1.3376, train_err=0.0669, 32_h1=0.0737, 32_l2=0.0360, 64_h1=0.1609, 64_l2=0.0533\n",
      "[122] time=2.05, avg_loss=1.3325, train_err=0.0666, 32_h1=0.0738, 32_l2=0.0361, 64_h1=0.1579, 64_l2=0.0483\n",
      "[123] time=2.07, avg_loss=1.3674, train_err=0.0684, 32_h1=0.0739, 32_l2=0.0367, 64_h1=0.1574, 64_l2=0.0534\n",
      "[124] time=2.12, avg_loss=1.3259, train_err=0.0663, 32_h1=0.0720, 32_l2=0.0350, 64_h1=0.1577, 64_l2=0.0533\n",
      "[125] time=2.06, avg_loss=1.3302, train_err=0.0665, 32_h1=0.0723, 32_l2=0.0344, 64_h1=0.1561, 64_l2=0.0491\n",
      "[126] time=2.20, avg_loss=1.3242, train_err=0.0662, 32_h1=0.0736, 32_l2=0.0359, 64_h1=0.1586, 64_l2=0.0557\n",
      "[127] time=2.17, avg_loss=1.3468, train_err=0.0673, 32_h1=0.0735, 32_l2=0.0361, 64_h1=0.1567, 64_l2=0.0528\n",
      "[128] time=2.07, avg_loss=1.3699, train_err=0.0685, 32_h1=0.0757, 32_l2=0.0413, 64_h1=0.1569, 64_l2=0.0610\n",
      "[129] time=2.08, avg_loss=1.3452, train_err=0.0673, 32_h1=0.0738, 32_l2=0.0361, 64_h1=0.1509, 64_l2=0.0533\n",
      "[130] time=2.13, avg_loss=1.3388, train_err=0.0669, 32_h1=0.0720, 32_l2=0.0351, 64_h1=0.1597, 64_l2=0.0520\n",
      "[131] time=2.11, avg_loss=1.3186, train_err=0.0659, 32_h1=0.0734, 32_l2=0.0371, 64_h1=0.1587, 64_l2=0.0546\n",
      "[132] time=2.23, avg_loss=1.3270, train_err=0.0663, 32_h1=0.0716, 32_l2=0.0347, 64_h1=0.1549, 64_l2=0.0497\n",
      "[133] time=2.24, avg_loss=1.3089, train_err=0.0654, 32_h1=0.0760, 32_l2=0.0424, 64_h1=0.1537, 64_l2=0.0550\n",
      "[134] time=2.13, avg_loss=1.3252, train_err=0.0663, 32_h1=0.0716, 32_l2=0.0336, 64_h1=0.1493, 64_l2=0.0476\n",
      "[135] time=2.23, avg_loss=1.3171, train_err=0.0659, 32_h1=0.0707, 32_l2=0.0338, 64_h1=0.1575, 64_l2=0.0499\n",
      "[136] time=2.15, avg_loss=1.3104, train_err=0.0655, 32_h1=0.0717, 32_l2=0.0345, 64_h1=0.1510, 64_l2=0.0522\n",
      "[137] time=2.24, avg_loss=1.3029, train_err=0.0651, 32_h1=0.0705, 32_l2=0.0329, 64_h1=0.1548, 64_l2=0.0501\n",
      "[138] time=2.24, avg_loss=1.3016, train_err=0.0651, 32_h1=0.0735, 32_l2=0.0361, 64_h1=0.1619, 64_l2=0.0573\n",
      "[139] time=2.33, avg_loss=1.3313, train_err=0.0666, 32_h1=0.0711, 32_l2=0.0341, 64_h1=0.1541, 64_l2=0.0515\n",
      "[140] time=2.47, avg_loss=1.3047, train_err=0.0652, 32_h1=0.0724, 32_l2=0.0355, 64_h1=0.1569, 64_l2=0.0533\n",
      "[141] time=2.37, avg_loss=1.2998, train_err=0.0650, 32_h1=0.0761, 32_l2=0.0394, 64_h1=0.1579, 64_l2=0.0573\n",
      "[142] time=2.43, avg_loss=1.3035, train_err=0.0652, 32_h1=0.0730, 32_l2=0.0353, 64_h1=0.1572, 64_l2=0.0500\n",
      "[143] time=2.42, avg_loss=1.3276, train_err=0.0664, 32_h1=0.0824, 32_l2=0.0504, 64_h1=0.1662, 64_l2=0.0668\n",
      "[144] time=2.35, avg_loss=1.3368, train_err=0.0668, 32_h1=0.0737, 32_l2=0.0373, 64_h1=0.1616, 64_l2=0.0562\n",
      "[145] time=2.43, avg_loss=1.2852, train_err=0.0643, 32_h1=0.0702, 32_l2=0.0327, 64_h1=0.1487, 64_l2=0.0478\n",
      "[146] time=2.41, avg_loss=1.2907, train_err=0.0645, 32_h1=0.0741, 32_l2=0.0371, 64_h1=0.1643, 64_l2=0.0554\n",
      "[147] time=2.37, avg_loss=1.2927, train_err=0.0646, 32_h1=0.0702, 32_l2=0.0327, 64_h1=0.1558, 64_l2=0.0508\n",
      "[148] time=2.42, avg_loss=1.2866, train_err=0.0643, 32_h1=0.0730, 32_l2=0.0354, 64_h1=0.1637, 64_l2=0.0553\n",
      "[149] time=2.36, avg_loss=1.2960, train_err=0.0648, 32_h1=0.0716, 32_l2=0.0344, 64_h1=0.1562, 64_l2=0.0541\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.09\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 67649\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f7760c75160>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f7760c759a0>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f7760c759a0>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f7854f93be0>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.42, avg_loss=10.6596, train_err=0.5330, 32_h1=0.2937, 32_l2=0.2000, 64_h1=0.3461, 64_l2=0.2044\n",
      "[1] time=2.37, avg_loss=5.1054, train_err=0.2553, 32_h1=0.2403, 32_l2=0.1754, 64_h1=0.3010, 64_l2=0.1798\n",
      "[2] time=2.34, avg_loss=4.1560, train_err=0.2078, 32_h1=0.1963, 32_l2=0.1385, 64_h1=0.2652, 64_l2=0.1501\n",
      "[3] time=2.42, avg_loss=3.7029, train_err=0.1851, 32_h1=0.1721, 32_l2=0.1140, 64_h1=0.2377, 64_l2=0.1175\n",
      "[4] time=2.41, avg_loss=3.2841, train_err=0.1642, 32_h1=0.1496, 32_l2=0.0952, 64_h1=0.2215, 64_l2=0.1035\n",
      "[5] time=2.34, avg_loss=3.0148, train_err=0.1507, 32_h1=0.1438, 32_l2=0.0925, 64_h1=0.2191, 64_l2=0.1042\n",
      "[6] time=2.38, avg_loss=2.9040, train_err=0.1452, 32_h1=0.1347, 32_l2=0.0852, 64_h1=0.2024, 64_l2=0.0916\n",
      "[7] time=2.41, avg_loss=2.7049, train_err=0.1352, 32_h1=0.1244, 32_l2=0.0749, 64_h1=0.2031, 64_l2=0.0893\n",
      "[8] time=2.40, avg_loss=2.5050, train_err=0.1252, 32_h1=0.1302, 32_l2=0.0824, 64_h1=0.2002, 64_l2=0.0817\n",
      "[9] time=2.40, avg_loss=2.4838, train_err=0.1242, 32_h1=0.1191, 32_l2=0.0687, 64_h1=0.2030, 64_l2=0.0833\n",
      "[10] time=2.36, avg_loss=2.3637, train_err=0.1182, 32_h1=0.1114, 32_l2=0.0630, 64_h1=0.1854, 64_l2=0.0686\n",
      "[11] time=2.35, avg_loss=2.2509, train_err=0.1125, 32_h1=0.1179, 32_l2=0.0737, 64_h1=0.1890, 64_l2=0.0783\n",
      "[12] time=2.38, avg_loss=2.2581, train_err=0.1129, 32_h1=0.1255, 32_l2=0.0878, 64_h1=0.1881, 64_l2=0.0930\n",
      "[13] time=2.36, avg_loss=2.2250, train_err=0.1112, 32_h1=0.1119, 32_l2=0.0648, 64_h1=0.1946, 64_l2=0.0844\n",
      "[14] time=2.41, avg_loss=2.1781, train_err=0.1089, 32_h1=0.1106, 32_l2=0.0661, 64_h1=0.1893, 64_l2=0.0788\n",
      "[15] time=2.35, avg_loss=2.0829, train_err=0.1041, 32_h1=0.1083, 32_l2=0.0643, 64_h1=0.1828, 64_l2=0.0717\n",
      "[16] time=2.41, avg_loss=1.9765, train_err=0.0988, 32_h1=0.1069, 32_l2=0.0645, 64_h1=0.1820, 64_l2=0.0760\n",
      "[17] time=2.39, avg_loss=2.0612, train_err=0.1031, 32_h1=0.0973, 32_l2=0.0532, 64_h1=0.1695, 64_l2=0.0686\n",
      "[18] time=2.34, avg_loss=2.0159, train_err=0.1008, 32_h1=0.0985, 32_l2=0.0551, 64_h1=0.1716, 64_l2=0.0655\n",
      "[19] time=2.42, avg_loss=1.9921, train_err=0.0996, 32_h1=0.0973, 32_l2=0.0555, 64_h1=0.1604, 64_l2=0.0625\n",
      "[20] time=2.37, avg_loss=1.8823, train_err=0.0941, 32_h1=0.0992, 32_l2=0.0578, 64_h1=0.1757, 64_l2=0.0741\n",
      "[21] time=2.38, avg_loss=1.9147, train_err=0.0957, 32_h1=0.1017, 32_l2=0.0580, 64_h1=0.1793, 64_l2=0.0731\n",
      "[22] time=2.41, avg_loss=1.9271, train_err=0.0964, 32_h1=0.1072, 32_l2=0.0699, 64_h1=0.1831, 64_l2=0.0758\n",
      "[23] time=2.37, avg_loss=1.8410, train_err=0.0920, 32_h1=0.0905, 32_l2=0.0497, 64_h1=0.1759, 64_l2=0.0648\n",
      "[24] time=2.35, avg_loss=1.8572, train_err=0.0929, 32_h1=0.0992, 32_l2=0.0579, 64_h1=0.1805, 64_l2=0.0752\n",
      "[25] time=2.42, avg_loss=1.8217, train_err=0.0911, 32_h1=0.1110, 32_l2=0.0730, 64_h1=0.1622, 64_l2=0.0793\n",
      "[26] time=2.35, avg_loss=1.9022, train_err=0.0951, 32_h1=0.0952, 32_l2=0.0560, 64_h1=0.1629, 64_l2=0.0626\n",
      "[27] time=2.22, avg_loss=1.7989, train_err=0.0899, 32_h1=0.0916, 32_l2=0.0487, 64_h1=0.1539, 64_l2=0.0540\n",
      "[28] time=2.16, avg_loss=1.8553, train_err=0.0928, 32_h1=0.0926, 32_l2=0.0536, 64_h1=0.1663, 64_l2=0.0672\n",
      "[29] time=2.25, avg_loss=1.7889, train_err=0.0894, 32_h1=0.0905, 32_l2=0.0466, 64_h1=0.1593, 64_l2=0.0600\n",
      "[30] time=2.16, avg_loss=1.7978, train_err=0.0899, 32_h1=0.0859, 32_l2=0.0439, 64_h1=0.1651, 64_l2=0.0602\n",
      "[31] time=2.24, avg_loss=1.7831, train_err=0.0892, 32_h1=0.0979, 32_l2=0.0569, 64_h1=0.1824, 64_l2=0.0649\n",
      "[32] time=2.08, avg_loss=1.7241, train_err=0.0862, 32_h1=0.0860, 32_l2=0.0424, 64_h1=0.1680, 64_l2=0.0622\n",
      "[33] time=2.10, avg_loss=1.7168, train_err=0.0858, 32_h1=0.0880, 32_l2=0.0474, 64_h1=0.1654, 64_l2=0.0569\n",
      "[34] time=2.14, avg_loss=1.7063, train_err=0.0853, 32_h1=0.0911, 32_l2=0.0534, 64_h1=0.1687, 64_l2=0.0700\n",
      "[35] time=2.23, avg_loss=1.7256, train_err=0.0863, 32_h1=0.0878, 32_l2=0.0473, 64_h1=0.1616, 64_l2=0.0571\n",
      "[36] time=2.21, avg_loss=1.6704, train_err=0.0835, 32_h1=0.0847, 32_l2=0.0433, 64_h1=0.1592, 64_l2=0.0555\n",
      "[37] time=2.22, avg_loss=1.7429, train_err=0.0871, 32_h1=0.0897, 32_l2=0.0494, 64_h1=0.1779, 64_l2=0.0617\n",
      "[38] time=2.28, avg_loss=1.6999, train_err=0.0850, 32_h1=0.0865, 32_l2=0.0479, 64_h1=0.1754, 64_l2=0.0640\n",
      "[39] time=2.14, avg_loss=1.6598, train_err=0.0830, 32_h1=0.0812, 32_l2=0.0394, 64_h1=0.1646, 64_l2=0.0543\n",
      "[40] time=2.20, avg_loss=1.6204, train_err=0.0810, 32_h1=0.0853, 32_l2=0.0468, 64_h1=0.1696, 64_l2=0.0622\n",
      "[41] time=2.18, avg_loss=1.6361, train_err=0.0818, 32_h1=0.0824, 32_l2=0.0418, 64_h1=0.1669, 64_l2=0.0610\n",
      "[42] time=2.12, avg_loss=1.6647, train_err=0.0832, 32_h1=0.0848, 32_l2=0.0450, 64_h1=0.1691, 64_l2=0.0579\n",
      "[43] time=2.13, avg_loss=1.6520, train_err=0.0826, 32_h1=0.0857, 32_l2=0.0463, 64_h1=0.1598, 64_l2=0.0608\n",
      "[44] time=2.15, avg_loss=1.6194, train_err=0.0810, 32_h1=0.0827, 32_l2=0.0423, 64_h1=0.1667, 64_l2=0.0589\n",
      "[45] time=2.08, avg_loss=1.6084, train_err=0.0804, 32_h1=0.0819, 32_l2=0.0413, 64_h1=0.1646, 64_l2=0.0567\n",
      "[46] time=2.13, avg_loss=1.6301, train_err=0.0815, 32_h1=0.0842, 32_l2=0.0447, 64_h1=0.1704, 64_l2=0.0585\n",
      "[47] time=2.17, avg_loss=1.6388, train_err=0.0819, 32_h1=0.0910, 32_l2=0.0569, 64_h1=0.1652, 64_l2=0.0697\n",
      "[48] time=2.05, avg_loss=1.6045, train_err=0.0802, 32_h1=0.0845, 32_l2=0.0459, 64_h1=0.1614, 64_l2=0.0575\n",
      "[49] time=2.06, avg_loss=1.6062, train_err=0.0803, 32_h1=0.0823, 32_l2=0.0428, 64_h1=0.1671, 64_l2=0.0565\n",
      "[50] time=2.11, avg_loss=1.6503, train_err=0.0825, 32_h1=0.0899, 32_l2=0.0507, 64_h1=0.1667, 64_l2=0.0621\n",
      "[51] time=2.17, avg_loss=1.6220, train_err=0.0811, 32_h1=0.0822, 32_l2=0.0416, 64_h1=0.1702, 64_l2=0.0618\n",
      "[52] time=2.08, avg_loss=1.5669, train_err=0.0783, 32_h1=0.0815, 32_l2=0.0432, 64_h1=0.1668, 64_l2=0.0567\n",
      "[53] time=2.17, avg_loss=1.5657, train_err=0.0783, 32_h1=0.0861, 32_l2=0.0558, 64_h1=0.1696, 64_l2=0.0664\n",
      "[54] time=2.20, avg_loss=1.5965, train_err=0.0798, 32_h1=0.0859, 32_l2=0.0530, 64_h1=0.1723, 64_l2=0.0633\n",
      "[55] time=2.23, avg_loss=1.5839, train_err=0.0792, 32_h1=0.0785, 32_l2=0.0383, 64_h1=0.1659, 64_l2=0.0539\n",
      "[56] time=2.46, avg_loss=1.5531, train_err=0.0777, 32_h1=0.0835, 32_l2=0.0464, 64_h1=0.1643, 64_l2=0.0614\n",
      "[57] time=2.38, avg_loss=1.5593, train_err=0.0780, 32_h1=0.0868, 32_l2=0.0552, 64_h1=0.1705, 64_l2=0.0654\n",
      "[58] time=2.37, avg_loss=1.5237, train_err=0.0762, 32_h1=0.0795, 32_l2=0.0416, 64_h1=0.1666, 64_l2=0.0608\n",
      "[59] time=2.36, avg_loss=1.5936, train_err=0.0797, 32_h1=0.0809, 32_l2=0.0415, 64_h1=0.1591, 64_l2=0.0577\n",
      "[60] time=2.38, avg_loss=1.5510, train_err=0.0776, 32_h1=0.0780, 32_l2=0.0390, 64_h1=0.1651, 64_l2=0.0541\n",
      "[61] time=2.35, avg_loss=1.5442, train_err=0.0772, 32_h1=0.0819, 32_l2=0.0446, 64_h1=0.1734, 64_l2=0.0582\n",
      "[62] time=2.46, avg_loss=1.5788, train_err=0.0789, 32_h1=0.0818, 32_l2=0.0440, 64_h1=0.1673, 64_l2=0.0584\n",
      "[63] time=2.38, avg_loss=1.5105, train_err=0.0755, 32_h1=0.0784, 32_l2=0.0396, 64_h1=0.1695, 64_l2=0.0548\n",
      "[64] time=2.34, avg_loss=1.5048, train_err=0.0752, 32_h1=0.0767, 32_l2=0.0368, 64_h1=0.1647, 64_l2=0.0554\n",
      "[65] time=2.35, avg_loss=1.5230, train_err=0.0761, 32_h1=0.0797, 32_l2=0.0433, 64_h1=0.1697, 64_l2=0.0602\n",
      "[66] time=2.34, avg_loss=1.5166, train_err=0.0758, 32_h1=0.0773, 32_l2=0.0387, 64_h1=0.1596, 64_l2=0.0530\n",
      "[67] time=2.38, avg_loss=1.5100, train_err=0.0755, 32_h1=0.0785, 32_l2=0.0397, 64_h1=0.1642, 64_l2=0.0532\n",
      "[68] time=2.37, avg_loss=1.5147, train_err=0.0757, 32_h1=0.0766, 32_l2=0.0375, 64_h1=0.1621, 64_l2=0.0503\n",
      "[69] time=2.32, avg_loss=1.4971, train_err=0.0749, 32_h1=0.0805, 32_l2=0.0447, 64_h1=0.1630, 64_l2=0.0558\n",
      "[70] time=2.36, avg_loss=1.5014, train_err=0.0751, 32_h1=0.0799, 32_l2=0.0413, 64_h1=0.1566, 64_l2=0.0528\n",
      "[71] time=2.37, avg_loss=1.4905, train_err=0.0745, 32_h1=0.0796, 32_l2=0.0415, 64_h1=0.1591, 64_l2=0.0554\n",
      "[72] time=2.36, avg_loss=1.5595, train_err=0.0780, 32_h1=0.0803, 32_l2=0.0448, 64_h1=0.1578, 64_l2=0.0596\n",
      "[73] time=2.36, avg_loss=1.4843, train_err=0.0742, 32_h1=0.0775, 32_l2=0.0397, 64_h1=0.1563, 64_l2=0.0495\n",
      "[74] time=2.40, avg_loss=1.4644, train_err=0.0732, 32_h1=0.0785, 32_l2=0.0412, 64_h1=0.1609, 64_l2=0.0574\n",
      "[75] time=2.31, avg_loss=1.4927, train_err=0.0746, 32_h1=0.0780, 32_l2=0.0406, 64_h1=0.1640, 64_l2=0.0576\n",
      "[76] time=2.37, avg_loss=1.4570, train_err=0.0728, 32_h1=0.0755, 32_l2=0.0360, 64_h1=0.1621, 64_l2=0.0536\n",
      "[77] time=2.40, avg_loss=1.4692, train_err=0.0735, 32_h1=0.0761, 32_l2=0.0376, 64_h1=0.1602, 64_l2=0.0532\n",
      "[78] time=2.42, avg_loss=1.4852, train_err=0.0743, 32_h1=0.0833, 32_l2=0.0469, 64_h1=0.1661, 64_l2=0.0633\n",
      "[79] time=2.39, avg_loss=1.5000, train_err=0.0750, 32_h1=0.0760, 32_l2=0.0374, 64_h1=0.1657, 64_l2=0.0544\n",
      "[80] time=2.40, avg_loss=1.4790, train_err=0.0739, 32_h1=0.0793, 32_l2=0.0465, 64_h1=0.1638, 64_l2=0.0661\n",
      "[81] time=2.37, avg_loss=1.4966, train_err=0.0748, 32_h1=0.0755, 32_l2=0.0377, 64_h1=0.1605, 64_l2=0.0553\n",
      "[82] time=2.41, avg_loss=1.4509, train_err=0.0725, 32_h1=0.0781, 32_l2=0.0399, 64_h1=0.1636, 64_l2=0.0615\n",
      "[83] time=2.37, avg_loss=1.5025, train_err=0.0751, 32_h1=0.0784, 32_l2=0.0405, 64_h1=0.1630, 64_l2=0.0610\n",
      "[84] time=2.36, avg_loss=1.4393, train_err=0.0720, 32_h1=0.0761, 32_l2=0.0383, 64_h1=0.1595, 64_l2=0.0521\n",
      "[85] time=2.47, avg_loss=1.4344, train_err=0.0717, 32_h1=0.0746, 32_l2=0.0357, 64_h1=0.1643, 64_l2=0.0539\n",
      "[86] time=2.36, avg_loss=1.4142, train_err=0.0707, 32_h1=0.0762, 32_l2=0.0398, 64_h1=0.1635, 64_l2=0.0533\n",
      "[87] time=2.36, avg_loss=1.4479, train_err=0.0724, 32_h1=0.0756, 32_l2=0.0373, 64_h1=0.1608, 64_l2=0.0514\n",
      "[88] time=2.35, avg_loss=1.4383, train_err=0.0719, 32_h1=0.0822, 32_l2=0.0467, 64_h1=0.1693, 64_l2=0.0607\n",
      "[89] time=2.40, avg_loss=1.4431, train_err=0.0722, 32_h1=0.0753, 32_l2=0.0369, 64_h1=0.1582, 64_l2=0.0517\n",
      "[90] time=2.38, avg_loss=1.4394, train_err=0.0720, 32_h1=0.0861, 32_l2=0.0506, 64_h1=0.1701, 64_l2=0.0603\n",
      "[91] time=2.38, avg_loss=1.4447, train_err=0.0722, 32_h1=0.0736, 32_l2=0.0348, 64_h1=0.1588, 64_l2=0.0510\n",
      "[92] time=2.37, avg_loss=1.4179, train_err=0.0709, 32_h1=0.0756, 32_l2=0.0387, 64_h1=0.1640, 64_l2=0.0538\n",
      "[93] time=2.32, avg_loss=1.4606, train_err=0.0730, 32_h1=0.0738, 32_l2=0.0348, 64_h1=0.1635, 64_l2=0.0504\n",
      "[94] time=2.12, avg_loss=1.4073, train_err=0.0704, 32_h1=0.0747, 32_l2=0.0382, 64_h1=0.1626, 64_l2=0.0550\n",
      "[95] time=2.15, avg_loss=1.3919, train_err=0.0696, 32_h1=0.0764, 32_l2=0.0383, 64_h1=0.1659, 64_l2=0.0548\n",
      "[96] time=2.26, avg_loss=1.4282, train_err=0.0714, 32_h1=0.0784, 32_l2=0.0419, 64_h1=0.1723, 64_l2=0.0590\n",
      "[97] time=2.25, avg_loss=1.4280, train_err=0.0714, 32_h1=0.0735, 32_l2=0.0357, 64_h1=0.1596, 64_l2=0.0512\n",
      "[98] time=2.13, avg_loss=1.3984, train_err=0.0699, 32_h1=0.0765, 32_l2=0.0381, 64_h1=0.1665, 64_l2=0.0554\n",
      "[99] time=2.04, avg_loss=1.4410, train_err=0.0720, 32_h1=0.0745, 32_l2=0.0372, 64_h1=0.1565, 64_l2=0.0509\n",
      "[100] time=2.10, avg_loss=1.4172, train_err=0.0709, 32_h1=0.0787, 32_l2=0.0460, 64_h1=0.1677, 64_l2=0.0628\n",
      "[101] time=2.22, avg_loss=1.4072, train_err=0.0704, 32_h1=0.0739, 32_l2=0.0358, 64_h1=0.1640, 64_l2=0.0539\n",
      "[102] time=2.20, avg_loss=1.4196, train_err=0.0710, 32_h1=0.0746, 32_l2=0.0353, 64_h1=0.1620, 64_l2=0.0545\n",
      "[103] time=2.09, avg_loss=1.3972, train_err=0.0699, 32_h1=0.0755, 32_l2=0.0397, 64_h1=0.1582, 64_l2=0.0554\n",
      "[104] time=2.10, avg_loss=1.4286, train_err=0.0714, 32_h1=0.0751, 32_l2=0.0384, 64_h1=0.1604, 64_l2=0.0579\n",
      "[105] time=2.19, avg_loss=1.4099, train_err=0.0705, 32_h1=0.0745, 32_l2=0.0372, 64_h1=0.1577, 64_l2=0.0540\n",
      "[106] time=2.20, avg_loss=1.3825, train_err=0.0691, 32_h1=0.0729, 32_l2=0.0361, 64_h1=0.1654, 64_l2=0.0498\n",
      "[107] time=2.24, avg_loss=1.3762, train_err=0.0688, 32_h1=0.0792, 32_l2=0.0466, 64_h1=0.1605, 64_l2=0.0559\n",
      "[108] time=2.18, avg_loss=1.3778, train_err=0.0689, 32_h1=0.0776, 32_l2=0.0403, 64_h1=0.1645, 64_l2=0.0574\n",
      "[109] time=2.38, avg_loss=1.3820, train_err=0.0691, 32_h1=0.0742, 32_l2=0.0360, 64_h1=0.1584, 64_l2=0.0525\n",
      "[110] time=2.16, avg_loss=1.3744, train_err=0.0687, 32_h1=0.0741, 32_l2=0.0357, 64_h1=0.1536, 64_l2=0.0488\n",
      "[111] time=2.27, avg_loss=1.3914, train_err=0.0696, 32_h1=0.0740, 32_l2=0.0378, 64_h1=0.1658, 64_l2=0.0582\n",
      "[112] time=2.20, avg_loss=1.3753, train_err=0.0688, 32_h1=0.0742, 32_l2=0.0362, 64_h1=0.1606, 64_l2=0.0517\n",
      "[113] time=2.07, avg_loss=1.3687, train_err=0.0684, 32_h1=0.0742, 32_l2=0.0363, 64_h1=0.1603, 64_l2=0.0536\n",
      "[114] time=2.04, avg_loss=1.3693, train_err=0.0685, 32_h1=0.0743, 32_l2=0.0364, 64_h1=0.1586, 64_l2=0.0519\n",
      "[115] time=2.06, avg_loss=1.3837, train_err=0.0692, 32_h1=0.0732, 32_l2=0.0353, 64_h1=0.1624, 64_l2=0.0557\n",
      "[116] time=2.04, avg_loss=1.3977, train_err=0.0699, 32_h1=0.0725, 32_l2=0.0347, 64_h1=0.1596, 64_l2=0.0506\n",
      "[117] time=2.05, avg_loss=1.3677, train_err=0.0684, 32_h1=0.0720, 32_l2=0.0342, 64_h1=0.1621, 64_l2=0.0528\n",
      "[118] time=2.10, avg_loss=1.3541, train_err=0.0677, 32_h1=0.0739, 32_l2=0.0381, 64_h1=0.1646, 64_l2=0.0556\n",
      "[119] time=2.07, avg_loss=1.3619, train_err=0.0681, 32_h1=0.0723, 32_l2=0.0343, 64_h1=0.1582, 64_l2=0.0530\n",
      "[120] time=2.13, avg_loss=1.3684, train_err=0.0684, 32_h1=0.0757, 32_l2=0.0386, 64_h1=0.1613, 64_l2=0.0561\n",
      "[121] time=2.23, avg_loss=1.3702, train_err=0.0685, 32_h1=0.0746, 32_l2=0.0384, 64_h1=0.1641, 64_l2=0.0617\n",
      "[122] time=2.35, avg_loss=1.3645, train_err=0.0682, 32_h1=0.0724, 32_l2=0.0349, 64_h1=0.1634, 64_l2=0.0540\n",
      "[123] time=2.34, avg_loss=1.3435, train_err=0.0672, 32_h1=0.0735, 32_l2=0.0355, 64_h1=0.1504, 64_l2=0.0472\n",
      "[124] time=2.36, avg_loss=1.3447, train_err=0.0672, 32_h1=0.0798, 32_l2=0.0477, 64_h1=0.1692, 64_l2=0.0549\n",
      "[125] time=2.35, avg_loss=1.3575, train_err=0.0679, 32_h1=0.0737, 32_l2=0.0364, 64_h1=0.1625, 64_l2=0.0559\n",
      "[126] time=2.35, avg_loss=1.3531, train_err=0.0677, 32_h1=0.0730, 32_l2=0.0365, 64_h1=0.1592, 64_l2=0.0515\n",
      "[127] time=2.37, avg_loss=1.3404, train_err=0.0670, 32_h1=0.0724, 32_l2=0.0351, 64_h1=0.1592, 64_l2=0.0495\n",
      "[128] time=2.34, avg_loss=1.3348, train_err=0.0667, 32_h1=0.0787, 32_l2=0.0433, 64_h1=0.1697, 64_l2=0.0571\n",
      "[129] time=2.35, avg_loss=1.3368, train_err=0.0668, 32_h1=0.0727, 32_l2=0.0352, 64_h1=0.1643, 64_l2=0.0558\n",
      "[130] time=2.43, avg_loss=1.3279, train_err=0.0664, 32_h1=0.0718, 32_l2=0.0339, 64_h1=0.1591, 64_l2=0.0519\n",
      "[131] time=2.37, avg_loss=1.3251, train_err=0.0663, 32_h1=0.0743, 32_l2=0.0380, 64_h1=0.1604, 64_l2=0.0557\n",
      "[132] time=2.35, avg_loss=1.3525, train_err=0.0676, 32_h1=0.0732, 32_l2=0.0356, 64_h1=0.1621, 64_l2=0.0541\n",
      "[133] time=2.42, avg_loss=1.3323, train_err=0.0666, 32_h1=0.0818, 32_l2=0.0536, 64_h1=0.1628, 64_l2=0.0688\n",
      "[134] time=2.38, avg_loss=1.3573, train_err=0.0679, 32_h1=0.0731, 32_l2=0.0357, 64_h1=0.1652, 64_l2=0.0509\n",
      "[135] time=2.36, avg_loss=1.3242, train_err=0.0662, 32_h1=0.0719, 32_l2=0.0347, 64_h1=0.1590, 64_l2=0.0532\n",
      "[136] time=2.39, avg_loss=1.3163, train_err=0.0658, 32_h1=0.0711, 32_l2=0.0334, 64_h1=0.1632, 64_l2=0.0525\n",
      "[137] time=2.35, avg_loss=1.3115, train_err=0.0656, 32_h1=0.0738, 32_l2=0.0381, 64_h1=0.1562, 64_l2=0.0534\n",
      "[138] time=2.33, avg_loss=1.3258, train_err=0.0663, 32_h1=0.0727, 32_l2=0.0378, 64_h1=0.1550, 64_l2=0.0526\n",
      "[139] time=2.38, avg_loss=1.3174, train_err=0.0659, 32_h1=0.0718, 32_l2=0.0342, 64_h1=0.1610, 64_l2=0.0503\n",
      "[140] time=2.36, avg_loss=1.3433, train_err=0.0672, 32_h1=0.0732, 32_l2=0.0363, 64_h1=0.1583, 64_l2=0.0545\n",
      "[141] time=2.32, avg_loss=1.3205, train_err=0.0660, 32_h1=0.0715, 32_l2=0.0340, 64_h1=0.1607, 64_l2=0.0492\n",
      "[142] time=2.35, avg_loss=1.3256, train_err=0.0663, 32_h1=0.0720, 32_l2=0.0349, 64_h1=0.1618, 64_l2=0.0513\n",
      "[143] time=2.35, avg_loss=1.3139, train_err=0.0657, 32_h1=0.0712, 32_l2=0.0335, 64_h1=0.1638, 64_l2=0.0555\n",
      "[144] time=2.43, avg_loss=1.2932, train_err=0.0647, 32_h1=0.0709, 32_l2=0.0331, 64_h1=0.1637, 64_l2=0.0529\n",
      "[145] time=2.39, avg_loss=1.3042, train_err=0.0652, 32_h1=0.0725, 32_l2=0.0345, 64_h1=0.1646, 64_l2=0.0524\n",
      "[146] time=2.33, avg_loss=1.3057, train_err=0.0653, 32_h1=0.0720, 32_l2=0.0339, 64_h1=0.1540, 64_l2=0.0489\n",
      "[147] time=2.35, avg_loss=1.3020, train_err=0.0651, 32_h1=0.0712, 32_l2=0.0339, 64_h1=0.1615, 64_l2=0.0536\n",
      "[148] time=2.37, avg_loss=1.3125, train_err=0.0656, 32_h1=0.0712, 32_l2=0.0338, 64_h1=0.1587, 64_l2=0.0504\n",
      "[149] time=2.38, avg_loss=1.2801, train_err=0.0640, 32_h1=0.0711, 32_l2=0.0337, 64_h1=0.1612, 64_l2=0.0534\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.09999999999999999\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 67649\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f7761b37fd0>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f776fe01c10>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f776fe01c10>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f787f0a37c0>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.36, avg_loss=11.2643, train_err=0.5632, 32_h1=0.3678, 32_l2=0.2522, 64_h1=0.4261, 64_l2=0.2556\n",
      "[1] time=2.38, avg_loss=5.7927, train_err=0.2896, 32_h1=0.2484, 32_l2=0.1662, 64_h1=0.3153, 64_l2=0.1729\n",
      "[2] time=2.37, avg_loss=4.1545, train_err=0.2077, 32_h1=0.2040, 32_l2=0.1405, 64_h1=0.2628, 64_l2=0.1420\n",
      "[3] time=2.39, avg_loss=3.5571, train_err=0.1779, 32_h1=0.1652, 32_l2=0.1036, 64_h1=0.2305, 64_l2=0.1145\n",
      "[4] time=2.35, avg_loss=3.1385, train_err=0.1569, 32_h1=0.1493, 32_l2=0.0894, 64_h1=0.2137, 64_l2=0.0916\n",
      "[5] time=2.35, avg_loss=2.8997, train_err=0.1450, 32_h1=0.1390, 32_l2=0.0832, 64_h1=0.2112, 64_l2=0.0981\n",
      "[6] time=2.43, avg_loss=2.6793, train_err=0.1340, 32_h1=0.1307, 32_l2=0.0783, 64_h1=0.2097, 64_l2=0.0924\n",
      "[7] time=2.36, avg_loss=2.5927, train_err=0.1296, 32_h1=0.1261, 32_l2=0.0733, 64_h1=0.1965, 64_l2=0.0876\n",
      "[8] time=2.36, avg_loss=2.3762, train_err=0.1188, 32_h1=0.1163, 32_l2=0.0704, 64_h1=0.1896, 64_l2=0.0845\n",
      "[9] time=2.38, avg_loss=2.3073, train_err=0.1154, 32_h1=0.1145, 32_l2=0.0673, 64_h1=0.1901, 64_l2=0.0753\n",
      "[10] time=2.35, avg_loss=2.1779, train_err=0.1089, 32_h1=0.1071, 32_l2=0.0627, 64_h1=0.1883, 64_l2=0.0769\n",
      "[11] time=2.16, avg_loss=2.0872, train_err=0.1044, 32_h1=0.1038, 32_l2=0.0573, 64_h1=0.1842, 64_l2=0.0742\n",
      "[12] time=2.20, avg_loss=2.1026, train_err=0.1051, 32_h1=0.1040, 32_l2=0.0606, 64_h1=0.1727, 64_l2=0.0675\n",
      "[13] time=2.19, avg_loss=2.0603, train_err=0.1030, 32_h1=0.0982, 32_l2=0.0534, 64_h1=0.1823, 64_l2=0.0718\n",
      "[14] time=2.22, avg_loss=1.9741, train_err=0.0987, 32_h1=0.1017, 32_l2=0.0575, 64_h1=0.1748, 64_l2=0.0697\n",
      "[15] time=2.22, avg_loss=1.9953, train_err=0.0998, 32_h1=0.0981, 32_l2=0.0529, 64_h1=0.1730, 64_l2=0.0624\n",
      "[16] time=2.22, avg_loss=2.0003, train_err=0.1000, 32_h1=0.0955, 32_l2=0.0515, 64_h1=0.1649, 64_l2=0.0615\n",
      "[17] time=2.21, avg_loss=1.9481, train_err=0.0974, 32_h1=0.0975, 32_l2=0.0586, 64_h1=0.1713, 64_l2=0.0678\n",
      "[18] time=2.26, avg_loss=1.9082, train_err=0.0954, 32_h1=0.0893, 32_l2=0.0459, 64_h1=0.1700, 64_l2=0.0616\n",
      "[19] time=2.16, avg_loss=1.8371, train_err=0.0919, 32_h1=0.0930, 32_l2=0.0508, 64_h1=0.1659, 64_l2=0.0628\n",
      "[20] time=2.12, avg_loss=1.7944, train_err=0.0897, 32_h1=0.0960, 32_l2=0.0596, 64_h1=0.1544, 64_l2=0.0661\n",
      "[21] time=2.09, avg_loss=1.7936, train_err=0.0897, 32_h1=0.0932, 32_l2=0.0527, 64_h1=0.1731, 64_l2=0.0660\n",
      "[22] time=2.09, avg_loss=1.7522, train_err=0.0876, 32_h1=0.0877, 32_l2=0.0471, 64_h1=0.1694, 64_l2=0.0627\n",
      "[23] time=2.16, avg_loss=1.7387, train_err=0.0869, 32_h1=0.0914, 32_l2=0.0503, 64_h1=0.1664, 64_l2=0.0612\n",
      "[24] time=2.08, avg_loss=1.7318, train_err=0.0866, 32_h1=0.0877, 32_l2=0.0473, 64_h1=0.1707, 64_l2=0.0667\n",
      "[25] time=2.18, avg_loss=1.7096, train_err=0.0855, 32_h1=0.0891, 32_l2=0.0535, 64_h1=0.1592, 64_l2=0.0630\n",
      "[26] time=2.22, avg_loss=1.7145, train_err=0.0857, 32_h1=0.0839, 32_l2=0.0431, 64_h1=0.1697, 64_l2=0.0627\n",
      "[27] time=2.10, avg_loss=1.7595, train_err=0.0880, 32_h1=0.0899, 32_l2=0.0470, 64_h1=0.1785, 64_l2=0.0626\n",
      "[28] time=2.09, avg_loss=1.7103, train_err=0.0855, 32_h1=0.0879, 32_l2=0.0488, 64_h1=0.1653, 64_l2=0.0639\n",
      "[29] time=2.16, avg_loss=1.6505, train_err=0.0825, 32_h1=0.0934, 32_l2=0.0561, 64_h1=0.1608, 64_l2=0.0603\n",
      "[30] time=2.21, avg_loss=1.6629, train_err=0.0831, 32_h1=0.0856, 32_l2=0.0465, 64_h1=0.1680, 64_l2=0.0611\n",
      "[31] time=2.09, avg_loss=1.6338, train_err=0.0817, 32_h1=0.0882, 32_l2=0.0544, 64_h1=0.1732, 64_l2=0.0676\n",
      "[32] time=2.09, avg_loss=1.7076, train_err=0.0854, 32_h1=0.0819, 32_l2=0.0401, 64_h1=0.1587, 64_l2=0.0555\n",
      "[33] time=2.21, avg_loss=1.6529, train_err=0.0826, 32_h1=0.0838, 32_l2=0.0489, 64_h1=0.1601, 64_l2=0.0588\n",
      "[34] time=2.19, avg_loss=1.6238, train_err=0.0812, 32_h1=0.0854, 32_l2=0.0487, 64_h1=0.1637, 64_l2=0.0621\n",
      "[35] time=2.07, avg_loss=1.5690, train_err=0.0785, 32_h1=0.0789, 32_l2=0.0392, 64_h1=0.1610, 64_l2=0.0583\n",
      "[36] time=2.05, avg_loss=1.6469, train_err=0.0823, 32_h1=0.0832, 32_l2=0.0461, 64_h1=0.1681, 64_l2=0.0590\n",
      "[37] time=2.06, avg_loss=1.5971, train_err=0.0799, 32_h1=0.0817, 32_l2=0.0420, 64_h1=0.1584, 64_l2=0.0548\n",
      "[38] time=2.06, avg_loss=1.5602, train_err=0.0780, 32_h1=0.0848, 32_l2=0.0442, 64_h1=0.1615, 64_l2=0.0592\n",
      "[39] time=2.04, avg_loss=1.6192, train_err=0.0810, 32_h1=0.0820, 32_l2=0.0428, 64_h1=0.1612, 64_l2=0.0606\n",
      "[40] time=2.26, avg_loss=1.5944, train_err=0.0797, 32_h1=0.0851, 32_l2=0.0465, 64_h1=0.1624, 64_l2=0.0583\n",
      "[41] time=2.38, avg_loss=1.5906, train_err=0.0795, 32_h1=0.0878, 32_l2=0.0545, 64_h1=0.1663, 64_l2=0.0632\n",
      "[42] time=2.36, avg_loss=1.5551, train_err=0.0778, 32_h1=0.0848, 32_l2=0.0474, 64_h1=0.1712, 64_l2=0.0642\n",
      "[43] time=2.36, avg_loss=1.5526, train_err=0.0776, 32_h1=0.0787, 32_l2=0.0389, 64_h1=0.1602, 64_l2=0.0492\n",
      "[44] time=2.34, avg_loss=1.5740, train_err=0.0787, 32_h1=0.0842, 32_l2=0.0454, 64_h1=0.1618, 64_l2=0.0568\n",
      "[45] time=2.37, avg_loss=1.5640, train_err=0.0782, 32_h1=0.0823, 32_l2=0.0463, 64_h1=0.1569, 64_l2=0.0541\n",
      "[46] time=2.32, avg_loss=1.5371, train_err=0.0769, 32_h1=0.0800, 32_l2=0.0420, 64_h1=0.1625, 64_l2=0.0608\n",
      "[47] time=2.36, avg_loss=1.6177, train_err=0.0809, 32_h1=0.0903, 32_l2=0.0574, 64_h1=0.1642, 64_l2=0.0650\n",
      "[48] time=2.34, avg_loss=1.5763, train_err=0.0788, 32_h1=0.0813, 32_l2=0.0424, 64_h1=0.1596, 64_l2=0.0531\n",
      "[49] time=2.38, avg_loss=1.5615, train_err=0.0781, 32_h1=0.0848, 32_l2=0.0491, 64_h1=0.1670, 64_l2=0.0586\n",
      "[50] time=2.42, avg_loss=1.5294, train_err=0.0765, 32_h1=0.0848, 32_l2=0.0519, 64_h1=0.1707, 64_l2=0.0619\n",
      "[51] time=2.39, avg_loss=1.5207, train_err=0.0760, 32_h1=0.0762, 32_l2=0.0385, 64_h1=0.1581, 64_l2=0.0574\n",
      "[52] time=2.39, avg_loss=1.5093, train_err=0.0755, 32_h1=0.0795, 32_l2=0.0408, 64_h1=0.1624, 64_l2=0.0545\n",
      "[53] time=2.35, avg_loss=1.5433, train_err=0.0772, 32_h1=0.0866, 32_l2=0.0529, 64_h1=0.1684, 64_l2=0.0594\n",
      "[54] time=2.51, avg_loss=1.5385, train_err=0.0769, 32_h1=0.0768, 32_l2=0.0375, 64_h1=0.1604, 64_l2=0.0522\n",
      "[55] time=2.36, avg_loss=1.5141, train_err=0.0757, 32_h1=0.0831, 32_l2=0.0492, 64_h1=0.1549, 64_l2=0.0556\n",
      "[56] time=2.31, avg_loss=1.4947, train_err=0.0747, 32_h1=0.0767, 32_l2=0.0412, 64_h1=0.1570, 64_l2=0.0558\n",
      "[57] time=2.41, avg_loss=1.4938, train_err=0.0747, 32_h1=0.0773, 32_l2=0.0393, 64_h1=0.1580, 64_l2=0.0495\n",
      "[58] time=2.37, avg_loss=1.5351, train_err=0.0768, 32_h1=0.0819, 32_l2=0.0456, 64_h1=0.1656, 64_l2=0.0529\n",
      "[59] time=2.38, avg_loss=1.4722, train_err=0.0736, 32_h1=0.0794, 32_l2=0.0413, 64_h1=0.1601, 64_l2=0.0570\n",
      "[60] time=2.37, avg_loss=1.4936, train_err=0.0747, 32_h1=0.0786, 32_l2=0.0394, 64_h1=0.1506, 64_l2=0.0501\n",
      "[61] time=2.34, avg_loss=1.4962, train_err=0.0748, 32_h1=0.0847, 32_l2=0.0541, 64_h1=0.1651, 64_l2=0.0609\n",
      "[62] time=2.37, avg_loss=1.5251, train_err=0.0763, 32_h1=0.0770, 32_l2=0.0383, 64_h1=0.1491, 64_l2=0.0439\n",
      "[63] time=2.32, avg_loss=1.4730, train_err=0.0737, 32_h1=0.0772, 32_l2=0.0425, 64_h1=0.1635, 64_l2=0.0557\n",
      "[64] time=2.36, avg_loss=1.4542, train_err=0.0727, 32_h1=0.0798, 32_l2=0.0431, 64_h1=0.1591, 64_l2=0.0552\n",
      "[65] time=2.36, avg_loss=1.4651, train_err=0.0733, 32_h1=0.0749, 32_l2=0.0364, 64_h1=0.1613, 64_l2=0.0539\n",
      "[66] time=2.39, avg_loss=1.4604, train_err=0.0730, 32_h1=0.0751, 32_l2=0.0365, 64_h1=0.1565, 64_l2=0.0516\n",
      "[67] time=2.37, avg_loss=1.4576, train_err=0.0729, 32_h1=0.0787, 32_l2=0.0432, 64_h1=0.1627, 64_l2=0.0567\n",
      "[68] time=2.38, avg_loss=1.4446, train_err=0.0722, 32_h1=0.0768, 32_l2=0.0388, 64_h1=0.1582, 64_l2=0.0553\n",
      "[69] time=2.36, avg_loss=1.4574, train_err=0.0729, 32_h1=0.0798, 32_l2=0.0427, 64_h1=0.1573, 64_l2=0.0554\n",
      "[70] time=2.39, avg_loss=1.4496, train_err=0.0725, 32_h1=0.0751, 32_l2=0.0378, 64_h1=0.1616, 64_l2=0.0532\n",
      "[71] time=2.37, avg_loss=1.4296, train_err=0.0715, 32_h1=0.0772, 32_l2=0.0391, 64_h1=0.1629, 64_l2=0.0537\n",
      "[72] time=2.39, avg_loss=1.4531, train_err=0.0727, 32_h1=0.0780, 32_l2=0.0408, 64_h1=0.1572, 64_l2=0.0529\n",
      "[73] time=2.35, avg_loss=1.4532, train_err=0.0727, 32_h1=0.0768, 32_l2=0.0398, 64_h1=0.1534, 64_l2=0.0485\n",
      "[74] time=2.37, avg_loss=1.4544, train_err=0.0727, 32_h1=0.0819, 32_l2=0.0464, 64_h1=0.1686, 64_l2=0.0636\n",
      "[75] time=2.31, avg_loss=1.4557, train_err=0.0728, 32_h1=0.0754, 32_l2=0.0364, 64_h1=0.1575, 64_l2=0.0501\n",
      "[76] time=2.35, avg_loss=1.4335, train_err=0.0717, 32_h1=0.0765, 32_l2=0.0386, 64_h1=0.1576, 64_l2=0.0523\n",
      "[77] time=2.43, avg_loss=1.4311, train_err=0.0716, 32_h1=0.0766, 32_l2=0.0385, 64_h1=0.1599, 64_l2=0.0529\n",
      "[78] time=2.52, avg_loss=1.4160, train_err=0.0708, 32_h1=0.0730, 32_l2=0.0340, 64_h1=0.1618, 64_l2=0.0505\n",
      "[79] time=2.29, avg_loss=1.4270, train_err=0.0713, 32_h1=0.0738, 32_l2=0.0354, 64_h1=0.1583, 64_l2=0.0537\n",
      "[80] time=2.08, avg_loss=1.4442, train_err=0.0722, 32_h1=0.0733, 32_l2=0.0354, 64_h1=0.1609, 64_l2=0.0532\n",
      "[81] time=2.18, avg_loss=1.4223, train_err=0.0711, 32_h1=0.0750, 32_l2=0.0367, 64_h1=0.1600, 64_l2=0.0491\n",
      "[82] time=2.08, avg_loss=1.4229, train_err=0.0711, 32_h1=0.0743, 32_l2=0.0361, 64_h1=0.1621, 64_l2=0.0545\n",
      "[83] time=2.08, avg_loss=1.4356, train_err=0.0718, 32_h1=0.0762, 32_l2=0.0387, 64_h1=0.1559, 64_l2=0.0489\n",
      "[84] time=2.06, avg_loss=1.4153, train_err=0.0708, 32_h1=0.0773, 32_l2=0.0396, 64_h1=0.1556, 64_l2=0.0460\n",
      "[85] time=2.08, avg_loss=1.3995, train_err=0.0700, 32_h1=0.0736, 32_l2=0.0359, 64_h1=0.1568, 64_l2=0.0533\n",
      "[86] time=2.07, avg_loss=1.4387, train_err=0.0719, 32_h1=0.0769, 32_l2=0.0401, 64_h1=0.1594, 64_l2=0.0520\n",
      "[87] time=2.08, avg_loss=1.4205, train_err=0.0710, 32_h1=0.0754, 32_l2=0.0378, 64_h1=0.1623, 64_l2=0.0567\n",
      "[88] time=2.04, avg_loss=1.3980, train_err=0.0699, 32_h1=0.0754, 32_l2=0.0391, 64_h1=0.1602, 64_l2=0.0543\n",
      "[89] time=2.26, avg_loss=1.3825, train_err=0.0691, 32_h1=0.0741, 32_l2=0.0372, 64_h1=0.1530, 64_l2=0.0475\n",
      "[90] time=2.23, avg_loss=1.3863, train_err=0.0693, 32_h1=0.0788, 32_l2=0.0461, 64_h1=0.1613, 64_l2=0.0599\n",
      "[91] time=2.15, avg_loss=1.4186, train_err=0.0709, 32_h1=0.0754, 32_l2=0.0393, 64_h1=0.1548, 64_l2=0.0531\n",
      "[92] time=2.23, avg_loss=1.3755, train_err=0.0688, 32_h1=0.0763, 32_l2=0.0384, 64_h1=0.1636, 64_l2=0.0566\n",
      "[93] time=2.08, avg_loss=1.3995, train_err=0.0700, 32_h1=0.0733, 32_l2=0.0354, 64_h1=0.1551, 64_l2=0.0490\n",
      "[94] time=2.17, avg_loss=1.3884, train_err=0.0694, 32_h1=0.0762, 32_l2=0.0408, 64_h1=0.1571, 64_l2=0.0529\n",
      "[95] time=2.16, avg_loss=1.3881, train_err=0.0694, 32_h1=0.0797, 32_l2=0.0455, 64_h1=0.1684, 64_l2=0.0591\n",
      "[96] time=2.08, avg_loss=1.4004, train_err=0.0700, 32_h1=0.0728, 32_l2=0.0345, 64_h1=0.1574, 64_l2=0.0484\n",
      "[97] time=2.09, avg_loss=1.3597, train_err=0.0680, 32_h1=0.0748, 32_l2=0.0376, 64_h1=0.1593, 64_l2=0.0489\n",
      "[98] time=2.12, avg_loss=1.3527, train_err=0.0676, 32_h1=0.0747, 32_l2=0.0366, 64_h1=0.1595, 64_l2=0.0492\n",
      "[99] time=2.19, avg_loss=1.3843, train_err=0.0692, 32_h1=0.0739, 32_l2=0.0369, 64_h1=0.1603, 64_l2=0.0560\n",
      "[100] time=2.05, avg_loss=1.3899, train_err=0.0695, 32_h1=0.0728, 32_l2=0.0350, 64_h1=0.1618, 64_l2=0.0524\n",
      "[101] time=2.09, avg_loss=1.3662, train_err=0.0683, 32_h1=0.0721, 32_l2=0.0338, 64_h1=0.1540, 64_l2=0.0471\n",
      "[102] time=2.13, avg_loss=1.3716, train_err=0.0686, 32_h1=0.0718, 32_l2=0.0338, 64_h1=0.1583, 64_l2=0.0488\n",
      "[103] time=2.05, avg_loss=1.3711, train_err=0.0686, 32_h1=0.0725, 32_l2=0.0352, 64_h1=0.1555, 64_l2=0.0514\n",
      "[104] time=2.21, avg_loss=1.3733, train_err=0.0687, 32_h1=0.0742, 32_l2=0.0360, 64_h1=0.1613, 64_l2=0.0539\n",
      "[105] time=2.16, avg_loss=1.3405, train_err=0.0670, 32_h1=0.0746, 32_l2=0.0388, 64_h1=0.1636, 64_l2=0.0568\n",
      "[106] time=2.08, avg_loss=1.3495, train_err=0.0675, 32_h1=0.0742, 32_l2=0.0374, 64_h1=0.1519, 64_l2=0.0513\n",
      "[107] time=2.25, avg_loss=1.3464, train_err=0.0673, 32_h1=0.0731, 32_l2=0.0350, 64_h1=0.1532, 64_l2=0.0493\n",
      "[108] time=2.32, avg_loss=1.3389, train_err=0.0669, 32_h1=0.0733, 32_l2=0.0352, 64_h1=0.1666, 64_l2=0.0534\n",
      "[109] time=2.34, avg_loss=1.3708, train_err=0.0685, 32_h1=0.0745, 32_l2=0.0385, 64_h1=0.1632, 64_l2=0.0537\n",
      "[110] time=2.31, avg_loss=1.3679, train_err=0.0684, 32_h1=0.0727, 32_l2=0.0351, 64_h1=0.1606, 64_l2=0.0523\n",
      "[111] time=2.36, avg_loss=1.3603, train_err=0.0680, 32_h1=0.0728, 32_l2=0.0348, 64_h1=0.1630, 64_l2=0.0534\n",
      "[112] time=2.33, avg_loss=1.3578, train_err=0.0679, 32_h1=0.0741, 32_l2=0.0375, 64_h1=0.1678, 64_l2=0.0568\n",
      "[113] time=2.35, avg_loss=1.3312, train_err=0.0666, 32_h1=0.0731, 32_l2=0.0355, 64_h1=0.1565, 64_l2=0.0505\n",
      "[114] time=2.44, avg_loss=1.3297, train_err=0.0665, 32_h1=0.0712, 32_l2=0.0334, 64_h1=0.1592, 64_l2=0.0520\n",
      "[115] time=2.35, avg_loss=1.3392, train_err=0.0670, 32_h1=0.0711, 32_l2=0.0329, 64_h1=0.1565, 64_l2=0.0498\n",
      "[116] time=2.33, avg_loss=1.3408, train_err=0.0670, 32_h1=0.0729, 32_l2=0.0355, 64_h1=0.1552, 64_l2=0.0502\n",
      "[117] time=2.39, avg_loss=1.3205, train_err=0.0660, 32_h1=0.0762, 32_l2=0.0442, 64_h1=0.1554, 64_l2=0.0573\n",
      "[118] time=2.36, avg_loss=1.3497, train_err=0.0675, 32_h1=0.0728, 32_l2=0.0351, 64_h1=0.1632, 64_l2=0.0515\n",
      "[119] time=2.35, avg_loss=1.3489, train_err=0.0674, 32_h1=0.0726, 32_l2=0.0355, 64_h1=0.1633, 64_l2=0.0529\n",
      "[120] time=2.34, avg_loss=1.3130, train_err=0.0657, 32_h1=0.0725, 32_l2=0.0358, 64_h1=0.1558, 64_l2=0.0481\n",
      "[121] time=2.39, avg_loss=1.3075, train_err=0.0654, 32_h1=0.0707, 32_l2=0.0328, 64_h1=0.1595, 64_l2=0.0503\n",
      "[122] time=2.35, avg_loss=1.3194, train_err=0.0660, 32_h1=0.0722, 32_l2=0.0356, 64_h1=0.1603, 64_l2=0.0501\n",
      "[123] time=2.35, avg_loss=1.3056, train_err=0.0653, 32_h1=0.0712, 32_l2=0.0336, 64_h1=0.1549, 64_l2=0.0470\n",
      "[124] time=2.35, avg_loss=1.3196, train_err=0.0660, 32_h1=0.0767, 32_l2=0.0425, 64_h1=0.1599, 64_l2=0.0558\n",
      "[125] time=2.39, avg_loss=1.3329, train_err=0.0666, 32_h1=0.0715, 32_l2=0.0342, 64_h1=0.1602, 64_l2=0.0490\n",
      "[126] time=2.36, avg_loss=1.3166, train_err=0.0658, 32_h1=0.0718, 32_l2=0.0343, 64_h1=0.1508, 64_l2=0.0438\n",
      "[127] time=2.36, avg_loss=1.3243, train_err=0.0662, 32_h1=0.0725, 32_l2=0.0355, 64_h1=0.1556, 64_l2=0.0493\n",
      "[128] time=2.32, avg_loss=1.3092, train_err=0.0655, 32_h1=0.0721, 32_l2=0.0346, 64_h1=0.1624, 64_l2=0.0540\n",
      "[129] time=2.37, avg_loss=1.3050, train_err=0.0652, 32_h1=0.0715, 32_l2=0.0345, 64_h1=0.1603, 64_l2=0.0502\n",
      "[130] time=2.34, avg_loss=1.3123, train_err=0.0656, 32_h1=0.0744, 32_l2=0.0396, 64_h1=0.1545, 64_l2=0.0529\n",
      "[131] time=2.35, avg_loss=1.3049, train_err=0.0652, 32_h1=0.0704, 32_l2=0.0326, 64_h1=0.1558, 64_l2=0.0482\n",
      "[132] time=2.34, avg_loss=1.3012, train_err=0.0651, 32_h1=0.0729, 32_l2=0.0352, 64_h1=0.1567, 64_l2=0.0471\n",
      "[133] time=2.32, avg_loss=1.3137, train_err=0.0657, 32_h1=0.0722, 32_l2=0.0348, 64_h1=0.1635, 64_l2=0.0544\n",
      "[134] time=2.35, avg_loss=1.3006, train_err=0.0650, 32_h1=0.0717, 32_l2=0.0353, 64_h1=0.1600, 64_l2=0.0478\n",
      "[135] time=2.36, avg_loss=1.2945, train_err=0.0647, 32_h1=0.0723, 32_l2=0.0351, 64_h1=0.1552, 64_l2=0.0444\n",
      "[136] time=2.34, avg_loss=1.2884, train_err=0.0644, 32_h1=0.0714, 32_l2=0.0342, 64_h1=0.1527, 64_l2=0.0468\n",
      "[137] time=2.42, avg_loss=1.2812, train_err=0.0641, 32_h1=0.0706, 32_l2=0.0329, 64_h1=0.1631, 64_l2=0.0501\n",
      "[138] time=2.32, avg_loss=1.2927, train_err=0.0646, 32_h1=0.0747, 32_l2=0.0391, 64_h1=0.1630, 64_l2=0.0553\n",
      "[139] time=2.33, avg_loss=1.2873, train_err=0.0644, 32_h1=0.0710, 32_l2=0.0338, 64_h1=0.1587, 64_l2=0.0467\n",
      "[140] time=2.37, avg_loss=1.3168, train_err=0.0658, 32_h1=0.0722, 32_l2=0.0349, 64_h1=0.1618, 64_l2=0.0524\n",
      "[141] time=2.34, avg_loss=1.2786, train_err=0.0639, 32_h1=0.0721, 32_l2=0.0377, 64_h1=0.1593, 64_l2=0.0519\n",
      "[142] time=2.37, avg_loss=1.2902, train_err=0.0645, 32_h1=0.0712, 32_l2=0.0338, 64_h1=0.1632, 64_l2=0.0508\n",
      "[143] time=2.36, avg_loss=1.3033, train_err=0.0652, 32_h1=0.0743, 32_l2=0.0388, 64_h1=0.1627, 64_l2=0.0547\n",
      "[144] time=2.37, avg_loss=1.2849, train_err=0.0642, 32_h1=0.0712, 32_l2=0.0339, 64_h1=0.1562, 64_l2=0.0468\n",
      "[145] time=2.36, avg_loss=1.2711, train_err=0.0636, 32_h1=0.0701, 32_l2=0.0326, 64_h1=0.1590, 64_l2=0.0493\n",
      "[146] time=2.32, avg_loss=1.2765, train_err=0.0638, 32_h1=0.0704, 32_l2=0.0329, 64_h1=0.1581, 64_l2=0.0494\n",
      "[147] time=2.09, avg_loss=1.2725, train_err=0.0636, 32_h1=0.0705, 32_l2=0.0331, 64_h1=0.1618, 64_l2=0.0483\n",
      "[148] time=2.08, avg_loss=1.2771, train_err=0.0639, 32_h1=0.0712, 32_l2=0.0337, 64_h1=0.1575, 64_l2=0.0487\n",
      "[149] time=2.13, avg_loss=1.2584, train_err=0.0629, 32_h1=0.0709, 32_l2=0.0343, 64_h1=0.1579, 64_l2=0.0514\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in np.arange(0.01, 0.11, 0.01):\n",
    "    # Read the configuration\n",
    "    config_name = 'default'\n",
    "    pipe = ConfigPipeline([YamlConfig('./tfno_darcy_config.yaml', config_name='default', config_folder='./config'),\n",
    "                          ])\n",
    "    config = pipe.read_conf()\n",
    "    config_name = pipe.steps[-1].config_name\n",
    "    \n",
    "    config.tfno2d.rank = i\n",
    "    \n",
    "    # Set-up distributed communication, if using\n",
    "    device, is_logger = setup(config)\n",
    "    \n",
    "    # Make sure we only print information when needed\n",
    "    config.verbose = config.verbose and is_logger\n",
    "\n",
    "    #Print config to screen\n",
    "    if config.verbose and is_logger:\n",
    "        pipe.log()\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    # Loading the Darcy flow training set in 32x32 resolution, test set in 32x32 and 64x64 resolutions\n",
    "    train_loader, test_loaders, output_encoder = load_darcy_pt(\n",
    "            config.data.folder, train_resolution=config.data.train_resolution, n_train=config.data.n_train, batch_size=config.data.batch_size, \n",
    "            positional_encoding=config.data.positional_encoding,\n",
    "            test_resolutions=config.data.test_resolutions, n_tests=config.data.n_tests, test_batch_sizes=config.data.test_batch_sizes,\n",
    "            encode_input=config.data.encode_input, encode_output=config.data.encode_output,\n",
    "            )\n",
    "    \n",
    "    model = get_model(config)\n",
    "    model = model.to(device)\n",
    "\n",
    "    #Log parameter count\n",
    "    if is_logger:\n",
    "        n_params = count_params(model)\n",
    "\n",
    "        if config.verbose:\n",
    "            print(f'\\nn_params: {n_params}')\n",
    "            sys.stdout.flush()\n",
    "    \n",
    "    #Create the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                    lr=config.opt.learning_rate, \n",
    "                                    weight_decay=config.opt.weight_decay)\n",
    "\n",
    "    if config.opt.scheduler == 'ReduceLROnPlateau':\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=config.opt.gamma, patience=config.opt.scheduler_patience, mode='min')\n",
    "    elif config.opt.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.opt.scheduler_T_max)\n",
    "    elif config.opt.scheduler == 'StepLR':\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n",
    "                                                    step_size=config.opt.step_size,\n",
    "                                                    gamma=config.opt.gamma)\n",
    "    else:\n",
    "        raise ValueError(f'Got {config.opt.scheduler=}')\n",
    "    \n",
    "    # Creating the losses\n",
    "    l2loss = LpLoss(d=2, p=2)\n",
    "    h1loss = H1Loss(d=2)\n",
    "    if config.opt.training_loss == 'l2':\n",
    "        train_loss = l2loss\n",
    "    elif config.opt.training_loss == 'h1':\n",
    "        train_loss = h1loss\n",
    "    else:\n",
    "        raise ValueError(f'Got training_loss={config.opt.training_loss} but expected one of [\"l2\", \"h1\"]')\n",
    "    eval_losses={'h1': h1loss, 'l2': l2loss}\n",
    "    \n",
    "    if config.verbose and is_logger:\n",
    "        print('\\n### MODEL ###\\n', model)\n",
    "        print('\\n### OPTIMIZER ###\\n', optimizer)\n",
    "        print('\\n### SCHEDULER ###\\n', scheduler)\n",
    "        print('\\n### LOSSES ###')\n",
    "        print(f'\\n * Train: {train_loss}')\n",
    "        print(f'\\n * Test: {eval_losses}')\n",
    "        print(f'\\n### Beginning Training...\\n')\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    trainer = Trainer(model, n_epochs=config.opt.n_epochs,\n",
    "                      device=device,\n",
    "                      mg_patching_levels=config.patching.levels,\n",
    "                      mg_patching_padding=config.patching.padding,\n",
    "                      mg_patching_stitching=config.patching.stitching,\n",
    "                      wandb_log=config.wandb.log,\n",
    "                      log_test_interval=config.wandb.log_test_interval,\n",
    "                      log_output=False,\n",
    "                      use_distributed=config.distributed.use_distributed,\n",
    "                      verbose=config.verbose and is_logger)\n",
    "    \n",
    "    trainer.train(train_loader, test_loaders,\n",
    "                  output_encoder,\n",
    "                  model, \n",
    "                  optimizer,\n",
    "                  scheduler, \n",
    "                  regularizer=False, \n",
    "                  training_loss=train_loss,\n",
    "                  eval_losses=eval_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb1a790",
   "metadata": {},
   "source": [
    "# _________________\n",
    "# Begin HW4 plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5a8b1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b886919",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(np.array([[8, (0.0856+0.0861)/2, (0.0416+0.0421)/2, (0.1813+0.1725)/2, (0.0597+0.0607)/2],\n",
    "                              [10, (0.0752+0.0735)/2, (0.0360+0.0338)/2, (0.1653+0.1659)/2, (0.0531+0.0534)/2],\n",
    "                              [12, (0.0722+0.0718)/2, (0.0355+0.0337)/2, (0.1565+0.1614)/2, (0.0485+0.0522)/2],\n",
    "                              [14, (0.0748+0.0743)/2, (0.0351+0.0356)/2, (0.1627+0.1596)/2, (0.0518+0.0521)/2],\n",
    "                              [16, (0.0727+0.0734)/2, (0.0341+0.0357)/2, (0.1606+0.1554)/2, (0.0544+0.0516)/2],\n",
    "                              [18, (0.0769+0.0780)/2, (0.0386+0.0385)/2, (0.1594+0.1608)/2, (0.0527+0.0580)/2],\n",
    "                              [20, (0.0797+0.0786)/2, (0.0413+0.0370)/2, (0.1560+0.1603)/2, (0.0533+0.0526)/2],\n",
    "                              [22, (0.0803+0.0766)/2, (0.0406+0.0363)/2, (0.1589+0.1659)/2, (0.0573+0.0566)/2],\n",
    "                              [24, (0.0776+0.0775)/2, (0.0354+0.0354)/2, (0.1622+0.1587)/2, (0.0528+0.0509)/2],\n",
    "                              [26, (0.0777+0.0786)/2, (0.0355+0.0367)/2, (0.1626+0.1623)/2, (0.0530+0.0488)/2],\n",
    "                              [28, (0.0772+0.0780)/2, (0.0362+0.0363)/2, (0.1497+0.1595)/2, (0.0484+0.0569)/2],\n",
    "                              [30, (0.0774+0.0776)/2, (0.0356+0.0360)/2, (0.1647+0.1658)/2, (0.0540+0.0548)/2],\n",
    "                              [32, (0.0769+0.0773)/2, (0.0354+0.0355)/2, (0.1835+0.1762)/2, (0.0537+0.0534)/2]]),\n",
    "                    columns=['n_modes', '32_h1', '32_l2', '64_h1', '64_l2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b67977fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_modes</th>\n",
       "      <th>32_h1</th>\n",
       "      <th>32_l2</th>\n",
       "      <th>64_h1</th>\n",
       "      <th>64_l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.08585</td>\n",
       "      <td>0.04185</td>\n",
       "      <td>0.17690</td>\n",
       "      <td>0.06020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.07435</td>\n",
       "      <td>0.03490</td>\n",
       "      <td>0.16560</td>\n",
       "      <td>0.05325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.03460</td>\n",
       "      <td>0.15895</td>\n",
       "      <td>0.05035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.07455</td>\n",
       "      <td>0.03535</td>\n",
       "      <td>0.16115</td>\n",
       "      <td>0.05195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.07305</td>\n",
       "      <td>0.03490</td>\n",
       "      <td>0.15800</td>\n",
       "      <td>0.05300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.07745</td>\n",
       "      <td>0.03855</td>\n",
       "      <td>0.16010</td>\n",
       "      <td>0.05535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07915</td>\n",
       "      <td>0.03915</td>\n",
       "      <td>0.15815</td>\n",
       "      <td>0.05295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.07845</td>\n",
       "      <td>0.03845</td>\n",
       "      <td>0.16240</td>\n",
       "      <td>0.05695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.07755</td>\n",
       "      <td>0.03540</td>\n",
       "      <td>0.16045</td>\n",
       "      <td>0.05185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.07815</td>\n",
       "      <td>0.03610</td>\n",
       "      <td>0.16245</td>\n",
       "      <td>0.05090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.07760</td>\n",
       "      <td>0.03625</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.05265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.07750</td>\n",
       "      <td>0.03580</td>\n",
       "      <td>0.16525</td>\n",
       "      <td>0.05440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.07710</td>\n",
       "      <td>0.03545</td>\n",
       "      <td>0.17985</td>\n",
       "      <td>0.05355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_modes    32_h1    32_l2    64_h1    64_l2\n",
       "0       8.0  0.08585  0.04185  0.17690  0.06020\n",
       "1      10.0  0.07435  0.03490  0.16560  0.05325\n",
       "2      12.0  0.07200  0.03460  0.15895  0.05035\n",
       "3      14.0  0.07455  0.03535  0.16115  0.05195\n",
       "4      16.0  0.07305  0.03490  0.15800  0.05300\n",
       "5      18.0  0.07745  0.03855  0.16010  0.05535\n",
       "6      20.0  0.07915  0.03915  0.15815  0.05295\n",
       "7      22.0  0.07845  0.03845  0.16240  0.05695\n",
       "8      24.0  0.07755  0.03540  0.16045  0.05185\n",
       "9      26.0  0.07815  0.03610  0.16245  0.05090\n",
       "10     28.0  0.07760  0.03625  0.15460  0.05265\n",
       "11     30.0  0.07750  0.03580  0.16525  0.05440\n",
       "12     32.0  0.07710  0.03545  0.17985  0.05355"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c873d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:xlabel='n_modes'>, <AxesSubplot:xlabel='n_modes'>,\n",
       "       <AxesSubplot:xlabel='n_modes'>, <AxesSubplot:xlabel='n_modes'>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_1.plot.line(x='n_modes', subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92296382",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame(np.array([[0.01, 19537, (0.0875+0.0916)/2, (0.0441+0.0508)/2, (0.1798+0.1738)/2, (0.0581+0.0628)/2],\n",
    "                              [0.02, 26497, (0.0754+0.0719)/2, (0.0370+0.0334)/2, (0.1623+0.1590)/2, (0.0572+0.0497)/2],\n",
    "                              [0.03, 30849, (0.0773+0.0726)/2, (0.0396+0.0348)/2, (0.1570+0.1598)/2, (0.0493+0.0488)/2],\n",
    "                              [0.04, 35713, (0.0736+0.0749)/2, (0.0373+0.0393)/2, (0.1626+0.1595)/2, (0.0518+0.0525)/2],\n",
    "                              [0.05, 38337, (0.0734+0.0789)/2, (0.0353+0.0426)/2, (0.1628+0.1620)/2, (0.0513+0.0564)/2],\n",
    "                              [0.06, 56961, (0.0710+0.0715)/2, (0.0338+0.0339)/2, (0.1566+0.1594)/2, (0.0482+0.0536)/2],\n",
    "                              [0.07, 62161, (0.0710+0.0710)/2, (0.0331+0.0339)/2, (0.1665+0.1644)/2, (0.0523+0.0502)/2],\n",
    "                              [0.08, 62161, (0.0716+0.0704)/2, (0.0344+0.0330)/2, (0.1562+0.1611)/2, (0.0541+0.0532)/2],\n",
    "                              [0.09, 67649, (0.0711+0.0713)/2, (0.0337+0.0351)/2, (0.1612+0.1584)/2, (0.0534+0.0522)/2],\n",
    "                              [0.1, 67649, (0.0709+0.0712)/2, (0.0343+0.0341)/2, (0.1579+0.1616)/2, (0.0514+0.0486)/2],\n",
    "                              [0.2, 137473, (0.0724+0.0750)/2, (0.0359+0.0359)/2, (0.1545+0.1630)/2, (0.0497+0.0505)/2],\n",
    "                              [0.3, 173569, (0.0724+0.0746)/2, (0.0350+0.0353)/2, (0.1692+0.1633)/2, (0.0557+0.0496)/2],\n",
    "                              [0.4, 290385, (0.0779+0.0762)/2, (0.0394+0.0368)/2, (0.1574+0.1655)/2, (0.0500+0.0549)/2],\n",
    "                              [0.5, 311809, (0.0760+0.0776)/2, (0.0353+0.0368)/2, (0.1633+0.1683)/2, (0.0508+0.0562)/2],\n",
    "                              [0.6, 357057, (0.0785+0.0795)/2, (0.0373+0.0388)/2, (0.1661+0.1641)/2, (0.0501+0.0529)/2],\n",
    "                              [0.7, 380881, (0.0780+0.0778)/2, (0.0359+0.0368)/2, (0.1682+0.1716)/2, (0.0536+0.0541)/2],\n",
    "                              [0.8, 564097, (0.0824+0.0814)/2, (0.0392+0.0402)/2, (0.1708+0.1702)/2, (0.0526+0.0550)/2],\n",
    "                              [0.9, 600257, (0.0799+0.0819)/2, (0.0365+0.0385)/2, (0.1676+0.1749)/2, (0.0533+0.0580)/2]]),\n",
    "                    columns=['tfno2d.rank', 'n_params', '32_h1', '32_l2', '64_h1', '64_l2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91c329ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfno2d.rank</th>\n",
       "      <th>n_params</th>\n",
       "      <th>32_h1</th>\n",
       "      <th>32_l2</th>\n",
       "      <th>64_h1</th>\n",
       "      <th>64_l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>0.08955</td>\n",
       "      <td>0.04745</td>\n",
       "      <td>0.17680</td>\n",
       "      <td>0.06045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>26497.0</td>\n",
       "      <td>0.07365</td>\n",
       "      <td>0.03520</td>\n",
       "      <td>0.16065</td>\n",
       "      <td>0.05345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03</td>\n",
       "      <td>30849.0</td>\n",
       "      <td>0.07495</td>\n",
       "      <td>0.03720</td>\n",
       "      <td>0.15840</td>\n",
       "      <td>0.04905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.04</td>\n",
       "      <td>35713.0</td>\n",
       "      <td>0.07425</td>\n",
       "      <td>0.03830</td>\n",
       "      <td>0.16105</td>\n",
       "      <td>0.05215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>38337.0</td>\n",
       "      <td>0.07615</td>\n",
       "      <td>0.03895</td>\n",
       "      <td>0.16240</td>\n",
       "      <td>0.05385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.06</td>\n",
       "      <td>56961.0</td>\n",
       "      <td>0.07125</td>\n",
       "      <td>0.03385</td>\n",
       "      <td>0.15800</td>\n",
       "      <td>0.05090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.07</td>\n",
       "      <td>62161.0</td>\n",
       "      <td>0.07100</td>\n",
       "      <td>0.03350</td>\n",
       "      <td>0.16545</td>\n",
       "      <td>0.05125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.08</td>\n",
       "      <td>62161.0</td>\n",
       "      <td>0.07100</td>\n",
       "      <td>0.03370</td>\n",
       "      <td>0.15865</td>\n",
       "      <td>0.05365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.09</td>\n",
       "      <td>67649.0</td>\n",
       "      <td>0.07120</td>\n",
       "      <td>0.03440</td>\n",
       "      <td>0.15980</td>\n",
       "      <td>0.05280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.10</td>\n",
       "      <td>67649.0</td>\n",
       "      <td>0.07105</td>\n",
       "      <td>0.03420</td>\n",
       "      <td>0.15975</td>\n",
       "      <td>0.05000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.20</td>\n",
       "      <td>137473.0</td>\n",
       "      <td>0.07370</td>\n",
       "      <td>0.03590</td>\n",
       "      <td>0.15875</td>\n",
       "      <td>0.05010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.30</td>\n",
       "      <td>173569.0</td>\n",
       "      <td>0.07350</td>\n",
       "      <td>0.03515</td>\n",
       "      <td>0.16625</td>\n",
       "      <td>0.05265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.40</td>\n",
       "      <td>290385.0</td>\n",
       "      <td>0.07705</td>\n",
       "      <td>0.03810</td>\n",
       "      <td>0.16145</td>\n",
       "      <td>0.05245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.50</td>\n",
       "      <td>311809.0</td>\n",
       "      <td>0.07680</td>\n",
       "      <td>0.03605</td>\n",
       "      <td>0.16580</td>\n",
       "      <td>0.05350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.60</td>\n",
       "      <td>357057.0</td>\n",
       "      <td>0.07900</td>\n",
       "      <td>0.03805</td>\n",
       "      <td>0.16510</td>\n",
       "      <td>0.05150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.70</td>\n",
       "      <td>380881.0</td>\n",
       "      <td>0.07790</td>\n",
       "      <td>0.03635</td>\n",
       "      <td>0.16990</td>\n",
       "      <td>0.05385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.80</td>\n",
       "      <td>564097.0</td>\n",
       "      <td>0.08190</td>\n",
       "      <td>0.03970</td>\n",
       "      <td>0.17050</td>\n",
       "      <td>0.05380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.90</td>\n",
       "      <td>600257.0</td>\n",
       "      <td>0.08090</td>\n",
       "      <td>0.03750</td>\n",
       "      <td>0.17125</td>\n",
       "      <td>0.05565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tfno2d.rank  n_params    32_h1    32_l2    64_h1    64_l2\n",
       "0          0.01   19537.0  0.08955  0.04745  0.17680  0.06045\n",
       "1          0.02   26497.0  0.07365  0.03520  0.16065  0.05345\n",
       "2          0.03   30849.0  0.07495  0.03720  0.15840  0.04905\n",
       "3          0.04   35713.0  0.07425  0.03830  0.16105  0.05215\n",
       "4          0.05   38337.0  0.07615  0.03895  0.16240  0.05385\n",
       "5          0.06   56961.0  0.07125  0.03385  0.15800  0.05090\n",
       "6          0.07   62161.0  0.07100  0.03350  0.16545  0.05125\n",
       "7          0.08   62161.0  0.07100  0.03370  0.15865  0.05365\n",
       "8          0.09   67649.0  0.07120  0.03440  0.15980  0.05280\n",
       "9          0.10   67649.0  0.07105  0.03420  0.15975  0.05000\n",
       "10         0.20  137473.0  0.07370  0.03590  0.15875  0.05010\n",
       "11         0.30  173569.0  0.07350  0.03515  0.16625  0.05265\n",
       "12         0.40  290385.0  0.07705  0.03810  0.16145  0.05245\n",
       "13         0.50  311809.0  0.07680  0.03605  0.16580  0.05350\n",
       "14         0.60  357057.0  0.07900  0.03805  0.16510  0.05150\n",
       "15         0.70  380881.0  0.07790  0.03635  0.16990  0.05385\n",
       "16         0.80  564097.0  0.08190  0.03970  0.17050  0.05380\n",
       "17         0.90  600257.0  0.08090  0.03750  0.17125  0.05565"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ae10c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:xlabel='n_params'>, <AxesSubplot:xlabel='n_params'>,\n",
       "       <AxesSubplot:xlabel='n_params'>, <AxesSubplot:xlabel='n_params'>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_2.drop(columns=['tfno2d.rank']).plot.line(x='n_params', subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "165d3028",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.DataFrame(np.array([[0.01, 19537, (0.0875+0.0916)/2, (0.0441+0.0508)/2, (0.1798+0.1738)/2, (0.0581+0.0628)/2],\n",
    "                              [0.02, 26497, (0.0754+0.0719)/2, (0.0370+0.0334)/2, (0.1623+0.1590)/2, (0.0572+0.0497)/2],\n",
    "                              [0.03, 30849, (0.0773+0.0726)/2, (0.0396+0.0348)/2, (0.1570+0.1598)/2, (0.0493+0.0488)/2],\n",
    "                              [0.04, 35713, (0.0736+0.0749)/2, (0.0373+0.0393)/2, (0.1626+0.1595)/2, (0.0518+0.0525)/2],\n",
    "                              [0.05, 38337, (0.0734+0.0789)/2, (0.0353+0.0426)/2, (0.1628+0.1620)/2, (0.0513+0.0564)/2],\n",
    "                              [0.06, 56961, (0.0710+0.0715)/2, (0.0338+0.0339)/2, (0.1566+0.1594)/2, (0.0482+0.0536)/2],\n",
    "                              [0.07, 62161, (0.0710+0.0710)/2, (0.0331+0.0339)/2, (0.1665+0.1644)/2, (0.0523+0.0502)/2],\n",
    "                              [0.08, 62161, (0.0716+0.0704)/2, (0.0344+0.0330)/2, (0.1562+0.1611)/2, (0.0541+0.0532)/2],\n",
    "                              [0.09, 67649, (0.0711+0.0713)/2, (0.0337+0.0351)/2, (0.1612+0.1584)/2, (0.0534+0.0522)/2],\n",
    "                              [0.1, 67649, (0.0709+0.0712)/2, (0.0343+0.0341)/2, (0.1579+0.1616)/2, (0.0514+0.0486)/2],\n",
    "                              [0.2, 137473, (0.0724+0.0750)/2, (0.0359+0.0359)/2, (0.1545+0.1630)/2, (0.0497+0.0505)/2],\n",
    "                              ]),\n",
    "                    columns=['tfno2d.rank', 'n_params', '32_h1', '32_l2', '64_h1', '64_l2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f199323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:xlabel='tfno2d.rank'>,\n",
       "       <AxesSubplot:xlabel='tfno2d.rank'>,\n",
       "       <AxesSubplot:xlabel='tfno2d.rank'>,\n",
       "       <AxesSubplot:xlabel='tfno2d.rank'>,\n",
       "       <AxesSubplot:xlabel='tfno2d.rank'>], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_3.plot.line(x='tfno2d.rank', subplots=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
