{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c09c8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationESs\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import wandb\n",
    "import sys\n",
    "from configmypy import ConfigPipeline, YamlConfig, ArgparseConfig\n",
    "from neuralop import get_model\n",
    "from neuralop import Trainer\n",
    "from neuralop.training import setup\n",
    "from neuralop.datasets import load_darcy_pt\n",
    "from neuralop.utils import get_wandb_api_key, count_params\n",
    "from neuralop import LpLoss, H1Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ccf051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.1\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 67649\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f97576c0be0>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f975765a280>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f975765a280>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f97576c0d30>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=13.82, avg_loss=11.1117, train_err=0.5556, 32_h1=0.3107, 32_l2=0.2115, 64_h1=0.3718, 64_l2=0.2189\n",
      "[1] time=2.14, avg_loss=5.3529, train_err=0.2676, 32_h1=0.2142, 32_l2=0.1412, 64_h1=0.2804, 64_l2=0.1504\n",
      "[2] time=2.12, avg_loss=4.0505, train_err=0.2025, 32_h1=0.1954, 32_l2=0.1446, 64_h1=0.2686, 64_l2=0.1490\n",
      "[3] time=2.14, avg_loss=3.4969, train_err=0.1748, 32_h1=0.1925, 32_l2=0.1591, 64_h1=0.2691, 64_l2=0.1700\n",
      "[4] time=2.20, avg_loss=3.1940, train_err=0.1597, 32_h1=0.1499, 32_l2=0.0933, 64_h1=0.2155, 64_l2=0.0978\n",
      "[5] time=2.36, avg_loss=2.9492, train_err=0.1475, 32_h1=0.1383, 32_l2=0.0847, 64_h1=0.2172, 64_l2=0.0931\n",
      "[6] time=2.31, avg_loss=2.7797, train_err=0.1390, 32_h1=0.1365, 32_l2=0.0835, 64_h1=0.2135, 64_l2=0.0963\n",
      "[7] time=2.33, avg_loss=2.6132, train_err=0.1307, 32_h1=0.1287, 32_l2=0.0778, 64_h1=0.2157, 64_l2=0.0926\n",
      "[8] time=2.29, avg_loss=2.5406, train_err=0.1270, 32_h1=0.1753, 32_l2=0.1585, 64_h1=0.2496, 64_l2=0.1631\n",
      "[9] time=2.33, avg_loss=2.4874, train_err=0.1244, 32_h1=0.1194, 32_l2=0.0696, 64_h1=0.1975, 64_l2=0.0824\n",
      "[10] time=2.28, avg_loss=2.4214, train_err=0.1211, 32_h1=0.1154, 32_l2=0.0670, 64_h1=0.2065, 64_l2=0.0777\n",
      "[11] time=2.30, avg_loss=2.2354, train_err=0.1118, 32_h1=0.1151, 32_l2=0.0676, 64_h1=0.2018, 64_l2=0.0851\n",
      "[12] time=2.32, avg_loss=2.1777, train_err=0.1089, 32_h1=0.1092, 32_l2=0.0638, 64_h1=0.1918, 64_l2=0.0736\n",
      "[13] time=2.31, avg_loss=2.1356, train_err=0.1068, 32_h1=0.1105, 32_l2=0.0632, 64_h1=0.2017, 64_l2=0.0801\n",
      "[14] time=2.31, avg_loss=2.0829, train_err=0.1041, 32_h1=0.1156, 32_l2=0.0728, 64_h1=0.2010, 64_l2=0.0920\n",
      "[15] time=2.28, avg_loss=2.0589, train_err=0.1029, 32_h1=0.1094, 32_l2=0.0644, 64_h1=0.1878, 64_l2=0.0838\n",
      "[16] time=2.31, avg_loss=2.1170, train_err=0.1058, 32_h1=0.0994, 32_l2=0.0550, 64_h1=0.1925, 64_l2=0.0735\n",
      "[17] time=2.32, avg_loss=2.0010, train_err=0.1000, 32_h1=0.1109, 32_l2=0.0748, 64_h1=0.1934, 64_l2=0.0780\n",
      "[18] time=2.28, avg_loss=2.0272, train_err=0.1014, 32_h1=0.0965, 32_l2=0.0515, 64_h1=0.1799, 64_l2=0.0631\n",
      "[19] time=2.33, avg_loss=1.9376, train_err=0.0969, 32_h1=0.0997, 32_l2=0.0599, 64_h1=0.1828, 64_l2=0.0681\n",
      "[20] time=2.33, avg_loss=1.9244, train_err=0.0962, 32_h1=0.1113, 32_l2=0.0681, 64_h1=0.1871, 64_l2=0.0759\n",
      "[21] time=2.34, avg_loss=1.9975, train_err=0.0999, 32_h1=0.0951, 32_l2=0.0510, 64_h1=0.1893, 64_l2=0.0692\n",
      "[22] time=2.32, avg_loss=1.8381, train_err=0.0919, 32_h1=0.0959, 32_l2=0.0549, 64_h1=0.1767, 64_l2=0.0640\n",
      "[23] time=2.27, avg_loss=1.8252, train_err=0.0913, 32_h1=0.1004, 32_l2=0.0639, 64_h1=0.1922, 64_l2=0.0826\n",
      "[24] time=2.32, avg_loss=1.8892, train_err=0.0945, 32_h1=0.0949, 32_l2=0.0531, 64_h1=0.1806, 64_l2=0.0611\n",
      "[25] time=2.36, avg_loss=1.8298, train_err=0.0915, 32_h1=0.1040, 32_l2=0.0628, 64_h1=0.1902, 64_l2=0.0739\n",
      "[26] time=2.31, avg_loss=1.8400, train_err=0.0920, 32_h1=0.0976, 32_l2=0.0614, 64_h1=0.1839, 64_l2=0.0775\n",
      "[27] time=2.34, avg_loss=1.8274, train_err=0.0914, 32_h1=0.0934, 32_l2=0.0529, 64_h1=0.1798, 64_l2=0.0582\n",
      "[28] time=2.39, avg_loss=1.7564, train_err=0.0878, 32_h1=0.0888, 32_l2=0.0469, 64_h1=0.1729, 64_l2=0.0607\n",
      "[29] time=2.33, avg_loss=1.7194, train_err=0.0860, 32_h1=0.0915, 32_l2=0.0515, 64_h1=0.1818, 64_l2=0.0607\n",
      "[30] time=2.27, avg_loss=1.7729, train_err=0.0886, 32_h1=0.0892, 32_l2=0.0491, 64_h1=0.1701, 64_l2=0.0607\n",
      "[31] time=2.36, avg_loss=1.6960, train_err=0.0848, 32_h1=0.0906, 32_l2=0.0499, 64_h1=0.1737, 64_l2=0.0628\n",
      "[32] time=2.27, avg_loss=1.7599, train_err=0.0880, 32_h1=0.0881, 32_l2=0.0462, 64_h1=0.1783, 64_l2=0.0645\n",
      "[33] time=2.34, avg_loss=1.7255, train_err=0.0863, 32_h1=0.0890, 32_l2=0.0519, 64_h1=0.1733, 64_l2=0.0618\n",
      "[34] time=2.30, avg_loss=1.7505, train_err=0.0875, 32_h1=0.1038, 32_l2=0.0654, 64_h1=0.1770, 64_l2=0.0817\n",
      "[35] time=2.31, avg_loss=1.7812, train_err=0.0891, 32_h1=0.0865, 32_l2=0.0472, 64_h1=0.1677, 64_l2=0.0597\n",
      "[36] time=2.31, avg_loss=1.7207, train_err=0.0860, 32_h1=0.0901, 32_l2=0.0521, 64_h1=0.1739, 64_l2=0.0724\n",
      "[37] time=2.35, avg_loss=1.7129, train_err=0.0856, 32_h1=0.0923, 32_l2=0.0526, 64_h1=0.1818, 64_l2=0.0721\n",
      "[38] time=2.31, avg_loss=1.6559, train_err=0.0828, 32_h1=0.0846, 32_l2=0.0441, 64_h1=0.1687, 64_l2=0.0611\n",
      "[39] time=2.29, avg_loss=1.6720, train_err=0.0836, 32_h1=0.0895, 32_l2=0.0498, 64_h1=0.1802, 64_l2=0.0697\n",
      "[40] time=2.31, avg_loss=1.6331, train_err=0.0817, 32_h1=0.0821, 32_l2=0.0415, 64_h1=0.1736, 64_l2=0.0590\n",
      "[41] time=2.32, avg_loss=1.6179, train_err=0.0809, 32_h1=0.0894, 32_l2=0.0501, 64_h1=0.1720, 64_l2=0.0663\n",
      "[42] time=2.35, avg_loss=1.6791, train_err=0.0840, 32_h1=0.0833, 32_l2=0.0445, 64_h1=0.1632, 64_l2=0.0584\n",
      "[43] time=2.30, avg_loss=1.6719, train_err=0.0836, 32_h1=0.0860, 32_l2=0.0452, 64_h1=0.1802, 64_l2=0.0636\n",
      "[44] time=2.32, avg_loss=1.6272, train_err=0.0814, 32_h1=0.0820, 32_l2=0.0414, 64_h1=0.1644, 64_l2=0.0549\n",
      "[45] time=2.23, avg_loss=1.6208, train_err=0.0810, 32_h1=0.0904, 32_l2=0.0553, 64_h1=0.1625, 64_l2=0.0662\n",
      "[46] time=2.10, avg_loss=1.6361, train_err=0.0818, 32_h1=0.0869, 32_l2=0.0492, 64_h1=0.1638, 64_l2=0.0588\n",
      "[47] time=2.14, avg_loss=1.6634, train_err=0.0832, 32_h1=0.0886, 32_l2=0.0546, 64_h1=0.1759, 64_l2=0.0641\n",
      "[48] time=2.03, avg_loss=1.6441, train_err=0.0822, 32_h1=0.0808, 32_l2=0.0411, 64_h1=0.1687, 64_l2=0.0552\n",
      "[49] time=2.14, avg_loss=1.5811, train_err=0.0791, 32_h1=0.0917, 32_l2=0.0588, 64_h1=0.1753, 64_l2=0.0661\n",
      "[50] time=2.19, avg_loss=1.6354, train_err=0.0818, 32_h1=0.0828, 32_l2=0.0438, 64_h1=0.1673, 64_l2=0.0561\n",
      "[51] time=2.18, avg_loss=1.6101, train_err=0.0805, 32_h1=0.0822, 32_l2=0.0414, 64_h1=0.1579, 64_l2=0.0493\n",
      "[52] time=2.19, avg_loss=1.6075, train_err=0.0804, 32_h1=0.0959, 32_l2=0.0577, 64_h1=0.1758, 64_l2=0.0735\n",
      "[53] time=2.20, avg_loss=1.5927, train_err=0.0796, 32_h1=0.0815, 32_l2=0.0425, 64_h1=0.1740, 64_l2=0.0594\n",
      "[54] time=2.10, avg_loss=1.5762, train_err=0.0788, 32_h1=0.0794, 32_l2=0.0403, 64_h1=0.1717, 64_l2=0.0555\n",
      "[55] time=2.04, avg_loss=1.5462, train_err=0.0773, 32_h1=0.0825, 32_l2=0.0437, 64_h1=0.1745, 64_l2=0.0639\n",
      "[56] time=2.01, avg_loss=1.5472, train_err=0.0774, 32_h1=0.0817, 32_l2=0.0430, 64_h1=0.1732, 64_l2=0.0610\n",
      "[57] time=2.03, avg_loss=1.5859, train_err=0.0793, 32_h1=0.0873, 32_l2=0.0497, 64_h1=0.1753, 64_l2=0.0664\n",
      "[58] time=2.01, avg_loss=1.5617, train_err=0.0781, 32_h1=0.0805, 32_l2=0.0407, 64_h1=0.1698, 64_l2=0.0614\n",
      "[59] time=2.01, avg_loss=1.5329, train_err=0.0766, 32_h1=0.0797, 32_l2=0.0416, 64_h1=0.1710, 64_l2=0.0606\n",
      "[60] time=2.01, avg_loss=1.5728, train_err=0.0786, 32_h1=0.0812, 32_l2=0.0425, 64_h1=0.1671, 64_l2=0.0623\n",
      "[61] time=2.14, avg_loss=1.5777, train_err=0.0789, 32_h1=0.0795, 32_l2=0.0405, 64_h1=0.1765, 64_l2=0.0610\n",
      "[62] time=2.02, avg_loss=1.5317, train_err=0.0766, 32_h1=0.0790, 32_l2=0.0394, 64_h1=0.1662, 64_l2=0.0538\n",
      "[63] time=2.04, avg_loss=1.5032, train_err=0.0752, 32_h1=0.0834, 32_l2=0.0440, 64_h1=0.1690, 64_l2=0.0566\n",
      "[64] time=2.02, avg_loss=1.4995, train_err=0.0750, 32_h1=0.0787, 32_l2=0.0403, 64_h1=0.1694, 64_l2=0.0618\n",
      "[65] time=2.02, avg_loss=1.5035, train_err=0.0752, 32_h1=0.0792, 32_l2=0.0415, 64_h1=0.1743, 64_l2=0.0619\n",
      "[66] time=2.05, avg_loss=1.5317, train_err=0.0766, 32_h1=0.0805, 32_l2=0.0414, 64_h1=0.1497, 64_l2=0.0521\n",
      "[67] time=2.02, avg_loss=1.5100, train_err=0.0755, 32_h1=0.0837, 32_l2=0.0465, 64_h1=0.1689, 64_l2=0.0647\n",
      "[68] time=2.17, avg_loss=1.5568, train_err=0.0778, 32_h1=0.0825, 32_l2=0.0467, 64_h1=0.1718, 64_l2=0.0582\n",
      "[69] time=2.17, avg_loss=1.5080, train_err=0.0754, 32_h1=0.0773, 32_l2=0.0379, 64_h1=0.1618, 64_l2=0.0533\n",
      "[70] time=2.04, avg_loss=1.4952, train_err=0.0748, 32_h1=0.0772, 32_l2=0.0409, 64_h1=0.1690, 64_l2=0.0576\n",
      "[71] time=2.16, avg_loss=1.5038, train_err=0.0752, 32_h1=0.0852, 32_l2=0.0562, 64_h1=0.1717, 64_l2=0.0695\n",
      "[72] time=2.15, avg_loss=1.5140, train_err=0.0757, 32_h1=0.0800, 32_l2=0.0413, 64_h1=0.1655, 64_l2=0.0592\n",
      "[73] time=2.02, avg_loss=1.4680, train_err=0.0734, 32_h1=0.0745, 32_l2=0.0355, 64_h1=0.1676, 64_l2=0.0555\n",
      "[74] time=2.39, avg_loss=1.5233, train_err=0.0762, 32_h1=0.0773, 32_l2=0.0390, 64_h1=0.1599, 64_l2=0.0559\n",
      "[75] time=2.36, avg_loss=1.4607, train_err=0.0730, 32_h1=0.0777, 32_l2=0.0392, 64_h1=0.1682, 64_l2=0.0575\n",
      "[76] time=2.34, avg_loss=1.4710, train_err=0.0735, 32_h1=0.0814, 32_l2=0.0464, 64_h1=0.1754, 64_l2=0.0643\n",
      "[77] time=2.32, avg_loss=1.4475, train_err=0.0724, 32_h1=0.0766, 32_l2=0.0390, 64_h1=0.1624, 64_l2=0.0545\n",
      "[78] time=2.35, avg_loss=1.4928, train_err=0.0746, 32_h1=0.0813, 32_l2=0.0454, 64_h1=0.1659, 64_l2=0.0656\n",
      "[79] time=2.34, avg_loss=1.4904, train_err=0.0745, 32_h1=0.0754, 32_l2=0.0363, 64_h1=0.1651, 64_l2=0.0543\n",
      "[80] time=2.34, avg_loss=1.4412, train_err=0.0721, 32_h1=0.0747, 32_l2=0.0366, 64_h1=0.1679, 64_l2=0.0548\n",
      "[81] time=2.32, avg_loss=1.4422, train_err=0.0721, 32_h1=0.0766, 32_l2=0.0377, 64_h1=0.1645, 64_l2=0.0519\n",
      "[82] time=2.35, avg_loss=1.4450, train_err=0.0723, 32_h1=0.0769, 32_l2=0.0396, 64_h1=0.1657, 64_l2=0.0572\n",
      "[83] time=2.31, avg_loss=1.4374, train_err=0.0719, 32_h1=0.0749, 32_l2=0.0372, 64_h1=0.1648, 64_l2=0.0544\n",
      "[84] time=2.26, avg_loss=1.4632, train_err=0.0732, 32_h1=0.0887, 32_l2=0.0568, 64_h1=0.1719, 64_l2=0.0742\n",
      "[85] time=2.37, avg_loss=1.4606, train_err=0.0730, 32_h1=0.0768, 32_l2=0.0387, 64_h1=0.1663, 64_l2=0.0575\n",
      "[86] time=2.27, avg_loss=1.4534, train_err=0.0727, 32_h1=0.0744, 32_l2=0.0370, 64_h1=0.1655, 64_l2=0.0564\n",
      "[87] time=2.34, avg_loss=1.4112, train_err=0.0706, 32_h1=0.0745, 32_l2=0.0369, 64_h1=0.1629, 64_l2=0.0515\n",
      "[88] time=2.29, avg_loss=1.4431, train_err=0.0722, 32_h1=0.0778, 32_l2=0.0426, 64_h1=0.1651, 64_l2=0.0601\n",
      "[89] time=2.25, avg_loss=1.4120, train_err=0.0706, 32_h1=0.0739, 32_l2=0.0362, 64_h1=0.1725, 64_l2=0.0596\n",
      "[90] time=2.30, avg_loss=1.4404, train_err=0.0720, 32_h1=0.0771, 32_l2=0.0410, 64_h1=0.1646, 64_l2=0.0590\n",
      "[91] time=2.35, avg_loss=1.4585, train_err=0.0729, 32_h1=0.0791, 32_l2=0.0424, 64_h1=0.1646, 64_l2=0.0656\n",
      "[92] time=2.29, avg_loss=1.4653, train_err=0.0733, 32_h1=0.0757, 32_l2=0.0379, 64_h1=0.1624, 64_l2=0.0580\n",
      "[93] time=2.31, avg_loss=1.4112, train_err=0.0706, 32_h1=0.0756, 32_l2=0.0383, 64_h1=0.1708, 64_l2=0.0601\n",
      "[94] time=2.32, avg_loss=1.4545, train_err=0.0727, 32_h1=0.0759, 32_l2=0.0379, 64_h1=0.1731, 64_l2=0.0609\n",
      "[95] time=2.32, avg_loss=1.4056, train_err=0.0703, 32_h1=0.0757, 32_l2=0.0386, 64_h1=0.1631, 64_l2=0.0526\n",
      "[96] time=2.34, avg_loss=1.4119, train_err=0.0706, 32_h1=0.0751, 32_l2=0.0373, 64_h1=0.1598, 64_l2=0.0483\n",
      "[97] time=2.40, avg_loss=1.4212, train_err=0.0711, 32_h1=0.0780, 32_l2=0.0412, 64_h1=0.1637, 64_l2=0.0576\n",
      "[98] time=2.32, avg_loss=1.4358, train_err=0.0718, 32_h1=0.0757, 32_l2=0.0391, 64_h1=0.1705, 64_l2=0.0631\n",
      "[99] time=2.40, avg_loss=1.3947, train_err=0.0697, 32_h1=0.0801, 32_l2=0.0453, 64_h1=0.1706, 64_l2=0.0601\n",
      "[100] time=2.30, avg_loss=1.4010, train_err=0.0701, 32_h1=0.0730, 32_l2=0.0351, 64_h1=0.1653, 64_l2=0.0556\n",
      "[101] time=2.33, avg_loss=1.3875, train_err=0.0694, 32_h1=0.0733, 32_l2=0.0358, 64_h1=0.1673, 64_l2=0.0557\n",
      "[102] time=2.34, avg_loss=1.3738, train_err=0.0687, 32_h1=0.0713, 32_l2=0.0334, 64_h1=0.1604, 64_l2=0.0512\n",
      "[103] time=2.35, avg_loss=1.4213, train_err=0.0711, 32_h1=0.0787, 32_l2=0.0438, 64_h1=0.1628, 64_l2=0.0570\n",
      "[104] time=2.27, avg_loss=1.4229, train_err=0.0711, 32_h1=0.0739, 32_l2=0.0380, 64_h1=0.1642, 64_l2=0.0567\n",
      "[105] time=2.35, avg_loss=1.3946, train_err=0.0697, 32_h1=0.0782, 32_l2=0.0445, 64_h1=0.1711, 64_l2=0.0597\n",
      "[106] time=2.34, avg_loss=1.4049, train_err=0.0702, 32_h1=0.0758, 32_l2=0.0402, 64_h1=0.1635, 64_l2=0.0587\n",
      "[107] time=2.34, avg_loss=1.3828, train_err=0.0691, 32_h1=0.0715, 32_l2=0.0336, 64_h1=0.1693, 64_l2=0.0559\n",
      "[108] time=2.28, avg_loss=1.3854, train_err=0.0693, 32_h1=0.0752, 32_l2=0.0385, 64_h1=0.1650, 64_l2=0.0572\n",
      "[109] time=2.27, avg_loss=1.3953, train_err=0.0698, 32_h1=0.0723, 32_l2=0.0346, 64_h1=0.1608, 64_l2=0.0529\n",
      "[110] time=2.34, avg_loss=1.3759, train_err=0.0688, 32_h1=0.0741, 32_l2=0.0364, 64_h1=0.1629, 64_l2=0.0549\n",
      "[111] time=2.26, avg_loss=1.3738, train_err=0.0687, 32_h1=0.0721, 32_l2=0.0343, 64_h1=0.1647, 64_l2=0.0531\n",
      "[112] time=2.31, avg_loss=1.3830, train_err=0.0692, 32_h1=0.0721, 32_l2=0.0344, 64_h1=0.1624, 64_l2=0.0521\n",
      "[113] time=2.36, avg_loss=1.3599, train_err=0.0680, 32_h1=0.0717, 32_l2=0.0340, 64_h1=0.1687, 64_l2=0.0542\n",
      "[114] time=2.10, avg_loss=1.3877, train_err=0.0694, 32_h1=0.0735, 32_l2=0.0372, 64_h1=0.1676, 64_l2=0.0573\n",
      "[115] time=2.03, avg_loss=1.3579, train_err=0.0679, 32_h1=0.0726, 32_l2=0.0367, 64_h1=0.1680, 64_l2=0.0559\n",
      "[116] time=2.06, avg_loss=1.3782, train_err=0.0689, 32_h1=0.0740, 32_l2=0.0365, 64_h1=0.1595, 64_l2=0.0519\n",
      "[117] time=2.07, avg_loss=1.3577, train_err=0.0679, 32_h1=0.0715, 32_l2=0.0335, 64_h1=0.1670, 64_l2=0.0552\n",
      "[118] time=2.03, avg_loss=1.3642, train_err=0.0682, 32_h1=0.0738, 32_l2=0.0379, 64_h1=0.1670, 64_l2=0.0563\n",
      "[119] time=2.04, avg_loss=1.3491, train_err=0.0675, 32_h1=0.0730, 32_l2=0.0359, 64_h1=0.1613, 64_l2=0.0510\n",
      "[120] time=2.08, avg_loss=1.4379, train_err=0.0719, 32_h1=0.0742, 32_l2=0.0375, 64_h1=0.1603, 64_l2=0.0522\n",
      "[121] time=2.05, avg_loss=1.3751, train_err=0.0688, 32_h1=0.0724, 32_l2=0.0347, 64_h1=0.1662, 64_l2=0.0565\n",
      "[122] time=2.03, avg_loss=1.3514, train_err=0.0676, 32_h1=0.0730, 32_l2=0.0360, 64_h1=0.1737, 64_l2=0.0567\n",
      "[123] time=2.02, avg_loss=1.3386, train_err=0.0669, 32_h1=0.0729, 32_l2=0.0374, 64_h1=0.1640, 64_l2=0.0572\n",
      "[124] time=2.02, avg_loss=1.3434, train_err=0.0672, 32_h1=0.0741, 32_l2=0.0367, 64_h1=0.1666, 64_l2=0.0514\n",
      "[125] time=2.01, avg_loss=1.3476, train_err=0.0674, 32_h1=0.0713, 32_l2=0.0334, 64_h1=0.1648, 64_l2=0.0545\n",
      "[126] time=2.02, avg_loss=1.3473, train_err=0.0674, 32_h1=0.0731, 32_l2=0.0361, 64_h1=0.1691, 64_l2=0.0574\n",
      "[127] time=2.11, avg_loss=1.3547, train_err=0.0677, 32_h1=0.0722, 32_l2=0.0345, 64_h1=0.1637, 64_l2=0.0494\n",
      "[128] time=2.06, avg_loss=1.3308, train_err=0.0665, 32_h1=0.0751, 32_l2=0.0391, 64_h1=0.1687, 64_l2=0.0559\n",
      "[129] time=2.11, avg_loss=1.3948, train_err=0.0697, 32_h1=0.0718, 32_l2=0.0339, 64_h1=0.1688, 64_l2=0.0553\n",
      "[130] time=2.06, avg_loss=1.3324, train_err=0.0666, 32_h1=0.0730, 32_l2=0.0366, 64_h1=0.1620, 64_l2=0.0541\n",
      "[131] time=2.02, avg_loss=1.3449, train_err=0.0672, 32_h1=0.0747, 32_l2=0.0381, 64_h1=0.1605, 64_l2=0.0545\n",
      "[132] time=2.10, avg_loss=1.3506, train_err=0.0675, 32_h1=0.0706, 32_l2=0.0327, 64_h1=0.1589, 64_l2=0.0490\n",
      "[133] time=2.08, avg_loss=1.3326, train_err=0.0666, 32_h1=0.0727, 32_l2=0.0368, 64_h1=0.1642, 64_l2=0.0551\n",
      "[134] time=2.02, avg_loss=1.3209, train_err=0.0660, 32_h1=0.0711, 32_l2=0.0334, 64_h1=0.1683, 64_l2=0.0533\n",
      "[135] time=2.12, avg_loss=1.3192, train_err=0.0660, 32_h1=0.0722, 32_l2=0.0353, 64_h1=0.1631, 64_l2=0.0534\n",
      "[136] time=2.02, avg_loss=1.3292, train_err=0.0665, 32_h1=0.0716, 32_l2=0.0350, 64_h1=0.1630, 64_l2=0.0549\n",
      "[137] time=2.13, avg_loss=1.3252, train_err=0.0663, 32_h1=0.0716, 32_l2=0.0340, 64_h1=0.1622, 64_l2=0.0552\n",
      "[138] time=2.05, avg_loss=1.3177, train_err=0.0659, 32_h1=0.0709, 32_l2=0.0337, 64_h1=0.1669, 64_l2=0.0539\n",
      "[139] time=2.00, avg_loss=1.3294, train_err=0.0665, 32_h1=0.0737, 32_l2=0.0382, 64_h1=0.1657, 64_l2=0.0591\n",
      "[140] time=2.10, avg_loss=1.3252, train_err=0.0663, 32_h1=0.0717, 32_l2=0.0348, 64_h1=0.1615, 64_l2=0.0501\n",
      "[141] time=2.04, avg_loss=1.3366, train_err=0.0668, 32_h1=0.0734, 32_l2=0.0363, 64_h1=0.1639, 64_l2=0.0510\n",
      "[142] time=2.13, avg_loss=1.3114, train_err=0.0656, 32_h1=0.0708, 32_l2=0.0333, 64_h1=0.1624, 64_l2=0.0520\n",
      "[143] time=2.33, avg_loss=1.2909, train_err=0.0645, 32_h1=0.0727, 32_l2=0.0368, 64_h1=0.1635, 64_l2=0.0567\n",
      "[144] time=2.45, avg_loss=1.3262, train_err=0.0663, 32_h1=0.0703, 32_l2=0.0333, 64_h1=0.1652, 64_l2=0.0552\n",
      "[145] time=2.32, avg_loss=1.2976, train_err=0.0649, 32_h1=0.0711, 32_l2=0.0344, 64_h1=0.1623, 64_l2=0.0528\n",
      "[146] time=2.32, avg_loss=1.2874, train_err=0.0644, 32_h1=0.0707, 32_l2=0.0336, 64_h1=0.1655, 64_l2=0.0513\n",
      "[147] time=2.36, avg_loss=1.3003, train_err=0.0650, 32_h1=0.0719, 32_l2=0.0351, 64_h1=0.1698, 64_l2=0.0571\n",
      "[148] time=2.35, avg_loss=1.3009, train_err=0.0650, 32_h1=0.0713, 32_l2=0.0345, 64_h1=0.1605, 64_l2=0.0523\n",
      "[149] time=2.31, avg_loss=1.3148, train_err=0.0657, 32_h1=0.0742, 32_l2=0.0407, 64_h1=0.1683, 64_l2=0.0572\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.2\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 137473\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f983c59d6d0>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f975765a1f0>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f975765a1f0>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f975765a250>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.35, avg_loss=11.2855, train_err=0.5643, 32_h1=0.3354, 32_l2=0.2363, 64_h1=0.3849, 64_l2=0.2376\n",
      "[1] time=2.30, avg_loss=5.3942, train_err=0.2697, 32_h1=0.2562, 32_l2=0.1892, 64_h1=0.3078, 64_l2=0.1929\n",
      "[2] time=2.29, avg_loss=4.4745, train_err=0.2237, 32_h1=0.1970, 32_l2=0.1373, 64_h1=0.2528, 64_l2=0.1457\n",
      "[3] time=2.31, avg_loss=3.7556, train_err=0.1878, 32_h1=0.1832, 32_l2=0.1324, 64_h1=0.2325, 64_l2=0.1320\n",
      "[4] time=2.30, avg_loss=3.3706, train_err=0.1685, 32_h1=0.1857, 32_l2=0.1340, 64_h1=0.2368, 64_l2=0.1387\n",
      "[5] time=2.32, avg_loss=3.0322, train_err=0.1516, 32_h1=0.1497, 32_l2=0.1079, 64_h1=0.2168, 64_l2=0.1205\n",
      "[6] time=2.33, avg_loss=2.7983, train_err=0.1399, 32_h1=0.1329, 32_l2=0.0813, 64_h1=0.1907, 64_l2=0.0879\n",
      "[7] time=2.33, avg_loss=2.6422, train_err=0.1321, 32_h1=0.1426, 32_l2=0.0932, 64_h1=0.2128, 64_l2=0.1041\n",
      "[8] time=2.30, avg_loss=2.5582, train_err=0.1279, 32_h1=0.1333, 32_l2=0.0934, 64_h1=0.2047, 64_l2=0.1012\n",
      "[9] time=2.30, avg_loss=2.4973, train_err=0.1249, 32_h1=0.1234, 32_l2=0.0735, 64_h1=0.1917, 64_l2=0.0791\n",
      "[10] time=2.28, avg_loss=2.2504, train_err=0.1125, 32_h1=0.1096, 32_l2=0.0657, 64_h1=0.1811, 64_l2=0.0761\n",
      "[11] time=2.33, avg_loss=2.2228, train_err=0.1111, 32_h1=0.1073, 32_l2=0.0622, 64_h1=0.1785, 64_l2=0.0731\n",
      "[12] time=2.35, avg_loss=2.2309, train_err=0.1115, 32_h1=0.1125, 32_l2=0.0719, 64_h1=0.1840, 64_l2=0.0802\n",
      "[13] time=2.31, avg_loss=2.1102, train_err=0.1055, 32_h1=0.1068, 32_l2=0.0667, 64_h1=0.1769, 64_l2=0.0713\n",
      "[14] time=2.30, avg_loss=2.1267, train_err=0.1063, 32_h1=0.1023, 32_l2=0.0615, 64_h1=0.1765, 64_l2=0.0723\n",
      "[15] time=2.29, avg_loss=2.0733, train_err=0.1037, 32_h1=0.0976, 32_l2=0.0544, 64_h1=0.1733, 64_l2=0.0630\n",
      "[16] time=2.44, avg_loss=1.9433, train_err=0.0972, 32_h1=0.1044, 32_l2=0.0633, 64_h1=0.1712, 64_l2=0.0745\n",
      "[17] time=2.39, avg_loss=1.9783, train_err=0.0989, 32_h1=0.1022, 32_l2=0.0601, 64_h1=0.1787, 64_l2=0.0652\n",
      "[18] time=2.37, avg_loss=2.0237, train_err=0.1012, 32_h1=0.0983, 32_l2=0.0562, 64_h1=0.1665, 64_l2=0.0649\n",
      "[19] time=2.32, avg_loss=1.9342, train_err=0.0967, 32_h1=0.1116, 32_l2=0.0727, 64_h1=0.1813, 64_l2=0.0831\n",
      "[20] time=2.34, avg_loss=1.9089, train_err=0.0954, 32_h1=0.0952, 32_l2=0.0528, 64_h1=0.1761, 64_l2=0.0602\n",
      "[21] time=2.30, avg_loss=1.8974, train_err=0.0949, 32_h1=0.1005, 32_l2=0.0628, 64_h1=0.1777, 64_l2=0.0700\n",
      "[22] time=2.30, avg_loss=1.8654, train_err=0.0933, 32_h1=0.0986, 32_l2=0.0604, 64_h1=0.1788, 64_l2=0.0738\n",
      "[23] time=2.37, avg_loss=1.8694, train_err=0.0935, 32_h1=0.0914, 32_l2=0.0486, 64_h1=0.1757, 64_l2=0.0643\n",
      "[24] time=2.28, avg_loss=1.8391, train_err=0.0920, 32_h1=0.0897, 32_l2=0.0481, 64_h1=0.1757, 64_l2=0.0657\n",
      "[25] time=2.29, avg_loss=1.8148, train_err=0.0907, 32_h1=0.0958, 32_l2=0.0564, 64_h1=0.1809, 64_l2=0.0679\n",
      "[26] time=2.31, avg_loss=1.8857, train_err=0.0943, 32_h1=0.0925, 32_l2=0.0532, 64_h1=0.1730, 64_l2=0.0672\n",
      "[27] time=2.26, avg_loss=1.7921, train_err=0.0896, 32_h1=0.0868, 32_l2=0.0446, 64_h1=0.1671, 64_l2=0.0616\n",
      "[28] time=2.39, avg_loss=1.8097, train_err=0.0905, 32_h1=0.0963, 32_l2=0.0593, 64_h1=0.1730, 64_l2=0.0762\n",
      "[29] time=2.30, avg_loss=1.7659, train_err=0.0883, 32_h1=0.1035, 32_l2=0.0680, 64_h1=0.1821, 64_l2=0.0769\n",
      "[30] time=2.27, avg_loss=1.7735, train_err=0.0887, 32_h1=0.0860, 32_l2=0.0470, 64_h1=0.1622, 64_l2=0.0593\n",
      "[31] time=2.32, avg_loss=1.7144, train_err=0.0857, 32_h1=0.0896, 32_l2=0.0542, 64_h1=0.1738, 64_l2=0.0667\n",
      "[32] time=2.28, avg_loss=1.7866, train_err=0.0893, 32_h1=0.0863, 32_l2=0.0444, 64_h1=0.1587, 64_l2=0.0577\n",
      "[33] time=2.21, avg_loss=1.6616, train_err=0.0831, 32_h1=0.0843, 32_l2=0.0438, 64_h1=0.1683, 64_l2=0.0577\n",
      "[34] time=2.08, avg_loss=1.6857, train_err=0.0843, 32_h1=0.0905, 32_l2=0.0560, 64_h1=0.1644, 64_l2=0.0649\n",
      "[35] time=2.02, avg_loss=1.8112, train_err=0.0906, 32_h1=0.0883, 32_l2=0.0534, 64_h1=0.1683, 64_l2=0.0623\n",
      "[36] time=2.02, avg_loss=1.6971, train_err=0.0849, 32_h1=0.0843, 32_l2=0.0447, 64_h1=0.1568, 64_l2=0.0534\n",
      "[37] time=2.02, avg_loss=1.6790, train_err=0.0839, 32_h1=0.0849, 32_l2=0.0451, 64_h1=0.1579, 64_l2=0.0567\n",
      "[38] time=2.02, avg_loss=1.6773, train_err=0.0839, 32_h1=0.0876, 32_l2=0.0498, 64_h1=0.1670, 64_l2=0.0664\n",
      "[39] time=2.02, avg_loss=1.7239, train_err=0.0862, 32_h1=0.0816, 32_l2=0.0428, 64_h1=0.1673, 64_l2=0.0570\n",
      "[40] time=2.04, avg_loss=1.6377, train_err=0.0819, 32_h1=0.0871, 32_l2=0.0481, 64_h1=0.1609, 64_l2=0.0622\n",
      "[41] time=2.04, avg_loss=1.6396, train_err=0.0820, 32_h1=0.0838, 32_l2=0.0455, 64_h1=0.1686, 64_l2=0.0612\n",
      "[42] time=2.16, avg_loss=1.6440, train_err=0.0822, 32_h1=0.0820, 32_l2=0.0432, 64_h1=0.1656, 64_l2=0.0609\n",
      "[43] time=2.17, avg_loss=1.6006, train_err=0.0800, 32_h1=0.0836, 32_l2=0.0441, 64_h1=0.1600, 64_l2=0.0596\n",
      "[44] time=2.14, avg_loss=1.5983, train_err=0.0799, 32_h1=0.0819, 32_l2=0.0451, 64_h1=0.1667, 64_l2=0.0611\n",
      "[45] time=2.03, avg_loss=1.5860, train_err=0.0793, 32_h1=0.0811, 32_l2=0.0429, 64_h1=0.1600, 64_l2=0.0574\n",
      "[46] time=2.03, avg_loss=1.6461, train_err=0.0823, 32_h1=0.0922, 32_l2=0.0559, 64_h1=0.1703, 64_l2=0.0692\n",
      "[47] time=2.02, avg_loss=1.6111, train_err=0.0806, 32_h1=0.0849, 32_l2=0.0446, 64_h1=0.1576, 64_l2=0.0555\n",
      "[48] time=2.02, avg_loss=1.6126, train_err=0.0806, 32_h1=0.0820, 32_l2=0.0427, 64_h1=0.1571, 64_l2=0.0531\n",
      "[49] time=2.02, avg_loss=1.5250, train_err=0.0763, 32_h1=0.0781, 32_l2=0.0393, 64_h1=0.1606, 64_l2=0.0572\n",
      "[50] time=2.02, avg_loss=1.6272, train_err=0.0814, 32_h1=0.0798, 32_l2=0.0413, 64_h1=0.1678, 64_l2=0.0605\n",
      "[51] time=2.19, avg_loss=1.5210, train_err=0.0760, 32_h1=0.0818, 32_l2=0.0432, 64_h1=0.1541, 64_l2=0.0542\n",
      "[52] time=2.13, avg_loss=1.5626, train_err=0.0781, 32_h1=0.0821, 32_l2=0.0465, 64_h1=0.1629, 64_l2=0.0618\n",
      "[53] time=2.02, avg_loss=1.5385, train_err=0.0769, 32_h1=0.0820, 32_l2=0.0445, 64_h1=0.1601, 64_l2=0.0586\n",
      "[54] time=2.02, avg_loss=1.5117, train_err=0.0756, 32_h1=0.0809, 32_l2=0.0435, 64_h1=0.1607, 64_l2=0.0604\n",
      "[55] time=2.02, avg_loss=1.5048, train_err=0.0752, 32_h1=0.0772, 32_l2=0.0388, 64_h1=0.1614, 64_l2=0.0535\n",
      "[56] time=2.03, avg_loss=1.5436, train_err=0.0772, 32_h1=0.1003, 32_l2=0.0658, 64_h1=0.1654, 64_l2=0.0753\n",
      "[57] time=2.02, avg_loss=1.5943, train_err=0.0797, 32_h1=0.0832, 32_l2=0.0515, 64_h1=0.1574, 64_l2=0.0595\n",
      "[58] time=2.16, avg_loss=1.4881, train_err=0.0744, 32_h1=0.0789, 32_l2=0.0417, 64_h1=0.1673, 64_l2=0.0584\n",
      "[59] time=2.19, avg_loss=1.4906, train_err=0.0745, 32_h1=0.0798, 32_l2=0.0433, 64_h1=0.1595, 64_l2=0.0538\n",
      "[60] time=2.18, avg_loss=1.4876, train_err=0.0744, 32_h1=0.0785, 32_l2=0.0423, 64_h1=0.1632, 64_l2=0.0561\n",
      "[61] time=2.19, avg_loss=1.5022, train_err=0.0751, 32_h1=0.0919, 32_l2=0.0618, 64_h1=0.1671, 64_l2=0.0690\n",
      "[62] time=2.19, avg_loss=1.5175, train_err=0.0759, 32_h1=0.0767, 32_l2=0.0377, 64_h1=0.1525, 64_l2=0.0483\n",
      "[63] time=2.25, avg_loss=1.4706, train_err=0.0735, 32_h1=0.0785, 32_l2=0.0394, 64_h1=0.1536, 64_l2=0.0529\n",
      "[64] time=2.47, avg_loss=1.4520, train_err=0.0726, 32_h1=0.0756, 32_l2=0.0374, 64_h1=0.1559, 64_l2=0.0531\n",
      "[65] time=2.33, avg_loss=1.4947, train_err=0.0747, 32_h1=0.0789, 32_l2=0.0403, 64_h1=0.1592, 64_l2=0.0531\n",
      "[66] time=2.34, avg_loss=1.4927, train_err=0.0746, 32_h1=0.0786, 32_l2=0.0416, 64_h1=0.1596, 64_l2=0.0512\n",
      "[67] time=2.29, avg_loss=1.4884, train_err=0.0744, 32_h1=0.0765, 32_l2=0.0391, 64_h1=0.1563, 64_l2=0.0533\n",
      "[68] time=2.34, avg_loss=1.4554, train_err=0.0728, 32_h1=0.0764, 32_l2=0.0385, 64_h1=0.1587, 64_l2=0.0544\n",
      "[69] time=2.28, avg_loss=1.4822, train_err=0.0741, 32_h1=0.0794, 32_l2=0.0427, 64_h1=0.1645, 64_l2=0.0545\n",
      "[70] time=2.32, avg_loss=1.4625, train_err=0.0731, 32_h1=0.0764, 32_l2=0.0382, 64_h1=0.1606, 64_l2=0.0571\n",
      "[71] time=2.34, avg_loss=1.5498, train_err=0.0775, 32_h1=0.0815, 32_l2=0.0437, 64_h1=0.1472, 64_l2=0.0508\n",
      "[72] time=2.30, avg_loss=1.4839, train_err=0.0742, 32_h1=0.0858, 32_l2=0.0500, 64_h1=0.1605, 64_l2=0.0604\n",
      "[73] time=2.28, avg_loss=1.4376, train_err=0.0719, 32_h1=0.0771, 32_l2=0.0402, 64_h1=0.1657, 64_l2=0.0594\n",
      "[74] time=2.29, avg_loss=1.4141, train_err=0.0707, 32_h1=0.0759, 32_l2=0.0382, 64_h1=0.1622, 64_l2=0.0560\n",
      "[75] time=2.30, avg_loss=1.4400, train_err=0.0720, 32_h1=0.0762, 32_l2=0.0375, 64_h1=0.1566, 64_l2=0.0510\n",
      "[76] time=2.31, avg_loss=1.4315, train_err=0.0716, 32_h1=0.0750, 32_l2=0.0367, 64_h1=0.1521, 64_l2=0.0497\n",
      "[77] time=2.31, avg_loss=1.4087, train_err=0.0704, 32_h1=0.0759, 32_l2=0.0389, 64_h1=0.1641, 64_l2=0.0566\n",
      "[78] time=2.30, avg_loss=1.4338, train_err=0.0717, 32_h1=0.0817, 32_l2=0.0486, 64_h1=0.1599, 64_l2=0.0572\n",
      "[79] time=2.35, avg_loss=1.4470, train_err=0.0724, 32_h1=0.0787, 32_l2=0.0443, 64_h1=0.1572, 64_l2=0.0569\n",
      "[80] time=2.29, avg_loss=1.4166, train_err=0.0708, 32_h1=0.0753, 32_l2=0.0381, 64_h1=0.1581, 64_l2=0.0553\n",
      "[81] time=2.31, avg_loss=1.4715, train_err=0.0736, 32_h1=0.0750, 32_l2=0.0375, 64_h1=0.1546, 64_l2=0.0502\n",
      "[82] time=2.32, avg_loss=1.4200, train_err=0.0710, 32_h1=0.0814, 32_l2=0.0476, 64_h1=0.1537, 64_l2=0.0590\n",
      "[83] time=2.30, avg_loss=1.4142, train_err=0.0707, 32_h1=0.0753, 32_l2=0.0388, 64_h1=0.1541, 64_l2=0.0509\n",
      "[84] time=2.31, avg_loss=1.3900, train_err=0.0695, 32_h1=0.0756, 32_l2=0.0383, 64_h1=0.1527, 64_l2=0.0529\n",
      "[85] time=2.28, avg_loss=1.3848, train_err=0.0692, 32_h1=0.0746, 32_l2=0.0372, 64_h1=0.1604, 64_l2=0.0528\n",
      "[86] time=2.28, avg_loss=1.3811, train_err=0.0691, 32_h1=0.0792, 32_l2=0.0416, 64_h1=0.1599, 64_l2=0.0551\n",
      "[87] time=2.38, avg_loss=1.3972, train_err=0.0699, 32_h1=0.0776, 32_l2=0.0408, 64_h1=0.1532, 64_l2=0.0493\n",
      "[88] time=2.29, avg_loss=1.3947, train_err=0.0697, 32_h1=0.0851, 32_l2=0.0521, 64_h1=0.1599, 64_l2=0.0643\n",
      "[89] time=2.32, avg_loss=1.4320, train_err=0.0716, 32_h1=0.0750, 32_l2=0.0383, 64_h1=0.1591, 64_l2=0.0555\n",
      "[90] time=2.32, avg_loss=1.3796, train_err=0.0690, 32_h1=0.0752, 32_l2=0.0389, 64_h1=0.1576, 64_l2=0.0567\n",
      "[91] time=2.30, avg_loss=1.3929, train_err=0.0696, 32_h1=0.0762, 32_l2=0.0384, 64_h1=0.1557, 64_l2=0.0501\n",
      "[92] time=2.35, avg_loss=1.3562, train_err=0.0678, 32_h1=0.0748, 32_l2=0.0370, 64_h1=0.1637, 64_l2=0.0596\n",
      "[93] time=2.37, avg_loss=1.3589, train_err=0.0679, 32_h1=0.0743, 32_l2=0.0375, 64_h1=0.1595, 64_l2=0.0551\n",
      "[94] time=2.31, avg_loss=1.3638, train_err=0.0682, 32_h1=0.0735, 32_l2=0.0358, 64_h1=0.1530, 64_l2=0.0530\n",
      "[95] time=2.31, avg_loss=1.3460, train_err=0.0673, 32_h1=0.0741, 32_l2=0.0373, 64_h1=0.1605, 64_l2=0.0550\n",
      "[96] time=2.29, avg_loss=1.3568, train_err=0.0678, 32_h1=0.0736, 32_l2=0.0357, 64_h1=0.1539, 64_l2=0.0521\n",
      "[97] time=2.33, avg_loss=1.3784, train_err=0.0689, 32_h1=0.0771, 32_l2=0.0414, 64_h1=0.1616, 64_l2=0.0564\n",
      "[98] time=2.33, avg_loss=1.3399, train_err=0.0670, 32_h1=0.0751, 32_l2=0.0371, 64_h1=0.1521, 64_l2=0.0485\n",
      "[99] time=2.31, avg_loss=1.3372, train_err=0.0669, 32_h1=0.0733, 32_l2=0.0351, 64_h1=0.1609, 64_l2=0.0539\n",
      "[100] time=2.32, avg_loss=1.3518, train_err=0.0676, 32_h1=0.0748, 32_l2=0.0369, 64_h1=0.1530, 64_l2=0.0509\n",
      "[101] time=2.28, avg_loss=1.3604, train_err=0.0680, 32_h1=0.0743, 32_l2=0.0362, 64_h1=0.1558, 64_l2=0.0486\n",
      "[102] time=2.28, avg_loss=1.3488, train_err=0.0674, 32_h1=0.0753, 32_l2=0.0394, 64_h1=0.1613, 64_l2=0.0537\n",
      "[103] time=2.21, avg_loss=1.3784, train_err=0.0689, 32_h1=0.0725, 32_l2=0.0350, 64_h1=0.1571, 64_l2=0.0509\n",
      "[104] time=2.06, avg_loss=1.3676, train_err=0.0684, 32_h1=0.0781, 32_l2=0.0406, 64_h1=0.1535, 64_l2=0.0532\n",
      "[105] time=2.10, avg_loss=1.3524, train_err=0.0676, 32_h1=0.0825, 32_l2=0.0483, 64_h1=0.1554, 64_l2=0.0575\n",
      "[106] time=2.19, avg_loss=1.3245, train_err=0.0662, 32_h1=0.0735, 32_l2=0.0362, 64_h1=0.1590, 64_l2=0.0518\n",
      "[107] time=2.19, avg_loss=1.3256, train_err=0.0663, 32_h1=0.0730, 32_l2=0.0360, 64_h1=0.1547, 64_l2=0.0491\n",
      "[108] time=2.15, avg_loss=1.3264, train_err=0.0663, 32_h1=0.0744, 32_l2=0.0376, 64_h1=0.1568, 64_l2=0.0502\n",
      "[109] time=2.18, avg_loss=1.3351, train_err=0.0668, 32_h1=0.0731, 32_l2=0.0356, 64_h1=0.1618, 64_l2=0.0535\n",
      "[110] time=2.16, avg_loss=1.3275, train_err=0.0664, 32_h1=0.0723, 32_l2=0.0343, 64_h1=0.1631, 64_l2=0.0535\n",
      "[111] time=2.17, avg_loss=1.3098, train_err=0.0655, 32_h1=0.0720, 32_l2=0.0346, 64_h1=0.1572, 64_l2=0.0533\n",
      "[112] time=2.17, avg_loss=1.3190, train_err=0.0660, 32_h1=0.0728, 32_l2=0.0355, 64_h1=0.1572, 64_l2=0.0494\n",
      "[113] time=2.06, avg_loss=1.3276, train_err=0.0664, 32_h1=0.0742, 32_l2=0.0370, 64_h1=0.1540, 64_l2=0.0484\n",
      "[114] time=2.03, avg_loss=1.3141, train_err=0.0657, 32_h1=0.0725, 32_l2=0.0357, 64_h1=0.1552, 64_l2=0.0517\n",
      "[115] time=2.04, avg_loss=1.2946, train_err=0.0647, 32_h1=0.0756, 32_l2=0.0425, 64_h1=0.1595, 64_l2=0.0574\n",
      "[116] time=2.05, avg_loss=1.2964, train_err=0.0648, 32_h1=0.0731, 32_l2=0.0360, 64_h1=0.1535, 64_l2=0.0496\n",
      "[117] time=2.21, avg_loss=1.3095, train_err=0.0655, 32_h1=0.0758, 32_l2=0.0404, 64_h1=0.1587, 64_l2=0.0579\n",
      "[118] time=2.10, avg_loss=1.3318, train_err=0.0666, 32_h1=0.0749, 32_l2=0.0384, 64_h1=0.1585, 64_l2=0.0491\n",
      "[119] time=2.19, avg_loss=1.2980, train_err=0.0649, 32_h1=0.0741, 32_l2=0.0385, 64_h1=0.1614, 64_l2=0.0566\n",
      "[120] time=2.18, avg_loss=1.2986, train_err=0.0649, 32_h1=0.0726, 32_l2=0.0354, 64_h1=0.1584, 64_l2=0.0548\n",
      "[121] time=2.18, avg_loss=1.2895, train_err=0.0645, 32_h1=0.0728, 32_l2=0.0346, 64_h1=0.1616, 64_l2=0.0497\n",
      "[122] time=2.06, avg_loss=1.2857, train_err=0.0643, 32_h1=0.0755, 32_l2=0.0398, 64_h1=0.1654, 64_l2=0.0566\n",
      "[123] time=2.01, avg_loss=1.3150, train_err=0.0657, 32_h1=0.0722, 32_l2=0.0344, 64_h1=0.1579, 64_l2=0.0521\n",
      "[124] time=2.03, avg_loss=1.3082, train_err=0.0654, 32_h1=0.0742, 32_l2=0.0366, 64_h1=0.1563, 64_l2=0.0529\n",
      "[125] time=2.01, avg_loss=1.2818, train_err=0.0641, 32_h1=0.0724, 32_l2=0.0355, 64_h1=0.1547, 64_l2=0.0482\n",
      "[126] time=2.03, avg_loss=1.3059, train_err=0.0653, 32_h1=0.0721, 32_l2=0.0343, 64_h1=0.1564, 64_l2=0.0494\n",
      "[127] time=2.01, avg_loss=1.2725, train_err=0.0636, 32_h1=0.0729, 32_l2=0.0355, 64_h1=0.1531, 64_l2=0.0492\n",
      "[128] time=2.05, avg_loss=1.2640, train_err=0.0632, 32_h1=0.0724, 32_l2=0.0350, 64_h1=0.1552, 64_l2=0.0502\n",
      "[129] time=2.19, avg_loss=1.2798, train_err=0.0640, 32_h1=0.0724, 32_l2=0.0346, 64_h1=0.1547, 64_l2=0.0494\n",
      "[130] time=2.18, avg_loss=1.2696, train_err=0.0635, 32_h1=0.0731, 32_l2=0.0370, 64_h1=0.1557, 64_l2=0.0502\n",
      "[131] time=2.19, avg_loss=1.2750, train_err=0.0637, 32_h1=0.0727, 32_l2=0.0358, 64_h1=0.1570, 64_l2=0.0507\n",
      "[132] time=2.25, avg_loss=1.2632, train_err=0.0632, 32_h1=0.0729, 32_l2=0.0364, 64_h1=0.1559, 64_l2=0.0507\n",
      "[133] time=2.33, avg_loss=1.2789, train_err=0.0639, 32_h1=0.0759, 32_l2=0.0400, 64_h1=0.1589, 64_l2=0.0520\n",
      "[134] time=2.34, avg_loss=1.2660, train_err=0.0633, 32_h1=0.0720, 32_l2=0.0342, 64_h1=0.1577, 64_l2=0.0491\n",
      "[135] time=2.28, avg_loss=1.2591, train_err=0.0630, 32_h1=0.0716, 32_l2=0.0342, 64_h1=0.1571, 64_l2=0.0517\n",
      "[136] time=2.33, avg_loss=1.2544, train_err=0.0627, 32_h1=0.0735, 32_l2=0.0369, 64_h1=0.1565, 64_l2=0.0515\n",
      "[137] time=2.31, avg_loss=1.2744, train_err=0.0637, 32_h1=0.0756, 32_l2=0.0398, 64_h1=0.1573, 64_l2=0.0534\n",
      "[138] time=2.28, avg_loss=1.2659, train_err=0.0633, 32_h1=0.0791, 32_l2=0.0463, 64_h1=0.1598, 64_l2=0.0597\n",
      "[139] time=2.32, avg_loss=1.2753, train_err=0.0638, 32_h1=0.0724, 32_l2=0.0352, 64_h1=0.1587, 64_l2=0.0509\n",
      "[140] time=2.34, avg_loss=1.2654, train_err=0.0633, 32_h1=0.0729, 32_l2=0.0362, 64_h1=0.1614, 64_l2=0.0549\n",
      "[141] time=2.33, avg_loss=1.2747, train_err=0.0637, 32_h1=0.0751, 32_l2=0.0389, 64_h1=0.1621, 64_l2=0.0544\n",
      "[142] time=2.31, avg_loss=1.2412, train_err=0.0621, 32_h1=0.0714, 32_l2=0.0336, 64_h1=0.1562, 64_l2=0.0477\n",
      "[143] time=2.31, avg_loss=1.2339, train_err=0.0617, 32_h1=0.0719, 32_l2=0.0340, 64_h1=0.1599, 64_l2=0.0519\n",
      "[144] time=2.31, avg_loss=1.2295, train_err=0.0615, 32_h1=0.0723, 32_l2=0.0364, 64_h1=0.1552, 64_l2=0.0520\n",
      "[145] time=2.28, avg_loss=1.2295, train_err=0.0615, 32_h1=0.0722, 32_l2=0.0347, 64_h1=0.1530, 64_l2=0.0489\n",
      "[146] time=2.28, avg_loss=1.2219, train_err=0.0611, 32_h1=0.0737, 32_l2=0.0371, 64_h1=0.1604, 64_l2=0.0546\n",
      "[147] time=2.32, avg_loss=1.2272, train_err=0.0614, 32_h1=0.0722, 32_l2=0.0347, 64_h1=0.1587, 64_l2=0.0516\n",
      "[148] time=2.35, avg_loss=1.2371, train_err=0.0619, 32_h1=0.0729, 32_l2=0.0365, 64_h1=0.1599, 64_l2=0.0554\n",
      "[149] time=2.26, avg_loss=1.2187, train_err=0.0609, 32_h1=0.0752, 32_l2=0.0401, 64_h1=0.1591, 64_l2=0.0554\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.30000000000000004\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 173569\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(23, 23, 4, 4))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(23, 23, 4, 4))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(23, 23, 4, 4))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(23, 23, 4, 4))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(23, 23, 4, 4))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(23, 23, 4, 4))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(23, 23, 4, 4))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(23, 23, 4, 4))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f983c59d4f0>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f983c59d700>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f983c59d700>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f975765afa0>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.33, avg_loss=10.7220, train_err=0.5361, 32_h1=0.3175, 32_l2=0.2113, 64_h1=0.3666, 64_l2=0.2159\n",
      "[1] time=2.31, avg_loss=5.2124, train_err=0.2606, 32_h1=0.2250, 32_l2=0.1544, 64_h1=0.2872, 64_l2=0.1641\n",
      "[2] time=2.29, avg_loss=4.1640, train_err=0.2082, 32_h1=0.2256, 32_l2=0.1734, 64_h1=0.2904, 64_l2=0.1856\n",
      "[3] time=2.28, avg_loss=3.6410, train_err=0.1820, 32_h1=0.1669, 32_l2=0.1016, 64_h1=0.2147, 64_l2=0.1046\n",
      "[4] time=2.29, avg_loss=3.2468, train_err=0.1623, 32_h1=0.1730, 32_l2=0.1261, 64_h1=0.2465, 64_l2=0.1366\n",
      "[5] time=2.30, avg_loss=3.0317, train_err=0.1516, 32_h1=0.1684, 32_l2=0.1211, 64_h1=0.2236, 64_l2=0.1272\n",
      "[6] time=2.43, avg_loss=2.8149, train_err=0.1407, 32_h1=0.1411, 32_l2=0.0937, 64_h1=0.2067, 64_l2=0.1028\n",
      "[7] time=2.31, avg_loss=2.5428, train_err=0.1271, 32_h1=0.1511, 32_l2=0.1151, 64_h1=0.2281, 64_l2=0.1279\n",
      "[8] time=2.30, avg_loss=2.5562, train_err=0.1278, 32_h1=0.1182, 32_l2=0.0707, 64_h1=0.1866, 64_l2=0.0771\n",
      "[9] time=2.32, avg_loss=2.3618, train_err=0.1181, 32_h1=0.1221, 32_l2=0.0736, 64_h1=0.1947, 64_l2=0.0931\n",
      "[10] time=2.32, avg_loss=2.2333, train_err=0.1117, 32_h1=0.1258, 32_l2=0.0798, 64_h1=0.1758, 64_l2=0.0803\n",
      "[11] time=2.34, avg_loss=2.1513, train_err=0.1076, 32_h1=0.1056, 32_l2=0.0590, 64_h1=0.1780, 64_l2=0.0727\n",
      "[12] time=2.34, avg_loss=2.0614, train_err=0.1031, 32_h1=0.1036, 32_l2=0.0592, 64_h1=0.1879, 64_l2=0.0748\n",
      "[13] time=2.32, avg_loss=2.0077, train_err=0.1004, 32_h1=0.1053, 32_l2=0.0591, 64_h1=0.1766, 64_l2=0.0676\n",
      "[14] time=2.32, avg_loss=1.9824, train_err=0.0991, 32_h1=0.0998, 32_l2=0.0532, 64_h1=0.1899, 64_l2=0.0723\n",
      "[15] time=2.28, avg_loss=1.9857, train_err=0.0993, 32_h1=0.0977, 32_l2=0.0555, 64_h1=0.1733, 64_l2=0.0694\n",
      "[16] time=2.33, avg_loss=1.9017, train_err=0.0951, 32_h1=0.0991, 32_l2=0.0615, 64_h1=0.1732, 64_l2=0.0718\n",
      "[17] time=2.30, avg_loss=1.8904, train_err=0.0945, 32_h1=0.0967, 32_l2=0.0545, 64_h1=0.1740, 64_l2=0.0706\n",
      "[18] time=2.29, avg_loss=1.9296, train_err=0.0965, 32_h1=0.0908, 32_l2=0.0477, 64_h1=0.1707, 64_l2=0.0631\n",
      "[19] time=2.29, avg_loss=1.8071, train_err=0.0904, 32_h1=0.0893, 32_l2=0.0511, 64_h1=0.1743, 64_l2=0.0662\n",
      "[20] time=2.28, avg_loss=1.7599, train_err=0.0880, 32_h1=0.0900, 32_l2=0.0482, 64_h1=0.1608, 64_l2=0.0573\n",
      "[21] time=2.34, avg_loss=1.7755, train_err=0.0888, 32_h1=0.0870, 32_l2=0.0444, 64_h1=0.1651, 64_l2=0.0564\n",
      "[22] time=2.19, avg_loss=1.7535, train_err=0.0877, 32_h1=0.0992, 32_l2=0.0623, 64_h1=0.1730, 64_l2=0.0762\n",
      "[23] time=2.01, avg_loss=1.7451, train_err=0.0873, 32_h1=0.0947, 32_l2=0.0575, 64_h1=0.1728, 64_l2=0.0748\n",
      "[24] time=2.01, avg_loss=1.7856, train_err=0.0893, 32_h1=0.0873, 32_l2=0.0452, 64_h1=0.1588, 64_l2=0.0613\n",
      "[25] time=2.13, avg_loss=1.6786, train_err=0.0839, 32_h1=0.0943, 32_l2=0.0594, 64_h1=0.1621, 64_l2=0.0673\n",
      "[26] time=2.18, avg_loss=1.6829, train_err=0.0841, 32_h1=0.0839, 32_l2=0.0437, 64_h1=0.1724, 64_l2=0.0596\n",
      "[27] time=2.18, avg_loss=1.7252, train_err=0.0863, 32_h1=0.0896, 32_l2=0.0488, 64_h1=0.1691, 64_l2=0.0653\n",
      "[28] time=2.15, avg_loss=1.6515, train_err=0.0826, 32_h1=0.0836, 32_l2=0.0434, 64_h1=0.1550, 64_l2=0.0535\n",
      "[29] time=2.18, avg_loss=1.6638, train_err=0.0832, 32_h1=0.0833, 32_l2=0.0423, 64_h1=0.1599, 64_l2=0.0573\n",
      "[30] time=2.12, avg_loss=1.6364, train_err=0.0818, 32_h1=0.0818, 32_l2=0.0412, 64_h1=0.1678, 64_l2=0.0571\n",
      "[31] time=2.00, avg_loss=1.6931, train_err=0.0847, 32_h1=0.0933, 32_l2=0.0546, 64_h1=0.1737, 64_l2=0.0669\n",
      "[32] time=2.01, avg_loss=1.6796, train_err=0.0840, 32_h1=0.0800, 32_l2=0.0400, 64_h1=0.1613, 64_l2=0.0540\n",
      "[33] time=2.18, avg_loss=1.6117, train_err=0.0806, 32_h1=0.0901, 32_l2=0.0486, 64_h1=0.1719, 64_l2=0.0633\n",
      "[34] time=2.15, avg_loss=1.6164, train_err=0.0808, 32_h1=0.0821, 32_l2=0.0440, 64_h1=0.1519, 64_l2=0.0543\n",
      "[35] time=2.16, avg_loss=1.5649, train_err=0.0782, 32_h1=0.0865, 32_l2=0.0530, 64_h1=0.1617, 64_l2=0.0658\n",
      "[36] time=2.12, avg_loss=1.5825, train_err=0.0791, 32_h1=0.0864, 32_l2=0.0540, 64_h1=0.1659, 64_l2=0.0649\n",
      "[37] time=2.02, avg_loss=1.6005, train_err=0.0800, 32_h1=0.0811, 32_l2=0.0417, 64_h1=0.1660, 64_l2=0.0595\n",
      "[38] time=2.05, avg_loss=1.5605, train_err=0.0780, 32_h1=0.0802, 32_l2=0.0411, 64_h1=0.1536, 64_l2=0.0549\n",
      "[39] time=2.07, avg_loss=1.5638, train_err=0.0782, 32_h1=0.0792, 32_l2=0.0399, 64_h1=0.1641, 64_l2=0.0602\n",
      "[40] time=2.02, avg_loss=1.5856, train_err=0.0793, 32_h1=0.0817, 32_l2=0.0447, 64_h1=0.1661, 64_l2=0.0611\n",
      "[41] time=2.19, avg_loss=1.5934, train_err=0.0797, 32_h1=0.0848, 32_l2=0.0480, 64_h1=0.1662, 64_l2=0.0621\n",
      "[42] time=2.12, avg_loss=1.5566, train_err=0.0778, 32_h1=0.0817, 32_l2=0.0460, 64_h1=0.1644, 64_l2=0.0582\n",
      "[43] time=2.17, avg_loss=1.5158, train_err=0.0758, 32_h1=0.0786, 32_l2=0.0390, 64_h1=0.1580, 64_l2=0.0544\n",
      "[44] time=2.06, avg_loss=1.5108, train_err=0.0755, 32_h1=0.0802, 32_l2=0.0433, 64_h1=0.1605, 64_l2=0.0576\n",
      "[45] time=2.11, avg_loss=1.5560, train_err=0.0778, 32_h1=0.0789, 32_l2=0.0412, 64_h1=0.1597, 64_l2=0.0586\n",
      "[46] time=2.09, avg_loss=1.5441, train_err=0.0772, 32_h1=0.0831, 32_l2=0.0423, 64_h1=0.1699, 64_l2=0.0539\n",
      "[47] time=2.02, avg_loss=1.5267, train_err=0.0763, 32_h1=0.0773, 32_l2=0.0381, 64_h1=0.1523, 64_l2=0.0505\n",
      "[48] time=2.14, avg_loss=1.5468, train_err=0.0773, 32_h1=0.0836, 32_l2=0.0442, 64_h1=0.1554, 64_l2=0.0566\n",
      "[49] time=2.07, avg_loss=1.4990, train_err=0.0749, 32_h1=0.0815, 32_l2=0.0438, 64_h1=0.1584, 64_l2=0.0569\n",
      "[50] time=2.00, avg_loss=1.5170, train_err=0.0759, 32_h1=0.0810, 32_l2=0.0443, 64_h1=0.1616, 64_l2=0.0565\n",
      "[51] time=2.22, avg_loss=1.5395, train_err=0.0770, 32_h1=0.0972, 32_l2=0.0629, 64_h1=0.1708, 64_l2=0.0711\n",
      "[52] time=2.38, avg_loss=1.5341, train_err=0.0767, 32_h1=0.0758, 32_l2=0.0369, 64_h1=0.1588, 64_l2=0.0537\n",
      "[53] time=2.31, avg_loss=1.4996, train_err=0.0750, 32_h1=0.0827, 32_l2=0.0455, 64_h1=0.1549, 64_l2=0.0589\n",
      "[54] time=2.31, avg_loss=1.4699, train_err=0.0735, 32_h1=0.0783, 32_l2=0.0395, 64_h1=0.1660, 64_l2=0.0565\n",
      "[55] time=2.29, avg_loss=1.4735, train_err=0.0737, 32_h1=0.0783, 32_l2=0.0419, 64_h1=0.1586, 64_l2=0.0533\n",
      "[56] time=2.30, avg_loss=1.4624, train_err=0.0731, 32_h1=0.0789, 32_l2=0.0410, 64_h1=0.1615, 64_l2=0.0535\n",
      "[57] time=2.30, avg_loss=1.5004, train_err=0.0750, 32_h1=0.0792, 32_l2=0.0432, 64_h1=0.1654, 64_l2=0.0636\n",
      "[58] time=2.27, avg_loss=1.4770, train_err=0.0739, 32_h1=0.0757, 32_l2=0.0371, 64_h1=0.1594, 64_l2=0.0516\n",
      "[59] time=2.28, avg_loss=1.4935, train_err=0.0747, 32_h1=0.0766, 32_l2=0.0376, 64_h1=0.1567, 64_l2=0.0558\n",
      "[60] time=2.30, avg_loss=1.4339, train_err=0.0717, 32_h1=0.0764, 32_l2=0.0376, 64_h1=0.1631, 64_l2=0.0583\n",
      "[61] time=2.34, avg_loss=1.4920, train_err=0.0746, 32_h1=0.0959, 32_l2=0.0715, 64_h1=0.1754, 64_l2=0.0810\n",
      "[62] time=2.32, avg_loss=1.4537, train_err=0.0727, 32_h1=0.0754, 32_l2=0.0367, 64_h1=0.1586, 64_l2=0.0546\n",
      "[63] time=2.35, avg_loss=1.4436, train_err=0.0722, 32_h1=0.0866, 32_l2=0.0534, 64_h1=0.1632, 64_l2=0.0674\n",
      "[64] time=2.31, avg_loss=1.4679, train_err=0.0734, 32_h1=0.0773, 32_l2=0.0387, 64_h1=0.1619, 64_l2=0.0513\n",
      "[65] time=2.31, avg_loss=1.4422, train_err=0.0721, 32_h1=0.0757, 32_l2=0.0371, 64_h1=0.1605, 64_l2=0.0533\n",
      "[66] time=2.29, avg_loss=1.4118, train_err=0.0706, 32_h1=0.0762, 32_l2=0.0379, 64_h1=0.1535, 64_l2=0.0469\n",
      "[67] time=2.32, avg_loss=1.4055, train_err=0.0703, 32_h1=0.0759, 32_l2=0.0378, 64_h1=0.1547, 64_l2=0.0513\n",
      "[68] time=2.27, avg_loss=1.4242, train_err=0.0712, 32_h1=0.0811, 32_l2=0.0443, 64_h1=0.1567, 64_l2=0.0576\n",
      "[69] time=2.29, avg_loss=1.4481, train_err=0.0724, 32_h1=0.0782, 32_l2=0.0403, 64_h1=0.1658, 64_l2=0.0552\n",
      "[70] time=2.28, avg_loss=1.4189, train_err=0.0709, 32_h1=0.0742, 32_l2=0.0362, 64_h1=0.1568, 64_l2=0.0519\n",
      "[71] time=2.33, avg_loss=1.4022, train_err=0.0701, 32_h1=0.0761, 32_l2=0.0387, 64_h1=0.1585, 64_l2=0.0579\n",
      "[72] time=2.30, avg_loss=1.4002, train_err=0.0700, 32_h1=0.0765, 32_l2=0.0394, 64_h1=0.1668, 64_l2=0.0555\n",
      "[73] time=2.33, avg_loss=1.4111, train_err=0.0706, 32_h1=0.0808, 32_l2=0.0447, 64_h1=0.1583, 64_l2=0.0573\n",
      "[74] time=2.30, avg_loss=1.4136, train_err=0.0707, 32_h1=0.0806, 32_l2=0.0447, 64_h1=0.1550, 64_l2=0.0564\n",
      "[75] time=2.38, avg_loss=1.3993, train_err=0.0700, 32_h1=0.0748, 32_l2=0.0380, 64_h1=0.1606, 64_l2=0.0513\n",
      "[76] time=2.35, avg_loss=1.4188, train_err=0.0709, 32_h1=0.0812, 32_l2=0.0450, 64_h1=0.1677, 64_l2=0.0572\n",
      "[77] time=2.31, avg_loss=1.3957, train_err=0.0698, 32_h1=0.0736, 32_l2=0.0352, 64_h1=0.1621, 64_l2=0.0534\n",
      "[78] time=2.33, avg_loss=1.3702, train_err=0.0685, 32_h1=0.0732, 32_l2=0.0361, 64_h1=0.1609, 64_l2=0.0548\n",
      "[79] time=2.29, avg_loss=1.3521, train_err=0.0676, 32_h1=0.0787, 32_l2=0.0395, 64_h1=0.1692, 64_l2=0.0583\n",
      "[80] time=2.24, avg_loss=1.4187, train_err=0.0709, 32_h1=0.0746, 32_l2=0.0355, 64_h1=0.1682, 64_l2=0.0564\n",
      "[81] time=2.30, avg_loss=1.3719, train_err=0.0686, 32_h1=0.0730, 32_l2=0.0349, 64_h1=0.1606, 64_l2=0.0534\n",
      "[82] time=2.28, avg_loss=1.3652, train_err=0.0683, 32_h1=0.0728, 32_l2=0.0348, 64_h1=0.1578, 64_l2=0.0495\n",
      "[83] time=2.37, avg_loss=1.3628, train_err=0.0681, 32_h1=0.0735, 32_l2=0.0357, 64_h1=0.1565, 64_l2=0.0495\n",
      "[84] time=2.34, avg_loss=1.3863, train_err=0.0693, 32_h1=0.0740, 32_l2=0.0363, 64_h1=0.1616, 64_l2=0.0554\n",
      "[85] time=2.29, avg_loss=1.4005, train_err=0.0700, 32_h1=0.0790, 32_l2=0.0422, 64_h1=0.1710, 64_l2=0.0599\n",
      "[86] time=2.29, avg_loss=1.3994, train_err=0.0700, 32_h1=0.0861, 32_l2=0.0525, 64_h1=0.1610, 64_l2=0.0652\n",
      "[87] time=2.28, avg_loss=1.3985, train_err=0.0699, 32_h1=0.0747, 32_l2=0.0370, 64_h1=0.1571, 64_l2=0.0487\n",
      "[88] time=2.30, avg_loss=1.3631, train_err=0.0682, 32_h1=0.0749, 32_l2=0.0371, 64_h1=0.1596, 64_l2=0.0539\n",
      "[89] time=2.32, avg_loss=1.3485, train_err=0.0674, 32_h1=0.0819, 32_l2=0.0482, 64_h1=0.1619, 64_l2=0.0618\n",
      "[90] time=2.30, avg_loss=1.3619, train_err=0.0681, 32_h1=0.0735, 32_l2=0.0348, 64_h1=0.1558, 64_l2=0.0516\n",
      "[91] time=2.10, avg_loss=1.3303, train_err=0.0665, 32_h1=0.0733, 32_l2=0.0357, 64_h1=0.1599, 64_l2=0.0495\n",
      "[92] time=2.08, avg_loss=1.3244, train_err=0.0662, 32_h1=0.0758, 32_l2=0.0398, 64_h1=0.1630, 64_l2=0.0569\n",
      "[93] time=2.07, avg_loss=1.3238, train_err=0.0662, 32_h1=0.0732, 32_l2=0.0362, 64_h1=0.1638, 64_l2=0.0573\n",
      "[94] time=2.01, avg_loss=1.3316, train_err=0.0666, 32_h1=0.0765, 32_l2=0.0404, 64_h1=0.1643, 64_l2=0.0573\n",
      "[95] time=2.02, avg_loss=1.3691, train_err=0.0685, 32_h1=0.0731, 32_l2=0.0355, 64_h1=0.1611, 64_l2=0.0537\n",
      "[96] time=2.02, avg_loss=1.3168, train_err=0.0658, 32_h1=0.0741, 32_l2=0.0369, 64_h1=0.1654, 64_l2=0.0564\n",
      "[97] time=2.05, avg_loss=1.3263, train_err=0.0663, 32_h1=0.0758, 32_l2=0.0403, 64_h1=0.1705, 64_l2=0.0611\n",
      "[98] time=2.16, avg_loss=1.3243, train_err=0.0662, 32_h1=0.0756, 32_l2=0.0378, 64_h1=0.1639, 64_l2=0.0593\n",
      "[99] time=2.03, avg_loss=1.3315, train_err=0.0666, 32_h1=0.0760, 32_l2=0.0391, 64_h1=0.1604, 64_l2=0.0560\n",
      "[100] time=2.01, avg_loss=1.3256, train_err=0.0663, 32_h1=0.0734, 32_l2=0.0363, 64_h1=0.1600, 64_l2=0.0483\n",
      "[101] time=2.04, avg_loss=1.3164, train_err=0.0658, 32_h1=0.0758, 32_l2=0.0384, 64_h1=0.1643, 64_l2=0.0610\n",
      "[102] time=2.18, avg_loss=1.3505, train_err=0.0675, 32_h1=0.0769, 32_l2=0.0401, 64_h1=0.1552, 64_l2=0.0486\n",
      "[103] time=2.18, avg_loss=1.3213, train_err=0.0661, 32_h1=0.0732, 32_l2=0.0363, 64_h1=0.1622, 64_l2=0.0551\n",
      "[104] time=2.15, avg_loss=1.3213, train_err=0.0661, 32_h1=0.0785, 32_l2=0.0438, 64_h1=0.1648, 64_l2=0.0604\n",
      "[105] time=2.04, avg_loss=1.3104, train_err=0.0655, 32_h1=0.0711, 32_l2=0.0330, 64_h1=0.1587, 64_l2=0.0512\n",
      "[106] time=2.06, avg_loss=1.2788, train_err=0.0639, 32_h1=0.0722, 32_l2=0.0346, 64_h1=0.1597, 64_l2=0.0520\n",
      "[107] time=2.00, avg_loss=1.3045, train_err=0.0652, 32_h1=0.0721, 32_l2=0.0346, 64_h1=0.1616, 64_l2=0.0533\n",
      "[108] time=2.00, avg_loss=1.2817, train_err=0.0641, 32_h1=0.0776, 32_l2=0.0437, 64_h1=0.1645, 64_l2=0.0575\n",
      "[109] time=2.01, avg_loss=1.2828, train_err=0.0641, 32_h1=0.0738, 32_l2=0.0365, 64_h1=0.1634, 64_l2=0.0549\n",
      "[110] time=2.15, avg_loss=1.2892, train_err=0.0645, 32_h1=0.0726, 32_l2=0.0341, 64_h1=0.1606, 64_l2=0.0533\n",
      "[111] time=2.15, avg_loss=1.2870, train_err=0.0643, 32_h1=0.0739, 32_l2=0.0346, 64_h1=0.1686, 64_l2=0.0530\n",
      "[112] time=2.19, avg_loss=1.2727, train_err=0.0636, 32_h1=0.0753, 32_l2=0.0375, 64_h1=0.1657, 64_l2=0.0570\n",
      "[113] time=2.06, avg_loss=1.2774, train_err=0.0639, 32_h1=0.0729, 32_l2=0.0366, 64_h1=0.1581, 64_l2=0.0518\n",
      "[114] time=2.03, avg_loss=1.2742, train_err=0.0637, 32_h1=0.0744, 32_l2=0.0364, 64_h1=0.1667, 64_l2=0.0541\n",
      "[115] time=2.02, avg_loss=1.3058, train_err=0.0653, 32_h1=0.0737, 32_l2=0.0367, 64_h1=0.1539, 64_l2=0.0501\n",
      "[116] time=2.01, avg_loss=1.2816, train_err=0.0641, 32_h1=0.0762, 32_l2=0.0401, 64_h1=0.1606, 64_l2=0.0542\n",
      "[117] time=2.01, avg_loss=1.2751, train_err=0.0638, 32_h1=0.0777, 32_l2=0.0413, 64_h1=0.1566, 64_l2=0.0543\n",
      "[118] time=2.02, avg_loss=1.2755, train_err=0.0638, 32_h1=0.0725, 32_l2=0.0340, 64_h1=0.1582, 64_l2=0.0498\n",
      "[119] time=2.01, avg_loss=1.2920, train_err=0.0646, 32_h1=0.0744, 32_l2=0.0367, 64_h1=0.1667, 64_l2=0.0543\n",
      "[120] time=2.03, avg_loss=1.2820, train_err=0.0641, 32_h1=0.0721, 32_l2=0.0340, 64_h1=0.1609, 64_l2=0.0527\n",
      "[121] time=2.41, avg_loss=1.2530, train_err=0.0627, 32_h1=0.0765, 32_l2=0.0412, 64_h1=0.1655, 64_l2=0.0550\n",
      "[122] time=2.35, avg_loss=1.2552, train_err=0.0628, 32_h1=0.0733, 32_l2=0.0347, 64_h1=0.1648, 64_l2=0.0537\n",
      "[123] time=2.28, avg_loss=1.2442, train_err=0.0622, 32_h1=0.0725, 32_l2=0.0347, 64_h1=0.1617, 64_l2=0.0563\n",
      "[124] time=2.29, avg_loss=1.2428, train_err=0.0621, 32_h1=0.0734, 32_l2=0.0352, 64_h1=0.1553, 64_l2=0.0520\n",
      "[125] time=2.23, avg_loss=1.2541, train_err=0.0627, 32_h1=0.0735, 32_l2=0.0354, 64_h1=0.1619, 64_l2=0.0511\n",
      "[126] time=2.29, avg_loss=1.2524, train_err=0.0626, 32_h1=0.0726, 32_l2=0.0343, 64_h1=0.1629, 64_l2=0.0521\n",
      "[127] time=2.28, avg_loss=1.2375, train_err=0.0619, 32_h1=0.0726, 32_l2=0.0352, 64_h1=0.1653, 64_l2=0.0563\n",
      "[128] time=2.25, avg_loss=1.2439, train_err=0.0622, 32_h1=0.0735, 32_l2=0.0353, 64_h1=0.1573, 64_l2=0.0476\n",
      "[129] time=2.31, avg_loss=1.2367, train_err=0.0618, 32_h1=0.0747, 32_l2=0.0372, 64_h1=0.1603, 64_l2=0.0533\n",
      "[130] time=2.27, avg_loss=1.2252, train_err=0.0613, 32_h1=0.0739, 32_l2=0.0357, 64_h1=0.1640, 64_l2=0.0558\n",
      "[131] time=2.31, avg_loss=1.2224, train_err=0.0611, 32_h1=0.0732, 32_l2=0.0341, 64_h1=0.1633, 64_l2=0.0510\n",
      "[132] time=2.24, avg_loss=1.2306, train_err=0.0615, 32_h1=0.0728, 32_l2=0.0345, 64_h1=0.1609, 64_l2=0.0492\n",
      "[133] time=2.24, avg_loss=1.2275, train_err=0.0614, 32_h1=0.0759, 32_l2=0.0389, 64_h1=0.1641, 64_l2=0.0567\n",
      "[134] time=2.33, avg_loss=1.2218, train_err=0.0611, 32_h1=0.0738, 32_l2=0.0373, 64_h1=0.1634, 64_l2=0.0537\n",
      "[135] time=2.29, avg_loss=1.2284, train_err=0.0614, 32_h1=0.0736, 32_l2=0.0360, 64_h1=0.1630, 64_l2=0.0557\n",
      "[136] time=2.32, avg_loss=1.2211, train_err=0.0611, 32_h1=0.0767, 32_l2=0.0382, 64_h1=0.1671, 64_l2=0.0551\n",
      "[137] time=2.32, avg_loss=1.2310, train_err=0.0615, 32_h1=0.0748, 32_l2=0.0366, 64_h1=0.1712, 64_l2=0.0554\n",
      "[138] time=2.31, avg_loss=1.2118, train_err=0.0606, 32_h1=0.0726, 32_l2=0.0339, 64_h1=0.1634, 64_l2=0.0511\n",
      "[139] time=2.29, avg_loss=1.1881, train_err=0.0594, 32_h1=0.0733, 32_l2=0.0348, 64_h1=0.1636, 64_l2=0.0523\n",
      "[140] time=2.30, avg_loss=1.2173, train_err=0.0609, 32_h1=0.0732, 32_l2=0.0345, 64_h1=0.1650, 64_l2=0.0530\n",
      "[141] time=2.28, avg_loss=1.2035, train_err=0.0602, 32_h1=0.0727, 32_l2=0.0339, 64_h1=0.1621, 64_l2=0.0503\n",
      "[142] time=2.27, avg_loss=1.1888, train_err=0.0594, 32_h1=0.0734, 32_l2=0.0354, 64_h1=0.1621, 64_l2=0.0518\n",
      "[143] time=2.31, avg_loss=1.1850, train_err=0.0592, 32_h1=0.0732, 32_l2=0.0350, 64_h1=0.1636, 64_l2=0.0515\n",
      "[144] time=2.43, avg_loss=1.1718, train_err=0.0586, 32_h1=0.0732, 32_l2=0.0347, 64_h1=0.1651, 64_l2=0.0499\n",
      "[145] time=2.34, avg_loss=1.1831, train_err=0.0592, 32_h1=0.0728, 32_l2=0.0340, 64_h1=0.1629, 64_l2=0.0519\n",
      "[146] time=2.31, avg_loss=1.1743, train_err=0.0587, 32_h1=0.0732, 32_l2=0.0341, 64_h1=0.1661, 64_l2=0.0531\n",
      "[147] time=2.26, avg_loss=1.1770, train_err=0.0589, 32_h1=0.0736, 32_l2=0.0347, 64_h1=0.1625, 64_l2=0.0526\n",
      "[148] time=2.31, avg_loss=1.1613, train_err=0.0581, 32_h1=0.0755, 32_l2=0.0368, 64_h1=0.1677, 64_l2=0.0560\n",
      "[149] time=2.33, avg_loss=1.1748, train_err=0.0587, 32_h1=0.0746, 32_l2=0.0353, 64_h1=0.1633, 64_l2=0.0496\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.4\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 290385\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(25, 25, 5, 5))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(25, 25, 5, 5))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(25, 25, 5, 5))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(25, 25, 5, 5))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(25, 25, 5, 5))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(25, 25, 5, 5))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(25, 25, 5, 5))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(25, 25, 5, 5))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f97514244c0>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f975765aa30>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f975765aa30>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f983c59d4f0>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.30, avg_loss=10.4872, train_err=0.5244, 32_h1=0.3238, 32_l2=0.2271, 64_h1=0.3693, 64_l2=0.2261\n",
      "[1] time=2.29, avg_loss=4.8841, train_err=0.2442, 32_h1=0.2280, 32_l2=0.1572, 64_h1=0.2817, 64_l2=0.1631\n",
      "[2] time=2.30, avg_loss=3.8975, train_err=0.1949, 32_h1=0.1685, 32_l2=0.1071, 64_h1=0.2316, 64_l2=0.1112\n",
      "[3] time=2.33, avg_loss=3.3321, train_err=0.1666, 32_h1=0.1497, 32_l2=0.0927, 64_h1=0.2168, 64_l2=0.1000\n",
      "[4] time=2.34, avg_loss=3.0327, train_err=0.1516, 32_h1=0.1529, 32_l2=0.1084, 64_h1=0.2090, 64_l2=0.1101\n",
      "[5] time=2.30, avg_loss=2.7864, train_err=0.1393, 32_h1=0.1527, 32_l2=0.1058, 64_h1=0.2215, 64_l2=0.1099\n",
      "[6] time=2.30, avg_loss=2.5093, train_err=0.1255, 32_h1=0.1233, 32_l2=0.0755, 64_h1=0.1949, 64_l2=0.0830\n",
      "[7] time=2.30, avg_loss=2.4532, train_err=0.1227, 32_h1=0.1286, 32_l2=0.0902, 64_h1=0.1955, 64_l2=0.1015\n",
      "[8] time=2.34, avg_loss=2.2172, train_err=0.1109, 32_h1=0.1219, 32_l2=0.0794, 64_h1=0.2036, 64_l2=0.0879\n",
      "[9] time=2.35, avg_loss=2.1762, train_err=0.1088, 32_h1=0.1026, 32_l2=0.0576, 64_h1=0.1874, 64_l2=0.0703\n",
      "[10] time=2.33, avg_loss=2.0722, train_err=0.1036, 32_h1=0.1179, 32_l2=0.0822, 64_h1=0.1946, 64_l2=0.0965\n",
      "[11] time=2.14, avg_loss=2.0670, train_err=0.1033, 32_h1=0.1005, 32_l2=0.0594, 64_h1=0.1765, 64_l2=0.0717\n",
      "[12] time=2.19, avg_loss=1.9458, train_err=0.0973, 32_h1=0.0976, 32_l2=0.0547, 64_h1=0.1723, 64_l2=0.0696\n",
      "[13] time=2.21, avg_loss=1.9737, train_err=0.0987, 32_h1=0.1028, 32_l2=0.0603, 64_h1=0.1725, 64_l2=0.0672\n",
      "[14] time=2.20, avg_loss=1.8767, train_err=0.0938, 32_h1=0.0991, 32_l2=0.0667, 64_h1=0.1742, 64_l2=0.0740\n",
      "[15] time=2.11, avg_loss=1.9886, train_err=0.0994, 32_h1=0.0924, 32_l2=0.0496, 64_h1=0.1693, 64_l2=0.0621\n",
      "[16] time=2.20, avg_loss=1.8250, train_err=0.0913, 32_h1=0.0917, 32_l2=0.0491, 64_h1=0.1793, 64_l2=0.0641\n",
      "[17] time=2.18, avg_loss=1.8374, train_err=0.0919, 32_h1=0.1032, 32_l2=0.0688, 64_h1=0.1746, 64_l2=0.0821\n",
      "[18] time=2.15, avg_loss=1.8184, train_err=0.0909, 32_h1=0.0969, 32_l2=0.0631, 64_h1=0.1635, 64_l2=0.0709\n",
      "[19] time=2.13, avg_loss=1.8360, train_err=0.0918, 32_h1=0.0983, 32_l2=0.0623, 64_h1=0.1750, 64_l2=0.0811\n",
      "[20] time=2.03, avg_loss=1.7576, train_err=0.0879, 32_h1=0.0930, 32_l2=0.0552, 64_h1=0.1733, 64_l2=0.0725\n",
      "[21] time=2.03, avg_loss=1.7180, train_err=0.0859, 32_h1=0.0845, 32_l2=0.0445, 64_h1=0.1654, 64_l2=0.0583\n",
      "[22] time=2.07, avg_loss=1.6930, train_err=0.0847, 32_h1=0.0885, 32_l2=0.0466, 64_h1=0.1732, 64_l2=0.0626\n",
      "[23] time=2.02, avg_loss=1.7800, train_err=0.0890, 32_h1=0.0849, 32_l2=0.0454, 64_h1=0.1658, 64_l2=0.0568\n",
      "[24] time=2.08, avg_loss=1.6740, train_err=0.0837, 32_h1=0.0874, 32_l2=0.0487, 64_h1=0.1701, 64_l2=0.0676\n",
      "[25] time=2.13, avg_loss=1.6510, train_err=0.0826, 32_h1=0.0845, 32_l2=0.0470, 64_h1=0.1608, 64_l2=0.0554\n",
      "[26] time=2.14, avg_loss=1.7034, train_err=0.0852, 32_h1=0.0981, 32_l2=0.0559, 64_h1=0.1615, 64_l2=0.0691\n",
      "[27] time=2.09, avg_loss=1.6897, train_err=0.0845, 32_h1=0.0924, 32_l2=0.0544, 64_h1=0.1669, 64_l2=0.0663\n",
      "[28] time=2.02, avg_loss=1.6984, train_err=0.0849, 32_h1=0.0837, 32_l2=0.0432, 64_h1=0.1707, 64_l2=0.0617\n",
      "[29] time=2.02, avg_loss=1.6273, train_err=0.0814, 32_h1=0.0839, 32_l2=0.0449, 64_h1=0.1645, 64_l2=0.0563\n",
      "[30] time=2.03, avg_loss=1.6617, train_err=0.0831, 32_h1=0.0914, 32_l2=0.0551, 64_h1=0.1523, 64_l2=0.0645\n",
      "[31] time=2.05, avg_loss=1.6251, train_err=0.0813, 32_h1=0.0787, 32_l2=0.0379, 64_h1=0.1633, 64_l2=0.0565\n",
      "[32] time=2.16, avg_loss=1.6146, train_err=0.0807, 32_h1=0.0862, 32_l2=0.0503, 64_h1=0.1622, 64_l2=0.0608\n",
      "[33] time=2.10, avg_loss=1.5717, train_err=0.0786, 32_h1=0.0802, 32_l2=0.0395, 64_h1=0.1596, 64_l2=0.0540\n",
      "[34] time=2.19, avg_loss=1.5891, train_err=0.0795, 32_h1=0.1078, 32_l2=0.0788, 64_h1=0.1866, 64_l2=0.0843\n",
      "[35] time=2.21, avg_loss=1.6303, train_err=0.0815, 32_h1=0.0840, 32_l2=0.0495, 64_h1=0.1617, 64_l2=0.0591\n",
      "[36] time=2.03, avg_loss=1.5941, train_err=0.0797, 32_h1=0.0807, 32_l2=0.0457, 64_h1=0.1612, 64_l2=0.0585\n",
      "[37] time=2.08, avg_loss=1.5672, train_err=0.0784, 32_h1=0.0836, 32_l2=0.0456, 64_h1=0.1642, 64_l2=0.0500\n",
      "[38] time=2.05, avg_loss=1.5728, train_err=0.0786, 32_h1=0.0823, 32_l2=0.0438, 64_h1=0.1660, 64_l2=0.0602\n",
      "[39] time=2.03, avg_loss=1.5498, train_err=0.0775, 32_h1=0.0784, 32_l2=0.0402, 64_h1=0.1621, 64_l2=0.0557\n",
      "[40] time=2.40, avg_loss=1.5789, train_err=0.0789, 32_h1=0.0789, 32_l2=0.0394, 64_h1=0.1562, 64_l2=0.0518\n",
      "[41] time=2.41, avg_loss=1.5400, train_err=0.0770, 32_h1=0.0795, 32_l2=0.0421, 64_h1=0.1679, 64_l2=0.0584\n",
      "[42] time=2.32, avg_loss=1.5295, train_err=0.0765, 32_h1=0.0806, 32_l2=0.0426, 64_h1=0.1633, 64_l2=0.0568\n",
      "[43] time=2.32, avg_loss=1.5660, train_err=0.0783, 32_h1=0.0825, 32_l2=0.0456, 64_h1=0.1653, 64_l2=0.0584\n",
      "[44] time=2.35, avg_loss=1.5432, train_err=0.0772, 32_h1=0.0770, 32_l2=0.0376, 64_h1=0.1580, 64_l2=0.0510\n",
      "[45] time=2.33, avg_loss=1.5290, train_err=0.0765, 32_h1=0.0788, 32_l2=0.0410, 64_h1=0.1624, 64_l2=0.0549\n",
      "[46] time=2.34, avg_loss=1.5117, train_err=0.0756, 32_h1=0.0781, 32_l2=0.0398, 64_h1=0.1560, 64_l2=0.0505\n",
      "[47] time=2.30, avg_loss=1.5899, train_err=0.0795, 32_h1=0.0789, 32_l2=0.0410, 64_h1=0.1638, 64_l2=0.0633\n",
      "[48] time=2.28, avg_loss=1.4960, train_err=0.0748, 32_h1=0.0846, 32_l2=0.0497, 64_h1=0.1704, 64_l2=0.0700\n",
      "[49] time=2.34, avg_loss=1.5606, train_err=0.0780, 32_h1=0.0773, 32_l2=0.0398, 64_h1=0.1605, 64_l2=0.0528\n",
      "[50] time=2.31, avg_loss=1.4716, train_err=0.0736, 32_h1=0.0804, 32_l2=0.0416, 64_h1=0.1522, 64_l2=0.0476\n",
      "[51] time=2.34, avg_loss=1.5141, train_err=0.0757, 32_h1=0.0788, 32_l2=0.0402, 64_h1=0.1551, 64_l2=0.0548\n",
      "[52] time=2.32, avg_loss=1.4683, train_err=0.0734, 32_h1=0.0767, 32_l2=0.0378, 64_h1=0.1610, 64_l2=0.0565\n",
      "[53] time=2.35, avg_loss=1.4967, train_err=0.0748, 32_h1=0.0762, 32_l2=0.0380, 64_h1=0.1539, 64_l2=0.0525\n",
      "[54] time=2.29, avg_loss=1.4646, train_err=0.0732, 32_h1=0.0819, 32_l2=0.0472, 64_h1=0.1648, 64_l2=0.0607\n",
      "[55] time=2.37, avg_loss=1.4922, train_err=0.0746, 32_h1=0.0773, 32_l2=0.0395, 64_h1=0.1642, 64_l2=0.0574\n",
      "[56] time=2.32, avg_loss=1.5011, train_err=0.0751, 32_h1=0.0771, 32_l2=0.0390, 64_h1=0.1534, 64_l2=0.0524\n",
      "[57] time=2.34, avg_loss=1.4736, train_err=0.0737, 32_h1=0.0776, 32_l2=0.0410, 64_h1=0.1587, 64_l2=0.0506\n",
      "[58] time=2.33, avg_loss=1.4677, train_err=0.0734, 32_h1=0.0833, 32_l2=0.0459, 64_h1=0.1649, 64_l2=0.0555\n",
      "[59] time=2.30, avg_loss=1.5170, train_err=0.0758, 32_h1=0.0776, 32_l2=0.0416, 64_h1=0.1538, 64_l2=0.0571\n",
      "[60] time=2.32, avg_loss=1.4451, train_err=0.0723, 32_h1=0.0837, 32_l2=0.0504, 64_h1=0.1611, 64_l2=0.0678\n",
      "[61] time=2.31, avg_loss=1.4295, train_err=0.0715, 32_h1=0.0765, 32_l2=0.0390, 64_h1=0.1506, 64_l2=0.0484\n",
      "[62] time=2.35, avg_loss=1.4262, train_err=0.0713, 32_h1=0.0764, 32_l2=0.0382, 64_h1=0.1647, 64_l2=0.0592\n",
      "[63] time=2.37, avg_loss=1.4730, train_err=0.0737, 32_h1=0.0757, 32_l2=0.0387, 64_h1=0.1605, 64_l2=0.0551\n",
      "[64] time=2.40, avg_loss=1.4132, train_err=0.0707, 32_h1=0.0752, 32_l2=0.0360, 64_h1=0.1577, 64_l2=0.0514\n",
      "[65] time=2.28, avg_loss=1.4362, train_err=0.0718, 32_h1=0.0776, 32_l2=0.0411, 64_h1=0.1633, 64_l2=0.0604\n",
      "[66] time=2.31, avg_loss=1.4446, train_err=0.0722, 32_h1=0.0766, 32_l2=0.0382, 64_h1=0.1497, 64_l2=0.0459\n",
      "[67] time=2.32, avg_loss=1.4177, train_err=0.0709, 32_h1=0.0771, 32_l2=0.0401, 64_h1=0.1625, 64_l2=0.0527\n",
      "[68] time=2.32, avg_loss=1.4534, train_err=0.0727, 32_h1=0.0854, 32_l2=0.0491, 64_h1=0.1660, 64_l2=0.0662\n",
      "[69] time=2.33, avg_loss=1.4170, train_err=0.0709, 32_h1=0.0755, 32_l2=0.0372, 64_h1=0.1620, 64_l2=0.0535\n",
      "[70] time=2.32, avg_loss=1.4170, train_err=0.0709, 32_h1=0.0779, 32_l2=0.0404, 64_h1=0.1588, 64_l2=0.0527\n",
      "[71] time=2.29, avg_loss=1.4081, train_err=0.0704, 32_h1=0.0784, 32_l2=0.0412, 64_h1=0.1657, 64_l2=0.0554\n",
      "[72] time=2.29, avg_loss=1.4195, train_err=0.0710, 32_h1=0.0771, 32_l2=0.0400, 64_h1=0.1595, 64_l2=0.0487\n",
      "[73] time=2.29, avg_loss=1.4188, train_err=0.0709, 32_h1=0.0805, 32_l2=0.0425, 64_h1=0.1634, 64_l2=0.0540\n",
      "[74] time=2.30, avg_loss=1.4055, train_err=0.0703, 32_h1=0.0828, 32_l2=0.0484, 64_h1=0.1629, 64_l2=0.0617\n",
      "[75] time=2.35, avg_loss=1.4124, train_err=0.0706, 32_h1=0.0744, 32_l2=0.0366, 64_h1=0.1651, 64_l2=0.0574\n",
      "[76] time=2.33, avg_loss=1.3661, train_err=0.0683, 32_h1=0.0796, 32_l2=0.0438, 64_h1=0.1591, 64_l2=0.0613\n",
      "[77] time=2.35, avg_loss=1.3770, train_err=0.0689, 32_h1=0.0762, 32_l2=0.0393, 64_h1=0.1605, 64_l2=0.0555\n",
      "[78] time=2.32, avg_loss=1.3975, train_err=0.0699, 32_h1=0.0742, 32_l2=0.0356, 64_h1=0.1572, 64_l2=0.0547\n",
      "[79] time=2.33, avg_loss=1.3406, train_err=0.0670, 32_h1=0.0771, 32_l2=0.0413, 64_h1=0.1606, 64_l2=0.0589\n",
      "[80] time=2.26, avg_loss=1.4694, train_err=0.0735, 32_h1=0.0918, 32_l2=0.0608, 64_h1=0.1637, 64_l2=0.0740\n",
      "[81] time=2.17, avg_loss=1.3903, train_err=0.0695, 32_h1=0.0760, 32_l2=0.0379, 64_h1=0.1581, 64_l2=0.0525\n",
      "[82] time=2.15, avg_loss=1.3810, train_err=0.0691, 32_h1=0.0756, 32_l2=0.0404, 64_h1=0.1524, 64_l2=0.0563\n",
      "[83] time=2.03, avg_loss=1.3408, train_err=0.0670, 32_h1=0.0757, 32_l2=0.0400, 64_h1=0.1638, 64_l2=0.0580\n",
      "[84] time=2.21, avg_loss=1.3390, train_err=0.0669, 32_h1=0.0773, 32_l2=0.0400, 64_h1=0.1655, 64_l2=0.0612\n",
      "[85] time=2.11, avg_loss=1.3632, train_err=0.0682, 32_h1=0.0732, 32_l2=0.0353, 64_h1=0.1583, 64_l2=0.0525\n",
      "[86] time=2.08, avg_loss=1.3295, train_err=0.0665, 32_h1=0.0779, 32_l2=0.0410, 64_h1=0.1546, 64_l2=0.0550\n",
      "[87] time=2.02, avg_loss=1.3784, train_err=0.0689, 32_h1=0.0762, 32_l2=0.0397, 64_h1=0.1680, 64_l2=0.0577\n",
      "[88] time=2.18, avg_loss=1.3358, train_err=0.0668, 32_h1=0.0770, 32_l2=0.0390, 64_h1=0.1601, 64_l2=0.0538\n",
      "[89] time=2.09, avg_loss=1.3480, train_err=0.0674, 32_h1=0.0760, 32_l2=0.0387, 64_h1=0.1551, 64_l2=0.0515\n",
      "[90] time=2.06, avg_loss=1.3251, train_err=0.0663, 32_h1=0.0756, 32_l2=0.0380, 64_h1=0.1664, 64_l2=0.0574\n",
      "[91] time=2.07, avg_loss=1.3345, train_err=0.0667, 32_h1=0.0783, 32_l2=0.0419, 64_h1=0.1607, 64_l2=0.0557\n",
      "[92] time=2.04, avg_loss=1.3330, train_err=0.0666, 32_h1=0.0807, 32_l2=0.0472, 64_h1=0.1581, 64_l2=0.0569\n",
      "[93] time=2.14, avg_loss=1.3207, train_err=0.0660, 32_h1=0.0738, 32_l2=0.0357, 64_h1=0.1600, 64_l2=0.0496\n",
      "[94] time=2.07, avg_loss=1.3158, train_err=0.0658, 32_h1=0.0738, 32_l2=0.0355, 64_h1=0.1558, 64_l2=0.0484\n",
      "[95] time=2.02, avg_loss=1.3021, train_err=0.0651, 32_h1=0.0737, 32_l2=0.0357, 64_h1=0.1557, 64_l2=0.0531\n",
      "[96] time=2.02, avg_loss=1.3203, train_err=0.0660, 32_h1=0.0733, 32_l2=0.0347, 64_h1=0.1552, 64_l2=0.0478\n",
      "[97] time=2.03, avg_loss=1.3572, train_err=0.0679, 32_h1=0.0748, 32_l2=0.0365, 64_h1=0.1605, 64_l2=0.0561\n",
      "[98] time=2.05, avg_loss=1.3048, train_err=0.0652, 32_h1=0.0747, 32_l2=0.0365, 64_h1=0.1525, 64_l2=0.0498\n",
      "[99] time=2.11, avg_loss=1.2969, train_err=0.0648, 32_h1=0.0770, 32_l2=0.0395, 64_h1=0.1623, 64_l2=0.0568\n",
      "[100] time=2.13, avg_loss=1.2832, train_err=0.0642, 32_h1=0.0767, 32_l2=0.0405, 64_h1=0.1579, 64_l2=0.0545\n",
      "[101] time=2.14, avg_loss=1.2856, train_err=0.0643, 32_h1=0.0762, 32_l2=0.0387, 64_h1=0.1609, 64_l2=0.0590\n",
      "[102] time=2.18, avg_loss=1.3058, train_err=0.0653, 32_h1=0.0744, 32_l2=0.0355, 64_h1=0.1647, 64_l2=0.0532\n",
      "[103] time=2.08, avg_loss=1.3023, train_err=0.0651, 32_h1=0.0733, 32_l2=0.0347, 64_h1=0.1604, 64_l2=0.0506\n",
      "[104] time=2.15, avg_loss=1.2819, train_err=0.0641, 32_h1=0.0772, 32_l2=0.0401, 64_h1=0.1576, 64_l2=0.0509\n",
      "[105] time=2.06, avg_loss=1.2730, train_err=0.0636, 32_h1=0.0738, 32_l2=0.0355, 64_h1=0.1548, 64_l2=0.0512\n",
      "[106] time=2.03, avg_loss=1.2747, train_err=0.0637, 32_h1=0.0759, 32_l2=0.0387, 64_h1=0.1597, 64_l2=0.0557\n",
      "[107] time=2.04, avg_loss=1.2745, train_err=0.0637, 32_h1=0.0822, 32_l2=0.0481, 64_h1=0.1647, 64_l2=0.0580\n",
      "[108] time=2.10, avg_loss=1.3170, train_err=0.0658, 32_h1=0.0736, 32_l2=0.0352, 64_h1=0.1574, 64_l2=0.0514\n",
      "[109] time=2.10, avg_loss=1.2855, train_err=0.0643, 32_h1=0.0750, 32_l2=0.0374, 64_h1=0.1633, 64_l2=0.0554\n",
      "[110] time=2.37, avg_loss=1.2625, train_err=0.0631, 32_h1=0.0756, 32_l2=0.0393, 64_h1=0.1624, 64_l2=0.0579\n",
      "[111] time=2.35, avg_loss=1.2741, train_err=0.0637, 32_h1=0.0749, 32_l2=0.0373, 64_h1=0.1623, 64_l2=0.0549\n",
      "[112] time=2.35, avg_loss=1.2506, train_err=0.0625, 32_h1=0.0749, 32_l2=0.0363, 64_h1=0.1593, 64_l2=0.0542\n",
      "[113] time=2.32, avg_loss=1.2370, train_err=0.0619, 32_h1=0.0737, 32_l2=0.0356, 64_h1=0.1610, 64_l2=0.0543\n",
      "[114] time=2.31, avg_loss=1.2536, train_err=0.0627, 32_h1=0.0761, 32_l2=0.0390, 64_h1=0.1549, 64_l2=0.0539\n",
      "[115] time=2.31, avg_loss=1.2759, train_err=0.0638, 32_h1=0.0748, 32_l2=0.0369, 64_h1=0.1590, 64_l2=0.0546\n",
      "[116] time=2.30, avg_loss=1.2282, train_err=0.0614, 32_h1=0.0750, 32_l2=0.0372, 64_h1=0.1569, 64_l2=0.0524\n",
      "[117] time=2.32, avg_loss=1.2402, train_err=0.0620, 32_h1=0.0756, 32_l2=0.0376, 64_h1=0.1651, 64_l2=0.0531\n",
      "[118] time=2.37, avg_loss=1.2480, train_err=0.0624, 32_h1=0.0749, 32_l2=0.0360, 64_h1=0.1635, 64_l2=0.0503\n",
      "[119] time=2.38, avg_loss=1.2089, train_err=0.0604, 32_h1=0.0753, 32_l2=0.0364, 64_h1=0.1636, 64_l2=0.0523\n",
      "[120] time=2.38, avg_loss=1.2320, train_err=0.0616, 32_h1=0.0756, 32_l2=0.0372, 64_h1=0.1570, 64_l2=0.0518\n",
      "[121] time=2.31, avg_loss=1.2025, train_err=0.0601, 32_h1=0.0734, 32_l2=0.0345, 64_h1=0.1570, 64_l2=0.0492\n",
      "[122] time=2.30, avg_loss=1.2089, train_err=0.0604, 32_h1=0.0757, 32_l2=0.0368, 64_h1=0.1570, 64_l2=0.0510\n",
      "[123] time=2.27, avg_loss=1.2278, train_err=0.0614, 32_h1=0.0771, 32_l2=0.0403, 64_h1=0.1627, 64_l2=0.0551\n",
      "[124] time=2.34, avg_loss=1.2113, train_err=0.0606, 32_h1=0.0768, 32_l2=0.0404, 64_h1=0.1637, 64_l2=0.0558\n",
      "[125] time=2.35, avg_loss=1.1957, train_err=0.0598, 32_h1=0.0792, 32_l2=0.0434, 64_h1=0.1689, 64_l2=0.0594\n",
      "[126] time=2.30, avg_loss=1.2025, train_err=0.0601, 32_h1=0.0762, 32_l2=0.0378, 64_h1=0.1590, 64_l2=0.0491\n",
      "[127] time=2.34, avg_loss=1.1862, train_err=0.0593, 32_h1=0.0748, 32_l2=0.0358, 64_h1=0.1648, 64_l2=0.0548\n",
      "[128] time=2.30, avg_loss=1.2077, train_err=0.0604, 32_h1=0.0807, 32_l2=0.0442, 64_h1=0.1687, 64_l2=0.0586\n",
      "[129] time=2.33, avg_loss=1.2065, train_err=0.0603, 32_h1=0.0777, 32_l2=0.0373, 64_h1=0.1676, 64_l2=0.0549\n",
      "[130] time=2.44, avg_loss=1.1844, train_err=0.0592, 32_h1=0.0748, 32_l2=0.0357, 64_h1=0.1649, 64_l2=0.0541\n",
      "[131] time=2.34, avg_loss=1.1898, train_err=0.0595, 32_h1=0.0781, 32_l2=0.0411, 64_h1=0.1640, 64_l2=0.0527\n",
      "[132] time=2.33, avg_loss=1.1737, train_err=0.0587, 32_h1=0.0771, 32_l2=0.0402, 64_h1=0.1649, 64_l2=0.0589\n",
      "[133] time=2.42, avg_loss=1.1580, train_err=0.0579, 32_h1=0.0750, 32_l2=0.0366, 64_h1=0.1592, 64_l2=0.0516\n",
      "[134] time=2.35, avg_loss=1.1653, train_err=0.0583, 32_h1=0.0753, 32_l2=0.0360, 64_h1=0.1606, 64_l2=0.0511\n",
      "[135] time=2.35, avg_loss=1.1522, train_err=0.0576, 32_h1=0.0768, 32_l2=0.0374, 64_h1=0.1666, 64_l2=0.0520\n",
      "[136] time=2.31, avg_loss=1.1701, train_err=0.0585, 32_h1=0.0771, 32_l2=0.0382, 64_h1=0.1631, 64_l2=0.0559\n",
      "[137] time=2.31, avg_loss=1.1527, train_err=0.0576, 32_h1=0.0754, 32_l2=0.0357, 64_h1=0.1617, 64_l2=0.0503\n",
      "[138] time=2.35, avg_loss=1.1300, train_err=0.0565, 32_h1=0.0754, 32_l2=0.0352, 64_h1=0.1688, 64_l2=0.0529\n",
      "[139] time=2.37, avg_loss=1.1337, train_err=0.0567, 32_h1=0.0770, 32_l2=0.0381, 64_h1=0.1634, 64_l2=0.0521\n",
      "[140] time=2.33, avg_loss=1.1308, train_err=0.0565, 32_h1=0.0768, 32_l2=0.0368, 64_h1=0.1658, 64_l2=0.0553\n",
      "[141] time=2.41, avg_loss=1.1333, train_err=0.0567, 32_h1=0.0753, 32_l2=0.0348, 64_h1=0.1590, 64_l2=0.0504\n",
      "[142] time=2.33, avg_loss=1.1359, train_err=0.0568, 32_h1=0.0771, 32_l2=0.0378, 64_h1=0.1652, 64_l2=0.0572\n",
      "[143] time=2.32, avg_loss=1.1217, train_err=0.0561, 32_h1=0.0757, 32_l2=0.0355, 64_h1=0.1600, 64_l2=0.0524\n",
      "[144] time=2.31, avg_loss=1.1013, train_err=0.0551, 32_h1=0.0756, 32_l2=0.0365, 64_h1=0.1646, 64_l2=0.0532\n",
      "[145] time=2.34, avg_loss=1.1082, train_err=0.0554, 32_h1=0.0769, 32_l2=0.0373, 64_h1=0.1653, 64_l2=0.0538\n",
      "[146] time=2.36, avg_loss=1.1118, train_err=0.0556, 32_h1=0.0774, 32_l2=0.0379, 64_h1=0.1650, 64_l2=0.0522\n",
      "[147] time=2.31, avg_loss=1.0981, train_err=0.0549, 32_h1=0.0771, 32_l2=0.0376, 64_h1=0.1642, 64_l2=0.0547\n",
      "[148] time=2.32, avg_loss=1.0962, train_err=0.0548, 32_h1=0.0779, 32_l2=0.0374, 64_h1=0.1634, 64_l2=0.0507\n",
      "[149] time=2.06, avg_loss=1.1125, train_err=0.0556, 32_h1=0.0762, 32_l2=0.0368, 64_h1=0.1655, 64_l2=0.0549\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.5\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 311809\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(26, 26, 5, 5))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(26, 26, 5, 5))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(26, 26, 5, 5))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(26, 26, 5, 5))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(26, 26, 5, 5))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(26, 26, 5, 5))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(26, 26, 5, 5))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(26, 26, 5, 5))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f975765a1f0>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f975143d820>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f975143d820>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f975143d070>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.18, avg_loss=10.4602, train_err=0.5230, 32_h1=0.3687, 32_l2=0.2570, 64_h1=0.4143, 64_l2=0.2594\n",
      "[1] time=2.07, avg_loss=5.1797, train_err=0.2590, 32_h1=0.2339, 32_l2=0.1600, 64_h1=0.2998, 64_l2=0.1753\n",
      "[2] time=2.20, avg_loss=3.9824, train_err=0.1991, 32_h1=0.1885, 32_l2=0.1290, 64_h1=0.2558, 64_l2=0.1404\n",
      "[3] time=2.19, avg_loss=3.5844, train_err=0.1792, 32_h1=0.1595, 32_l2=0.1018, 64_h1=0.2231, 64_l2=0.1113\n",
      "[4] time=2.11, avg_loss=3.0189, train_err=0.1509, 32_h1=0.1452, 32_l2=0.0905, 64_h1=0.2091, 64_l2=0.0961\n",
      "[5] time=2.03, avg_loss=2.9228, train_err=0.1461, 32_h1=0.1325, 32_l2=0.0818, 64_h1=0.2086, 64_l2=0.0964\n",
      "[6] time=2.05, avg_loss=2.6319, train_err=0.1316, 32_h1=0.1313, 32_l2=0.0882, 64_h1=0.1936, 64_l2=0.0987\n",
      "[7] time=2.17, avg_loss=2.4910, train_err=0.1246, 32_h1=0.1165, 32_l2=0.0684, 64_h1=0.1919, 64_l2=0.0832\n",
      "[8] time=2.19, avg_loss=2.2683, train_err=0.1134, 32_h1=0.1108, 32_l2=0.0650, 64_h1=0.1830, 64_l2=0.0793\n",
      "[9] time=2.18, avg_loss=2.2810, train_err=0.1140, 32_h1=0.1131, 32_l2=0.0688, 64_h1=0.1887, 64_l2=0.0767\n",
      "[10] time=2.19, avg_loss=2.1469, train_err=0.1073, 32_h1=0.1194, 32_l2=0.0868, 64_h1=0.1907, 64_l2=0.0958\n",
      "[11] time=2.19, avg_loss=2.0846, train_err=0.1042, 32_h1=0.1161, 32_l2=0.0805, 64_h1=0.1755, 64_l2=0.0811\n",
      "[12] time=2.07, avg_loss=2.0298, train_err=0.1015, 32_h1=0.0965, 32_l2=0.0511, 64_h1=0.1758, 64_l2=0.0667\n",
      "[13] time=2.04, avg_loss=1.9842, train_err=0.0992, 32_h1=0.1112, 32_l2=0.0768, 64_h1=0.1856, 64_l2=0.0892\n",
      "[14] time=2.13, avg_loss=1.9824, train_err=0.0991, 32_h1=0.1309, 32_l2=0.0947, 64_h1=0.1764, 64_l2=0.0954\n",
      "[15] time=2.18, avg_loss=1.9687, train_err=0.0984, 32_h1=0.0931, 32_l2=0.0522, 64_h1=0.1699, 64_l2=0.0642\n",
      "[16] time=2.17, avg_loss=1.9443, train_err=0.0972, 32_h1=0.1002, 32_l2=0.0576, 64_h1=0.1769, 64_l2=0.0748\n",
      "[17] time=2.19, avg_loss=1.9123, train_err=0.0956, 32_h1=0.1011, 32_l2=0.0612, 64_h1=0.1819, 64_l2=0.0779\n",
      "[18] time=2.16, avg_loss=1.8229, train_err=0.0911, 32_h1=0.0899, 32_l2=0.0502, 64_h1=0.1654, 64_l2=0.0612\n",
      "[19] time=2.09, avg_loss=1.7902, train_err=0.0895, 32_h1=0.0931, 32_l2=0.0601, 64_h1=0.1647, 64_l2=0.0677\n",
      "[20] time=2.10, avg_loss=1.8453, train_err=0.0923, 32_h1=0.0914, 32_l2=0.0507, 64_h1=0.1605, 64_l2=0.0571\n",
      "[21] time=2.11, avg_loss=1.7696, train_err=0.0885, 32_h1=0.0869, 32_l2=0.0452, 64_h1=0.1606, 64_l2=0.0507\n",
      "[22] time=2.01, avg_loss=1.7159, train_err=0.0858, 32_h1=0.0900, 32_l2=0.0487, 64_h1=0.1815, 64_l2=0.0690\n",
      "[23] time=2.08, avg_loss=1.7596, train_err=0.0880, 32_h1=0.0920, 32_l2=0.0562, 64_h1=0.1653, 64_l2=0.0686\n",
      "[24] time=2.14, avg_loss=1.7651, train_err=0.0883, 32_h1=0.0964, 32_l2=0.0566, 64_h1=0.1692, 64_l2=0.0626\n",
      "[25] time=2.04, avg_loss=1.7027, train_err=0.0851, 32_h1=0.0979, 32_l2=0.0659, 64_h1=0.1658, 64_l2=0.0714\n",
      "[26] time=2.18, avg_loss=1.6591, train_err=0.0830, 32_h1=0.0895, 32_l2=0.0501, 64_h1=0.1609, 64_l2=0.0590\n",
      "[27] time=2.17, avg_loss=1.6810, train_err=0.0841, 32_h1=0.0877, 32_l2=0.0497, 64_h1=0.1558, 64_l2=0.0579\n",
      "[28] time=2.39, avg_loss=1.6824, train_err=0.0841, 32_h1=0.0850, 32_l2=0.0456, 64_h1=0.1623, 64_l2=0.0597\n",
      "[29] time=2.40, avg_loss=1.6182, train_err=0.0809, 32_h1=0.0810, 32_l2=0.0415, 64_h1=0.1594, 64_l2=0.0528\n",
      "[30] time=2.33, avg_loss=1.6463, train_err=0.0823, 32_h1=0.0929, 32_l2=0.0567, 64_h1=0.1688, 64_l2=0.0710\n",
      "[31] time=2.31, avg_loss=1.6406, train_err=0.0820, 32_h1=0.0835, 32_l2=0.0442, 64_h1=0.1570, 64_l2=0.0548\n",
      "[32] time=2.31, avg_loss=1.6306, train_err=0.0815, 32_h1=0.0804, 32_l2=0.0411, 64_h1=0.1632, 64_l2=0.0564\n",
      "[33] time=2.31, avg_loss=1.6055, train_err=0.0803, 32_h1=0.0823, 32_l2=0.0422, 64_h1=0.1594, 64_l2=0.0546\n",
      "[34] time=2.37, avg_loss=1.6101, train_err=0.0805, 32_h1=0.0835, 32_l2=0.0459, 64_h1=0.1608, 64_l2=0.0585\n",
      "[35] time=2.32, avg_loss=1.5893, train_err=0.0795, 32_h1=0.0928, 32_l2=0.0613, 64_h1=0.1629, 64_l2=0.0718\n",
      "[36] time=2.29, avg_loss=1.7102, train_err=0.0855, 32_h1=0.0843, 32_l2=0.0462, 64_h1=0.1639, 64_l2=0.0638\n",
      "[37] time=2.28, avg_loss=1.5598, train_err=0.0780, 32_h1=0.0836, 32_l2=0.0441, 64_h1=0.1549, 64_l2=0.0574\n",
      "[38] time=2.30, avg_loss=1.5508, train_err=0.0775, 32_h1=0.0870, 32_l2=0.0529, 64_h1=0.1629, 64_l2=0.0679\n",
      "[39] time=2.32, avg_loss=1.5238, train_err=0.0762, 32_h1=0.0842, 32_l2=0.0458, 64_h1=0.1620, 64_l2=0.0545\n",
      "[40] time=2.29, avg_loss=1.5826, train_err=0.0791, 32_h1=0.0907, 32_l2=0.0537, 64_h1=0.1585, 64_l2=0.0614\n",
      "[41] time=2.33, avg_loss=1.5401, train_err=0.0770, 32_h1=0.0805, 32_l2=0.0406, 64_h1=0.1624, 64_l2=0.0559\n",
      "[42] time=2.30, avg_loss=1.5175, train_err=0.0759, 32_h1=0.0772, 32_l2=0.0380, 64_h1=0.1604, 64_l2=0.0560\n",
      "[43] time=2.33, avg_loss=1.5294, train_err=0.0765, 32_h1=0.0786, 32_l2=0.0411, 64_h1=0.1579, 64_l2=0.0578\n",
      "[44] time=2.33, avg_loss=1.5093, train_err=0.0755, 32_h1=0.0808, 32_l2=0.0426, 64_h1=0.1605, 64_l2=0.0562\n",
      "[45] time=2.32, avg_loss=1.5187, train_err=0.0759, 32_h1=0.0829, 32_l2=0.0456, 64_h1=0.1587, 64_l2=0.0553\n",
      "[46] time=2.29, avg_loss=1.5343, train_err=0.0767, 32_h1=0.0826, 32_l2=0.0464, 64_h1=0.1526, 64_l2=0.0585\n",
      "[47] time=2.32, avg_loss=1.5226, train_err=0.0761, 32_h1=0.0810, 32_l2=0.0443, 64_h1=0.1620, 64_l2=0.0582\n",
      "[48] time=2.32, avg_loss=1.5570, train_err=0.0779, 32_h1=0.0791, 32_l2=0.0396, 64_h1=0.1545, 64_l2=0.0505\n",
      "[49] time=2.29, avg_loss=1.4654, train_err=0.0733, 32_h1=0.0769, 32_l2=0.0382, 64_h1=0.1552, 64_l2=0.0517\n",
      "[50] time=2.35, avg_loss=1.5416, train_err=0.0771, 32_h1=0.0823, 32_l2=0.0442, 64_h1=0.1535, 64_l2=0.0528\n",
      "[51] time=2.46, avg_loss=1.4666, train_err=0.0733, 32_h1=0.0763, 32_l2=0.0381, 64_h1=0.1621, 64_l2=0.0530\n",
      "[52] time=2.36, avg_loss=1.4421, train_err=0.0721, 32_h1=0.0763, 32_l2=0.0386, 64_h1=0.1630, 64_l2=0.0540\n",
      "[53] time=2.34, avg_loss=1.4541, train_err=0.0727, 32_h1=0.0770, 32_l2=0.0393, 64_h1=0.1594, 64_l2=0.0570\n",
      "[54] time=2.35, avg_loss=1.4535, train_err=0.0727, 32_h1=0.0762, 32_l2=0.0379, 64_h1=0.1683, 64_l2=0.0608\n",
      "[55] time=2.31, avg_loss=1.4808, train_err=0.0740, 32_h1=0.0809, 32_l2=0.0465, 64_h1=0.1575, 64_l2=0.0602\n",
      "[56] time=2.35, avg_loss=1.4696, train_err=0.0735, 32_h1=0.0792, 32_l2=0.0411, 64_h1=0.1640, 64_l2=0.0611\n",
      "[57] time=2.33, avg_loss=1.4370, train_err=0.0719, 32_h1=0.0816, 32_l2=0.0460, 64_h1=0.1575, 64_l2=0.0618\n",
      "[58] time=2.29, avg_loss=1.4434, train_err=0.0722, 32_h1=0.0775, 32_l2=0.0409, 64_h1=0.1580, 64_l2=0.0536\n",
      "[59] time=2.38, avg_loss=1.4879, train_err=0.0744, 32_h1=0.0743, 32_l2=0.0360, 64_h1=0.1568, 64_l2=0.0520\n",
      "[60] time=2.29, avg_loss=1.4449, train_err=0.0722, 32_h1=0.0825, 32_l2=0.0467, 64_h1=0.1635, 64_l2=0.0606\n",
      "[61] time=2.28, avg_loss=1.4365, train_err=0.0718, 32_h1=0.0819, 32_l2=0.0450, 64_h1=0.1698, 64_l2=0.0620\n",
      "[62] time=2.32, avg_loss=1.4228, train_err=0.0711, 32_h1=0.0740, 32_l2=0.0348, 64_h1=0.1567, 64_l2=0.0492\n",
      "[63] time=2.33, avg_loss=1.4383, train_err=0.0719, 32_h1=0.0756, 32_l2=0.0370, 64_h1=0.1601, 64_l2=0.0534\n",
      "[64] time=2.28, avg_loss=1.4029, train_err=0.0701, 32_h1=0.0770, 32_l2=0.0394, 64_h1=0.1548, 64_l2=0.0513\n",
      "[65] time=2.30, avg_loss=1.4305, train_err=0.0715, 32_h1=0.0806, 32_l2=0.0421, 64_h1=0.1574, 64_l2=0.0554\n",
      "[66] time=2.32, avg_loss=1.3983, train_err=0.0699, 32_h1=0.0798, 32_l2=0.0430, 64_h1=0.1660, 64_l2=0.0636\n",
      "[67] time=2.24, avg_loss=1.4630, train_err=0.0732, 32_h1=0.0759, 32_l2=0.0373, 64_h1=0.1541, 64_l2=0.0480\n",
      "[68] time=2.01, avg_loss=1.4347, train_err=0.0717, 32_h1=0.0774, 32_l2=0.0392, 64_h1=0.1597, 64_l2=0.0597\n",
      "[69] time=2.12, avg_loss=1.4016, train_err=0.0701, 32_h1=0.0766, 32_l2=0.0392, 64_h1=0.1605, 64_l2=0.0515\n",
      "[70] time=2.15, avg_loss=1.3715, train_err=0.0686, 32_h1=0.0768, 32_l2=0.0384, 64_h1=0.1647, 64_l2=0.0579\n",
      "[71] time=2.16, avg_loss=1.4099, train_err=0.0705, 32_h1=0.0805, 32_l2=0.0456, 64_h1=0.1581, 64_l2=0.0576\n",
      "[72] time=2.18, avg_loss=1.4049, train_err=0.0702, 32_h1=0.0761, 32_l2=0.0386, 64_h1=0.1551, 64_l2=0.0526\n",
      "[73] time=2.17, avg_loss=1.3740, train_err=0.0687, 32_h1=0.0745, 32_l2=0.0358, 64_h1=0.1579, 64_l2=0.0532\n",
      "[74] time=2.15, avg_loss=1.3719, train_err=0.0686, 32_h1=0.0838, 32_l2=0.0508, 64_h1=0.1707, 64_l2=0.0654\n",
      "[75] time=2.07, avg_loss=1.4136, train_err=0.0707, 32_h1=0.0752, 32_l2=0.0374, 64_h1=0.1600, 64_l2=0.0546\n",
      "[76] time=2.02, avg_loss=1.3865, train_err=0.0693, 32_h1=0.0742, 32_l2=0.0365, 64_h1=0.1615, 64_l2=0.0547\n",
      "[77] time=2.03, avg_loss=1.3788, train_err=0.0689, 32_h1=0.0789, 32_l2=0.0440, 64_h1=0.1581, 64_l2=0.0578\n",
      "[78] time=2.07, avg_loss=1.3955, train_err=0.0698, 32_h1=0.0772, 32_l2=0.0396, 64_h1=0.1601, 64_l2=0.0537\n",
      "[79] time=2.05, avg_loss=1.3634, train_err=0.0682, 32_h1=0.0763, 32_l2=0.0388, 64_h1=0.1670, 64_l2=0.0603\n",
      "[80] time=2.10, avg_loss=1.3648, train_err=0.0682, 32_h1=0.0761, 32_l2=0.0389, 64_h1=0.1584, 64_l2=0.0555\n",
      "[81] time=2.02, avg_loss=1.3747, train_err=0.0687, 32_h1=0.0775, 32_l2=0.0418, 64_h1=0.1648, 64_l2=0.0588\n",
      "[82] time=2.09, avg_loss=1.3585, train_err=0.0679, 32_h1=0.0747, 32_l2=0.0368, 64_h1=0.1626, 64_l2=0.0548\n",
      "[83] time=2.05, avg_loss=1.3243, train_err=0.0662, 32_h1=0.0773, 32_l2=0.0419, 64_h1=0.1637, 64_l2=0.0580\n",
      "[84] time=2.15, avg_loss=1.3208, train_err=0.0660, 32_h1=0.0731, 32_l2=0.0349, 64_h1=0.1591, 64_l2=0.0540\n",
      "[85] time=2.19, avg_loss=1.3141, train_err=0.0657, 32_h1=0.0745, 32_l2=0.0378, 64_h1=0.1575, 64_l2=0.0505\n",
      "[86] time=2.19, avg_loss=1.3586, train_err=0.0679, 32_h1=0.0793, 32_l2=0.0423, 64_h1=0.1641, 64_l2=0.0575\n",
      "[87] time=2.17, avg_loss=1.3327, train_err=0.0666, 32_h1=0.0744, 32_l2=0.0373, 64_h1=0.1569, 64_l2=0.0516\n",
      "[88] time=2.19, avg_loss=1.3018, train_err=0.0651, 32_h1=0.0739, 32_l2=0.0358, 64_h1=0.1583, 64_l2=0.0520\n",
      "[89] time=2.19, avg_loss=1.3384, train_err=0.0669, 32_h1=0.0804, 32_l2=0.0452, 64_h1=0.1646, 64_l2=0.0616\n",
      "[90] time=2.15, avg_loss=1.3571, train_err=0.0679, 32_h1=0.0764, 32_l2=0.0382, 64_h1=0.1607, 64_l2=0.0525\n",
      "[91] time=2.14, avg_loss=1.3268, train_err=0.0663, 32_h1=0.0822, 32_l2=0.0532, 64_h1=0.1693, 64_l2=0.0648\n",
      "[92] time=2.18, avg_loss=1.3180, train_err=0.0659, 32_h1=0.0783, 32_l2=0.0417, 64_h1=0.1655, 64_l2=0.0573\n",
      "[93] time=2.18, avg_loss=1.3127, train_err=0.0656, 32_h1=0.0782, 32_l2=0.0434, 64_h1=0.1583, 64_l2=0.0581\n",
      "[94] time=2.14, avg_loss=1.3018, train_err=0.0651, 32_h1=0.0747, 32_l2=0.0359, 64_h1=0.1600, 64_l2=0.0538\n",
      "[95] time=2.01, avg_loss=1.2869, train_err=0.0643, 32_h1=0.0782, 32_l2=0.0418, 64_h1=0.1635, 64_l2=0.0543\n",
      "[96] time=2.14, avg_loss=1.3189, train_err=0.0659, 32_h1=0.0753, 32_l2=0.0385, 64_h1=0.1601, 64_l2=0.0517\n",
      "[97] time=2.41, avg_loss=1.3174, train_err=0.0659, 32_h1=0.0769, 32_l2=0.0387, 64_h1=0.1587, 64_l2=0.0511\n",
      "[98] time=2.29, avg_loss=1.2950, train_err=0.0647, 32_h1=0.0738, 32_l2=0.0359, 64_h1=0.1613, 64_l2=0.0547\n",
      "[99] time=2.28, avg_loss=1.2540, train_err=0.0627, 32_h1=0.0742, 32_l2=0.0363, 64_h1=0.1561, 64_l2=0.0476\n",
      "[100] time=2.36, avg_loss=1.2785, train_err=0.0639, 32_h1=0.0735, 32_l2=0.0354, 64_h1=0.1615, 64_l2=0.0529\n",
      "[101] time=2.33, avg_loss=1.2845, train_err=0.0642, 32_h1=0.0732, 32_l2=0.0343, 64_h1=0.1600, 64_l2=0.0522\n",
      "[102] time=2.33, avg_loss=1.2696, train_err=0.0635, 32_h1=0.0743, 32_l2=0.0350, 64_h1=0.1592, 64_l2=0.0511\n",
      "[103] time=2.37, avg_loss=1.2687, train_err=0.0634, 32_h1=0.0747, 32_l2=0.0361, 64_h1=0.1665, 64_l2=0.0536\n",
      "[104] time=2.30, avg_loss=1.2524, train_err=0.0626, 32_h1=0.0751, 32_l2=0.0360, 64_h1=0.1620, 64_l2=0.0509\n",
      "[105] time=2.30, avg_loss=1.2653, train_err=0.0633, 32_h1=0.0751, 32_l2=0.0365, 64_h1=0.1660, 64_l2=0.0564\n",
      "[106] time=2.30, avg_loss=1.2471, train_err=0.0624, 32_h1=0.0734, 32_l2=0.0340, 64_h1=0.1550, 64_l2=0.0505\n",
      "[107] time=2.25, avg_loss=1.2600, train_err=0.0630, 32_h1=0.0751, 32_l2=0.0368, 64_h1=0.1600, 64_l2=0.0532\n",
      "[108] time=2.35, avg_loss=1.2495, train_err=0.0625, 32_h1=0.0789, 32_l2=0.0408, 64_h1=0.1632, 64_l2=0.0566\n",
      "[109] time=2.37, avg_loss=1.2426, train_err=0.0621, 32_h1=0.0749, 32_l2=0.0353, 64_h1=0.1570, 64_l2=0.0492\n",
      "[110] time=2.32, avg_loss=1.2360, train_err=0.0618, 32_h1=0.0766, 32_l2=0.0386, 64_h1=0.1571, 64_l2=0.0523\n",
      "[111] time=2.32, avg_loss=1.2381, train_err=0.0619, 32_h1=0.0751, 32_l2=0.0363, 64_h1=0.1629, 64_l2=0.0529\n",
      "[112] time=2.32, avg_loss=1.2091, train_err=0.0605, 32_h1=0.0763, 32_l2=0.0379, 64_h1=0.1656, 64_l2=0.0569\n",
      "[113] time=2.30, avg_loss=1.2450, train_err=0.0622, 32_h1=0.0738, 32_l2=0.0347, 64_h1=0.1635, 64_l2=0.0516\n",
      "[114] time=2.32, avg_loss=1.2097, train_err=0.0605, 32_h1=0.0748, 32_l2=0.0356, 64_h1=0.1641, 64_l2=0.0515\n",
      "[115] time=2.30, avg_loss=1.2960, train_err=0.0648, 32_h1=0.0779, 32_l2=0.0407, 64_h1=0.1610, 64_l2=0.0535\n",
      "[116] time=2.31, avg_loss=1.2356, train_err=0.0618, 32_h1=0.0776, 32_l2=0.0393, 64_h1=0.1628, 64_l2=0.0544\n",
      "[117] time=2.30, avg_loss=1.2097, train_err=0.0605, 32_h1=0.0760, 32_l2=0.0367, 64_h1=0.1679, 64_l2=0.0564\n",
      "[118] time=2.26, avg_loss=1.1999, train_err=0.0600, 32_h1=0.0764, 32_l2=0.0385, 64_h1=0.1632, 64_l2=0.0564\n",
      "[119] time=2.31, avg_loss=1.1809, train_err=0.0590, 32_h1=0.0754, 32_l2=0.0368, 64_h1=0.1633, 64_l2=0.0540\n",
      "[120] time=2.47, avg_loss=1.1942, train_err=0.0597, 32_h1=0.0754, 32_l2=0.0368, 64_h1=0.1627, 64_l2=0.0551\n",
      "[121] time=2.35, avg_loss=1.1720, train_err=0.0586, 32_h1=0.0756, 32_l2=0.0361, 64_h1=0.1652, 64_l2=0.0546\n",
      "[122] time=2.29, avg_loss=1.1827, train_err=0.0591, 32_h1=0.0778, 32_l2=0.0383, 64_h1=0.1666, 64_l2=0.0559\n",
      "[123] time=2.27, avg_loss=1.1745, train_err=0.0587, 32_h1=0.0759, 32_l2=0.0362, 64_h1=0.1656, 64_l2=0.0563\n",
      "[124] time=2.32, avg_loss=1.1939, train_err=0.0597, 32_h1=0.0760, 32_l2=0.0360, 64_h1=0.1652, 64_l2=0.0560\n",
      "[125] time=2.31, avg_loss=1.1535, train_err=0.0577, 32_h1=0.0760, 32_l2=0.0353, 64_h1=0.1661, 64_l2=0.0560\n",
      "[126] time=2.30, avg_loss=1.1390, train_err=0.0569, 32_h1=0.0750, 32_l2=0.0349, 64_h1=0.1640, 64_l2=0.0500\n",
      "[127] time=2.34, avg_loss=1.1413, train_err=0.0571, 32_h1=0.0771, 32_l2=0.0379, 64_h1=0.1669, 64_l2=0.0568\n",
      "[128] time=2.28, avg_loss=1.1626, train_err=0.0581, 32_h1=0.0758, 32_l2=0.0361, 64_h1=0.1638, 64_l2=0.0501\n",
      "[129] time=2.31, avg_loss=1.1561, train_err=0.0578, 32_h1=0.0776, 32_l2=0.0380, 64_h1=0.1650, 64_l2=0.0576\n",
      "[130] time=2.33, avg_loss=1.1322, train_err=0.0566, 32_h1=0.0754, 32_l2=0.0351, 64_h1=0.1657, 64_l2=0.0544\n",
      "[131] time=2.33, avg_loss=1.1401, train_err=0.0570, 32_h1=0.0765, 32_l2=0.0358, 64_h1=0.1658, 64_l2=0.0517\n",
      "[132] time=2.29, avg_loss=1.1320, train_err=0.0566, 32_h1=0.0762, 32_l2=0.0355, 64_h1=0.1684, 64_l2=0.0534\n",
      "[133] time=2.34, avg_loss=1.1180, train_err=0.0559, 32_h1=0.0769, 32_l2=0.0367, 64_h1=0.1652, 64_l2=0.0566\n",
      "[134] time=2.33, avg_loss=1.1139, train_err=0.0557, 32_h1=0.0777, 32_l2=0.0376, 64_h1=0.1669, 64_l2=0.0534\n",
      "[135] time=2.28, avg_loss=1.1346, train_err=0.0567, 32_h1=0.0771, 32_l2=0.0363, 64_h1=0.1643, 64_l2=0.0550\n",
      "[136] time=2.11, avg_loss=1.1092, train_err=0.0555, 32_h1=0.0777, 32_l2=0.0366, 64_h1=0.1657, 64_l2=0.0535\n",
      "[137] time=2.04, avg_loss=1.0954, train_err=0.0548, 32_h1=0.0768, 32_l2=0.0359, 64_h1=0.1690, 64_l2=0.0558\n",
      "[138] time=2.14, avg_loss=1.0989, train_err=0.0549, 32_h1=0.0776, 32_l2=0.0372, 64_h1=0.1681, 64_l2=0.0518\n",
      "[139] time=2.19, avg_loss=1.0912, train_err=0.0546, 32_h1=0.0774, 32_l2=0.0365, 64_h1=0.1625, 64_l2=0.0506\n",
      "[140] time=2.06, avg_loss=1.0749, train_err=0.0537, 32_h1=0.0773, 32_l2=0.0362, 64_h1=0.1656, 64_l2=0.0517\n",
      "[141] time=2.16, avg_loss=1.0884, train_err=0.0544, 32_h1=0.0780, 32_l2=0.0369, 64_h1=0.1661, 64_l2=0.0525\n",
      "[142] time=2.07, avg_loss=1.0733, train_err=0.0537, 32_h1=0.0773, 32_l2=0.0364, 64_h1=0.1704, 64_l2=0.0544\n",
      "[143] time=2.05, avg_loss=1.0780, train_err=0.0539, 32_h1=0.0798, 32_l2=0.0391, 64_h1=0.1624, 64_l2=0.0507\n",
      "[144] time=2.05, avg_loss=1.1020, train_err=0.0551, 32_h1=0.0804, 32_l2=0.0399, 64_h1=0.1726, 64_l2=0.0572\n",
      "[145] time=2.05, avg_loss=1.0747, train_err=0.0537, 32_h1=0.0773, 32_l2=0.0360, 64_h1=0.1648, 64_l2=0.0530\n",
      "[146] time=2.14, avg_loss=1.0489, train_err=0.0524, 32_h1=0.0767, 32_l2=0.0352, 64_h1=0.1687, 64_l2=0.0524\n",
      "[147] time=2.08, avg_loss=1.0352, train_err=0.0518, 32_h1=0.0785, 32_l2=0.0377, 64_h1=0.1655, 64_l2=0.0541\n",
      "[148] time=2.04, avg_loss=1.0398, train_err=0.0520, 32_h1=0.0774, 32_l2=0.0363, 64_h1=0.1695, 64_l2=0.0529\n",
      "[149] time=2.03, avg_loss=1.0435, train_err=0.0522, 32_h1=0.0776, 32_l2=0.0368, 64_h1=0.1683, 64_l2=0.0562\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.6\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 357057\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(28, 28, 5, 5))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(28, 28, 5, 5))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(28, 28, 5, 5))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(28, 28, 5, 5))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(28, 28, 5, 5))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(28, 28, 5, 5))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(28, 28, 5, 5))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(28, 28, 5, 5))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f986ea1ca90>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f97514240a0>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f97514240a0>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f9751424700>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.05, avg_loss=11.0235, train_err=0.5512, 32_h1=0.3170, 32_l2=0.2233, 64_h1=0.3792, 64_l2=0.2387\n",
      "[1] time=2.04, avg_loss=5.0457, train_err=0.2523, 32_h1=0.2483, 32_l2=0.1854, 64_h1=0.3054, 64_l2=0.1908\n",
      "[2] time=2.13, avg_loss=4.0375, train_err=0.2019, 32_h1=0.1785, 32_l2=0.1133, 64_h1=0.2350, 64_l2=0.1211\n",
      "[3] time=2.09, avg_loss=3.3130, train_err=0.1656, 32_h1=0.1541, 32_l2=0.0946, 64_h1=0.2201, 64_l2=0.1041\n",
      "[4] time=2.11, avg_loss=3.0088, train_err=0.1504, 32_h1=0.1662, 32_l2=0.1280, 64_h1=0.2420, 64_l2=0.1363\n",
      "[5] time=2.15, avg_loss=2.6819, train_err=0.1341, 32_h1=0.1305, 32_l2=0.0844, 64_h1=0.1918, 64_l2=0.0913\n",
      "[6] time=2.19, avg_loss=2.5255, train_err=0.1263, 32_h1=0.1260, 32_l2=0.0775, 64_h1=0.1933, 64_l2=0.0901\n",
      "[7] time=2.07, avg_loss=2.4599, train_err=0.1230, 32_h1=0.1339, 32_l2=0.0929, 64_h1=0.2095, 64_l2=0.1052\n",
      "[8] time=2.09, avg_loss=2.3732, train_err=0.1187, 32_h1=0.1267, 32_l2=0.0885, 64_h1=0.2007, 64_l2=0.0936\n",
      "[9] time=2.01, avg_loss=2.2615, train_err=0.1131, 32_h1=0.1380, 32_l2=0.0916, 64_h1=0.2241, 64_l2=0.1049\n",
      "[10] time=2.13, avg_loss=2.2307, train_err=0.1115, 32_h1=0.1122, 32_l2=0.0686, 64_h1=0.1738, 64_l2=0.0688\n",
      "[11] time=2.12, avg_loss=2.0989, train_err=0.1049, 32_h1=0.1018, 32_l2=0.0569, 64_h1=0.1833, 64_l2=0.0694\n",
      "[12] time=2.12, avg_loss=2.1250, train_err=0.1062, 32_h1=0.1033, 32_l2=0.0587, 64_h1=0.1884, 64_l2=0.0754\n",
      "[13] time=2.10, avg_loss=1.9974, train_err=0.0999, 32_h1=0.0992, 32_l2=0.0543, 64_h1=0.1804, 64_l2=0.0664\n",
      "[14] time=2.07, avg_loss=1.9653, train_err=0.0983, 32_h1=0.1023, 32_l2=0.0621, 64_h1=0.1730, 64_l2=0.0719\n",
      "[15] time=2.21, avg_loss=1.9606, train_err=0.0980, 32_h1=0.1003, 32_l2=0.0598, 64_h1=0.1762, 64_l2=0.0725\n",
      "[16] time=2.39, avg_loss=1.9549, train_err=0.0977, 32_h1=0.0957, 32_l2=0.0527, 64_h1=0.1778, 64_l2=0.0623\n",
      "[17] time=2.31, avg_loss=1.9304, train_err=0.0965, 32_h1=0.0930, 32_l2=0.0509, 64_h1=0.1822, 64_l2=0.0719\n",
      "[18] time=2.28, avg_loss=1.9626, train_err=0.0981, 32_h1=0.1132, 32_l2=0.0740, 64_h1=0.1861, 64_l2=0.0802\n",
      "[19] time=2.27, avg_loss=1.8491, train_err=0.0925, 32_h1=0.0894, 32_l2=0.0470, 64_h1=0.1742, 64_l2=0.0628\n",
      "[20] time=2.26, avg_loss=1.8240, train_err=0.0912, 32_h1=0.0972, 32_l2=0.0591, 64_h1=0.1731, 64_l2=0.0675\n",
      "[21] time=2.29, avg_loss=1.8712, train_err=0.0936, 32_h1=0.0862, 32_l2=0.0444, 64_h1=0.1610, 64_l2=0.0561\n",
      "[22] time=2.32, avg_loss=1.7998, train_err=0.0900, 32_h1=0.0891, 32_l2=0.0487, 64_h1=0.1694, 64_l2=0.0592\n",
      "[23] time=2.31, avg_loss=1.7262, train_err=0.0863, 32_h1=0.0904, 32_l2=0.0552, 64_h1=0.1745, 64_l2=0.0676\n",
      "[24] time=2.30, avg_loss=1.8323, train_err=0.0916, 32_h1=0.0932, 32_l2=0.0522, 64_h1=0.1613, 64_l2=0.0615\n",
      "[25] time=2.30, avg_loss=1.7590, train_err=0.0879, 32_h1=0.0848, 32_l2=0.0437, 64_h1=0.1625, 64_l2=0.0588\n",
      "[26] time=2.33, avg_loss=1.8625, train_err=0.0931, 32_h1=0.0946, 32_l2=0.0513, 64_h1=0.1577, 64_l2=0.0551\n",
      "[27] time=2.32, avg_loss=1.7224, train_err=0.0861, 32_h1=0.0865, 32_l2=0.0466, 64_h1=0.1626, 64_l2=0.0577\n",
      "[28] time=2.30, avg_loss=1.6877, train_err=0.0844, 32_h1=0.1035, 32_l2=0.0610, 64_h1=0.1704, 64_l2=0.0690\n",
      "[29] time=2.31, avg_loss=1.6827, train_err=0.0841, 32_h1=0.0864, 32_l2=0.0487, 64_h1=0.1619, 64_l2=0.0639\n",
      "[30] time=2.26, avg_loss=1.6843, train_err=0.0842, 32_h1=0.1111, 32_l2=0.0835, 64_h1=0.1683, 64_l2=0.0907\n",
      "[31] time=2.32, avg_loss=1.7140, train_err=0.0857, 32_h1=0.0813, 32_l2=0.0409, 64_h1=0.1658, 64_l2=0.0564\n",
      "[32] time=2.31, avg_loss=1.6859, train_err=0.0843, 32_h1=0.1000, 32_l2=0.0619, 64_h1=0.1768, 64_l2=0.0699\n",
      "[33] time=2.34, avg_loss=1.6649, train_err=0.0832, 32_h1=0.0831, 32_l2=0.0441, 64_h1=0.1553, 64_l2=0.0538\n",
      "[34] time=2.32, avg_loss=1.6355, train_err=0.0818, 32_h1=0.0943, 32_l2=0.0548, 64_h1=0.1763, 64_l2=0.0692\n",
      "[35] time=2.27, avg_loss=1.5952, train_err=0.0798, 32_h1=0.0831, 32_l2=0.0437, 64_h1=0.1601, 64_l2=0.0563\n",
      "[36] time=2.34, avg_loss=1.6120, train_err=0.0806, 32_h1=0.0819, 32_l2=0.0410, 64_h1=0.1636, 64_l2=0.0587\n",
      "[37] time=2.31, avg_loss=1.6273, train_err=0.0814, 32_h1=0.0811, 32_l2=0.0418, 64_h1=0.1649, 64_l2=0.0579\n",
      "[38] time=2.31, avg_loss=1.6071, train_err=0.0804, 32_h1=0.0799, 32_l2=0.0413, 64_h1=0.1591, 64_l2=0.0548\n",
      "[39] time=2.39, avg_loss=1.6100, train_err=0.0805, 32_h1=0.0862, 32_l2=0.0514, 64_h1=0.1582, 64_l2=0.0646\n",
      "[40] time=2.37, avg_loss=1.5724, train_err=0.0786, 32_h1=0.0810, 32_l2=0.0460, 64_h1=0.1641, 64_l2=0.0586\n",
      "[41] time=2.31, avg_loss=1.5670, train_err=0.0784, 32_h1=0.0797, 32_l2=0.0402, 64_h1=0.1583, 64_l2=0.0552\n",
      "[42] time=2.34, avg_loss=1.5670, train_err=0.0784, 32_h1=0.0830, 32_l2=0.0456, 64_h1=0.1671, 64_l2=0.0587\n",
      "[43] time=2.32, avg_loss=1.5714, train_err=0.0786, 32_h1=0.0824, 32_l2=0.0431, 64_h1=0.1587, 64_l2=0.0522\n",
      "[44] time=2.29, avg_loss=1.5620, train_err=0.0781, 32_h1=0.0799, 32_l2=0.0432, 64_h1=0.1590, 64_l2=0.0601\n",
      "[45] time=2.35, avg_loss=1.5387, train_err=0.0769, 32_h1=0.0815, 32_l2=0.0431, 64_h1=0.1505, 64_l2=0.0535\n",
      "[46] time=2.33, avg_loss=1.5800, train_err=0.0790, 32_h1=0.0808, 32_l2=0.0409, 64_h1=0.1636, 64_l2=0.0606\n",
      "[47] time=2.34, avg_loss=1.4813, train_err=0.0741, 32_h1=0.0823, 32_l2=0.0442, 64_h1=0.1661, 64_l2=0.0582\n",
      "[48] time=2.35, avg_loss=1.5366, train_err=0.0768, 32_h1=0.0775, 32_l2=0.0392, 64_h1=0.1681, 64_l2=0.0566\n",
      "[49] time=2.33, avg_loss=1.5348, train_err=0.0767, 32_h1=0.0875, 32_l2=0.0509, 64_h1=0.1639, 64_l2=0.0673\n",
      "[50] time=2.32, avg_loss=1.5464, train_err=0.0773, 32_h1=0.0819, 32_l2=0.0460, 64_h1=0.1582, 64_l2=0.0554\n",
      "[51] time=2.30, avg_loss=1.4802, train_err=0.0740, 32_h1=0.0796, 32_l2=0.0417, 64_h1=0.1579, 64_l2=0.0551\n",
      "[52] time=2.29, avg_loss=1.4789, train_err=0.0739, 32_h1=0.0759, 32_l2=0.0383, 64_h1=0.1542, 64_l2=0.0509\n",
      "[53] time=2.28, avg_loss=1.5014, train_err=0.0751, 32_h1=0.0795, 32_l2=0.0442, 64_h1=0.1493, 64_l2=0.0549\n",
      "[54] time=2.32, avg_loss=1.4945, train_err=0.0747, 32_h1=0.0781, 32_l2=0.0407, 64_h1=0.1585, 64_l2=0.0549\n",
      "[55] time=2.13, avg_loss=1.4969, train_err=0.0748, 32_h1=0.0766, 32_l2=0.0381, 64_h1=0.1560, 64_l2=0.0531\n",
      "[56] time=2.06, avg_loss=1.4733, train_err=0.0737, 32_h1=0.0772, 32_l2=0.0383, 64_h1=0.1593, 64_l2=0.0514\n",
      "[57] time=2.03, avg_loss=1.5085, train_err=0.0754, 32_h1=0.0803, 32_l2=0.0456, 64_h1=0.1628, 64_l2=0.0625\n",
      "[58] time=2.02, avg_loss=1.4867, train_err=0.0743, 32_h1=0.0836, 32_l2=0.0454, 64_h1=0.1639, 64_l2=0.0601\n",
      "[59] time=2.04, avg_loss=1.4463, train_err=0.0723, 32_h1=0.0804, 32_l2=0.0425, 64_h1=0.1634, 64_l2=0.0561\n",
      "[60] time=2.13, avg_loss=1.4858, train_err=0.0743, 32_h1=0.0866, 32_l2=0.0496, 64_h1=0.1595, 64_l2=0.0601\n",
      "[61] time=2.11, avg_loss=1.4726, train_err=0.0736, 32_h1=0.0794, 32_l2=0.0425, 64_h1=0.1591, 64_l2=0.0581\n",
      "[62] time=2.19, avg_loss=1.4974, train_err=0.0749, 32_h1=0.0798, 32_l2=0.0446, 64_h1=0.1646, 64_l2=0.0587\n",
      "[63] time=2.19, avg_loss=1.4598, train_err=0.0730, 32_h1=0.0878, 32_l2=0.0557, 64_h1=0.1742, 64_l2=0.0716\n",
      "[64] time=2.05, avg_loss=1.4651, train_err=0.0733, 32_h1=0.0798, 32_l2=0.0431, 64_h1=0.1611, 64_l2=0.0577\n",
      "[65] time=2.01, avg_loss=1.5240, train_err=0.0762, 32_h1=0.0795, 32_l2=0.0431, 64_h1=0.1641, 64_l2=0.0616\n",
      "[66] time=2.19, avg_loss=1.4507, train_err=0.0725, 32_h1=0.0812, 32_l2=0.0469, 64_h1=0.1538, 64_l2=0.0572\n",
      "[67] time=2.09, avg_loss=1.4169, train_err=0.0708, 32_h1=0.0777, 32_l2=0.0385, 64_h1=0.1687, 64_l2=0.0579\n",
      "[68] time=2.02, avg_loss=1.4104, train_err=0.0705, 32_h1=0.0766, 32_l2=0.0395, 64_h1=0.1591, 64_l2=0.0502\n",
      "[69] time=2.01, avg_loss=1.3876, train_err=0.0694, 32_h1=0.0744, 32_l2=0.0378, 64_h1=0.1486, 64_l2=0.0493\n",
      "[70] time=2.02, avg_loss=1.4016, train_err=0.0701, 32_h1=0.0752, 32_l2=0.0371, 64_h1=0.1620, 64_l2=0.0536\n",
      "[71] time=2.03, avg_loss=1.3859, train_err=0.0693, 32_h1=0.0774, 32_l2=0.0416, 64_h1=0.1620, 64_l2=0.0564\n",
      "[72] time=2.04, avg_loss=1.4188, train_err=0.0709, 32_h1=0.0773, 32_l2=0.0397, 64_h1=0.1605, 64_l2=0.0506\n",
      "[73] time=2.20, avg_loss=1.4014, train_err=0.0701, 32_h1=0.0747, 32_l2=0.0366, 64_h1=0.1622, 64_l2=0.0547\n",
      "[74] time=2.18, avg_loss=1.3764, train_err=0.0688, 32_h1=0.0748, 32_l2=0.0365, 64_h1=0.1589, 64_l2=0.0498\n",
      "[75] time=2.15, avg_loss=1.3889, train_err=0.0694, 32_h1=0.0770, 32_l2=0.0404, 64_h1=0.1628, 64_l2=0.0549\n",
      "[76] time=2.04, avg_loss=1.4234, train_err=0.0712, 32_h1=0.0750, 32_l2=0.0375, 64_h1=0.1530, 64_l2=0.0516\n",
      "[77] time=2.13, avg_loss=1.3650, train_err=0.0683, 32_h1=0.0805, 32_l2=0.0433, 64_h1=0.1667, 64_l2=0.0637\n",
      "[78] time=2.02, avg_loss=1.4300, train_err=0.0715, 32_h1=0.0837, 32_l2=0.0508, 64_h1=0.1640, 64_l2=0.0684\n",
      "[79] time=2.03, avg_loss=1.3790, train_err=0.0689, 32_h1=0.0775, 32_l2=0.0431, 64_h1=0.1675, 64_l2=0.0601\n",
      "[80] time=2.01, avg_loss=1.3523, train_err=0.0676, 32_h1=0.0781, 32_l2=0.0424, 64_h1=0.1533, 64_l2=0.0589\n",
      "[81] time=2.01, avg_loss=1.3888, train_err=0.0694, 32_h1=0.0769, 32_l2=0.0395, 64_h1=0.1697, 64_l2=0.0574\n",
      "[82] time=2.13, avg_loss=1.3332, train_err=0.0667, 32_h1=0.0782, 32_l2=0.0425, 64_h1=0.1541, 64_l2=0.0570\n",
      "[83] time=2.07, avg_loss=1.3568, train_err=0.0678, 32_h1=0.0756, 32_l2=0.0385, 64_h1=0.1636, 64_l2=0.0583\n",
      "[84] time=2.09, avg_loss=1.3588, train_err=0.0679, 32_h1=0.0771, 32_l2=0.0400, 64_h1=0.1568, 64_l2=0.0524\n",
      "[85] time=2.52, avg_loss=1.3441, train_err=0.0672, 32_h1=0.0757, 32_l2=0.0398, 64_h1=0.1646, 64_l2=0.0596\n",
      "[86] time=2.31, avg_loss=1.3426, train_err=0.0671, 32_h1=0.0771, 32_l2=0.0386, 64_h1=0.1609, 64_l2=0.0541\n",
      "[87] time=2.33, avg_loss=1.3751, train_err=0.0688, 32_h1=0.0771, 32_l2=0.0391, 64_h1=0.1635, 64_l2=0.0584\n",
      "[88] time=2.34, avg_loss=1.3383, train_err=0.0669, 32_h1=0.0796, 32_l2=0.0455, 64_h1=0.1587, 64_l2=0.0567\n",
      "[89] time=2.33, avg_loss=1.3463, train_err=0.0673, 32_h1=0.0743, 32_l2=0.0365, 64_h1=0.1627, 64_l2=0.0515\n",
      "[90] time=2.34, avg_loss=1.3152, train_err=0.0658, 32_h1=0.0745, 32_l2=0.0381, 64_h1=0.1617, 64_l2=0.0567\n",
      "[91] time=2.31, avg_loss=1.3083, train_err=0.0654, 32_h1=0.0786, 32_l2=0.0427, 64_h1=0.1657, 64_l2=0.0553\n",
      "[92] time=2.30, avg_loss=1.3053, train_err=0.0653, 32_h1=0.0742, 32_l2=0.0351, 64_h1=0.1672, 64_l2=0.0537\n",
      "[93] time=2.30, avg_loss=1.4169, train_err=0.0708, 32_h1=0.0774, 32_l2=0.0391, 64_h1=0.1515, 64_l2=0.0477\n",
      "[94] time=2.32, avg_loss=1.3164, train_err=0.0658, 32_h1=0.0746, 32_l2=0.0359, 64_h1=0.1561, 64_l2=0.0465\n",
      "[95] time=2.32, avg_loss=1.2925, train_err=0.0646, 32_h1=0.0754, 32_l2=0.0379, 64_h1=0.1644, 64_l2=0.0581\n",
      "[96] time=2.35, avg_loss=1.2861, train_err=0.0643, 32_h1=0.0743, 32_l2=0.0358, 64_h1=0.1638, 64_l2=0.0515\n",
      "[97] time=2.38, avg_loss=1.3006, train_err=0.0650, 32_h1=0.0764, 32_l2=0.0392, 64_h1=0.1623, 64_l2=0.0560\n",
      "[98] time=2.28, avg_loss=1.2834, train_err=0.0642, 32_h1=0.0737, 32_l2=0.0348, 64_h1=0.1596, 64_l2=0.0531\n",
      "[99] time=2.31, avg_loss=1.2855, train_err=0.0643, 32_h1=0.0798, 32_l2=0.0429, 64_h1=0.1682, 64_l2=0.0594\n",
      "[100] time=2.29, avg_loss=1.3026, train_err=0.0651, 32_h1=0.0819, 32_l2=0.0471, 64_h1=0.1622, 64_l2=0.0613\n",
      "[101] time=2.30, avg_loss=1.2798, train_err=0.0640, 32_h1=0.0740, 32_l2=0.0358, 64_h1=0.1623, 64_l2=0.0557\n",
      "[102] time=2.30, avg_loss=1.2958, train_err=0.0648, 32_h1=0.0788, 32_l2=0.0424, 64_h1=0.1631, 64_l2=0.0602\n",
      "[103] time=2.32, avg_loss=1.2972, train_err=0.0649, 32_h1=0.0753, 32_l2=0.0377, 64_h1=0.1674, 64_l2=0.0565\n",
      "[104] time=2.30, avg_loss=1.2584, train_err=0.0629, 32_h1=0.0746, 32_l2=0.0359, 64_h1=0.1585, 64_l2=0.0504\n",
      "[105] time=2.31, avg_loss=1.2692, train_err=0.0635, 32_h1=0.0776, 32_l2=0.0396, 64_h1=0.1676, 64_l2=0.0582\n",
      "[106] time=2.31, avg_loss=1.2649, train_err=0.0632, 32_h1=0.0772, 32_l2=0.0385, 64_h1=0.1660, 64_l2=0.0573\n",
      "[107] time=2.31, avg_loss=1.2764, train_err=0.0638, 32_h1=0.0745, 32_l2=0.0355, 64_h1=0.1691, 64_l2=0.0536\n",
      "[108] time=2.38, avg_loss=1.2650, train_err=0.0633, 32_h1=0.0767, 32_l2=0.0384, 64_h1=0.1626, 64_l2=0.0529\n",
      "[109] time=2.36, avg_loss=1.2540, train_err=0.0627, 32_h1=0.0755, 32_l2=0.0365, 64_h1=0.1626, 64_l2=0.0546\n",
      "[110] time=2.32, avg_loss=1.2458, train_err=0.0623, 32_h1=0.0780, 32_l2=0.0405, 64_h1=0.1617, 64_l2=0.0537\n",
      "[111] time=2.30, avg_loss=1.2218, train_err=0.0611, 32_h1=0.0796, 32_l2=0.0427, 64_h1=0.1620, 64_l2=0.0565\n",
      "[112] time=2.29, avg_loss=1.3096, train_err=0.0655, 32_h1=0.0755, 32_l2=0.0361, 64_h1=0.1644, 64_l2=0.0514\n",
      "[113] time=2.29, avg_loss=1.2235, train_err=0.0612, 32_h1=0.0746, 32_l2=0.0353, 64_h1=0.1570, 64_l2=0.0500\n",
      "[114] time=2.28, avg_loss=1.2234, train_err=0.0612, 32_h1=0.0750, 32_l2=0.0355, 64_h1=0.1660, 64_l2=0.0536\n",
      "[115] time=2.30, avg_loss=1.2340, train_err=0.0617, 32_h1=0.0745, 32_l2=0.0352, 64_h1=0.1668, 64_l2=0.0509\n",
      "[116] time=2.28, avg_loss=1.2243, train_err=0.0612, 32_h1=0.0765, 32_l2=0.0373, 64_h1=0.1626, 64_l2=0.0522\n",
      "[117] time=2.25, avg_loss=1.2103, train_err=0.0605, 32_h1=0.0805, 32_l2=0.0447, 64_h1=0.1680, 64_l2=0.0623\n",
      "[118] time=2.27, avg_loss=1.2384, train_err=0.0619, 32_h1=0.0772, 32_l2=0.0383, 64_h1=0.1594, 64_l2=0.0528\n",
      "[119] time=2.29, avg_loss=1.2295, train_err=0.0615, 32_h1=0.0751, 32_l2=0.0350, 64_h1=0.1597, 64_l2=0.0507\n",
      "[120] time=2.34, avg_loss=1.2070, train_err=0.0603, 32_h1=0.0780, 32_l2=0.0393, 64_h1=0.1693, 64_l2=0.0588\n",
      "[121] time=2.33, avg_loss=1.2121, train_err=0.0606, 32_h1=0.0763, 32_l2=0.0367, 64_h1=0.1676, 64_l2=0.0548\n",
      "[122] time=2.31, avg_loss=1.2164, train_err=0.0608, 32_h1=0.0770, 32_l2=0.0391, 64_h1=0.1630, 64_l2=0.0565\n",
      "[123] time=2.39, avg_loss=1.1984, train_err=0.0599, 32_h1=0.0758, 32_l2=0.0359, 64_h1=0.1625, 64_l2=0.0526\n",
      "[124] time=2.30, avg_loss=1.2009, train_err=0.0600, 32_h1=0.0778, 32_l2=0.0382, 64_h1=0.1685, 64_l2=0.0520\n",
      "[125] time=2.18, avg_loss=1.1824, train_err=0.0591, 32_h1=0.0753, 32_l2=0.0352, 64_h1=0.1640, 64_l2=0.0532\n",
      "[126] time=2.01, avg_loss=1.1779, train_err=0.0589, 32_h1=0.0766, 32_l2=0.0369, 64_h1=0.1630, 64_l2=0.0528\n",
      "[127] time=2.01, avg_loss=1.1786, train_err=0.0589, 32_h1=0.0761, 32_l2=0.0364, 64_h1=0.1704, 64_l2=0.0559\n",
      "[128] time=2.09, avg_loss=1.1741, train_err=0.0587, 32_h1=0.0758, 32_l2=0.0359, 64_h1=0.1681, 64_l2=0.0536\n",
      "[129] time=2.18, avg_loss=1.1756, train_err=0.0588, 32_h1=0.0764, 32_l2=0.0362, 64_h1=0.1676, 64_l2=0.0511\n",
      "[130] time=2.17, avg_loss=1.1637, train_err=0.0582, 32_h1=0.0751, 32_l2=0.0352, 64_h1=0.1666, 64_l2=0.0550\n",
      "[131] time=2.05, avg_loss=1.1462, train_err=0.0573, 32_h1=0.0759, 32_l2=0.0365, 64_h1=0.1632, 64_l2=0.0517\n",
      "[132] time=2.01, avg_loss=1.1720, train_err=0.0586, 32_h1=0.0754, 32_l2=0.0355, 64_h1=0.1644, 64_l2=0.0528\n",
      "[133] time=2.01, avg_loss=1.2242, train_err=0.0612, 32_h1=0.0777, 32_l2=0.0379, 64_h1=0.1662, 64_l2=0.0535\n",
      "[134] time=2.01, avg_loss=1.1580, train_err=0.0579, 32_h1=0.0775, 32_l2=0.0379, 64_h1=0.1695, 64_l2=0.0543\n",
      "[135] time=2.01, avg_loss=1.1516, train_err=0.0576, 32_h1=0.0754, 32_l2=0.0354, 64_h1=0.1697, 64_l2=0.0546\n",
      "[136] time=2.06, avg_loss=1.1210, train_err=0.0560, 32_h1=0.0763, 32_l2=0.0363, 64_h1=0.1673, 64_l2=0.0544\n",
      "[137] time=2.19, avg_loss=1.1225, train_err=0.0561, 32_h1=0.0767, 32_l2=0.0361, 64_h1=0.1667, 64_l2=0.0515\n",
      "[138] time=2.18, avg_loss=1.1183, train_err=0.0559, 32_h1=0.0762, 32_l2=0.0364, 64_h1=0.1640, 64_l2=0.0524\n",
      "[139] time=2.19, avg_loss=1.1517, train_err=0.0576, 32_h1=0.0764, 32_l2=0.0359, 64_h1=0.1685, 64_l2=0.0541\n",
      "[140] time=2.15, avg_loss=1.1187, train_err=0.0559, 32_h1=0.0787, 32_l2=0.0396, 64_h1=0.1652, 64_l2=0.0550\n",
      "[141] time=2.17, avg_loss=1.1076, train_err=0.0554, 32_h1=0.0762, 32_l2=0.0371, 64_h1=0.1678, 64_l2=0.0531\n",
      "[142] time=2.03, avg_loss=1.1144, train_err=0.0557, 32_h1=0.0778, 32_l2=0.0374, 64_h1=0.1690, 64_l2=0.0562\n",
      "[143] time=2.01, avg_loss=1.1140, train_err=0.0557, 32_h1=0.0771, 32_l2=0.0364, 64_h1=0.1703, 64_l2=0.0562\n",
      "[144] time=2.20, avg_loss=1.1004, train_err=0.0550, 32_h1=0.0765, 32_l2=0.0356, 64_h1=0.1670, 64_l2=0.0526\n",
      "[145] time=2.09, avg_loss=1.1289, train_err=0.0564, 32_h1=0.0777, 32_l2=0.0364, 64_h1=0.1634, 64_l2=0.0503\n",
      "[146] time=2.11, avg_loss=1.0938, train_err=0.0547, 32_h1=0.0781, 32_l2=0.0375, 64_h1=0.1714, 64_l2=0.0565\n",
      "[147] time=2.19, avg_loss=1.0899, train_err=0.0545, 32_h1=0.0766, 32_l2=0.0358, 64_h1=0.1703, 64_l2=0.0545\n",
      "[148] time=2.17, avg_loss=1.0777, train_err=0.0539, 32_h1=0.0775, 32_l2=0.0371, 64_h1=0.1636, 64_l2=0.0522\n",
      "[149] time=2.20, avg_loss=1.0828, train_err=0.0541, 32_h1=0.0795, 32_l2=0.0388, 64_h1=0.1641, 64_l2=0.0529\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.7000000000000001\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 380881\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(29, 29, 5, 5))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(29, 29, 5, 5))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(29, 29, 5, 5))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(29, 29, 5, 5))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(29, 29, 5, 5))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(29, 29, 5, 5))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(29, 29, 5, 5))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(29, 29, 5, 5))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f97576c0250>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f986ea1c670>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f986ea1c670>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f986ea1ca90>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.20, avg_loss=10.5567, train_err=0.5278, 32_h1=0.3192, 32_l2=0.2168, 64_h1=0.3719, 64_l2=0.2197\n",
      "[1] time=2.19, avg_loss=5.1663, train_err=0.2583, 32_h1=0.2846, 32_l2=0.2343, 64_h1=0.3101, 64_l2=0.2287\n",
      "[2] time=2.19, avg_loss=4.2933, train_err=0.2147, 32_h1=0.2147, 32_l2=0.1451, 64_h1=0.2609, 64_l2=0.1462\n",
      "[3] time=2.17, avg_loss=3.5882, train_err=0.1794, 32_h1=0.1952, 32_l2=0.1446, 64_h1=0.2411, 64_l2=0.1461\n",
      "[4] time=2.19, avg_loss=3.1048, train_err=0.1552, 32_h1=0.1465, 32_l2=0.0995, 64_h1=0.2134, 64_l2=0.1098\n",
      "[5] time=2.27, avg_loss=2.8460, train_err=0.1423, 32_h1=0.1283, 32_l2=0.0790, 64_h1=0.1910, 64_l2=0.0855\n",
      "[6] time=2.30, avg_loss=2.7005, train_err=0.1350, 32_h1=0.1409, 32_l2=0.1033, 64_h1=0.2033, 64_l2=0.1113\n",
      "[7] time=2.30, avg_loss=2.4441, train_err=0.1222, 32_h1=0.1200, 32_l2=0.0753, 64_h1=0.1753, 64_l2=0.0787\n",
      "[8] time=2.31, avg_loss=2.3429, train_err=0.1171, 32_h1=0.1165, 32_l2=0.0725, 64_h1=0.1866, 64_l2=0.0833\n",
      "[9] time=2.30, avg_loss=2.2936, train_err=0.1147, 32_h1=0.1080, 32_l2=0.0633, 64_h1=0.1729, 64_l2=0.0748\n",
      "[10] time=2.28, avg_loss=2.0636, train_err=0.1032, 32_h1=0.0987, 32_l2=0.0541, 64_h1=0.1768, 64_l2=0.0692\n",
      "[11] time=2.31, avg_loss=2.0402, train_err=0.1020, 32_h1=0.1194, 32_l2=0.0866, 64_h1=0.1796, 64_l2=0.0939\n",
      "[12] time=2.30, avg_loss=2.0372, train_err=0.1019, 32_h1=0.1039, 32_l2=0.0643, 64_h1=0.1748, 64_l2=0.0764\n",
      "[13] time=2.28, avg_loss=1.9521, train_err=0.0976, 32_h1=0.0975, 32_l2=0.0552, 64_h1=0.1729, 64_l2=0.0687\n",
      "[14] time=2.36, avg_loss=1.9502, train_err=0.0975, 32_h1=0.0947, 32_l2=0.0507, 64_h1=0.1599, 64_l2=0.0612\n",
      "[15] time=2.37, avg_loss=1.8634, train_err=0.0932, 32_h1=0.0922, 32_l2=0.0479, 64_h1=0.1671, 64_l2=0.0645\n",
      "[16] time=2.32, avg_loss=1.8066, train_err=0.0903, 32_h1=0.0890, 32_l2=0.0459, 64_h1=0.1669, 64_l2=0.0610\n",
      "[17] time=2.31, avg_loss=1.8637, train_err=0.0932, 32_h1=0.0986, 32_l2=0.0578, 64_h1=0.1674, 64_l2=0.0726\n",
      "[18] time=2.30, avg_loss=1.7932, train_err=0.0897, 32_h1=0.1029, 32_l2=0.0692, 64_h1=0.1699, 64_l2=0.0774\n",
      "[19] time=2.31, avg_loss=1.8147, train_err=0.0907, 32_h1=0.0931, 32_l2=0.0551, 64_h1=0.1673, 64_l2=0.0618\n",
      "[20] time=2.37, avg_loss=1.7989, train_err=0.0899, 32_h1=0.0882, 32_l2=0.0494, 64_h1=0.1672, 64_l2=0.0607\n",
      "[21] time=2.31, avg_loss=1.7776, train_err=0.0889, 32_h1=0.0890, 32_l2=0.0484, 64_h1=0.1686, 64_l2=0.0616\n",
      "[22] time=2.35, avg_loss=1.7088, train_err=0.0854, 32_h1=0.0896, 32_l2=0.0479, 64_h1=0.1668, 64_l2=0.0665\n",
      "[23] time=2.32, avg_loss=1.7528, train_err=0.0876, 32_h1=0.0879, 32_l2=0.0512, 64_h1=0.1670, 64_l2=0.0687\n",
      "[24] time=2.30, avg_loss=1.7387, train_err=0.0869, 32_h1=0.0910, 32_l2=0.0538, 64_h1=0.1708, 64_l2=0.0679\n",
      "[25] time=2.27, avg_loss=1.6984, train_err=0.0849, 32_h1=0.0859, 32_l2=0.0427, 64_h1=0.1483, 64_l2=0.0516\n",
      "[26] time=2.27, avg_loss=1.6378, train_err=0.0819, 32_h1=0.0866, 32_l2=0.0463, 64_h1=0.1628, 64_l2=0.0568\n",
      "[27] time=2.27, avg_loss=1.7106, train_err=0.0855, 32_h1=0.0848, 32_l2=0.0439, 64_h1=0.1686, 64_l2=0.0577\n",
      "[28] time=2.39, avg_loss=1.6843, train_err=0.0842, 32_h1=0.0877, 32_l2=0.0519, 64_h1=0.1647, 64_l2=0.0611\n",
      "[29] time=2.31, avg_loss=1.6098, train_err=0.0805, 32_h1=0.0867, 32_l2=0.0456, 64_h1=0.1562, 64_l2=0.0590\n",
      "[30] time=2.29, avg_loss=1.6317, train_err=0.0816, 32_h1=0.0921, 32_l2=0.0547, 64_h1=0.1754, 64_l2=0.0719\n",
      "[31] time=2.27, avg_loss=1.6124, train_err=0.0806, 32_h1=0.0810, 32_l2=0.0410, 64_h1=0.1609, 64_l2=0.0570\n",
      "[32] time=2.28, avg_loss=1.6648, train_err=0.0832, 32_h1=0.0897, 32_l2=0.0573, 64_h1=0.1576, 64_l2=0.0686\n",
      "[33] time=2.35, avg_loss=1.6044, train_err=0.0802, 32_h1=0.0855, 32_l2=0.0487, 64_h1=0.1600, 64_l2=0.0644\n",
      "[34] time=2.31, avg_loss=1.6146, train_err=0.0807, 32_h1=0.0877, 32_l2=0.0502, 64_h1=0.1553, 64_l2=0.0572\n",
      "[35] time=2.32, avg_loss=1.5893, train_err=0.0795, 32_h1=0.0838, 32_l2=0.0434, 64_h1=0.1650, 64_l2=0.0604\n",
      "[36] time=2.30, avg_loss=1.5717, train_err=0.0786, 32_h1=0.0836, 32_l2=0.0455, 64_h1=0.1631, 64_l2=0.0637\n",
      "[37] time=2.31, avg_loss=1.6146, train_err=0.0807, 32_h1=0.0835, 32_l2=0.0453, 64_h1=0.1574, 64_l2=0.0572\n",
      "[38] time=2.36, avg_loss=1.5448, train_err=0.0772, 32_h1=0.0858, 32_l2=0.0491, 64_h1=0.1573, 64_l2=0.0572\n",
      "[39] time=2.31, avg_loss=1.5908, train_err=0.0795, 32_h1=0.0954, 32_l2=0.0628, 64_h1=0.1648, 64_l2=0.0787\n",
      "[40] time=2.28, avg_loss=1.5966, train_err=0.0798, 32_h1=0.0798, 32_l2=0.0394, 64_h1=0.1571, 64_l2=0.0505\n",
      "[41] time=2.30, avg_loss=1.5389, train_err=0.0769, 32_h1=0.0796, 32_l2=0.0419, 64_h1=0.1648, 64_l2=0.0568\n",
      "[42] time=2.32, avg_loss=1.5527, train_err=0.0776, 32_h1=0.0789, 32_l2=0.0390, 64_h1=0.1587, 64_l2=0.0506\n",
      "[43] time=2.32, avg_loss=1.5581, train_err=0.0779, 32_h1=0.0853, 32_l2=0.0502, 64_h1=0.1584, 64_l2=0.0577\n",
      "[44] time=2.24, avg_loss=1.5452, train_err=0.0773, 32_h1=0.0865, 32_l2=0.0505, 64_h1=0.1595, 64_l2=0.0565\n",
      "[45] time=2.07, avg_loss=1.5139, train_err=0.0757, 32_h1=0.0921, 32_l2=0.0602, 64_h1=0.1511, 64_l2=0.0645\n",
      "[46] time=2.09, avg_loss=1.5381, train_err=0.0769, 32_h1=0.0813, 32_l2=0.0439, 64_h1=0.1468, 64_l2=0.0499\n",
      "[47] time=2.10, avg_loss=1.5516, train_err=0.0776, 32_h1=0.0804, 32_l2=0.0435, 64_h1=0.1535, 64_l2=0.0558\n",
      "[48] time=2.04, avg_loss=1.5261, train_err=0.0763, 32_h1=0.0798, 32_l2=0.0408, 64_h1=0.1590, 64_l2=0.0549\n",
      "[49] time=2.20, avg_loss=1.4955, train_err=0.0748, 32_h1=0.0864, 32_l2=0.0554, 64_h1=0.1579, 64_l2=0.0626\n",
      "[50] time=2.05, avg_loss=1.5457, train_err=0.0773, 32_h1=0.0833, 32_l2=0.0509, 64_h1=0.1630, 64_l2=0.0623\n",
      "[51] time=2.15, avg_loss=1.4964, train_err=0.0748, 32_h1=0.0775, 32_l2=0.0408, 64_h1=0.1524, 64_l2=0.0522\n",
      "[52] time=2.05, avg_loss=1.4765, train_err=0.0738, 32_h1=0.0818, 32_l2=0.0459, 64_h1=0.1634, 64_l2=0.0596\n",
      "[53] time=2.06, avg_loss=1.4990, train_err=0.0750, 32_h1=0.0898, 32_l2=0.0580, 64_h1=0.1613, 64_l2=0.0699\n",
      "[54] time=2.24, avg_loss=1.4526, train_err=0.0726, 32_h1=0.0921, 32_l2=0.0594, 64_h1=0.1717, 64_l2=0.0747\n",
      "[55] time=2.18, avg_loss=1.5271, train_err=0.0764, 32_h1=0.0790, 32_l2=0.0411, 64_h1=0.1520, 64_l2=0.0529\n",
      "[56] time=2.12, avg_loss=1.5015, train_err=0.0751, 32_h1=0.0784, 32_l2=0.0412, 64_h1=0.1604, 64_l2=0.0588\n",
      "[57] time=2.11, avg_loss=1.4418, train_err=0.0721, 32_h1=0.0772, 32_l2=0.0399, 64_h1=0.1583, 64_l2=0.0551\n",
      "[58] time=2.19, avg_loss=1.4318, train_err=0.0716, 32_h1=0.0770, 32_l2=0.0376, 64_h1=0.1556, 64_l2=0.0485\n",
      "[59] time=2.18, avg_loss=1.4412, train_err=0.0721, 32_h1=0.0797, 32_l2=0.0411, 64_h1=0.1599, 64_l2=0.0516\n",
      "[60] time=2.12, avg_loss=1.5198, train_err=0.0760, 32_h1=0.0794, 32_l2=0.0423, 64_h1=0.1693, 64_l2=0.0618\n",
      "[61] time=2.10, avg_loss=1.4713, train_err=0.0736, 32_h1=0.0844, 32_l2=0.0491, 64_h1=0.1570, 64_l2=0.0594\n",
      "[62] time=2.05, avg_loss=1.4997, train_err=0.0750, 32_h1=0.0754, 32_l2=0.0375, 64_h1=0.1639, 64_l2=0.0544\n",
      "[63] time=2.02, avg_loss=1.4107, train_err=0.0705, 32_h1=0.0755, 32_l2=0.0380, 64_h1=0.1614, 64_l2=0.0562\n",
      "[64] time=2.17, avg_loss=1.4543, train_err=0.0727, 32_h1=0.0781, 32_l2=0.0409, 64_h1=0.1592, 64_l2=0.0541\n",
      "[65] time=2.14, avg_loss=1.4262, train_err=0.0713, 32_h1=0.0762, 32_l2=0.0389, 64_h1=0.1601, 64_l2=0.0587\n",
      "[66] time=2.12, avg_loss=1.4215, train_err=0.0711, 32_h1=0.0784, 32_l2=0.0416, 64_h1=0.1542, 64_l2=0.0508\n",
      "[67] time=2.13, avg_loss=1.3839, train_err=0.0692, 32_h1=0.0803, 32_l2=0.0465, 64_h1=0.1571, 64_l2=0.0594\n",
      "[68] time=2.08, avg_loss=1.4043, train_err=0.0702, 32_h1=0.0753, 32_l2=0.0370, 64_h1=0.1621, 64_l2=0.0517\n",
      "[69] time=2.09, avg_loss=1.4027, train_err=0.0701, 32_h1=0.0754, 32_l2=0.0385, 64_h1=0.1571, 64_l2=0.0522\n",
      "[70] time=2.11, avg_loss=1.3999, train_err=0.0700, 32_h1=0.0772, 32_l2=0.0397, 64_h1=0.1626, 64_l2=0.0573\n",
      "[71] time=2.17, avg_loss=1.3957, train_err=0.0698, 32_h1=0.0754, 32_l2=0.0381, 64_h1=0.1583, 64_l2=0.0528\n",
      "[72] time=2.19, avg_loss=1.3939, train_err=0.0697, 32_h1=0.0753, 32_l2=0.0371, 64_h1=0.1607, 64_l2=0.0542\n",
      "[73] time=2.14, avg_loss=1.3838, train_err=0.0692, 32_h1=0.0821, 32_l2=0.0461, 64_h1=0.1641, 64_l2=0.0614\n",
      "[74] time=2.40, avg_loss=1.4222, train_err=0.0711, 32_h1=0.0774, 32_l2=0.0393, 64_h1=0.1671, 64_l2=0.0559\n",
      "[75] time=2.29, avg_loss=1.3792, train_err=0.0690, 32_h1=0.0811, 32_l2=0.0446, 64_h1=0.1667, 64_l2=0.0629\n",
      "[76] time=2.30, avg_loss=1.3845, train_err=0.0692, 32_h1=0.0779, 32_l2=0.0401, 64_h1=0.1581, 64_l2=0.0461\n",
      "[77] time=2.32, avg_loss=1.3780, train_err=0.0689, 32_h1=0.0767, 32_l2=0.0408, 64_h1=0.1637, 64_l2=0.0596\n",
      "[78] time=2.30, avg_loss=1.3530, train_err=0.0676, 32_h1=0.0746, 32_l2=0.0367, 64_h1=0.1664, 64_l2=0.0568\n",
      "[79] time=2.31, avg_loss=1.3540, train_err=0.0677, 32_h1=0.0819, 32_l2=0.0494, 64_h1=0.1625, 64_l2=0.0658\n",
      "[80] time=2.31, avg_loss=1.3943, train_err=0.0697, 32_h1=0.0757, 32_l2=0.0376, 64_h1=0.1595, 64_l2=0.0552\n",
      "[81] time=2.28, avg_loss=1.3662, train_err=0.0683, 32_h1=0.0799, 32_l2=0.0433, 64_h1=0.1677, 64_l2=0.0627\n",
      "[82] time=2.27, avg_loss=1.3526, train_err=0.0676, 32_h1=0.0773, 32_l2=0.0398, 64_h1=0.1653, 64_l2=0.0596\n",
      "[83] time=2.29, avg_loss=1.3530, train_err=0.0676, 32_h1=0.0754, 32_l2=0.0380, 64_h1=0.1576, 64_l2=0.0539\n",
      "[84] time=2.27, avg_loss=1.3807, train_err=0.0690, 32_h1=0.0758, 32_l2=0.0400, 64_h1=0.1519, 64_l2=0.0533\n",
      "[85] time=2.33, avg_loss=1.3413, train_err=0.0671, 32_h1=0.0777, 32_l2=0.0409, 64_h1=0.1607, 64_l2=0.0555\n",
      "[86] time=2.28, avg_loss=1.3460, train_err=0.0673, 32_h1=0.0745, 32_l2=0.0383, 64_h1=0.1592, 64_l2=0.0500\n",
      "[87] time=2.30, avg_loss=1.3475, train_err=0.0674, 32_h1=0.0761, 32_l2=0.0384, 64_h1=0.1626, 64_l2=0.0578\n",
      "[88] time=2.25, avg_loss=1.3266, train_err=0.0663, 32_h1=0.0758, 32_l2=0.0391, 64_h1=0.1584, 64_l2=0.0542\n",
      "[89] time=2.33, avg_loss=1.3129, train_err=0.0656, 32_h1=0.0762, 32_l2=0.0408, 64_h1=0.1579, 64_l2=0.0552\n",
      "[90] time=2.30, avg_loss=1.3252, train_err=0.0663, 32_h1=0.0756, 32_l2=0.0387, 64_h1=0.1610, 64_l2=0.0527\n",
      "[91] time=2.34, avg_loss=1.3749, train_err=0.0687, 32_h1=0.0800, 32_l2=0.0479, 64_h1=0.1611, 64_l2=0.0625\n",
      "[92] time=2.33, avg_loss=1.3354, train_err=0.0668, 32_h1=0.0833, 32_l2=0.0522, 64_h1=0.1654, 64_l2=0.0622\n",
      "[93] time=2.34, avg_loss=1.3344, train_err=0.0667, 32_h1=0.0750, 32_l2=0.0370, 64_h1=0.1675, 64_l2=0.0570\n",
      "[94] time=2.34, avg_loss=1.2972, train_err=0.0649, 32_h1=0.0781, 32_l2=0.0399, 64_h1=0.1666, 64_l2=0.0607\n",
      "[95] time=2.32, avg_loss=1.3099, train_err=0.0655, 32_h1=0.0745, 32_l2=0.0366, 64_h1=0.1590, 64_l2=0.0501\n",
      "[96] time=2.30, avg_loss=1.2859, train_err=0.0643, 32_h1=0.0765, 32_l2=0.0401, 64_h1=0.1662, 64_l2=0.0552\n",
      "[97] time=2.43, avg_loss=1.3132, train_err=0.0657, 32_h1=0.0747, 32_l2=0.0362, 64_h1=0.1620, 64_l2=0.0521\n",
      "[98] time=2.29, avg_loss=1.3000, train_err=0.0650, 32_h1=0.0776, 32_l2=0.0426, 64_h1=0.1665, 64_l2=0.0560\n",
      "[99] time=2.37, avg_loss=1.2934, train_err=0.0647, 32_h1=0.0748, 32_l2=0.0387, 64_h1=0.1608, 64_l2=0.0536\n",
      "[100] time=2.32, avg_loss=1.3139, train_err=0.0657, 32_h1=0.0772, 32_l2=0.0404, 64_h1=0.1629, 64_l2=0.0581\n",
      "[101] time=2.31, avg_loss=1.3487, train_err=0.0674, 32_h1=0.0768, 32_l2=0.0379, 64_h1=0.1623, 64_l2=0.0566\n",
      "[102] time=2.32, avg_loss=1.2670, train_err=0.0633, 32_h1=0.0730, 32_l2=0.0348, 64_h1=0.1581, 64_l2=0.0525\n",
      "[103] time=2.35, avg_loss=1.2579, train_err=0.0629, 32_h1=0.0738, 32_l2=0.0358, 64_h1=0.1567, 64_l2=0.0510\n",
      "[104] time=2.34, avg_loss=1.2611, train_err=0.0631, 32_h1=0.0731, 32_l2=0.0352, 64_h1=0.1586, 64_l2=0.0524\n",
      "[105] time=2.28, avg_loss=1.2823, train_err=0.0641, 32_h1=0.0758, 32_l2=0.0381, 64_h1=0.1631, 64_l2=0.0529\n",
      "[106] time=2.28, avg_loss=1.2562, train_err=0.0628, 32_h1=0.0747, 32_l2=0.0372, 64_h1=0.1624, 64_l2=0.0516\n",
      "[107] time=2.30, avg_loss=1.2547, train_err=0.0627, 32_h1=0.0732, 32_l2=0.0348, 64_h1=0.1617, 64_l2=0.0511\n",
      "[108] time=2.35, avg_loss=1.2714, train_err=0.0636, 32_h1=0.0767, 32_l2=0.0390, 64_h1=0.1634, 64_l2=0.0567\n",
      "[109] time=2.34, avg_loss=1.2554, train_err=0.0628, 32_h1=0.0749, 32_l2=0.0372, 64_h1=0.1615, 64_l2=0.0566\n",
      "[110] time=2.33, avg_loss=1.2407, train_err=0.0620, 32_h1=0.0739, 32_l2=0.0350, 64_h1=0.1610, 64_l2=0.0496\n",
      "[111] time=2.31, avg_loss=1.2409, train_err=0.0620, 32_h1=0.0748, 32_l2=0.0369, 64_h1=0.1682, 64_l2=0.0561\n",
      "[112] time=2.36, avg_loss=1.2468, train_err=0.0623, 32_h1=0.0748, 32_l2=0.0369, 64_h1=0.1633, 64_l2=0.0549\n",
      "[113] time=2.23, avg_loss=1.2253, train_err=0.0613, 32_h1=0.0767, 32_l2=0.0395, 64_h1=0.1632, 64_l2=0.0565\n",
      "[114] time=2.06, avg_loss=1.2154, train_err=0.0608, 32_h1=0.0748, 32_l2=0.0359, 64_h1=0.1661, 64_l2=0.0532\n",
      "[115] time=2.03, avg_loss=1.2075, train_err=0.0604, 32_h1=0.0750, 32_l2=0.0369, 64_h1=0.1632, 64_l2=0.0545\n",
      "[116] time=2.07, avg_loss=1.2224, train_err=0.0611, 32_h1=0.0789, 32_l2=0.0429, 64_h1=0.1617, 64_l2=0.0599\n",
      "[117] time=2.04, avg_loss=1.2329, train_err=0.0616, 32_h1=0.0779, 32_l2=0.0396, 64_h1=0.1584, 64_l2=0.0546\n",
      "[118] time=2.04, avg_loss=1.2097, train_err=0.0605, 32_h1=0.0801, 32_l2=0.0455, 64_h1=0.1605, 64_l2=0.0600\n",
      "[119] time=2.08, avg_loss=1.2176, train_err=0.0609, 32_h1=0.0762, 32_l2=0.0373, 64_h1=0.1660, 64_l2=0.0538\n",
      "[120] time=2.06, avg_loss=1.1990, train_err=0.0599, 32_h1=0.0767, 32_l2=0.0384, 64_h1=0.1617, 64_l2=0.0542\n",
      "[121] time=2.06, avg_loss=1.2080, train_err=0.0604, 32_h1=0.0774, 32_l2=0.0395, 64_h1=0.1585, 64_l2=0.0539\n",
      "[122] time=2.02, avg_loss=1.1893, train_err=0.0595, 32_h1=0.0745, 32_l2=0.0349, 64_h1=0.1644, 64_l2=0.0532\n",
      "[123] time=2.04, avg_loss=1.1683, train_err=0.0584, 32_h1=0.0779, 32_l2=0.0393, 64_h1=0.1672, 64_l2=0.0569\n",
      "[124] time=2.04, avg_loss=1.1761, train_err=0.0588, 32_h1=0.0763, 32_l2=0.0384, 64_h1=0.1625, 64_l2=0.0551\n",
      "[125] time=2.10, avg_loss=1.1933, train_err=0.0597, 32_h1=0.0754, 32_l2=0.0374, 64_h1=0.1662, 64_l2=0.0538\n",
      "[126] time=2.18, avg_loss=1.1570, train_err=0.0579, 32_h1=0.0752, 32_l2=0.0364, 64_h1=0.1632, 64_l2=0.0505\n",
      "[127] time=2.19, avg_loss=1.1459, train_err=0.0573, 32_h1=0.0771, 32_l2=0.0372, 64_h1=0.1597, 64_l2=0.0514\n",
      "[128] time=2.16, avg_loss=1.1427, train_err=0.0571, 32_h1=0.0751, 32_l2=0.0352, 64_h1=0.1640, 64_l2=0.0488\n",
      "[129] time=2.13, avg_loss=1.1661, train_err=0.0583, 32_h1=0.0761, 32_l2=0.0381, 64_h1=0.1644, 64_l2=0.0545\n",
      "[130] time=2.19, avg_loss=1.1402, train_err=0.0570, 32_h1=0.0764, 32_l2=0.0365, 64_h1=0.1646, 64_l2=0.0545\n",
      "[131] time=2.15, avg_loss=1.1286, train_err=0.0564, 32_h1=0.0785, 32_l2=0.0413, 64_h1=0.1694, 64_l2=0.0599\n",
      "[132] time=2.01, avg_loss=1.1256, train_err=0.0563, 32_h1=0.0761, 32_l2=0.0368, 64_h1=0.1677, 64_l2=0.0518\n",
      "[133] time=2.04, avg_loss=1.1266, train_err=0.0563, 32_h1=0.0774, 32_l2=0.0386, 64_h1=0.1684, 64_l2=0.0537\n",
      "[134] time=2.22, avg_loss=1.1404, train_err=0.0570, 32_h1=0.0772, 32_l2=0.0377, 64_h1=0.1656, 64_l2=0.0536\n",
      "[135] time=2.04, avg_loss=1.1156, train_err=0.0558, 32_h1=0.0778, 32_l2=0.0385, 64_h1=0.1711, 64_l2=0.0579\n",
      "[136] time=2.13, avg_loss=1.1735, train_err=0.0587, 32_h1=0.0782, 32_l2=0.0382, 64_h1=0.1683, 64_l2=0.0572\n",
      "[137] time=2.17, avg_loss=1.1158, train_err=0.0558, 32_h1=0.0776, 32_l2=0.0380, 64_h1=0.1685, 64_l2=0.0550\n",
      "[138] time=2.18, avg_loss=1.1135, train_err=0.0557, 32_h1=0.0781, 32_l2=0.0376, 64_h1=0.1678, 64_l2=0.0555\n",
      "[139] time=2.19, avg_loss=1.1170, train_err=0.0558, 32_h1=0.0778, 32_l2=0.0372, 64_h1=0.1687, 64_l2=0.0582\n",
      "[140] time=2.07, avg_loss=1.0998, train_err=0.0550, 32_h1=0.0788, 32_l2=0.0390, 64_h1=0.1657, 64_l2=0.0544\n",
      "[141] time=2.17, avg_loss=1.0853, train_err=0.0543, 32_h1=0.0768, 32_l2=0.0368, 64_h1=0.1713, 64_l2=0.0571\n",
      "[142] time=2.35, avg_loss=1.0761, train_err=0.0538, 32_h1=0.0769, 32_l2=0.0360, 64_h1=0.1729, 64_l2=0.0565\n",
      "[143] time=2.40, avg_loss=1.0767, train_err=0.0538, 32_h1=0.0772, 32_l2=0.0374, 64_h1=0.1664, 64_l2=0.0564\n",
      "[144] time=2.34, avg_loss=1.0690, train_err=0.0534, 32_h1=0.0766, 32_l2=0.0357, 64_h1=0.1625, 64_l2=0.0524\n",
      "[145] time=2.32, avg_loss=1.0791, train_err=0.0540, 32_h1=0.0781, 32_l2=0.0376, 64_h1=0.1665, 64_l2=0.0535\n",
      "[146] time=2.32, avg_loss=1.0829, train_err=0.0541, 32_h1=0.0791, 32_l2=0.0401, 64_h1=0.1695, 64_l2=0.0583\n",
      "[147] time=2.31, avg_loss=1.0504, train_err=0.0525, 32_h1=0.0776, 32_l2=0.0375, 64_h1=0.1650, 64_l2=0.0534\n",
      "[148] time=2.32, avg_loss=1.0263, train_err=0.0513, 32_h1=0.0778, 32_l2=0.0363, 64_h1=0.1712, 64_l2=0.0528\n",
      "[149] time=2.33, avg_loss=1.0390, train_err=0.0520, 32_h1=0.0778, 32_l2=0.0368, 64_h1=0.1716, 64_l2=0.0541\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.8\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 564097\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(30, 30, 6, 6))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(30, 30, 6, 6))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(30, 30, 6, 6))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(30, 30, 6, 6))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(30, 30, 6, 6))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(30, 30, 6, 6))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(30, 30, 6, 6))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(30, 30, 6, 6))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f983c59d4f0>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f97576c0280>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f97576c0280>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f97576c0250>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.29, avg_loss=9.9813, train_err=0.4991, 32_h1=0.2804, 32_l2=0.1928, 64_h1=0.3184, 64_l2=0.1844\n",
      "[1] time=2.30, avg_loss=4.3633, train_err=0.2182, 32_h1=0.1822, 32_l2=0.1245, 64_h1=0.2282, 64_l2=0.1224\n",
      "[2] time=2.31, avg_loss=3.3717, train_err=0.1686, 32_h1=0.1503, 32_l2=0.0950, 64_h1=0.2161, 64_l2=0.1015\n",
      "[3] time=2.26, avg_loss=2.9819, train_err=0.1491, 32_h1=0.1428, 32_l2=0.0882, 64_h1=0.2159, 64_l2=0.0967\n",
      "[4] time=2.28, avg_loss=2.6815, train_err=0.1341, 32_h1=0.1343, 32_l2=0.0903, 64_h1=0.1981, 64_l2=0.0970\n",
      "[5] time=2.27, avg_loss=2.5144, train_err=0.1257, 32_h1=0.1252, 32_l2=0.0747, 64_h1=0.1996, 64_l2=0.0881\n",
      "[6] time=2.30, avg_loss=2.4421, train_err=0.1221, 32_h1=0.1251, 32_l2=0.0765, 64_h1=0.2126, 64_l2=0.0936\n",
      "[7] time=2.29, avg_loss=2.3348, train_err=0.1167, 32_h1=0.1220, 32_l2=0.0845, 64_h1=0.1877, 64_l2=0.0911\n",
      "[8] time=2.30, avg_loss=2.2597, train_err=0.1130, 32_h1=0.1077, 32_l2=0.0595, 64_h1=0.1830, 64_l2=0.0692\n",
      "[9] time=2.32, avg_loss=2.2413, train_err=0.1121, 32_h1=0.1170, 32_l2=0.0733, 64_h1=0.1809, 64_l2=0.0777\n",
      "[10] time=2.26, avg_loss=2.1392, train_err=0.1070, 32_h1=0.1041, 32_l2=0.0595, 64_h1=0.1829, 64_l2=0.0750\n",
      "[11] time=2.31, avg_loss=2.0988, train_err=0.1049, 32_h1=0.1164, 32_l2=0.0777, 64_h1=0.1995, 64_l2=0.0903\n",
      "[12] time=2.34, avg_loss=2.0566, train_err=0.1028, 32_h1=0.1059, 32_l2=0.0609, 64_h1=0.1964, 64_l2=0.0766\n",
      "[13] time=2.31, avg_loss=1.9773, train_err=0.0989, 32_h1=0.0982, 32_l2=0.0542, 64_h1=0.1806, 64_l2=0.0688\n",
      "[14] time=2.34, avg_loss=1.9238, train_err=0.0962, 32_h1=0.1095, 32_l2=0.0688, 64_h1=0.1802, 64_l2=0.0768\n",
      "[15] time=2.27, avg_loss=2.0339, train_err=0.1017, 32_h1=0.0988, 32_l2=0.0589, 64_h1=0.1833, 64_l2=0.0729\n",
      "[16] time=2.40, avg_loss=1.9212, train_err=0.0961, 32_h1=0.1037, 32_l2=0.0634, 64_h1=0.1718, 64_l2=0.0694\n",
      "[17] time=2.30, avg_loss=1.8896, train_err=0.0945, 32_h1=0.0950, 32_l2=0.0526, 64_h1=0.1773, 64_l2=0.0673\n",
      "[18] time=2.32, avg_loss=1.8998, train_err=0.0950, 32_h1=0.0920, 32_l2=0.0527, 64_h1=0.1767, 64_l2=0.0637\n",
      "[19] time=2.31, avg_loss=1.8417, train_err=0.0921, 32_h1=0.0880, 32_l2=0.0483, 64_h1=0.1678, 64_l2=0.0620\n",
      "[20] time=2.29, avg_loss=1.8543, train_err=0.0927, 32_h1=0.0992, 32_l2=0.0619, 64_h1=0.1864, 64_l2=0.0749\n",
      "[21] time=2.29, avg_loss=1.8413, train_err=0.0921, 32_h1=0.0978, 32_l2=0.0605, 64_h1=0.1664, 64_l2=0.0698\n",
      "[22] time=2.25, avg_loss=1.8012, train_err=0.0901, 32_h1=0.0887, 32_l2=0.0467, 64_h1=0.1645, 64_l2=0.0573\n",
      "[23] time=2.25, avg_loss=1.7644, train_err=0.0882, 32_h1=0.0953, 32_l2=0.0537, 64_h1=0.1740, 64_l2=0.0689\n",
      "[24] time=2.32, avg_loss=1.7735, train_err=0.0887, 32_h1=0.0923, 32_l2=0.0567, 64_h1=0.1697, 64_l2=0.0729\n",
      "[25] time=2.30, avg_loss=1.7697, train_err=0.0885, 32_h1=0.0933, 32_l2=0.0591, 64_h1=0.1662, 64_l2=0.0693\n",
      "[26] time=2.32, avg_loss=1.7283, train_err=0.0864, 32_h1=0.0904, 32_l2=0.0540, 64_h1=0.1690, 64_l2=0.0636\n",
      "[27] time=2.25, avg_loss=1.6940, train_err=0.0847, 32_h1=0.0895, 32_l2=0.0500, 64_h1=0.1712, 64_l2=0.0677\n",
      "[28] time=2.30, avg_loss=1.7740, train_err=0.0887, 32_h1=0.0851, 32_l2=0.0453, 64_h1=0.1588, 64_l2=0.0525\n",
      "[29] time=2.30, avg_loss=1.7023, train_err=0.0851, 32_h1=0.0923, 32_l2=0.0519, 64_h1=0.1737, 64_l2=0.0658\n",
      "[30] time=2.28, avg_loss=1.7290, train_err=0.0865, 32_h1=0.1042, 32_l2=0.0698, 64_h1=0.1832, 64_l2=0.0830\n",
      "[31] time=2.36, avg_loss=1.8138, train_err=0.0907, 32_h1=0.0854, 32_l2=0.0457, 64_h1=0.1609, 64_l2=0.0550\n",
      "[32] time=2.22, avg_loss=1.7071, train_err=0.0854, 32_h1=0.0852, 32_l2=0.0470, 64_h1=0.1685, 64_l2=0.0598\n",
      "[33] time=2.07, avg_loss=1.6573, train_err=0.0829, 32_h1=0.0864, 32_l2=0.0495, 64_h1=0.1743, 64_l2=0.0662\n",
      "[34] time=2.01, avg_loss=1.6640, train_err=0.0832, 32_h1=0.0814, 32_l2=0.0411, 64_h1=0.1659, 64_l2=0.0570\n",
      "[35] time=2.08, avg_loss=1.5869, train_err=0.0793, 32_h1=0.0823, 32_l2=0.0421, 64_h1=0.1577, 64_l2=0.0503\n",
      "[36] time=2.04, avg_loss=1.5945, train_err=0.0797, 32_h1=0.0806, 32_l2=0.0413, 64_h1=0.1651, 64_l2=0.0594\n",
      "[37] time=2.18, avg_loss=1.6479, train_err=0.0824, 32_h1=0.0850, 32_l2=0.0452, 64_h1=0.1693, 64_l2=0.0598\n",
      "[38] time=2.23, avg_loss=1.7071, train_err=0.0854, 32_h1=0.0872, 32_l2=0.0494, 64_h1=0.1650, 64_l2=0.0623\n",
      "[39] time=2.16, avg_loss=1.5688, train_err=0.0784, 32_h1=0.0841, 32_l2=0.0451, 64_h1=0.1685, 64_l2=0.0599\n",
      "[40] time=2.19, avg_loss=1.6396, train_err=0.0820, 32_h1=0.1137, 32_l2=0.0869, 64_h1=0.1906, 64_l2=0.0941\n",
      "[41] time=2.08, avg_loss=1.6094, train_err=0.0805, 32_h1=0.0816, 32_l2=0.0430, 64_h1=0.1679, 64_l2=0.0630\n",
      "[42] time=2.15, avg_loss=1.5987, train_err=0.0799, 32_h1=0.0835, 32_l2=0.0456, 64_h1=0.1632, 64_l2=0.0612\n",
      "[43] time=2.18, avg_loss=1.5623, train_err=0.0781, 32_h1=0.0864, 32_l2=0.0498, 64_h1=0.1634, 64_l2=0.0597\n",
      "[44] time=2.01, avg_loss=1.5805, train_err=0.0790, 32_h1=0.0891, 32_l2=0.0555, 64_h1=0.1677, 64_l2=0.0668\n",
      "[45] time=2.05, avg_loss=1.5670, train_err=0.0783, 32_h1=0.0845, 32_l2=0.0458, 64_h1=0.1718, 64_l2=0.0657\n",
      "[46] time=2.17, avg_loss=1.5486, train_err=0.0774, 32_h1=0.0789, 32_l2=0.0395, 64_h1=0.1620, 64_l2=0.0539\n",
      "[47] time=2.03, avg_loss=1.6029, train_err=0.0801, 32_h1=0.0830, 32_l2=0.0454, 64_h1=0.1672, 64_l2=0.0617\n",
      "[48] time=2.06, avg_loss=1.5504, train_err=0.0775, 32_h1=0.0893, 32_l2=0.0560, 64_h1=0.1658, 64_l2=0.0603\n",
      "[49] time=2.15, avg_loss=1.5629, train_err=0.0781, 32_h1=0.0824, 32_l2=0.0442, 64_h1=0.1612, 64_l2=0.0553\n",
      "[50] time=2.01, avg_loss=1.5429, train_err=0.0771, 32_h1=0.0809, 32_l2=0.0420, 64_h1=0.1609, 64_l2=0.0537\n",
      "[51] time=2.07, avg_loss=1.5305, train_err=0.0765, 32_h1=0.0834, 32_l2=0.0511, 64_h1=0.1572, 64_l2=0.0587\n",
      "[52] time=2.14, avg_loss=1.5009, train_err=0.0750, 32_h1=0.0779, 32_l2=0.0383, 64_h1=0.1580, 64_l2=0.0549\n",
      "[53] time=2.15, avg_loss=1.5573, train_err=0.0779, 32_h1=0.0815, 32_l2=0.0414, 64_h1=0.1623, 64_l2=0.0557\n",
      "[54] time=2.19, avg_loss=1.5317, train_err=0.0766, 32_h1=0.0788, 32_l2=0.0406, 64_h1=0.1631, 64_l2=0.0556\n",
      "[55] time=2.19, avg_loss=1.4849, train_err=0.0742, 32_h1=0.1010, 32_l2=0.0739, 64_h1=0.1626, 64_l2=0.0813\n",
      "[56] time=2.07, avg_loss=1.5749, train_err=0.0787, 32_h1=0.0799, 32_l2=0.0419, 64_h1=0.1632, 64_l2=0.0603\n",
      "[57] time=2.00, avg_loss=1.4473, train_err=0.0724, 32_h1=0.0827, 32_l2=0.0463, 64_h1=0.1684, 64_l2=0.0651\n",
      "[58] time=2.01, avg_loss=1.4440, train_err=0.0722, 32_h1=0.0828, 32_l2=0.0521, 64_h1=0.1658, 64_l2=0.0624\n",
      "[59] time=2.01, avg_loss=1.4713, train_err=0.0736, 32_h1=0.0786, 32_l2=0.0392, 64_h1=0.1590, 64_l2=0.0554\n",
      "[60] time=2.04, avg_loss=1.4775, train_err=0.0739, 32_h1=0.0782, 32_l2=0.0388, 64_h1=0.1636, 64_l2=0.0586\n",
      "[61] time=2.09, avg_loss=1.4823, train_err=0.0741, 32_h1=0.0797, 32_l2=0.0423, 64_h1=0.1634, 64_l2=0.0567\n",
      "[62] time=2.28, avg_loss=1.4872, train_err=0.0744, 32_h1=0.0799, 32_l2=0.0439, 64_h1=0.1577, 64_l2=0.0585\n",
      "[63] time=2.34, avg_loss=1.4385, train_err=0.0719, 32_h1=0.0768, 32_l2=0.0383, 64_h1=0.1583, 64_l2=0.0510\n",
      "[64] time=2.37, avg_loss=1.4728, train_err=0.0736, 32_h1=0.0826, 32_l2=0.0447, 64_h1=0.1655, 64_l2=0.0577\n",
      "[65] time=2.43, avg_loss=1.4656, train_err=0.0733, 32_h1=0.0797, 32_l2=0.0437, 64_h1=0.1609, 64_l2=0.0543\n",
      "[66] time=2.42, avg_loss=1.5013, train_err=0.0751, 32_h1=0.0794, 32_l2=0.0424, 64_h1=0.1589, 64_l2=0.0558\n",
      "[67] time=2.39, avg_loss=1.4333, train_err=0.0717, 32_h1=0.0775, 32_l2=0.0423, 64_h1=0.1676, 64_l2=0.0578\n",
      "[68] time=2.38, avg_loss=1.4010, train_err=0.0701, 32_h1=0.0795, 32_l2=0.0465, 64_h1=0.1581, 64_l2=0.0623\n",
      "[69] time=2.29, avg_loss=1.4284, train_err=0.0714, 32_h1=0.0796, 32_l2=0.0408, 64_h1=0.1645, 64_l2=0.0552\n",
      "[70] time=2.35, avg_loss=1.4510, train_err=0.0725, 32_h1=0.0800, 32_l2=0.0415, 64_h1=0.1605, 64_l2=0.0520\n",
      "[71] time=2.40, avg_loss=1.4694, train_err=0.0735, 32_h1=0.0834, 32_l2=0.0473, 64_h1=0.1564, 64_l2=0.0555\n",
      "[72] time=2.45, avg_loss=1.3843, train_err=0.0692, 32_h1=0.0784, 32_l2=0.0438, 64_h1=0.1664, 64_l2=0.0599\n",
      "[73] time=2.32, avg_loss=1.3918, train_err=0.0696, 32_h1=0.0785, 32_l2=0.0387, 64_h1=0.1647, 64_l2=0.0525\n",
      "[74] time=2.40, avg_loss=1.3903, train_err=0.0695, 32_h1=0.0773, 32_l2=0.0398, 64_h1=0.1682, 64_l2=0.0620\n",
      "[75] time=2.35, avg_loss=1.3764, train_err=0.0688, 32_h1=0.0762, 32_l2=0.0375, 64_h1=0.1686, 64_l2=0.0584\n",
      "[76] time=2.31, avg_loss=1.3545, train_err=0.0677, 32_h1=0.0757, 32_l2=0.0390, 64_h1=0.1600, 64_l2=0.0588\n",
      "[77] time=2.40, avg_loss=1.3701, train_err=0.0685, 32_h1=0.0777, 32_l2=0.0393, 64_h1=0.1633, 64_l2=0.0574\n",
      "[78] time=2.33, avg_loss=1.3897, train_err=0.0695, 32_h1=0.0772, 32_l2=0.0396, 64_h1=0.1628, 64_l2=0.0563\n",
      "[79] time=2.29, avg_loss=1.3748, train_err=0.0687, 32_h1=0.0768, 32_l2=0.0377, 64_h1=0.1537, 64_l2=0.0484\n",
      "[80] time=2.30, avg_loss=1.3800, train_err=0.0690, 32_h1=0.0758, 32_l2=0.0375, 64_h1=0.1651, 64_l2=0.0557\n",
      "[81] time=2.32, avg_loss=1.3493, train_err=0.0675, 32_h1=0.0765, 32_l2=0.0385, 64_h1=0.1587, 64_l2=0.0558\n",
      "[82] time=2.33, avg_loss=1.3687, train_err=0.0684, 32_h1=0.0793, 32_l2=0.0442, 64_h1=0.1673, 64_l2=0.0568\n",
      "[83] time=2.31, avg_loss=1.4295, train_err=0.0715, 32_h1=0.0812, 32_l2=0.0466, 64_h1=0.1651, 64_l2=0.0646\n",
      "[84] time=2.32, avg_loss=1.3493, train_err=0.0675, 32_h1=0.0753, 32_l2=0.0368, 64_h1=0.1625, 64_l2=0.0530\n",
      "[85] time=2.40, avg_loss=1.3902, train_err=0.0695, 32_h1=0.0749, 32_l2=0.0370, 64_h1=0.1585, 64_l2=0.0499\n",
      "[86] time=2.40, avg_loss=1.3296, train_err=0.0665, 32_h1=0.0789, 32_l2=0.0405, 64_h1=0.1615, 64_l2=0.0592\n",
      "[87] time=2.37, avg_loss=1.3232, train_err=0.0662, 32_h1=0.0739, 32_l2=0.0355, 64_h1=0.1573, 64_l2=0.0487\n",
      "[88] time=2.40, avg_loss=1.3364, train_err=0.0668, 32_h1=0.0783, 32_l2=0.0411, 64_h1=0.1668, 64_l2=0.0579\n",
      "[89] time=2.42, avg_loss=1.3161, train_err=0.0658, 32_h1=0.0754, 32_l2=0.0374, 64_h1=0.1630, 64_l2=0.0521\n",
      "[90] time=2.31, avg_loss=1.3125, train_err=0.0656, 32_h1=0.0755, 32_l2=0.0381, 64_h1=0.1622, 64_l2=0.0544\n",
      "[91] time=2.31, avg_loss=1.3439, train_err=0.0672, 32_h1=0.0847, 32_l2=0.0534, 64_h1=0.1692, 64_l2=0.0639\n",
      "[92] time=2.38, avg_loss=1.3477, train_err=0.0674, 32_h1=0.0752, 32_l2=0.0375, 64_h1=0.1605, 64_l2=0.0525\n",
      "[93] time=2.33, avg_loss=1.3257, train_err=0.0663, 32_h1=0.0751, 32_l2=0.0375, 64_h1=0.1627, 64_l2=0.0521\n",
      "[94] time=2.34, avg_loss=1.3079, train_err=0.0654, 32_h1=0.0798, 32_l2=0.0411, 64_h1=0.1616, 64_l2=0.0550\n",
      "[95] time=2.38, avg_loss=1.3051, train_err=0.0653, 32_h1=0.0760, 32_l2=0.0377, 64_h1=0.1587, 64_l2=0.0502\n",
      "[96] time=2.32, avg_loss=1.3213, train_err=0.0661, 32_h1=0.0774, 32_l2=0.0387, 64_h1=0.1601, 64_l2=0.0548\n",
      "[97] time=2.35, avg_loss=1.3234, train_err=0.0662, 32_h1=0.0764, 32_l2=0.0377, 64_h1=0.1635, 64_l2=0.0552\n",
      "[98] time=2.30, avg_loss=1.2859, train_err=0.0643, 32_h1=0.0769, 32_l2=0.0381, 64_h1=0.1643, 64_l2=0.0510\n",
      "[99] time=2.36, avg_loss=1.2531, train_err=0.0627, 32_h1=0.0743, 32_l2=0.0357, 64_h1=0.1639, 64_l2=0.0561\n",
      "[100] time=2.20, avg_loss=1.2756, train_err=0.0638, 32_h1=0.0753, 32_l2=0.0362, 64_h1=0.1614, 64_l2=0.0496\n",
      "[101] time=2.02, avg_loss=1.2961, train_err=0.0648, 32_h1=0.0777, 32_l2=0.0414, 64_h1=0.1664, 64_l2=0.0579\n",
      "[102] time=2.05, avg_loss=1.3025, train_err=0.0651, 32_h1=0.0749, 32_l2=0.0360, 64_h1=0.1617, 64_l2=0.0489\n",
      "[103] time=2.06, avg_loss=1.2669, train_err=0.0633, 32_h1=0.0772, 32_l2=0.0387, 64_h1=0.1648, 64_l2=0.0540\n",
      "[104] time=2.02, avg_loss=1.2560, train_err=0.0628, 32_h1=0.0773, 32_l2=0.0399, 64_h1=0.1671, 64_l2=0.0588\n",
      "[105] time=2.01, avg_loss=1.2903, train_err=0.0645, 32_h1=0.0783, 32_l2=0.0408, 64_h1=0.1680, 64_l2=0.0575\n",
      "[106] time=2.01, avg_loss=1.2452, train_err=0.0623, 32_h1=0.0778, 32_l2=0.0410, 64_h1=0.1671, 64_l2=0.0515\n",
      "[107] time=2.06, avg_loss=1.2502, train_err=0.0625, 32_h1=0.0758, 32_l2=0.0364, 64_h1=0.1616, 64_l2=0.0538\n",
      "[108] time=2.06, avg_loss=1.2436, train_err=0.0622, 32_h1=0.0754, 32_l2=0.0365, 64_h1=0.1674, 64_l2=0.0553\n",
      "[109] time=2.03, avg_loss=1.2703, train_err=0.0635, 32_h1=0.0807, 32_l2=0.0424, 64_h1=0.1689, 64_l2=0.0566\n",
      "[110] time=2.09, avg_loss=1.2298, train_err=0.0615, 32_h1=0.0760, 32_l2=0.0375, 64_h1=0.1702, 64_l2=0.0568\n",
      "[111] time=2.07, avg_loss=1.2351, train_err=0.0618, 32_h1=0.0773, 32_l2=0.0388, 64_h1=0.1680, 64_l2=0.0598\n",
      "[112] time=2.19, avg_loss=1.2560, train_err=0.0628, 32_h1=0.0784, 32_l2=0.0399, 64_h1=0.1649, 64_l2=0.0566\n",
      "[113] time=2.16, avg_loss=1.2412, train_err=0.0621, 32_h1=0.0769, 32_l2=0.0375, 64_h1=0.1604, 64_l2=0.0520\n",
      "[114] time=2.03, avg_loss=1.1835, train_err=0.0592, 32_h1=0.0752, 32_l2=0.0359, 64_h1=0.1671, 64_l2=0.0554\n",
      "[115] time=2.01, avg_loss=1.1774, train_err=0.0589, 32_h1=0.0788, 32_l2=0.0400, 64_h1=0.1708, 64_l2=0.0572\n",
      "[116] time=2.03, avg_loss=1.1975, train_err=0.0599, 32_h1=0.0766, 32_l2=0.0373, 64_h1=0.1653, 64_l2=0.0549\n",
      "[117] time=2.00, avg_loss=1.1975, train_err=0.0599, 32_h1=0.0762, 32_l2=0.0364, 64_h1=0.1706, 64_l2=0.0569\n",
      "[118] time=2.09, avg_loss=1.1766, train_err=0.0588, 32_h1=0.0752, 32_l2=0.0353, 64_h1=0.1645, 64_l2=0.0514\n",
      "[119] time=2.02, avg_loss=1.1946, train_err=0.0597, 32_h1=0.0784, 32_l2=0.0408, 64_h1=0.1677, 64_l2=0.0563\n",
      "[120] time=2.04, avg_loss=1.2241, train_err=0.0612, 32_h1=0.0763, 32_l2=0.0365, 64_h1=0.1657, 64_l2=0.0508\n",
      "[121] time=2.00, avg_loss=1.1623, train_err=0.0581, 32_h1=0.0779, 32_l2=0.0389, 64_h1=0.1685, 64_l2=0.0544\n",
      "[122] time=2.00, avg_loss=1.1762, train_err=0.0588, 32_h1=0.0786, 32_l2=0.0400, 64_h1=0.1725, 64_l2=0.0598\n",
      "[123] time=2.01, avg_loss=1.1593, train_err=0.0580, 32_h1=0.0804, 32_l2=0.0424, 64_h1=0.1623, 64_l2=0.0560\n",
      "[124] time=2.00, avg_loss=1.1638, train_err=0.0582, 32_h1=0.0772, 32_l2=0.0369, 64_h1=0.1682, 64_l2=0.0536\n",
      "[125] time=2.07, avg_loss=1.1518, train_err=0.0576, 32_h1=0.0791, 32_l2=0.0394, 64_h1=0.1722, 64_l2=0.0531\n",
      "[126] time=2.13, avg_loss=1.1663, train_err=0.0583, 32_h1=0.0769, 32_l2=0.0368, 64_h1=0.1645, 64_l2=0.0523\n",
      "[127] time=2.07, avg_loss=1.1576, train_err=0.0579, 32_h1=0.0811, 32_l2=0.0417, 64_h1=0.1682, 64_l2=0.0588\n",
      "[128] time=2.07, avg_loss=1.1459, train_err=0.0573, 32_h1=0.0783, 32_l2=0.0389, 64_h1=0.1675, 64_l2=0.0545\n",
      "[129] time=2.12, avg_loss=1.1259, train_err=0.0563, 32_h1=0.0789, 32_l2=0.0387, 64_h1=0.1703, 64_l2=0.0540\n",
      "[130] time=2.34, avg_loss=1.1243, train_err=0.0562, 32_h1=0.0777, 32_l2=0.0367, 64_h1=0.1695, 64_l2=0.0548\n",
      "[131] time=2.37, avg_loss=1.1000, train_err=0.0550, 32_h1=0.0796, 32_l2=0.0399, 64_h1=0.1695, 64_l2=0.0524\n",
      "[132] time=2.35, avg_loss=1.1162, train_err=0.0558, 32_h1=0.0784, 32_l2=0.0391, 64_h1=0.1669, 64_l2=0.0571\n",
      "[133] time=2.33, avg_loss=1.1017, train_err=0.0551, 32_h1=0.0788, 32_l2=0.0378, 64_h1=0.1684, 64_l2=0.0556\n",
      "[134] time=2.28, avg_loss=1.1159, train_err=0.0558, 32_h1=0.0778, 32_l2=0.0372, 64_h1=0.1666, 64_l2=0.0522\n",
      "[135] time=2.42, avg_loss=1.1012, train_err=0.0551, 32_h1=0.0788, 32_l2=0.0383, 64_h1=0.1680, 64_l2=0.0529\n",
      "[136] time=2.41, avg_loss=1.0893, train_err=0.0545, 32_h1=0.0791, 32_l2=0.0375, 64_h1=0.1656, 64_l2=0.0514\n",
      "[137] time=2.36, avg_loss=1.1011, train_err=0.0551, 32_h1=0.0809, 32_l2=0.0424, 64_h1=0.1659, 64_l2=0.0582\n",
      "[138] time=2.42, avg_loss=1.0937, train_err=0.0547, 32_h1=0.0822, 32_l2=0.0462, 64_h1=0.1712, 64_l2=0.0583\n",
      "[139] time=2.34, avg_loss=1.0938, train_err=0.0547, 32_h1=0.0797, 32_l2=0.0387, 64_h1=0.1717, 64_l2=0.0554\n",
      "[140] time=2.32, avg_loss=1.0789, train_err=0.0539, 32_h1=0.0796, 32_l2=0.0381, 64_h1=0.1722, 64_l2=0.0551\n",
      "[141] time=2.31, avg_loss=1.0782, train_err=0.0539, 32_h1=0.0790, 32_l2=0.0375, 64_h1=0.1670, 64_l2=0.0559\n",
      "[142] time=2.33, avg_loss=1.0643, train_err=0.0532, 32_h1=0.0800, 32_l2=0.0396, 64_h1=0.1699, 64_l2=0.0562\n",
      "[143] time=2.39, avg_loss=1.0588, train_err=0.0529, 32_h1=0.0811, 32_l2=0.0410, 64_h1=0.1718, 64_l2=0.0589\n",
      "[144] time=2.37, avg_loss=1.0666, train_err=0.0533, 32_h1=0.0807, 32_l2=0.0395, 64_h1=0.1681, 64_l2=0.0547\n",
      "[145] time=2.35, avg_loss=1.0823, train_err=0.0541, 32_h1=0.0799, 32_l2=0.0384, 64_h1=0.1674, 64_l2=0.0560\n",
      "[146] time=2.31, avg_loss=1.0453, train_err=0.0523, 32_h1=0.0799, 32_l2=0.0392, 64_h1=0.1709, 64_l2=0.0539\n",
      "[147] time=2.29, avg_loss=1.0492, train_err=0.0525, 32_h1=0.0803, 32_l2=0.0392, 64_h1=0.1733, 64_l2=0.0573\n",
      "[148] time=2.27, avg_loss=1.0339, train_err=0.0517, 32_h1=0.0811, 32_l2=0.0395, 64_h1=0.1697, 64_l2=0.0579\n",
      "[149] time=2.31, avg_loss=1.0391, train_err=0.0520, 32_h1=0.0814, 32_l2=0.0402, 64_h1=0.1702, 64_l2=0.0550\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.9\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 600257\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(31, 31, 6, 6))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(31, 31, 6, 6))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(31, 31, 6, 6))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(31, 31, 6, 6))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(31, 31, 6, 6))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(31, 31, 6, 6))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(31, 31, 6, 6))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(31, 31, 6, 6))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f986ea1ca90>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f975765a9a0>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f975765a9a0>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f983c59d4f0>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.30, avg_loss=10.2585, train_err=0.5129, 32_h1=0.3248, 32_l2=0.2182, 64_h1=0.3767, 64_l2=0.2223\n",
      "[1] time=2.35, avg_loss=4.9759, train_err=0.2488, 32_h1=0.2088, 32_l2=0.1416, 64_h1=0.2705, 64_l2=0.1555\n",
      "[2] time=2.41, avg_loss=3.8321, train_err=0.1916, 32_h1=0.1796, 32_l2=0.1242, 64_h1=0.2357, 64_l2=0.1296\n",
      "[3] time=2.47, avg_loss=3.3396, train_err=0.1670, 32_h1=0.1715, 32_l2=0.1135, 64_h1=0.2130, 64_l2=0.1132\n",
      "[4] time=2.39, avg_loss=3.0330, train_err=0.1517, 32_h1=0.1607, 32_l2=0.1089, 64_h1=0.2031, 64_l2=0.1108\n",
      "[5] time=2.29, avg_loss=2.8449, train_err=0.1422, 32_h1=0.1436, 32_l2=0.0956, 64_h1=0.2062, 64_l2=0.0998\n",
      "[6] time=2.36, avg_loss=2.7133, train_err=0.1357, 32_h1=0.1335, 32_l2=0.0857, 64_h1=0.2149, 64_l2=0.0982\n",
      "[7] time=2.32, avg_loss=2.5779, train_err=0.1289, 32_h1=0.1151, 32_l2=0.0636, 64_h1=0.1957, 64_l2=0.0769\n",
      "[8] time=2.33, avg_loss=2.3694, train_err=0.1185, 32_h1=0.1186, 32_l2=0.0731, 64_h1=0.1874, 64_l2=0.0863\n",
      "[9] time=2.37, avg_loss=2.3962, train_err=0.1198, 32_h1=0.1155, 32_l2=0.0664, 64_h1=0.1956, 64_l2=0.0798\n",
      "[10] time=2.38, avg_loss=2.1790, train_err=0.1090, 32_h1=0.1070, 32_l2=0.0615, 64_h1=0.1795, 64_l2=0.0683\n",
      "[11] time=2.34, avg_loss=2.1257, train_err=0.1063, 32_h1=0.1071, 32_l2=0.0599, 64_h1=0.1833, 64_l2=0.0752\n",
      "[12] time=2.37, avg_loss=2.0746, train_err=0.1037, 32_h1=0.0993, 32_l2=0.0535, 64_h1=0.1825, 64_l2=0.0669\n",
      "[13] time=2.37, avg_loss=2.1380, train_err=0.1069, 32_h1=0.1217, 32_l2=0.0870, 64_h1=0.1949, 64_l2=0.0964\n",
      "[14] time=2.33, avg_loss=2.0295, train_err=0.1015, 32_h1=0.1036, 32_l2=0.0639, 64_h1=0.1816, 64_l2=0.0700\n",
      "[15] time=2.32, avg_loss=1.9621, train_err=0.0981, 32_h1=0.1030, 32_l2=0.0605, 64_h1=0.1806, 64_l2=0.0747\n",
      "[16] time=2.29, avg_loss=1.9733, train_err=0.0987, 32_h1=0.0954, 32_l2=0.0509, 64_h1=0.1759, 64_l2=0.0654\n",
      "[17] time=2.29, avg_loss=1.8760, train_err=0.0938, 32_h1=0.0945, 32_l2=0.0521, 64_h1=0.1698, 64_l2=0.0634\n",
      "[18] time=2.33, avg_loss=1.8595, train_err=0.0930, 32_h1=0.0968, 32_l2=0.0552, 64_h1=0.1688, 64_l2=0.0627\n",
      "[19] time=2.20, avg_loss=1.9626, train_err=0.0981, 32_h1=0.0981, 32_l2=0.0556, 64_h1=0.1807, 64_l2=0.0680\n",
      "[20] time=2.21, avg_loss=1.8363, train_err=0.0918, 32_h1=0.0974, 32_l2=0.0594, 64_h1=0.1725, 64_l2=0.0719\n",
      "[21] time=2.22, avg_loss=1.8651, train_err=0.0933, 32_h1=0.0963, 32_l2=0.0566, 64_h1=0.1738, 64_l2=0.0654\n",
      "[22] time=2.18, avg_loss=1.7914, train_err=0.0896, 32_h1=0.0884, 32_l2=0.0459, 64_h1=0.1684, 64_l2=0.0581\n",
      "[23] time=2.18, avg_loss=1.8229, train_err=0.0911, 32_h1=0.0913, 32_l2=0.0495, 64_h1=0.1770, 64_l2=0.0639\n",
      "[24] time=2.04, avg_loss=1.7673, train_err=0.0884, 32_h1=0.0888, 32_l2=0.0483, 64_h1=0.1602, 64_l2=0.0563\n",
      "[25] time=2.12, avg_loss=1.7566, train_err=0.0878, 32_h1=0.0845, 32_l2=0.0426, 64_h1=0.1668, 64_l2=0.0546\n",
      "[26] time=2.18, avg_loss=1.6405, train_err=0.0820, 32_h1=0.0828, 32_l2=0.0415, 64_h1=0.1669, 64_l2=0.0549\n",
      "[27] time=2.12, avg_loss=1.6722, train_err=0.0836, 32_h1=0.0934, 32_l2=0.0526, 64_h1=0.1779, 64_l2=0.0672\n",
      "[28] time=2.02, avg_loss=1.7028, train_err=0.0851, 32_h1=0.0876, 32_l2=0.0501, 64_h1=0.1634, 64_l2=0.0652\n",
      "[29] time=2.01, avg_loss=1.6528, train_err=0.0826, 32_h1=0.0816, 32_l2=0.0415, 64_h1=0.1637, 64_l2=0.0555\n",
      "[30] time=2.01, avg_loss=1.6281, train_err=0.0814, 32_h1=0.0921, 32_l2=0.0548, 64_h1=0.1720, 64_l2=0.0646\n",
      "[31] time=2.01, avg_loss=1.6646, train_err=0.0832, 32_h1=0.0844, 32_l2=0.0445, 64_h1=0.1703, 64_l2=0.0645\n",
      "[32] time=2.17, avg_loss=1.6289, train_err=0.0814, 32_h1=0.0815, 32_l2=0.0415, 64_h1=0.1647, 64_l2=0.0574\n",
      "[33] time=2.13, avg_loss=1.6220, train_err=0.0811, 32_h1=0.0818, 32_l2=0.0419, 64_h1=0.1643, 64_l2=0.0572\n",
      "[34] time=2.18, avg_loss=1.6161, train_err=0.0808, 32_h1=0.0884, 32_l2=0.0504, 64_h1=0.1647, 64_l2=0.0570\n",
      "[35] time=2.03, avg_loss=1.6161, train_err=0.0808, 32_h1=0.0899, 32_l2=0.0575, 64_h1=0.1693, 64_l2=0.0710\n",
      "[36] time=2.10, avg_loss=1.6147, train_err=0.0807, 32_h1=0.0835, 32_l2=0.0450, 64_h1=0.1693, 64_l2=0.0652\n",
      "[37] time=2.13, avg_loss=1.5927, train_err=0.0796, 32_h1=0.0837, 32_l2=0.0442, 64_h1=0.1724, 64_l2=0.0624\n",
      "[38] time=2.10, avg_loss=1.6071, train_err=0.0804, 32_h1=0.0916, 32_l2=0.0552, 64_h1=0.1747, 64_l2=0.0722\n",
      "[39] time=2.19, avg_loss=1.5968, train_err=0.0798, 32_h1=0.0842, 32_l2=0.0460, 64_h1=0.1664, 64_l2=0.0579\n",
      "[40] time=2.13, avg_loss=1.5584, train_err=0.0779, 32_h1=0.0795, 32_l2=0.0401, 64_h1=0.1568, 64_l2=0.0527\n",
      "[41] time=2.04, avg_loss=1.5532, train_err=0.0777, 32_h1=0.0790, 32_l2=0.0398, 64_h1=0.1588, 64_l2=0.0490\n",
      "[42] time=2.03, avg_loss=1.5483, train_err=0.0774, 32_h1=0.0808, 32_l2=0.0417, 64_h1=0.1642, 64_l2=0.0559\n",
      "[43] time=2.02, avg_loss=1.5815, train_err=0.0791, 32_h1=0.0811, 32_l2=0.0434, 64_h1=0.1591, 64_l2=0.0558\n",
      "[44] time=2.01, avg_loss=1.5222, train_err=0.0761, 32_h1=0.0818, 32_l2=0.0432, 64_h1=0.1597, 64_l2=0.0548\n",
      "[45] time=2.16, avg_loss=1.5145, train_err=0.0757, 32_h1=0.0840, 32_l2=0.0460, 64_h1=0.1562, 64_l2=0.0581\n",
      "[46] time=2.16, avg_loss=1.5262, train_err=0.0763, 32_h1=0.0831, 32_l2=0.0441, 64_h1=0.1613, 64_l2=0.0614\n",
      "[47] time=2.16, avg_loss=1.5087, train_err=0.0754, 32_h1=0.0800, 32_l2=0.0425, 64_h1=0.1591, 64_l2=0.0568\n",
      "[48] time=2.07, avg_loss=1.4950, train_err=0.0747, 32_h1=0.0798, 32_l2=0.0432, 64_h1=0.1653, 64_l2=0.0593\n",
      "[49] time=2.24, avg_loss=1.5078, train_err=0.0754, 32_h1=0.0891, 32_l2=0.0516, 64_h1=0.1746, 64_l2=0.0670\n",
      "[50] time=2.38, avg_loss=1.4862, train_err=0.0743, 32_h1=0.0768, 32_l2=0.0387, 64_h1=0.1614, 64_l2=0.0566\n",
      "[51] time=2.28, avg_loss=1.5006, train_err=0.0750, 32_h1=0.0795, 32_l2=0.0415, 64_h1=0.1698, 64_l2=0.0576\n",
      "[52] time=2.32, avg_loss=1.5186, train_err=0.0759, 32_h1=0.0800, 32_l2=0.0413, 64_h1=0.1631, 64_l2=0.0574\n",
      "[53] time=2.31, avg_loss=1.5087, train_err=0.0754, 32_h1=0.0811, 32_l2=0.0447, 64_h1=0.1637, 64_l2=0.0575\n",
      "[54] time=2.32, avg_loss=1.4883, train_err=0.0744, 32_h1=0.0819, 32_l2=0.0460, 64_h1=0.1650, 64_l2=0.0601\n",
      "[55] time=2.28, avg_loss=1.4632, train_err=0.0732, 32_h1=0.0843, 32_l2=0.0472, 64_h1=0.1711, 64_l2=0.0631\n",
      "[56] time=2.34, avg_loss=1.4454, train_err=0.0723, 32_h1=0.0801, 32_l2=0.0438, 64_h1=0.1611, 64_l2=0.0578\n",
      "[57] time=2.32, avg_loss=1.4686, train_err=0.0734, 32_h1=0.0794, 32_l2=0.0401, 64_h1=0.1672, 64_l2=0.0559\n",
      "[58] time=2.30, avg_loss=1.4626, train_err=0.0731, 32_h1=0.0772, 32_l2=0.0383, 64_h1=0.1651, 64_l2=0.0588\n",
      "[59] time=2.34, avg_loss=1.4426, train_err=0.0721, 32_h1=0.0822, 32_l2=0.0445, 64_h1=0.1629, 64_l2=0.0585\n",
      "[60] time=2.33, avg_loss=1.4214, train_err=0.0711, 32_h1=0.0761, 32_l2=0.0381, 64_h1=0.1598, 64_l2=0.0510\n",
      "[61] time=2.36, avg_loss=1.4362, train_err=0.0718, 32_h1=0.0788, 32_l2=0.0412, 64_h1=0.1577, 64_l2=0.0556\n",
      "[62] time=2.33, avg_loss=1.4251, train_err=0.0713, 32_h1=0.0789, 32_l2=0.0405, 64_h1=0.1607, 64_l2=0.0555\n",
      "[63] time=2.38, avg_loss=1.4301, train_err=0.0715, 32_h1=0.0854, 32_l2=0.0511, 64_h1=0.1693, 64_l2=0.0625\n",
      "[64] time=2.33, avg_loss=1.4411, train_err=0.0721, 32_h1=0.0778, 32_l2=0.0392, 64_h1=0.1659, 64_l2=0.0572\n",
      "[65] time=2.32, avg_loss=1.4382, train_err=0.0719, 32_h1=0.0796, 32_l2=0.0437, 64_h1=0.1553, 64_l2=0.0572\n",
      "[66] time=2.34, avg_loss=1.4234, train_err=0.0712, 32_h1=0.0793, 32_l2=0.0409, 64_h1=0.1559, 64_l2=0.0547\n",
      "[67] time=2.29, avg_loss=1.3859, train_err=0.0693, 32_h1=0.0766, 32_l2=0.0389, 64_h1=0.1611, 64_l2=0.0511\n",
      "[68] time=2.34, avg_loss=1.3873, train_err=0.0694, 32_h1=0.0743, 32_l2=0.0350, 64_h1=0.1598, 64_l2=0.0505\n",
      "[69] time=2.33, avg_loss=1.3714, train_err=0.0686, 32_h1=0.0795, 32_l2=0.0421, 64_h1=0.1577, 64_l2=0.0545\n",
      "[70] time=2.28, avg_loss=1.4309, train_err=0.0715, 32_h1=0.0799, 32_l2=0.0471, 64_h1=0.1667, 64_l2=0.0613\n",
      "[71] time=2.34, avg_loss=1.4025, train_err=0.0701, 32_h1=0.0806, 32_l2=0.0441, 64_h1=0.1539, 64_l2=0.0512\n",
      "[72] time=2.33, avg_loss=1.3952, train_err=0.0698, 32_h1=0.0748, 32_l2=0.0365, 64_h1=0.1639, 64_l2=0.0555\n",
      "[73] time=2.38, avg_loss=1.3806, train_err=0.0690, 32_h1=0.0766, 32_l2=0.0385, 64_h1=0.1619, 64_l2=0.0548\n",
      "[74] time=2.33, avg_loss=1.3636, train_err=0.0682, 32_h1=0.0766, 32_l2=0.0382, 64_h1=0.1583, 64_l2=0.0505\n",
      "[75] time=2.31, avg_loss=1.3632, train_err=0.0682, 32_h1=0.0772, 32_l2=0.0385, 64_h1=0.1613, 64_l2=0.0556\n",
      "[76] time=2.39, avg_loss=1.3954, train_err=0.0698, 32_h1=0.0756, 32_l2=0.0371, 64_h1=0.1633, 64_l2=0.0532\n",
      "[77] time=2.32, avg_loss=1.3666, train_err=0.0683, 32_h1=0.0752, 32_l2=0.0368, 64_h1=0.1626, 64_l2=0.0510\n",
      "[78] time=2.33, avg_loss=1.3804, train_err=0.0690, 32_h1=0.0782, 32_l2=0.0410, 64_h1=0.1586, 64_l2=0.0513\n",
      "[79] time=2.29, avg_loss=1.3482, train_err=0.0674, 32_h1=0.0762, 32_l2=0.0390, 64_h1=0.1614, 64_l2=0.0548\n",
      "[80] time=2.41, avg_loss=1.3476, train_err=0.0674, 32_h1=0.0750, 32_l2=0.0366, 64_h1=0.1660, 64_l2=0.0554\n",
      "[81] time=2.36, avg_loss=1.3703, train_err=0.0685, 32_h1=0.0754, 32_l2=0.0371, 64_h1=0.1579, 64_l2=0.0505\n",
      "[82] time=2.35, avg_loss=1.3532, train_err=0.0677, 32_h1=0.0764, 32_l2=0.0382, 64_h1=0.1615, 64_l2=0.0508\n",
      "[83] time=2.32, avg_loss=1.3178, train_err=0.0659, 32_h1=0.0741, 32_l2=0.0356, 64_h1=0.1559, 64_l2=0.0497\n",
      "[84] time=2.32, avg_loss=1.3082, train_err=0.0654, 32_h1=0.0749, 32_l2=0.0359, 64_h1=0.1600, 64_l2=0.0547\n",
      "[85] time=2.35, avg_loss=1.3211, train_err=0.0661, 32_h1=0.0753, 32_l2=0.0371, 64_h1=0.1609, 64_l2=0.0532\n",
      "[86] time=2.34, avg_loss=1.3128, train_err=0.0656, 32_h1=0.0770, 32_l2=0.0395, 64_h1=0.1635, 64_l2=0.0578\n",
      "[87] time=2.32, avg_loss=1.3107, train_err=0.0655, 32_h1=0.0773, 32_l2=0.0408, 64_h1=0.1647, 64_l2=0.0595\n",
      "[88] time=2.30, avg_loss=1.3342, train_err=0.0667, 32_h1=0.0758, 32_l2=0.0377, 64_h1=0.1637, 64_l2=0.0550\n",
      "[89] time=2.18, avg_loss=1.2917, train_err=0.0646, 32_h1=0.0744, 32_l2=0.0364, 64_h1=0.1608, 64_l2=0.0512\n",
      "[90] time=2.15, avg_loss=1.2867, train_err=0.0643, 32_h1=0.0785, 32_l2=0.0410, 64_h1=0.1727, 64_l2=0.0646\n",
      "[91] time=2.20, avg_loss=1.2962, train_err=0.0648, 32_h1=0.0803, 32_l2=0.0459, 64_h1=0.1730, 64_l2=0.0609\n",
      "[92] time=2.13, avg_loss=1.2953, train_err=0.0648, 32_h1=0.0782, 32_l2=0.0408, 64_h1=0.1653, 64_l2=0.0582\n",
      "[93] time=2.03, avg_loss=1.3007, train_err=0.0650, 32_h1=0.0761, 32_l2=0.0376, 64_h1=0.1622, 64_l2=0.0557\n",
      "[94] time=2.07, avg_loss=1.2725, train_err=0.0636, 32_h1=0.0798, 32_l2=0.0432, 64_h1=0.1611, 64_l2=0.0534\n",
      "[95] time=2.08, avg_loss=1.2952, train_err=0.0648, 32_h1=0.0777, 32_l2=0.0391, 64_h1=0.1636, 64_l2=0.0546\n",
      "[96] time=2.00, avg_loss=1.2853, train_err=0.0643, 32_h1=0.0813, 32_l2=0.0446, 64_h1=0.1642, 64_l2=0.0576\n",
      "[97] time=2.14, avg_loss=1.2683, train_err=0.0634, 32_h1=0.0761, 32_l2=0.0381, 64_h1=0.1584, 64_l2=0.0543\n",
      "[98] time=2.19, avg_loss=1.2397, train_err=0.0620, 32_h1=0.0762, 32_l2=0.0378, 64_h1=0.1614, 64_l2=0.0530\n",
      "[99] time=2.20, avg_loss=1.2256, train_err=0.0613, 32_h1=0.0796, 32_l2=0.0425, 64_h1=0.1698, 64_l2=0.0591\n",
      "[100] time=2.14, avg_loss=1.2197, train_err=0.0610, 32_h1=0.0748, 32_l2=0.0358, 64_h1=0.1548, 64_l2=0.0471\n",
      "[101] time=2.20, avg_loss=1.2386, train_err=0.0619, 32_h1=0.0780, 32_l2=0.0398, 64_h1=0.1683, 64_l2=0.0586\n",
      "[102] time=2.10, avg_loss=1.2629, train_err=0.0631, 32_h1=0.0776, 32_l2=0.0390, 64_h1=0.1618, 64_l2=0.0524\n",
      "[103] time=2.08, avg_loss=1.2262, train_err=0.0613, 32_h1=0.0751, 32_l2=0.0357, 64_h1=0.1622, 64_l2=0.0506\n",
      "[104] time=2.18, avg_loss=1.2350, train_err=0.0617, 32_h1=0.0754, 32_l2=0.0357, 64_h1=0.1631, 64_l2=0.0535\n",
      "[105] time=2.07, avg_loss=1.2225, train_err=0.0611, 32_h1=0.0760, 32_l2=0.0371, 64_h1=0.1613, 64_l2=0.0534\n",
      "[106] time=2.18, avg_loss=1.2018, train_err=0.0601, 32_h1=0.0771, 32_l2=0.0372, 64_h1=0.1568, 64_l2=0.0482\n",
      "[107] time=2.16, avg_loss=1.2218, train_err=0.0611, 32_h1=0.0765, 32_l2=0.0376, 64_h1=0.1660, 64_l2=0.0576\n",
      "[108] time=2.21, avg_loss=1.2023, train_err=0.0601, 32_h1=0.0777, 32_l2=0.0393, 64_h1=0.1694, 64_l2=0.0559\n",
      "[109] time=2.12, avg_loss=1.2006, train_err=0.0600, 32_h1=0.0775, 32_l2=0.0373, 64_h1=0.1586, 64_l2=0.0490\n",
      "[110] time=2.10, avg_loss=1.1900, train_err=0.0595, 32_h1=0.0773, 32_l2=0.0381, 64_h1=0.1690, 64_l2=0.0559\n",
      "[111] time=2.15, avg_loss=1.1881, train_err=0.0594, 32_h1=0.0850, 32_l2=0.0521, 64_h1=0.1691, 64_l2=0.0622\n",
      "[112] time=2.15, avg_loss=1.2081, train_err=0.0604, 32_h1=0.0784, 32_l2=0.0391, 64_h1=0.1707, 64_l2=0.0538\n",
      "[113] time=2.18, avg_loss=1.2089, train_err=0.0604, 32_h1=0.0771, 32_l2=0.0367, 64_h1=0.1607, 64_l2=0.0491\n",
      "[114] time=2.03, avg_loss=1.1483, train_err=0.0574, 32_h1=0.0772, 32_l2=0.0369, 64_h1=0.1689, 64_l2=0.0529\n",
      "[115] time=2.13, avg_loss=1.1552, train_err=0.0578, 32_h1=0.0773, 32_l2=0.0370, 64_h1=0.1633, 64_l2=0.0529\n",
      "[116] time=2.04, avg_loss=1.1570, train_err=0.0579, 32_h1=0.0779, 32_l2=0.0374, 64_h1=0.1638, 64_l2=0.0531\n",
      "[117] time=2.24, avg_loss=1.1522, train_err=0.0576, 32_h1=0.0779, 32_l2=0.0378, 64_h1=0.1686, 64_l2=0.0514\n",
      "[118] time=2.39, avg_loss=1.2022, train_err=0.0601, 32_h1=0.0782, 32_l2=0.0374, 64_h1=0.1630, 64_l2=0.0532\n",
      "[119] time=2.30, avg_loss=1.1424, train_err=0.0571, 32_h1=0.0773, 32_l2=0.0373, 64_h1=0.1647, 64_l2=0.0520\n",
      "[120] time=2.29, avg_loss=1.1234, train_err=0.0562, 32_h1=0.0763, 32_l2=0.0354, 64_h1=0.1679, 64_l2=0.0529\n",
      "[121] time=2.33, avg_loss=1.1327, train_err=0.0566, 32_h1=0.0792, 32_l2=0.0406, 64_h1=0.1616, 64_l2=0.0534\n",
      "[122] time=2.31, avg_loss=1.0983, train_err=0.0549, 32_h1=0.0766, 32_l2=0.0358, 64_h1=0.1651, 64_l2=0.0534\n",
      "[123] time=2.36, avg_loss=1.0916, train_err=0.0546, 32_h1=0.0789, 32_l2=0.0383, 64_h1=0.1691, 64_l2=0.0544\n",
      "[124] time=2.29, avg_loss=1.0855, train_err=0.0543, 32_h1=0.0789, 32_l2=0.0378, 64_h1=0.1669, 64_l2=0.0566\n",
      "[125] time=2.30, avg_loss=1.0983, train_err=0.0549, 32_h1=0.0803, 32_l2=0.0405, 64_h1=0.1676, 64_l2=0.0550\n",
      "[126] time=2.28, avg_loss=1.1361, train_err=0.0568, 32_h1=0.0794, 32_l2=0.0392, 64_h1=0.1644, 64_l2=0.0510\n",
      "[127] time=2.34, avg_loss=1.0795, train_err=0.0540, 32_h1=0.0778, 32_l2=0.0367, 64_h1=0.1667, 64_l2=0.0541\n",
      "[128] time=2.30, avg_loss=1.0843, train_err=0.0542, 32_h1=0.0787, 32_l2=0.0375, 64_h1=0.1681, 64_l2=0.0547\n",
      "[129] time=2.37, avg_loss=1.0724, train_err=0.0536, 32_h1=0.0794, 32_l2=0.0378, 64_h1=0.1659, 64_l2=0.0525\n",
      "[130] time=2.34, avg_loss=1.0777, train_err=0.0539, 32_h1=0.0805, 32_l2=0.0390, 64_h1=0.1667, 64_l2=0.0526\n",
      "[131] time=2.32, avg_loss=1.0533, train_err=0.0527, 32_h1=0.0780, 32_l2=0.0363, 64_h1=0.1681, 64_l2=0.0514\n",
      "[132] time=2.28, avg_loss=1.0401, train_err=0.0520, 32_h1=0.0782, 32_l2=0.0360, 64_h1=0.1699, 64_l2=0.0527\n",
      "[133] time=2.33, avg_loss=1.0422, train_err=0.0521, 32_h1=0.0791, 32_l2=0.0370, 64_h1=0.1684, 64_l2=0.0545\n",
      "[134] time=2.37, avg_loss=1.0519, train_err=0.0526, 32_h1=0.0806, 32_l2=0.0383, 64_h1=0.1648, 64_l2=0.0520\n",
      "[135] time=2.34, avg_loss=1.0295, train_err=0.0515, 32_h1=0.0796, 32_l2=0.0373, 64_h1=0.1648, 64_l2=0.0539\n",
      "[136] time=2.32, avg_loss=1.0207, train_err=0.0510, 32_h1=0.0794, 32_l2=0.0377, 64_h1=0.1742, 64_l2=0.0580\n",
      "[137] time=2.36, avg_loss=1.0206, train_err=0.0510, 32_h1=0.0804, 32_l2=0.0383, 64_h1=0.1699, 64_l2=0.0530\n",
      "[138] time=2.33, avg_loss=1.0137, train_err=0.0507, 32_h1=0.0805, 32_l2=0.0381, 64_h1=0.1637, 64_l2=0.0501\n",
      "[139] time=2.39, avg_loss=1.0031, train_err=0.0502, 32_h1=0.0799, 32_l2=0.0385, 64_h1=0.1663, 64_l2=0.0552\n",
      "[140] time=2.33, avg_loss=1.0020, train_err=0.0501, 32_h1=0.0793, 32_l2=0.0367, 64_h1=0.1732, 64_l2=0.0539\n",
      "[141] time=2.46, avg_loss=0.9935, train_err=0.0497, 32_h1=0.0800, 32_l2=0.0381, 64_h1=0.1653, 64_l2=0.0514\n",
      "[142] time=2.34, avg_loss=0.9936, train_err=0.0497, 32_h1=0.0819, 32_l2=0.0402, 64_h1=0.1710, 64_l2=0.0551\n",
      "[143] time=2.35, avg_loss=1.0169, train_err=0.0508, 32_h1=0.0795, 32_l2=0.0368, 64_h1=0.1677, 64_l2=0.0514\n",
      "[144] time=2.29, avg_loss=0.9915, train_err=0.0496, 32_h1=0.0807, 32_l2=0.0387, 64_h1=0.1690, 64_l2=0.0535\n",
      "[145] time=2.28, avg_loss=0.9814, train_err=0.0491, 32_h1=0.0793, 32_l2=0.0373, 64_h1=0.1674, 64_l2=0.0532\n",
      "[146] time=2.36, avg_loss=0.9598, train_err=0.0480, 32_h1=0.0800, 32_l2=0.0369, 64_h1=0.1690, 64_l2=0.0530\n",
      "[147] time=2.31, avg_loss=0.9662, train_err=0.0483, 32_h1=0.0808, 32_l2=0.0382, 64_h1=0.1710, 64_l2=0.0550\n",
      "[148] time=2.35, avg_loss=1.0001, train_err=0.0500, 32_h1=0.0813, 32_l2=0.0393, 64_h1=0.1694, 64_l2=0.0563\n",
      "[149] time=2.33, avg_loss=0.9552, train_err=0.0478, 32_h1=0.0819, 32_l2=0.0385, 64_h1=0.1749, 64_l2=0.0580\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in np.arange(0.1, 1.0, 0.1):\n",
    "    # Read the configuration\n",
    "    config_name = 'default'\n",
    "    pipe = ConfigPipeline([YamlConfig('./tfno_darcy_config.yaml', config_name='default', config_folder='./config'),\n",
    "                          ])\n",
    "    config = pipe.read_conf()\n",
    "    config_name = pipe.steps[-1].config_name\n",
    "    \n",
    "    config.tfno2d.rank = i\n",
    "    \n",
    "    # Set-up distributed communication, if using\n",
    "    device, is_logger = setup(config)\n",
    "    \n",
    "    # Make sure we only print information when needed\n",
    "    config.verbose = config.verbose and is_logger\n",
    "\n",
    "    #Print config to screen\n",
    "    if config.verbose and is_logger:\n",
    "        pipe.log()\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    # Loading the Darcy flow training set in 32x32 resolution, test set in 32x32 and 64x64 resolutions\n",
    "    train_loader, test_loaders, output_encoder = load_darcy_pt(\n",
    "            config.data.folder, train_resolution=config.data.train_resolution, n_train=config.data.n_train, batch_size=config.data.batch_size, \n",
    "            positional_encoding=config.data.positional_encoding,\n",
    "            test_resolutions=config.data.test_resolutions, n_tests=config.data.n_tests, test_batch_sizes=config.data.test_batch_sizes,\n",
    "            encode_input=config.data.encode_input, encode_output=config.data.encode_output,\n",
    "            )\n",
    "    \n",
    "    model = get_model(config)\n",
    "    model = model.to(device)\n",
    "\n",
    "    #Log parameter count\n",
    "    if is_logger:\n",
    "        n_params = count_params(model)\n",
    "\n",
    "        if config.verbose:\n",
    "            print(f'\\nn_params: {n_params}')\n",
    "            sys.stdout.flush()\n",
    "    \n",
    "    #Create the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                    lr=config.opt.learning_rate, \n",
    "                                    weight_decay=config.opt.weight_decay)\n",
    "\n",
    "    if config.opt.scheduler == 'ReduceLROnPlateau':\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=config.opt.gamma, patience=config.opt.scheduler_patience, mode='min')\n",
    "    elif config.opt.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.opt.scheduler_T_max)\n",
    "    elif config.opt.scheduler == 'StepLR':\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n",
    "                                                    step_size=config.opt.step_size,\n",
    "                                                    gamma=config.opt.gamma)\n",
    "    else:\n",
    "        raise ValueError(f'Got {config.opt.scheduler=}')\n",
    "    \n",
    "    # Creating the losses\n",
    "    l2loss = LpLoss(d=2, p=2)\n",
    "    h1loss = H1Loss(d=2)\n",
    "    if config.opt.training_loss == 'l2':\n",
    "        train_loss = l2loss\n",
    "    elif config.opt.training_loss == 'h1':\n",
    "        train_loss = h1loss\n",
    "    else:\n",
    "        raise ValueError(f'Got training_loss={config.opt.training_loss} but expected one of [\"l2\", \"h1\"]')\n",
    "    eval_losses={'h1': h1loss, 'l2': l2loss}\n",
    "    \n",
    "    if config.verbose and is_logger:\n",
    "        print('\\n### MODEL ###\\n', model)\n",
    "        print('\\n### OPTIMIZER ###\\n', optimizer)\n",
    "        print('\\n### SCHEDULER ###\\n', scheduler)\n",
    "        print('\\n### LOSSES ###')\n",
    "        print(f'\\n * Train: {train_loss}')\n",
    "        print(f'\\n * Test: {eval_losses}')\n",
    "        print(f'\\n### Beginning Training...\\n')\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    trainer = Trainer(model, n_epochs=config.opt.n_epochs,\n",
    "                      device=device,\n",
    "                      mg_patching_levels=config.patching.levels,\n",
    "                      mg_patching_padding=config.patching.padding,\n",
    "                      mg_patching_stitching=config.patching.stitching,\n",
    "                      wandb_log=config.wandb.log,\n",
    "                      log_test_interval=config.wandb.log_test_interval,\n",
    "                      log_output=False,\n",
    "                      use_distributed=config.distributed.use_distributed,\n",
    "                      verbose=config.verbose and is_logger)\n",
    "    \n",
    "    trainer.train(train_loader, test_loaders,\n",
    "                  output_encoder,\n",
    "                  model, \n",
    "                  optimizer,\n",
    "                  scheduler, \n",
    "                  regularizer=False, \n",
    "                  training_loss=train_loss,\n",
    "                  eval_losses=eval_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31616af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556c009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
