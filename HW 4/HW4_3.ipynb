{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fdeb3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationESs\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import wandb\n",
    "import sys\n",
    "from configmypy import ConfigPipeline, YamlConfig, ArgparseConfig\n",
    "from neuralop import get_model\n",
    "from neuralop import Trainer\n",
    "from neuralop.training import setup\n",
    "from neuralop.datasets import load_darcy_pt\n",
    "from neuralop.utils import get_wandb_api_key, count_params\n",
    "from neuralop import LpLoss, H1Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0d544c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.02\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 26497\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(8, 8, 2, 2))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(8, 8, 2, 2))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(8, 8, 2, 2))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(8, 8, 2, 2))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(8, 8, 2, 2))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(8, 8, 2, 2))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(8, 8, 2, 2))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(8, 8, 2, 2))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f97514243a0>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f986ea1c7f0>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f986ea1c7f0>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f983c59d6a0>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.40, avg_loss=10.8973, train_err=0.5449, 32_h1=0.3498, 32_l2=0.2381, 64_h1=0.3977, 64_l2=0.2377\n",
      "[1] time=2.39, avg_loss=5.6832, train_err=0.2842, 32_h1=0.2562, 32_l2=0.1819, 64_h1=0.3169, 64_l2=0.1919\n",
      "[2] time=2.41, avg_loss=4.6075, train_err=0.2304, 32_h1=0.2082, 32_l2=0.1377, 64_h1=0.2625, 64_l2=0.1385\n",
      "[3] time=2.36, avg_loss=4.0401, train_err=0.2020, 32_h1=0.1974, 32_l2=0.1330, 64_h1=0.2688, 64_l2=0.1421\n",
      "[4] time=2.10, avg_loss=3.6706, train_err=0.1835, 32_h1=0.1774, 32_l2=0.1160, 64_h1=0.2331, 64_l2=0.1164\n",
      "[5] time=2.13, avg_loss=3.4273, train_err=0.1714, 32_h1=0.1694, 32_l2=0.1120, 64_h1=0.2277, 64_l2=0.1123\n",
      "[6] time=2.15, avg_loss=3.2053, train_err=0.1603, 32_h1=0.1562, 32_l2=0.1013, 64_h1=0.2138, 64_l2=0.1047\n",
      "[7] time=2.15, avg_loss=3.1008, train_err=0.1550, 32_h1=0.1575, 32_l2=0.1088, 64_h1=0.2154, 64_l2=0.1150\n",
      "[8] time=2.26, avg_loss=2.8961, train_err=0.1448, 32_h1=0.1430, 32_l2=0.0891, 64_h1=0.2118, 64_l2=0.0984\n",
      "[9] time=2.29, avg_loss=2.7629, train_err=0.1381, 32_h1=0.1446, 32_l2=0.0947, 64_h1=0.2042, 64_l2=0.0985\n",
      "[10] time=2.15, avg_loss=2.6596, train_err=0.1330, 32_h1=0.1450, 32_l2=0.1058, 64_h1=0.2024, 64_l2=0.1115\n",
      "[11] time=2.22, avg_loss=2.6167, train_err=0.1308, 32_h1=0.1222, 32_l2=0.0742, 64_h1=0.1926, 64_l2=0.0836\n",
      "[12] time=2.09, avg_loss=2.5484, train_err=0.1274, 32_h1=0.1557, 32_l2=0.1145, 64_h1=0.2216, 64_l2=0.1206\n",
      "[13] time=2.09, avg_loss=2.4066, train_err=0.1203, 32_h1=0.1188, 32_l2=0.0748, 64_h1=0.2017, 64_l2=0.0863\n",
      "[14] time=2.08, avg_loss=2.3938, train_err=0.1197, 32_h1=0.1210, 32_l2=0.0789, 64_h1=0.1880, 64_l2=0.0869\n",
      "[15] time=2.23, avg_loss=2.2991, train_err=0.1150, 32_h1=0.1139, 32_l2=0.0668, 64_h1=0.1856, 64_l2=0.0716\n",
      "[16] time=2.18, avg_loss=2.2133, train_err=0.1107, 32_h1=0.1137, 32_l2=0.0665, 64_h1=0.1815, 64_l2=0.0795\n",
      "[17] time=2.15, avg_loss=2.2338, train_err=0.1117, 32_h1=0.1075, 32_l2=0.0629, 64_h1=0.1814, 64_l2=0.0755\n",
      "[18] time=2.30, avg_loss=2.1995, train_err=0.1100, 32_h1=0.1069, 32_l2=0.0628, 64_h1=0.1770, 64_l2=0.0756\n",
      "[19] time=2.24, avg_loss=2.1998, train_err=0.1100, 32_h1=0.1032, 32_l2=0.0605, 64_h1=0.1793, 64_l2=0.0706\n",
      "[20] time=2.20, avg_loss=2.0737, train_err=0.1037, 32_h1=0.1037, 32_l2=0.0603, 64_h1=0.1928, 64_l2=0.0731\n",
      "[21] time=2.27, avg_loss=2.1005, train_err=0.1050, 32_h1=0.0982, 32_l2=0.0544, 64_h1=0.1792, 64_l2=0.0678\n",
      "[22] time=2.28, avg_loss=1.9803, train_err=0.0990, 32_h1=0.0990, 32_l2=0.0537, 64_h1=0.1794, 64_l2=0.0677\n",
      "[23] time=2.26, avg_loss=2.0319, train_err=0.1016, 32_h1=0.1042, 32_l2=0.0653, 64_h1=0.1716, 64_l2=0.0692\n",
      "[24] time=2.18, avg_loss=1.9330, train_err=0.0966, 32_h1=0.0961, 32_l2=0.0540, 64_h1=0.1678, 64_l2=0.0601\n",
      "[25] time=2.16, avg_loss=1.9986, train_err=0.0999, 32_h1=0.0925, 32_l2=0.0488, 64_h1=0.1668, 64_l2=0.0594\n",
      "[26] time=2.18, avg_loss=1.9429, train_err=0.0971, 32_h1=0.0959, 32_l2=0.0539, 64_h1=0.1706, 64_l2=0.0615\n",
      "[27] time=2.09, avg_loss=1.9062, train_err=0.0953, 32_h1=0.0950, 32_l2=0.0500, 64_h1=0.1757, 64_l2=0.0623\n",
      "[28] time=2.11, avg_loss=1.9110, train_err=0.0955, 32_h1=0.0952, 32_l2=0.0583, 64_h1=0.1672, 64_l2=0.0662\n",
      "[29] time=2.09, avg_loss=1.8847, train_err=0.0942, 32_h1=0.0952, 32_l2=0.0549, 64_h1=0.1687, 64_l2=0.0678\n",
      "[30] time=2.24, avg_loss=1.9155, train_err=0.0958, 32_h1=0.1097, 32_l2=0.0675, 64_h1=0.1877, 64_l2=0.0808\n",
      "[31] time=2.33, avg_loss=1.8721, train_err=0.0936, 32_h1=0.0973, 32_l2=0.0572, 64_h1=0.1754, 64_l2=0.0690\n",
      "[32] time=2.48, avg_loss=1.8451, train_err=0.0923, 32_h1=0.0941, 32_l2=0.0547, 64_h1=0.1690, 64_l2=0.0660\n",
      "[33] time=2.36, avg_loss=1.8800, train_err=0.0940, 32_h1=0.0902, 32_l2=0.0478, 64_h1=0.1698, 64_l2=0.0590\n",
      "[34] time=2.38, avg_loss=1.7945, train_err=0.0897, 32_h1=0.0980, 32_l2=0.0550, 64_h1=0.1733, 64_l2=0.0706\n",
      "[35] time=2.43, avg_loss=1.8872, train_err=0.0944, 32_h1=0.0928, 32_l2=0.0512, 64_h1=0.1704, 64_l2=0.0624\n",
      "[36] time=2.40, avg_loss=1.7799, train_err=0.0890, 32_h1=0.0924, 32_l2=0.0539, 64_h1=0.1662, 64_l2=0.0635\n",
      "[37] time=2.41, avg_loss=1.7482, train_err=0.0874, 32_h1=0.0972, 32_l2=0.0567, 64_h1=0.1614, 64_l2=0.0676\n",
      "[38] time=2.41, avg_loss=1.7593, train_err=0.0880, 32_h1=0.0898, 32_l2=0.0507, 64_h1=0.1624, 64_l2=0.0614\n",
      "[39] time=2.37, avg_loss=1.8108, train_err=0.0905, 32_h1=0.0962, 32_l2=0.0567, 64_h1=0.1671, 64_l2=0.0671\n",
      "[40] time=2.37, avg_loss=1.7542, train_err=0.0877, 32_h1=0.0918, 32_l2=0.0532, 64_h1=0.1667, 64_l2=0.0623\n",
      "[41] time=2.42, avg_loss=1.8044, train_err=0.0902, 32_h1=0.0910, 32_l2=0.0492, 64_h1=0.1666, 64_l2=0.0624\n",
      "[42] time=2.41, avg_loss=1.7366, train_err=0.0868, 32_h1=0.0885, 32_l2=0.0469, 64_h1=0.1595, 64_l2=0.0580\n",
      "[43] time=2.37, avg_loss=1.7289, train_err=0.0864, 32_h1=0.0929, 32_l2=0.0544, 64_h1=0.1681, 64_l2=0.0604\n",
      "[44] time=2.43, avg_loss=1.7170, train_err=0.0859, 32_h1=0.0878, 32_l2=0.0470, 64_h1=0.1684, 64_l2=0.0623\n",
      "[45] time=2.37, avg_loss=1.6975, train_err=0.0849, 32_h1=0.0875, 32_l2=0.0444, 64_h1=0.1603, 64_l2=0.0566\n",
      "[46] time=2.39, avg_loss=1.7042, train_err=0.0852, 32_h1=0.0980, 32_l2=0.0600, 64_h1=0.1715, 64_l2=0.0735\n",
      "[47] time=2.39, avg_loss=1.7522, train_err=0.0876, 32_h1=0.0923, 32_l2=0.0538, 64_h1=0.1706, 64_l2=0.0671\n",
      "[48] time=2.39, avg_loss=1.6647, train_err=0.0832, 32_h1=0.0940, 32_l2=0.0587, 64_h1=0.1642, 64_l2=0.0659\n",
      "[49] time=2.39, avg_loss=1.6966, train_err=0.0848, 32_h1=0.0884, 32_l2=0.0482, 64_h1=0.1683, 64_l2=0.0638\n",
      "[50] time=2.41, avg_loss=1.6720, train_err=0.0836, 32_h1=0.0835, 32_l2=0.0426, 64_h1=0.1549, 64_l2=0.0547\n",
      "[51] time=2.38, avg_loss=1.6437, train_err=0.0822, 32_h1=0.0840, 32_l2=0.0436, 64_h1=0.1621, 64_l2=0.0585\n",
      "[52] time=2.37, avg_loss=1.6565, train_err=0.0828, 32_h1=0.0869, 32_l2=0.0479, 64_h1=0.1658, 64_l2=0.0656\n",
      "[53] time=2.38, avg_loss=1.6727, train_err=0.0836, 32_h1=0.0845, 32_l2=0.0432, 64_h1=0.1658, 64_l2=0.0538\n",
      "[54] time=2.41, avg_loss=1.6658, train_err=0.0833, 32_h1=0.0846, 32_l2=0.0438, 64_h1=0.1559, 64_l2=0.0560\n",
      "[55] time=2.44, avg_loss=1.6168, train_err=0.0808, 32_h1=0.0829, 32_l2=0.0426, 64_h1=0.1702, 64_l2=0.0567\n",
      "[56] time=2.39, avg_loss=1.6593, train_err=0.0830, 32_h1=0.0973, 32_l2=0.0627, 64_h1=0.1791, 64_l2=0.0787\n",
      "[57] time=2.35, avg_loss=1.7043, train_err=0.0852, 32_h1=0.0861, 32_l2=0.0485, 64_h1=0.1681, 64_l2=0.0587\n",
      "[58] time=2.41, avg_loss=1.6748, train_err=0.0837, 32_h1=0.0847, 32_l2=0.0442, 64_h1=0.1670, 64_l2=0.0599\n",
      "[59] time=2.38, avg_loss=1.6024, train_err=0.0801, 32_h1=0.0816, 32_l2=0.0407, 64_h1=0.1627, 64_l2=0.0583\n",
      "[60] time=2.41, avg_loss=1.5913, train_err=0.0796, 32_h1=0.0840, 32_l2=0.0419, 64_h1=0.1575, 64_l2=0.0527\n",
      "[61] time=2.39, avg_loss=1.6095, train_err=0.0805, 32_h1=0.0849, 32_l2=0.0486, 64_h1=0.1605, 64_l2=0.0621\n",
      "[62] time=2.40, avg_loss=1.6619, train_err=0.0831, 32_h1=0.0815, 32_l2=0.0414, 64_h1=0.1559, 64_l2=0.0553\n",
      "[63] time=2.45, avg_loss=1.6202, train_err=0.0810, 32_h1=0.0853, 32_l2=0.0469, 64_h1=0.1577, 64_l2=0.0551\n",
      "[64] time=2.43, avg_loss=1.6386, train_err=0.0819, 32_h1=0.0798, 32_l2=0.0399, 64_h1=0.1559, 64_l2=0.0542\n",
      "[65] time=2.40, avg_loss=1.5837, train_err=0.0792, 32_h1=0.0904, 32_l2=0.0539, 64_h1=0.1625, 64_l2=0.0651\n",
      "[66] time=2.39, avg_loss=1.6085, train_err=0.0804, 32_h1=0.0825, 32_l2=0.0426, 64_h1=0.1609, 64_l2=0.0576\n",
      "[67] time=2.45, avg_loss=1.5537, train_err=0.0777, 32_h1=0.0825, 32_l2=0.0442, 64_h1=0.1725, 64_l2=0.0566\n",
      "[68] time=2.38, avg_loss=1.5821, train_err=0.0791, 32_h1=0.0787, 32_l2=0.0385, 64_h1=0.1608, 64_l2=0.0535\n",
      "[69] time=2.39, avg_loss=1.5870, train_err=0.0794, 32_h1=0.0793, 32_l2=0.0394, 64_h1=0.1592, 64_l2=0.0538\n",
      "[70] time=2.21, avg_loss=1.6167, train_err=0.0808, 32_h1=0.0860, 32_l2=0.0494, 64_h1=0.1619, 64_l2=0.0572\n",
      "[71] time=2.08, avg_loss=1.5966, train_err=0.0798, 32_h1=0.0793, 32_l2=0.0387, 64_h1=0.1548, 64_l2=0.0507\n",
      "[72] time=2.08, avg_loss=1.5392, train_err=0.0770, 32_h1=0.0817, 32_l2=0.0420, 64_h1=0.1508, 64_l2=0.0493\n",
      "[73] time=2.08, avg_loss=1.5488, train_err=0.0774, 32_h1=0.0804, 32_l2=0.0411, 64_h1=0.1621, 64_l2=0.0582\n",
      "[74] time=2.09, avg_loss=1.5904, train_err=0.0795, 32_h1=0.0780, 32_l2=0.0380, 64_h1=0.1611, 64_l2=0.0533\n",
      "[75] time=2.08, avg_loss=1.6027, train_err=0.0801, 32_h1=0.0823, 32_l2=0.0414, 64_h1=0.1590, 64_l2=0.0508\n",
      "[76] time=2.11, avg_loss=1.5876, train_err=0.0794, 32_h1=0.0828, 32_l2=0.0433, 64_h1=0.1525, 64_l2=0.0540\n",
      "[77] time=2.19, avg_loss=1.5358, train_err=0.0768, 32_h1=0.0796, 32_l2=0.0394, 64_h1=0.1530, 64_l2=0.0539\n",
      "[78] time=2.25, avg_loss=1.5228, train_err=0.0761, 32_h1=0.0791, 32_l2=0.0389, 64_h1=0.1638, 64_l2=0.0527\n",
      "[79] time=2.15, avg_loss=1.5391, train_err=0.0770, 32_h1=0.0798, 32_l2=0.0407, 64_h1=0.1577, 64_l2=0.0535\n",
      "[80] time=2.09, avg_loss=1.5322, train_err=0.0766, 32_h1=0.0851, 32_l2=0.0483, 64_h1=0.1683, 64_l2=0.0635\n",
      "[81] time=2.29, avg_loss=1.5314, train_err=0.0766, 32_h1=0.0837, 32_l2=0.0444, 64_h1=0.1569, 64_l2=0.0609\n",
      "[82] time=2.14, avg_loss=1.5537, train_err=0.0777, 32_h1=0.0799, 32_l2=0.0403, 64_h1=0.1586, 64_l2=0.0531\n",
      "[83] time=2.09, avg_loss=1.5256, train_err=0.0763, 32_h1=0.0780, 32_l2=0.0371, 64_h1=0.1507, 64_l2=0.0486\n",
      "[84] time=2.12, avg_loss=1.5401, train_err=0.0770, 32_h1=0.0828, 32_l2=0.0454, 64_h1=0.1670, 64_l2=0.0563\n",
      "[85] time=2.09, avg_loss=1.5367, train_err=0.0768, 32_h1=0.0890, 32_l2=0.0591, 64_h1=0.1636, 64_l2=0.0710\n",
      "[86] time=2.26, avg_loss=1.5611, train_err=0.0781, 32_h1=0.0767, 32_l2=0.0380, 64_h1=0.1534, 64_l2=0.0519\n",
      "[87] time=2.28, avg_loss=1.5108, train_err=0.0755, 32_h1=0.0785, 32_l2=0.0423, 64_h1=0.1612, 64_l2=0.0562\n",
      "[88] time=2.14, avg_loss=1.5061, train_err=0.0753, 32_h1=0.0869, 32_l2=0.0485, 64_h1=0.1592, 64_l2=0.0565\n",
      "[89] time=2.25, avg_loss=1.5115, train_err=0.0756, 32_h1=0.0809, 32_l2=0.0436, 64_h1=0.1561, 64_l2=0.0518\n",
      "[90] time=2.10, avg_loss=1.5334, train_err=0.0767, 32_h1=0.0805, 32_l2=0.0451, 64_h1=0.1640, 64_l2=0.0570\n",
      "[91] time=2.12, avg_loss=1.5092, train_err=0.0755, 32_h1=0.0811, 32_l2=0.0477, 64_h1=0.1636, 64_l2=0.0603\n",
      "[92] time=2.12, avg_loss=1.4976, train_err=0.0749, 32_h1=0.0963, 32_l2=0.0654, 64_h1=0.1748, 64_l2=0.0732\n",
      "[93] time=2.11, avg_loss=1.4996, train_err=0.0750, 32_h1=0.0799, 32_l2=0.0429, 64_h1=0.1673, 64_l2=0.0589\n",
      "[94] time=2.26, avg_loss=1.5125, train_err=0.0756, 32_h1=0.0761, 32_l2=0.0372, 64_h1=0.1575, 64_l2=0.0534\n",
      "[95] time=2.23, avg_loss=1.4910, train_err=0.0745, 32_h1=0.0790, 32_l2=0.0419, 64_h1=0.1535, 64_l2=0.0529\n",
      "[96] time=2.08, avg_loss=1.4614, train_err=0.0731, 32_h1=0.0806, 32_l2=0.0455, 64_h1=0.1580, 64_l2=0.0558\n",
      "[97] time=2.09, avg_loss=1.4798, train_err=0.0740, 32_h1=0.0790, 32_l2=0.0431, 64_h1=0.1580, 64_l2=0.0540\n",
      "[98] time=2.08, avg_loss=1.4790, train_err=0.0740, 32_h1=0.0780, 32_l2=0.0405, 64_h1=0.1565, 64_l2=0.0518\n",
      "[99] time=2.44, avg_loss=1.5025, train_err=0.0751, 32_h1=0.0779, 32_l2=0.0421, 64_h1=0.1541, 64_l2=0.0518\n",
      "[100] time=2.47, avg_loss=1.4808, train_err=0.0740, 32_h1=0.0752, 32_l2=0.0368, 64_h1=0.1520, 64_l2=0.0491\n",
      "[101] time=2.41, avg_loss=1.4616, train_err=0.0731, 32_h1=0.0780, 32_l2=0.0397, 64_h1=0.1647, 64_l2=0.0546\n",
      "[102] time=2.40, avg_loss=1.4791, train_err=0.0740, 32_h1=0.0775, 32_l2=0.0387, 64_h1=0.1597, 64_l2=0.0513\n",
      "[103] time=2.41, avg_loss=1.4625, train_err=0.0731, 32_h1=0.0759, 32_l2=0.0379, 64_h1=0.1508, 64_l2=0.0519\n",
      "[104] time=2.39, avg_loss=1.4954, train_err=0.0748, 32_h1=0.0760, 32_l2=0.0364, 64_h1=0.1627, 64_l2=0.0531\n",
      "[105] time=2.39, avg_loss=1.4637, train_err=0.0732, 32_h1=0.0760, 32_l2=0.0381, 64_h1=0.1501, 64_l2=0.0533\n",
      "[106] time=2.37, avg_loss=1.4540, train_err=0.0727, 32_h1=0.0789, 32_l2=0.0410, 64_h1=0.1559, 64_l2=0.0574\n",
      "[107] time=2.44, avg_loss=1.4669, train_err=0.0733, 32_h1=0.0759, 32_l2=0.0387, 64_h1=0.1541, 64_l2=0.0526\n",
      "[108] time=2.44, avg_loss=1.4600, train_err=0.0730, 32_h1=0.0765, 32_l2=0.0388, 64_h1=0.1608, 64_l2=0.0538\n",
      "[109] time=2.41, avg_loss=1.4520, train_err=0.0726, 32_h1=0.0760, 32_l2=0.0385, 64_h1=0.1589, 64_l2=0.0565\n",
      "[110] time=2.37, avg_loss=1.4521, train_err=0.0726, 32_h1=0.0756, 32_l2=0.0375, 64_h1=0.1536, 64_l2=0.0510\n",
      "[111] time=2.47, avg_loss=1.4563, train_err=0.0728, 32_h1=0.0781, 32_l2=0.0403, 64_h1=0.1654, 64_l2=0.0548\n",
      "[112] time=2.40, avg_loss=1.4584, train_err=0.0729, 32_h1=0.0750, 32_l2=0.0361, 64_h1=0.1577, 64_l2=0.0512\n",
      "[113] time=2.40, avg_loss=1.4464, train_err=0.0723, 32_h1=0.0751, 32_l2=0.0373, 64_h1=0.1532, 64_l2=0.0509\n",
      "[114] time=2.39, avg_loss=1.4727, train_err=0.0736, 32_h1=0.0760, 32_l2=0.0399, 64_h1=0.1537, 64_l2=0.0550\n",
      "[115] time=2.42, avg_loss=1.4439, train_err=0.0722, 32_h1=0.0781, 32_l2=0.0389, 64_h1=0.1599, 64_l2=0.0513\n",
      "[116] time=2.38, avg_loss=1.4329, train_err=0.0716, 32_h1=0.0773, 32_l2=0.0429, 64_h1=0.1611, 64_l2=0.0563\n",
      "[117] time=2.40, avg_loss=1.4781, train_err=0.0739, 32_h1=0.0763, 32_l2=0.0389, 64_h1=0.1597, 64_l2=0.0529\n",
      "[118] time=2.42, avg_loss=1.4382, train_err=0.0719, 32_h1=0.0741, 32_l2=0.0371, 64_h1=0.1511, 64_l2=0.0504\n",
      "[119] time=2.37, avg_loss=1.4190, train_err=0.0709, 32_h1=0.0746, 32_l2=0.0367, 64_h1=0.1550, 64_l2=0.0486\n",
      "[120] time=2.37, avg_loss=1.4184, train_err=0.0709, 32_h1=0.0745, 32_l2=0.0362, 64_h1=0.1549, 64_l2=0.0509\n",
      "[121] time=2.48, avg_loss=1.4102, train_err=0.0705, 32_h1=0.0766, 32_l2=0.0417, 64_h1=0.1509, 64_l2=0.0519\n",
      "[122] time=2.47, avg_loss=1.4111, train_err=0.0706, 32_h1=0.0733, 32_l2=0.0349, 64_h1=0.1551, 64_l2=0.0481\n",
      "[123] time=2.40, avg_loss=1.4188, train_err=0.0709, 32_h1=0.0761, 32_l2=0.0404, 64_h1=0.1542, 64_l2=0.0559\n",
      "[124] time=2.40, avg_loss=1.4278, train_err=0.0714, 32_h1=0.0746, 32_l2=0.0371, 64_h1=0.1533, 64_l2=0.0497\n",
      "[125] time=2.39, avg_loss=1.4112, train_err=0.0706, 32_h1=0.0750, 32_l2=0.0374, 64_h1=0.1527, 64_l2=0.0534\n",
      "[126] time=2.42, avg_loss=1.4239, train_err=0.0712, 32_h1=0.0733, 32_l2=0.0355, 64_h1=0.1569, 64_l2=0.0488\n",
      "[127] time=2.38, avg_loss=1.3972, train_err=0.0699, 32_h1=0.0750, 32_l2=0.0378, 64_h1=0.1555, 64_l2=0.0529\n",
      "[128] time=2.39, avg_loss=1.4102, train_err=0.0705, 32_h1=0.0769, 32_l2=0.0394, 64_h1=0.1541, 64_l2=0.0490\n",
      "[129] time=2.38, avg_loss=1.4209, train_err=0.0710, 32_h1=0.0731, 32_l2=0.0360, 64_h1=0.1534, 64_l2=0.0515\n",
      "[130] time=2.42, avg_loss=1.4348, train_err=0.0717, 32_h1=0.0776, 32_l2=0.0405, 64_h1=0.1528, 64_l2=0.0487\n",
      "[131] time=2.39, avg_loss=1.4083, train_err=0.0704, 32_h1=0.0760, 32_l2=0.0395, 64_h1=0.1586, 64_l2=0.0561\n",
      "[132] time=2.38, avg_loss=1.4023, train_err=0.0701, 32_h1=0.0730, 32_l2=0.0352, 64_h1=0.1545, 64_l2=0.0525\n",
      "[133] time=2.40, avg_loss=1.3995, train_err=0.0700, 32_h1=0.0763, 32_l2=0.0391, 64_h1=0.1569, 64_l2=0.0541\n",
      "[134] time=2.37, avg_loss=1.4221, train_err=0.0711, 32_h1=0.0738, 32_l2=0.0352, 64_h1=0.1560, 64_l2=0.0528\n",
      "[135] time=2.41, avg_loss=1.3991, train_err=0.0700, 32_h1=0.0742, 32_l2=0.0360, 64_h1=0.1570, 64_l2=0.0545\n",
      "[136] time=2.40, avg_loss=1.3939, train_err=0.0697, 32_h1=0.0808, 32_l2=0.0458, 64_h1=0.1626, 64_l2=0.0580\n",
      "[137] time=2.31, avg_loss=1.4107, train_err=0.0705, 32_h1=0.0735, 32_l2=0.0363, 64_h1=0.1534, 64_l2=0.0502\n",
      "[138] time=2.13, avg_loss=1.3843, train_err=0.0692, 32_h1=0.0737, 32_l2=0.0359, 64_h1=0.1604, 64_l2=0.0566\n",
      "[139] time=2.28, avg_loss=1.3956, train_err=0.0698, 32_h1=0.0741, 32_l2=0.0374, 64_h1=0.1543, 64_l2=0.0484\n",
      "[140] time=2.27, avg_loss=1.4018, train_err=0.0701, 32_h1=0.0743, 32_l2=0.0362, 64_h1=0.1576, 64_l2=0.0513\n",
      "[141] time=2.27, avg_loss=1.3792, train_err=0.0690, 32_h1=0.0733, 32_l2=0.0379, 64_h1=0.1534, 64_l2=0.0499\n",
      "[142] time=2.12, avg_loss=1.3834, train_err=0.0692, 32_h1=0.0757, 32_l2=0.0374, 64_h1=0.1585, 64_l2=0.0472\n",
      "[143] time=2.08, avg_loss=1.3893, train_err=0.0695, 32_h1=0.0744, 32_l2=0.0380, 64_h1=0.1563, 64_l2=0.0551\n",
      "[144] time=2.09, avg_loss=1.3834, train_err=0.0692, 32_h1=0.0727, 32_l2=0.0345, 64_h1=0.1575, 64_l2=0.0514\n",
      "[145] time=2.09, avg_loss=1.4001, train_err=0.0700, 32_h1=0.0743, 32_l2=0.0364, 64_h1=0.1503, 64_l2=0.0492\n",
      "[146] time=2.08, avg_loss=1.3765, train_err=0.0688, 32_h1=0.0737, 32_l2=0.0367, 64_h1=0.1568, 64_l2=0.0525\n",
      "[147] time=2.08, avg_loss=1.3703, train_err=0.0685, 32_h1=0.0753, 32_l2=0.0388, 64_h1=0.1510, 64_l2=0.0535\n",
      "[148] time=2.11, avg_loss=1.3654, train_err=0.0683, 32_h1=0.0735, 32_l2=0.0355, 64_h1=0.1523, 64_l2=0.0491\n",
      "[149] time=2.08, avg_loss=1.3656, train_err=0.0683, 32_h1=0.0727, 32_l2=0.0351, 64_h1=0.1502, 64_l2=0.0485\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.03\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 30849\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(10, 10, 2, 2))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(10, 10, 2, 2))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(10, 10, 2, 2))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(10, 10, 2, 2))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(10, 10, 2, 2))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(10, 10, 2, 2))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(10, 10, 2, 2))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(10, 10, 2, 2))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f975765afa0>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f97514249a0>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f97514249a0>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f97576c01f0>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.20, avg_loss=11.8345, train_err=0.5917, 32_h1=0.3412, 32_l2=0.2312, 64_h1=0.3993, 64_l2=0.2381\n",
      "[1] time=2.13, avg_loss=5.5169, train_err=0.2758, 32_h1=0.2479, 32_l2=0.1738, 64_h1=0.2958, 64_l2=0.1743\n",
      "[2] time=2.19, avg_loss=4.6089, train_err=0.2304, 32_h1=0.2184, 32_l2=0.1496, 64_h1=0.2780, 64_l2=0.1575\n",
      "[3] time=2.09, avg_loss=4.0871, train_err=0.2044, 32_h1=0.2088, 32_l2=0.1500, 64_h1=0.2779, 64_l2=0.1591\n",
      "[4] time=2.09, avg_loss=3.6971, train_err=0.1849, 32_h1=0.1755, 32_l2=0.1141, 64_h1=0.2300, 64_l2=0.1200\n",
      "[5] time=2.09, avg_loss=3.4292, train_err=0.1715, 32_h1=0.1673, 32_l2=0.1112, 64_h1=0.2346, 64_l2=0.1209\n",
      "[6] time=2.08, avg_loss=3.1728, train_err=0.1586, 32_h1=0.1559, 32_l2=0.0983, 64_h1=0.2207, 64_l2=0.1046\n",
      "[7] time=2.14, avg_loss=3.0752, train_err=0.1538, 32_h1=0.1514, 32_l2=0.0970, 64_h1=0.2086, 64_l2=0.1004\n",
      "[8] time=2.10, avg_loss=2.9713, train_err=0.1486, 32_h1=0.1504, 32_l2=0.0980, 64_h1=0.2204, 64_l2=0.1089\n",
      "[9] time=2.14, avg_loss=2.7514, train_err=0.1376, 32_h1=0.1516, 32_l2=0.1075, 64_h1=0.2156, 64_l2=0.1097\n",
      "[10] time=2.22, avg_loss=2.6600, train_err=0.1330, 32_h1=0.1333, 32_l2=0.0818, 64_h1=0.1960, 64_l2=0.0878\n",
      "[11] time=2.19, avg_loss=2.5562, train_err=0.1278, 32_h1=0.1236, 32_l2=0.0739, 64_h1=0.1877, 64_l2=0.0817\n",
      "[12] time=2.14, avg_loss=2.4385, train_err=0.1219, 32_h1=0.1192, 32_l2=0.0687, 64_h1=0.1856, 64_l2=0.0803\n",
      "[13] time=2.19, avg_loss=2.3684, train_err=0.1184, 32_h1=0.1264, 32_l2=0.0749, 64_h1=0.1860, 64_l2=0.0753\n",
      "[14] time=2.21, avg_loss=2.3530, train_err=0.1177, 32_h1=0.1169, 32_l2=0.0695, 64_h1=0.1953, 64_l2=0.0870\n",
      "[15] time=2.23, avg_loss=2.2945, train_err=0.1147, 32_h1=0.1196, 32_l2=0.0731, 64_h1=0.1874, 64_l2=0.0783\n",
      "[16] time=2.41, avg_loss=2.2326, train_err=0.1116, 32_h1=0.1142, 32_l2=0.0661, 64_h1=0.1947, 64_l2=0.0826\n",
      "[17] time=2.42, avg_loss=2.1994, train_err=0.1100, 32_h1=0.1090, 32_l2=0.0621, 64_h1=0.1912, 64_l2=0.0780\n",
      "[18] time=2.35, avg_loss=2.1812, train_err=0.1091, 32_h1=0.1151, 32_l2=0.0672, 64_h1=0.1813, 64_l2=0.0746\n",
      "[19] time=2.37, avg_loss=2.1170, train_err=0.1058, 32_h1=0.1148, 32_l2=0.0688, 64_h1=0.1812, 64_l2=0.0830\n",
      "[20] time=2.37, avg_loss=2.0831, train_err=0.1042, 32_h1=0.1208, 32_l2=0.0819, 64_h1=0.1835, 64_l2=0.0847\n",
      "[21] time=2.40, avg_loss=2.0614, train_err=0.1031, 32_h1=0.0970, 32_l2=0.0514, 64_h1=0.1727, 64_l2=0.0622\n",
      "[22] time=2.38, avg_loss=2.0062, train_err=0.1003, 32_h1=0.1004, 32_l2=0.0554, 64_h1=0.1723, 64_l2=0.0629\n",
      "[23] time=2.39, avg_loss=1.9917, train_err=0.0996, 32_h1=0.0962, 32_l2=0.0500, 64_h1=0.1702, 64_l2=0.0596\n",
      "[24] time=2.38, avg_loss=1.9333, train_err=0.0967, 32_h1=0.1016, 32_l2=0.0558, 64_h1=0.1770, 64_l2=0.0667\n",
      "[25] time=2.38, avg_loss=1.9293, train_err=0.0965, 32_h1=0.1010, 32_l2=0.0590, 64_h1=0.1779, 64_l2=0.0731\n",
      "[26] time=2.34, avg_loss=1.9473, train_err=0.0974, 32_h1=0.0951, 32_l2=0.0505, 64_h1=0.1689, 64_l2=0.0603\n",
      "[27] time=2.38, avg_loss=1.9045, train_err=0.0952, 32_h1=0.0928, 32_l2=0.0486, 64_h1=0.1705, 64_l2=0.0570\n",
      "[28] time=2.38, avg_loss=1.9157, train_err=0.0958, 32_h1=0.1006, 32_l2=0.0605, 64_h1=0.1671, 64_l2=0.0712\n",
      "[29] time=2.37, avg_loss=1.8521, train_err=0.0926, 32_h1=0.0996, 32_l2=0.0613, 64_h1=0.1790, 64_l2=0.0748\n",
      "[30] time=2.40, avg_loss=1.9016, train_err=0.0951, 32_h1=0.0927, 32_l2=0.0494, 64_h1=0.1761, 64_l2=0.0660\n",
      "[31] time=2.42, avg_loss=1.8224, train_err=0.0911, 32_h1=0.0896, 32_l2=0.0454, 64_h1=0.1721, 64_l2=0.0601\n",
      "[32] time=2.40, avg_loss=1.8504, train_err=0.0925, 32_h1=0.0901, 32_l2=0.0464, 64_h1=0.1681, 64_l2=0.0572\n",
      "[33] time=2.38, avg_loss=1.8060, train_err=0.0903, 32_h1=0.1036, 32_l2=0.0647, 64_h1=0.1735, 64_l2=0.0753\n",
      "[34] time=2.40, avg_loss=1.8498, train_err=0.0925, 32_h1=0.0954, 32_l2=0.0529, 64_h1=0.1727, 64_l2=0.0659\n",
      "[35] time=2.43, avg_loss=1.7835, train_err=0.0892, 32_h1=0.0975, 32_l2=0.0597, 64_h1=0.1681, 64_l2=0.0676\n",
      "[36] time=2.38, avg_loss=1.8360, train_err=0.0918, 32_h1=0.0925, 32_l2=0.0502, 64_h1=0.1615, 64_l2=0.0571\n",
      "[37] time=2.38, avg_loss=1.7281, train_err=0.0864, 32_h1=0.0891, 32_l2=0.0481, 64_h1=0.1755, 64_l2=0.0649\n",
      "[38] time=2.41, avg_loss=1.8066, train_err=0.0903, 32_h1=0.0891, 32_l2=0.0480, 64_h1=0.1627, 64_l2=0.0600\n",
      "[39] time=2.59, avg_loss=1.7593, train_err=0.0880, 32_h1=0.0907, 32_l2=0.0503, 64_h1=0.1731, 64_l2=0.0647\n",
      "[40] time=2.43, avg_loss=1.7619, train_err=0.0881, 32_h1=0.0932, 32_l2=0.0515, 64_h1=0.1652, 64_l2=0.0615\n",
      "[41] time=2.39, avg_loss=1.7495, train_err=0.0875, 32_h1=0.0922, 32_l2=0.0552, 64_h1=0.1748, 64_l2=0.0724\n",
      "[42] time=2.37, avg_loss=1.7646, train_err=0.0882, 32_h1=0.0886, 32_l2=0.0497, 64_h1=0.1755, 64_l2=0.0637\n",
      "[43] time=2.37, avg_loss=1.7321, train_err=0.0866, 32_h1=0.0869, 32_l2=0.0455, 64_h1=0.1651, 64_l2=0.0614\n",
      "[44] time=2.36, avg_loss=1.7436, train_err=0.0872, 32_h1=0.0960, 32_l2=0.0557, 64_h1=0.1740, 64_l2=0.0671\n",
      "[45] time=2.37, avg_loss=1.7060, train_err=0.0853, 32_h1=0.0883, 32_l2=0.0459, 64_h1=0.1672, 64_l2=0.0555\n",
      "[46] time=2.36, avg_loss=1.6801, train_err=0.0840, 32_h1=0.0900, 32_l2=0.0480, 64_h1=0.1752, 64_l2=0.0669\n",
      "[47] time=2.36, avg_loss=1.6647, train_err=0.0832, 32_h1=0.0878, 32_l2=0.0487, 64_h1=0.1660, 64_l2=0.0605\n",
      "[48] time=2.38, avg_loss=1.7232, train_err=0.0862, 32_h1=0.0856, 32_l2=0.0440, 64_h1=0.1721, 64_l2=0.0627\n",
      "[49] time=2.37, avg_loss=1.6868, train_err=0.0843, 32_h1=0.0884, 32_l2=0.0481, 64_h1=0.1670, 64_l2=0.0622\n",
      "[50] time=2.39, avg_loss=1.6536, train_err=0.0827, 32_h1=0.0836, 32_l2=0.0436, 64_h1=0.1685, 64_l2=0.0635\n",
      "[51] time=2.39, avg_loss=1.6680, train_err=0.0834, 32_h1=0.0891, 32_l2=0.0482, 64_h1=0.1720, 64_l2=0.0631\n",
      "[52] time=2.38, avg_loss=1.7493, train_err=0.0875, 32_h1=0.0838, 32_l2=0.0420, 64_h1=0.1575, 64_l2=0.0559\n",
      "[53] time=2.41, avg_loss=1.6217, train_err=0.0811, 32_h1=0.0891, 32_l2=0.0526, 64_h1=0.1700, 64_l2=0.0680\n",
      "[54] time=2.39, avg_loss=1.6359, train_err=0.0818, 32_h1=0.0813, 32_l2=0.0393, 64_h1=0.1648, 64_l2=0.0546\n",
      "[55] time=2.50, avg_loss=1.6301, train_err=0.0815, 32_h1=0.0827, 32_l2=0.0405, 64_h1=0.1698, 64_l2=0.0578\n",
      "[56] time=2.32, avg_loss=1.6142, train_err=0.0807, 32_h1=0.0882, 32_l2=0.0468, 64_h1=0.1656, 64_l2=0.0508\n",
      "[57] time=2.23, avg_loss=1.6519, train_err=0.0826, 32_h1=0.0855, 32_l2=0.0448, 64_h1=0.1600, 64_l2=0.0519\n",
      "[58] time=2.23, avg_loss=1.6184, train_err=0.0809, 32_h1=0.0810, 32_l2=0.0407, 64_h1=0.1610, 64_l2=0.0514\n",
      "[59] time=2.09, avg_loss=1.6371, train_err=0.0819, 32_h1=0.0850, 32_l2=0.0482, 64_h1=0.1661, 64_l2=0.0627\n",
      "[60] time=2.21, avg_loss=1.6256, train_err=0.0813, 32_h1=0.0908, 32_l2=0.0562, 64_h1=0.1689, 64_l2=0.0675\n",
      "[61] time=2.25, avg_loss=1.5978, train_err=0.0799, 32_h1=0.0884, 32_l2=0.0493, 64_h1=0.1648, 64_l2=0.0651\n",
      "[62] time=2.19, avg_loss=1.6155, train_err=0.0808, 32_h1=0.0870, 32_l2=0.0514, 64_h1=0.1632, 64_l2=0.0627\n",
      "[63] time=2.20, avg_loss=1.6165, train_err=0.0808, 32_h1=0.0851, 32_l2=0.0457, 64_h1=0.1620, 64_l2=0.0545\n",
      "[64] time=2.23, avg_loss=1.5672, train_err=0.0784, 32_h1=0.0794, 32_l2=0.0389, 64_h1=0.1619, 64_l2=0.0506\n",
      "[65] time=2.22, avg_loss=1.6000, train_err=0.0800, 32_h1=0.0891, 32_l2=0.0566, 64_h1=0.1713, 64_l2=0.0664\n",
      "[66] time=2.09, avg_loss=1.6553, train_err=0.0828, 32_h1=0.0880, 32_l2=0.0466, 64_h1=0.1588, 64_l2=0.0558\n",
      "[67] time=2.09, avg_loss=1.6006, train_err=0.0800, 32_h1=0.0829, 32_l2=0.0429, 64_h1=0.1659, 64_l2=0.0570\n",
      "[68] time=2.25, avg_loss=1.5865, train_err=0.0793, 32_h1=0.0833, 32_l2=0.0456, 64_h1=0.1736, 64_l2=0.0617\n",
      "[69] time=2.09, avg_loss=1.5793, train_err=0.0790, 32_h1=0.0813, 32_l2=0.0404, 64_h1=0.1649, 64_l2=0.0533\n",
      "[70] time=2.12, avg_loss=1.5595, train_err=0.0780, 32_h1=0.0843, 32_l2=0.0466, 64_h1=0.1659, 64_l2=0.0586\n",
      "[71] time=2.09, avg_loss=1.6036, train_err=0.0802, 32_h1=0.0833, 32_l2=0.0483, 64_h1=0.1698, 64_l2=0.0611\n",
      "[72] time=2.16, avg_loss=1.5621, train_err=0.0781, 32_h1=0.0846, 32_l2=0.0475, 64_h1=0.1631, 64_l2=0.0613\n",
      "[73] time=2.24, avg_loss=1.5382, train_err=0.0769, 32_h1=0.0815, 32_l2=0.0431, 64_h1=0.1640, 64_l2=0.0539\n",
      "[74] time=2.17, avg_loss=1.5518, train_err=0.0776, 32_h1=0.0813, 32_l2=0.0413, 64_h1=0.1545, 64_l2=0.0530\n",
      "[75] time=2.17, avg_loss=1.5699, train_err=0.0785, 32_h1=0.0773, 32_l2=0.0367, 64_h1=0.1612, 64_l2=0.0527\n",
      "[76] time=2.17, avg_loss=1.5594, train_err=0.0780, 32_h1=0.0805, 32_l2=0.0409, 64_h1=0.1609, 64_l2=0.0576\n",
      "[77] time=2.22, avg_loss=1.5600, train_err=0.0780, 32_h1=0.0809, 32_l2=0.0414, 64_h1=0.1573, 64_l2=0.0559\n",
      "[78] time=2.29, avg_loss=1.5414, train_err=0.0771, 32_h1=0.0822, 32_l2=0.0441, 64_h1=0.1669, 64_l2=0.0565\n",
      "[79] time=2.28, avg_loss=1.5298, train_err=0.0765, 32_h1=0.0807, 32_l2=0.0439, 64_h1=0.1631, 64_l2=0.0555\n",
      "[80] time=2.20, avg_loss=1.5409, train_err=0.0770, 32_h1=0.0784, 32_l2=0.0396, 64_h1=0.1638, 64_l2=0.0557\n",
      "[81] time=2.20, avg_loss=1.5084, train_err=0.0754, 32_h1=0.0770, 32_l2=0.0374, 64_h1=0.1626, 64_l2=0.0535\n",
      "[82] time=2.29, avg_loss=1.5168, train_err=0.0758, 32_h1=0.0775, 32_l2=0.0366, 64_h1=0.1686, 64_l2=0.0552\n",
      "[83] time=2.30, avg_loss=1.5010, train_err=0.0750, 32_h1=0.0778, 32_l2=0.0395, 64_h1=0.1606, 64_l2=0.0562\n",
      "[84] time=2.56, avg_loss=1.5155, train_err=0.0758, 32_h1=0.0793, 32_l2=0.0406, 64_h1=0.1615, 64_l2=0.0547\n",
      "[85] time=2.40, avg_loss=1.4992, train_err=0.0750, 32_h1=0.0793, 32_l2=0.0390, 64_h1=0.1690, 64_l2=0.0562\n",
      "[86] time=2.39, avg_loss=1.4951, train_err=0.0748, 32_h1=0.0764, 32_l2=0.0367, 64_h1=0.1650, 64_l2=0.0538\n",
      "[87] time=2.42, avg_loss=1.5194, train_err=0.0760, 32_h1=0.0776, 32_l2=0.0372, 64_h1=0.1545, 64_l2=0.0514\n",
      "[88] time=2.41, avg_loss=1.5389, train_err=0.0769, 32_h1=0.0846, 32_l2=0.0488, 64_h1=0.1704, 64_l2=0.0591\n",
      "[89] time=2.35, avg_loss=1.4960, train_err=0.0748, 32_h1=0.0776, 32_l2=0.0388, 64_h1=0.1658, 64_l2=0.0560\n",
      "[90] time=2.40, avg_loss=1.4854, train_err=0.0743, 32_h1=0.0777, 32_l2=0.0389, 64_h1=0.1628, 64_l2=0.0541\n",
      "[91] time=2.36, avg_loss=1.4600, train_err=0.0730, 32_h1=0.0775, 32_l2=0.0383, 64_h1=0.1637, 64_l2=0.0498\n",
      "[92] time=2.39, avg_loss=1.4679, train_err=0.0734, 32_h1=0.0793, 32_l2=0.0407, 64_h1=0.1675, 64_l2=0.0572\n",
      "[93] time=2.39, avg_loss=1.5075, train_err=0.0754, 32_h1=0.0795, 32_l2=0.0419, 64_h1=0.1626, 64_l2=0.0536\n",
      "[94] time=2.40, avg_loss=1.4646, train_err=0.0732, 32_h1=0.0756, 32_l2=0.0367, 64_h1=0.1565, 64_l2=0.0520\n",
      "[95] time=2.43, avg_loss=1.4577, train_err=0.0729, 32_h1=0.0769, 32_l2=0.0383, 64_h1=0.1615, 64_l2=0.0500\n",
      "[96] time=2.38, avg_loss=1.5016, train_err=0.0751, 32_h1=0.0831, 32_l2=0.0469, 64_h1=0.1674, 64_l2=0.0675\n",
      "[97] time=2.41, avg_loss=1.4768, train_err=0.0738, 32_h1=0.0795, 32_l2=0.0422, 64_h1=0.1647, 64_l2=0.0571\n",
      "[98] time=2.36, avg_loss=1.4730, train_err=0.0736, 32_h1=0.0754, 32_l2=0.0366, 64_h1=0.1628, 64_l2=0.0547\n",
      "[99] time=2.40, avg_loss=1.4606, train_err=0.0730, 32_h1=0.0744, 32_l2=0.0348, 64_h1=0.1609, 64_l2=0.0510\n",
      "[100] time=2.34, avg_loss=1.4566, train_err=0.0728, 32_h1=0.0777, 32_l2=0.0392, 64_h1=0.1614, 64_l2=0.0587\n",
      "[101] time=2.39, avg_loss=1.4580, train_err=0.0729, 32_h1=0.0768, 32_l2=0.0386, 64_h1=0.1564, 64_l2=0.0527\n",
      "[102] time=2.39, avg_loss=1.4437, train_err=0.0722, 32_h1=0.0779, 32_l2=0.0386, 64_h1=0.1644, 64_l2=0.0554\n",
      "[103] time=2.40, avg_loss=1.4881, train_err=0.0744, 32_h1=0.0757, 32_l2=0.0361, 64_h1=0.1616, 64_l2=0.0558\n",
      "[104] time=2.40, avg_loss=1.4922, train_err=0.0746, 32_h1=0.0800, 32_l2=0.0401, 64_h1=0.1652, 64_l2=0.0574\n",
      "[105] time=2.39, avg_loss=1.4613, train_err=0.0731, 32_h1=0.0804, 32_l2=0.0449, 64_h1=0.1633, 64_l2=0.0641\n",
      "[106] time=2.51, avg_loss=1.4417, train_err=0.0721, 32_h1=0.0754, 32_l2=0.0368, 64_h1=0.1653, 64_l2=0.0544\n",
      "[107] time=2.45, avg_loss=1.4735, train_err=0.0737, 32_h1=0.0781, 32_l2=0.0415, 64_h1=0.1572, 64_l2=0.0589\n",
      "[108] time=2.40, avg_loss=1.4386, train_err=0.0719, 32_h1=0.0760, 32_l2=0.0379, 64_h1=0.1576, 64_l2=0.0498\n",
      "[109] time=2.42, avg_loss=1.4803, train_err=0.0740, 32_h1=0.0745, 32_l2=0.0359, 64_h1=0.1603, 64_l2=0.0546\n",
      "[110] time=2.41, avg_loss=1.4307, train_err=0.0715, 32_h1=0.0746, 32_l2=0.0353, 64_h1=0.1618, 64_l2=0.0528\n",
      "[111] time=2.37, avg_loss=1.4286, train_err=0.0714, 32_h1=0.0743, 32_l2=0.0362, 64_h1=0.1624, 64_l2=0.0546\n",
      "[112] time=2.39, avg_loss=1.4440, train_err=0.0722, 32_h1=0.0748, 32_l2=0.0359, 64_h1=0.1684, 64_l2=0.0556\n",
      "[113] time=2.43, avg_loss=1.4589, train_err=0.0729, 32_h1=0.0762, 32_l2=0.0373, 64_h1=0.1636, 64_l2=0.0543\n",
      "[114] time=2.42, avg_loss=1.4268, train_err=0.0713, 32_h1=0.0809, 32_l2=0.0450, 64_h1=0.1649, 64_l2=0.0618\n",
      "[115] time=2.37, avg_loss=1.4366, train_err=0.0718, 32_h1=0.0750, 32_l2=0.0357, 64_h1=0.1590, 64_l2=0.0497\n",
      "[116] time=2.37, avg_loss=1.4123, train_err=0.0706, 32_h1=0.0755, 32_l2=0.0394, 64_h1=0.1554, 64_l2=0.0537\n",
      "[117] time=2.37, avg_loss=1.4124, train_err=0.0706, 32_h1=0.0751, 32_l2=0.0359, 64_h1=0.1560, 64_l2=0.0491\n",
      "[118] time=2.39, avg_loss=1.4263, train_err=0.0713, 32_h1=0.0750, 32_l2=0.0359, 64_h1=0.1611, 64_l2=0.0559\n",
      "[119] time=2.36, avg_loss=1.4125, train_err=0.0706, 32_h1=0.0748, 32_l2=0.0361, 64_h1=0.1657, 64_l2=0.0556\n",
      "[120] time=2.42, avg_loss=1.4093, train_err=0.0705, 32_h1=0.0746, 32_l2=0.0365, 64_h1=0.1612, 64_l2=0.0542\n",
      "[121] time=2.38, avg_loss=1.4158, train_err=0.0708, 32_h1=0.0787, 32_l2=0.0416, 64_h1=0.1651, 64_l2=0.0600\n",
      "[122] time=2.39, avg_loss=1.4152, train_err=0.0708, 32_h1=0.0748, 32_l2=0.0364, 64_h1=0.1575, 64_l2=0.0524\n",
      "[123] time=2.28, avg_loss=1.4225, train_err=0.0711, 32_h1=0.0782, 32_l2=0.0433, 64_h1=0.1638, 64_l2=0.0532\n",
      "[124] time=2.14, avg_loss=1.4108, train_err=0.0705, 32_h1=0.0740, 32_l2=0.0355, 64_h1=0.1595, 64_l2=0.0517\n",
      "[125] time=2.16, avg_loss=1.3888, train_err=0.0694, 32_h1=0.0747, 32_l2=0.0370, 64_h1=0.1650, 64_l2=0.0553\n",
      "[126] time=2.10, avg_loss=1.4079, train_err=0.0704, 32_h1=0.0740, 32_l2=0.0370, 64_h1=0.1623, 64_l2=0.0532\n",
      "[127] time=2.10, avg_loss=1.3940, train_err=0.0697, 32_h1=0.0758, 32_l2=0.0392, 64_h1=0.1594, 64_l2=0.0506\n",
      "[128] time=2.23, avg_loss=1.4015, train_err=0.0701, 32_h1=0.0796, 32_l2=0.0449, 64_h1=0.1607, 64_l2=0.0534\n",
      "[129] time=2.30, avg_loss=1.4191, train_err=0.0710, 32_h1=0.0762, 32_l2=0.0388, 64_h1=0.1620, 64_l2=0.0548\n",
      "[130] time=2.29, avg_loss=1.4029, train_err=0.0701, 32_h1=0.0755, 32_l2=0.0371, 64_h1=0.1616, 64_l2=0.0560\n",
      "[131] time=2.26, avg_loss=1.4017, train_err=0.0701, 32_h1=0.0730, 32_l2=0.0344, 64_h1=0.1600, 64_l2=0.0495\n",
      "[132] time=2.14, avg_loss=1.3764, train_err=0.0688, 32_h1=0.0746, 32_l2=0.0364, 64_h1=0.1601, 64_l2=0.0503\n",
      "[133] time=2.19, avg_loss=1.4001, train_err=0.0700, 32_h1=0.0741, 32_l2=0.0370, 64_h1=0.1612, 64_l2=0.0515\n",
      "[134] time=2.14, avg_loss=1.3922, train_err=0.0696, 32_h1=0.0780, 32_l2=0.0426, 64_h1=0.1609, 64_l2=0.0595\n",
      "[135] time=2.22, avg_loss=1.3849, train_err=0.0692, 32_h1=0.0765, 32_l2=0.0396, 64_h1=0.1588, 64_l2=0.0471\n",
      "[136] time=2.18, avg_loss=1.4185, train_err=0.0709, 32_h1=0.0757, 32_l2=0.0377, 64_h1=0.1581, 64_l2=0.0521\n",
      "[137] time=2.11, avg_loss=1.3963, train_err=0.0698, 32_h1=0.0733, 32_l2=0.0344, 64_h1=0.1599, 64_l2=0.0484\n",
      "[138] time=2.19, avg_loss=1.3818, train_err=0.0691, 32_h1=0.0737, 32_l2=0.0361, 64_h1=0.1594, 64_l2=0.0513\n",
      "[139] time=2.29, avg_loss=1.3747, train_err=0.0687, 32_h1=0.0766, 32_l2=0.0405, 64_h1=0.1624, 64_l2=0.0548\n",
      "[140] time=2.31, avg_loss=1.3770, train_err=0.0689, 32_h1=0.0727, 32_l2=0.0347, 64_h1=0.1586, 64_l2=0.0513\n",
      "[141] time=2.12, avg_loss=1.3863, train_err=0.0693, 32_h1=0.0720, 32_l2=0.0337, 64_h1=0.1589, 64_l2=0.0496\n",
      "[142] time=2.09, avg_loss=1.3646, train_err=0.0682, 32_h1=0.0729, 32_l2=0.0343, 64_h1=0.1586, 64_l2=0.0473\n",
      "[143] time=2.13, avg_loss=1.3618, train_err=0.0681, 32_h1=0.0728, 32_l2=0.0349, 64_h1=0.1643, 64_l2=0.0520\n",
      "[144] time=2.09, avg_loss=1.3834, train_err=0.0692, 32_h1=0.0728, 32_l2=0.0347, 64_h1=0.1553, 64_l2=0.0485\n",
      "[145] time=2.24, avg_loss=1.3537, train_err=0.0677, 32_h1=0.0726, 32_l2=0.0340, 64_h1=0.1623, 64_l2=0.0520\n",
      "[146] time=2.19, avg_loss=1.3558, train_err=0.0678, 32_h1=0.0747, 32_l2=0.0378, 64_h1=0.1607, 64_l2=0.0554\n",
      "[147] time=2.13, avg_loss=1.3796, train_err=0.0690, 32_h1=0.0742, 32_l2=0.0367, 64_h1=0.1570, 64_l2=0.0522\n",
      "[148] time=2.28, avg_loss=1.3634, train_err=0.0682, 32_h1=0.0727, 32_l2=0.0345, 64_h1=0.1611, 64_l2=0.0528\n",
      "[149] time=2.12, avg_loss=1.3606, train_err=0.0680, 32_h1=0.0737, 32_l2=0.0361, 64_h1=0.1583, 64_l2=0.0519\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.06\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 56961\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(14, 14, 3, 3))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(14, 14, 3, 3))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(14, 14, 3, 3))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(14, 14, 3, 3))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(14, 14, 3, 3))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(14, 14, 3, 3))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(14, 14, 3, 3))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(14, 14, 3, 3))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f983c59d700>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f97514240d0>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f97514240d0>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f975765afa0>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.22, avg_loss=10.8884, train_err=0.5444, 32_h1=0.3159, 32_l2=0.2076, 64_h1=0.3670, 64_l2=0.2111\n",
      "[1] time=2.60, avg_loss=5.2738, train_err=0.2637, 32_h1=0.2233, 32_l2=0.1510, 64_h1=0.2710, 64_l2=0.1588\n",
      "[2] time=2.51, avg_loss=4.1174, train_err=0.2059, 32_h1=0.2017, 32_l2=0.1474, 64_h1=0.2671, 64_l2=0.1545\n",
      "[3] time=2.43, avg_loss=3.4934, train_err=0.1747, 32_h1=0.1626, 32_l2=0.1018, 64_h1=0.2299, 64_l2=0.1122\n",
      "[4] time=2.42, avg_loss=3.2060, train_err=0.1603, 32_h1=0.1525, 32_l2=0.1030, 64_h1=0.2274, 64_l2=0.1173\n",
      "[5] time=2.44, avg_loss=2.8354, train_err=0.1418, 32_h1=0.1315, 32_l2=0.0792, 64_h1=0.1914, 64_l2=0.0844\n",
      "[6] time=2.41, avg_loss=2.7492, train_err=0.1375, 32_h1=0.1421, 32_l2=0.0924, 64_h1=0.2115, 64_l2=0.1059\n",
      "[7] time=2.41, avg_loss=2.4932, train_err=0.1247, 32_h1=0.1192, 32_l2=0.0720, 64_h1=0.1928, 64_l2=0.0870\n",
      "[8] time=2.42, avg_loss=2.3452, train_err=0.1173, 32_h1=0.1129, 32_l2=0.0657, 64_h1=0.1741, 64_l2=0.0690\n",
      "[9] time=2.49, avg_loss=2.2873, train_err=0.1144, 32_h1=0.1337, 32_l2=0.0889, 64_h1=0.1892, 64_l2=0.0941\n",
      "[10] time=2.44, avg_loss=2.1895, train_err=0.1095, 32_h1=0.1064, 32_l2=0.0607, 64_h1=0.1731, 64_l2=0.0701\n",
      "[11] time=2.42, avg_loss=2.1016, train_err=0.1051, 32_h1=0.1033, 32_l2=0.0556, 64_h1=0.1696, 64_l2=0.0613\n",
      "[12] time=2.48, avg_loss=2.1288, train_err=0.1064, 32_h1=0.1166, 32_l2=0.0793, 64_h1=0.1926, 64_l2=0.0927\n",
      "[13] time=2.47, avg_loss=2.0723, train_err=0.1036, 32_h1=0.1000, 32_l2=0.0559, 64_h1=0.1792, 64_l2=0.0715\n",
      "[14] time=2.45, avg_loss=1.9517, train_err=0.0976, 32_h1=0.1016, 32_l2=0.0585, 64_h1=0.1709, 64_l2=0.0621\n",
      "[15] time=2.41, avg_loss=1.9448, train_err=0.0972, 32_h1=0.0994, 32_l2=0.0555, 64_h1=0.1669, 64_l2=0.0622\n",
      "[16] time=2.39, avg_loss=1.9557, train_err=0.0978, 32_h1=0.1006, 32_l2=0.0607, 64_h1=0.1717, 64_l2=0.0694\n",
      "[17] time=2.48, avg_loss=1.8812, train_err=0.0941, 32_h1=0.0942, 32_l2=0.0522, 64_h1=0.1705, 64_l2=0.0663\n",
      "[18] time=2.45, avg_loss=1.8422, train_err=0.0921, 32_h1=0.0944, 32_l2=0.0521, 64_h1=0.1701, 64_l2=0.0590\n",
      "[19] time=2.41, avg_loss=1.8230, train_err=0.0912, 32_h1=0.0928, 32_l2=0.0502, 64_h1=0.1746, 64_l2=0.0652\n",
      "[20] time=2.45, avg_loss=1.8893, train_err=0.0945, 32_h1=0.1006, 32_l2=0.0574, 64_h1=0.1764, 64_l2=0.0672\n",
      "[21] time=2.41, avg_loss=1.8007, train_err=0.0900, 32_h1=0.0894, 32_l2=0.0466, 64_h1=0.1673, 64_l2=0.0576\n",
      "[22] time=2.49, avg_loss=1.8533, train_err=0.0927, 32_h1=0.0937, 32_l2=0.0531, 64_h1=0.1702, 64_l2=0.0622\n",
      "[23] time=2.49, avg_loss=1.7402, train_err=0.0870, 32_h1=0.0886, 32_l2=0.0479, 64_h1=0.1720, 64_l2=0.0626\n",
      "[24] time=2.50, avg_loss=1.7539, train_err=0.0877, 32_h1=0.0889, 32_l2=0.0478, 64_h1=0.1716, 64_l2=0.0629\n",
      "[25] time=2.44, avg_loss=1.7977, train_err=0.0899, 32_h1=0.0851, 32_l2=0.0431, 64_h1=0.1645, 64_l2=0.0567\n",
      "[26] time=2.54, avg_loss=1.6889, train_err=0.0844, 32_h1=0.0855, 32_l2=0.0447, 64_h1=0.1605, 64_l2=0.0531\n",
      "[27] time=2.43, avg_loss=1.7394, train_err=0.0870, 32_h1=0.0849, 32_l2=0.0431, 64_h1=0.1649, 64_l2=0.0524\n",
      "[28] time=2.46, avg_loss=1.7580, train_err=0.0879, 32_h1=0.0877, 32_l2=0.0471, 64_h1=0.1699, 64_l2=0.0622\n",
      "[29] time=2.39, avg_loss=1.7459, train_err=0.0873, 32_h1=0.0871, 32_l2=0.0458, 64_h1=0.1633, 64_l2=0.0535\n",
      "[30] time=2.43, avg_loss=1.6906, train_err=0.0845, 32_h1=0.0916, 32_l2=0.0551, 64_h1=0.1713, 64_l2=0.0694\n",
      "[31] time=2.41, avg_loss=1.6937, train_err=0.0847, 32_h1=0.0886, 32_l2=0.0493, 64_h1=0.1710, 64_l2=0.0604\n",
      "[32] time=2.46, avg_loss=1.6700, train_err=0.0835, 32_h1=0.0824, 32_l2=0.0419, 64_h1=0.1680, 64_l2=0.0569\n",
      "[33] time=2.42, avg_loss=1.6618, train_err=0.0831, 32_h1=0.0863, 32_l2=0.0456, 64_h1=0.1732, 64_l2=0.0620\n",
      "[34] time=2.43, avg_loss=1.7009, train_err=0.0850, 32_h1=0.0872, 32_l2=0.0468, 64_h1=0.1643, 64_l2=0.0540\n",
      "[35] time=2.42, avg_loss=1.6760, train_err=0.0838, 32_h1=0.0845, 32_l2=0.0440, 64_h1=0.1711, 64_l2=0.0596\n",
      "[36] time=2.41, avg_loss=1.6707, train_err=0.0835, 32_h1=0.0834, 32_l2=0.0424, 64_h1=0.1612, 64_l2=0.0565\n",
      "[37] time=2.40, avg_loss=1.6252, train_err=0.0813, 32_h1=0.0931, 32_l2=0.0581, 64_h1=0.1747, 64_l2=0.0696\n",
      "[38] time=2.24, avg_loss=1.6273, train_err=0.0814, 32_h1=0.0826, 32_l2=0.0421, 64_h1=0.1630, 64_l2=0.0551\n",
      "[39] time=2.13, avg_loss=1.6141, train_err=0.0807, 32_h1=0.0828, 32_l2=0.0427, 64_h1=0.1662, 64_l2=0.0587\n",
      "[40] time=2.28, avg_loss=1.5942, train_err=0.0797, 32_h1=0.0803, 32_l2=0.0403, 64_h1=0.1681, 64_l2=0.0546\n",
      "[41] time=2.28, avg_loss=1.6148, train_err=0.0807, 32_h1=0.0839, 32_l2=0.0457, 64_h1=0.1670, 64_l2=0.0592\n",
      "[42] time=2.28, avg_loss=1.6029, train_err=0.0801, 32_h1=0.0914, 32_l2=0.0564, 64_h1=0.1735, 64_l2=0.0691\n",
      "[43] time=2.27, avg_loss=1.6144, train_err=0.0807, 32_h1=0.0848, 32_l2=0.0463, 64_h1=0.1666, 64_l2=0.0574\n",
      "[44] time=2.15, avg_loss=1.6691, train_err=0.0835, 32_h1=0.0841, 32_l2=0.0458, 64_h1=0.1684, 64_l2=0.0601\n",
      "[45] time=2.29, avg_loss=1.5924, train_err=0.0796, 32_h1=0.0789, 32_l2=0.0390, 64_h1=0.1641, 64_l2=0.0510\n",
      "[46] time=2.29, avg_loss=1.5694, train_err=0.0785, 32_h1=0.0807, 32_l2=0.0428, 64_h1=0.1690, 64_l2=0.0593\n",
      "[47] time=2.11, avg_loss=1.5759, train_err=0.0788, 32_h1=0.0813, 32_l2=0.0446, 64_h1=0.1679, 64_l2=0.0615\n",
      "[48] time=2.16, avg_loss=1.5656, train_err=0.0783, 32_h1=0.0801, 32_l2=0.0412, 64_h1=0.1714, 64_l2=0.0546\n",
      "[49] time=2.19, avg_loss=1.5305, train_err=0.0765, 32_h1=0.0784, 32_l2=0.0397, 64_h1=0.1638, 64_l2=0.0543\n",
      "[50] time=2.09, avg_loss=1.5832, train_err=0.0792, 32_h1=0.0824, 32_l2=0.0427, 64_h1=0.1735, 64_l2=0.0628\n",
      "[51] time=2.12, avg_loss=1.5991, train_err=0.0800, 32_h1=0.0821, 32_l2=0.0452, 64_h1=0.1605, 64_l2=0.0572\n",
      "[52] time=2.29, avg_loss=1.5406, train_err=0.0770, 32_h1=0.0853, 32_l2=0.0474, 64_h1=0.1614, 64_l2=0.0538\n",
      "[53] time=2.19, avg_loss=1.5504, train_err=0.0775, 32_h1=0.0786, 32_l2=0.0385, 64_h1=0.1738, 64_l2=0.0564\n",
      "[54] time=2.09, avg_loss=1.5345, train_err=0.0767, 32_h1=0.0798, 32_l2=0.0417, 64_h1=0.1735, 64_l2=0.0591\n",
      "[55] time=2.16, avg_loss=1.5110, train_err=0.0756, 32_h1=0.0782, 32_l2=0.0390, 64_h1=0.1622, 64_l2=0.0531\n",
      "[56] time=2.09, avg_loss=1.5379, train_err=0.0769, 32_h1=0.0874, 32_l2=0.0480, 64_h1=0.1593, 64_l2=0.0535\n",
      "[57] time=2.10, avg_loss=1.5360, train_err=0.0768, 32_h1=0.0795, 32_l2=0.0398, 64_h1=0.1753, 64_l2=0.0574\n",
      "[58] time=2.16, avg_loss=1.5331, train_err=0.0767, 32_h1=0.0833, 32_l2=0.0455, 64_h1=0.1732, 64_l2=0.0650\n",
      "[59] time=2.21, avg_loss=1.5148, train_err=0.0757, 32_h1=0.0769, 32_l2=0.0377, 64_h1=0.1698, 64_l2=0.0578\n",
      "[60] time=2.15, avg_loss=1.5445, train_err=0.0772, 32_h1=0.0842, 32_l2=0.0473, 64_h1=0.1707, 64_l2=0.0652\n",
      "[61] time=2.20, avg_loss=1.5018, train_err=0.0751, 32_h1=0.0766, 32_l2=0.0378, 64_h1=0.1626, 64_l2=0.0541\n",
      "[62] time=2.11, avg_loss=1.5122, train_err=0.0756, 32_h1=0.0779, 32_l2=0.0388, 64_h1=0.1698, 64_l2=0.0556\n",
      "[63] time=2.13, avg_loss=1.5608, train_err=0.0780, 32_h1=0.0825, 32_l2=0.0445, 64_h1=0.1621, 64_l2=0.0504\n",
      "[64] time=2.17, avg_loss=1.4878, train_err=0.0744, 32_h1=0.0772, 32_l2=0.0390, 64_h1=0.1676, 64_l2=0.0529\n",
      "[65] time=2.23, avg_loss=1.5071, train_err=0.0754, 32_h1=0.0780, 32_l2=0.0405, 64_h1=0.1615, 64_l2=0.0558\n",
      "[66] time=2.52, avg_loss=1.5305, train_err=0.0765, 32_h1=0.0833, 32_l2=0.0470, 64_h1=0.1689, 64_l2=0.0591\n",
      "[67] time=2.47, avg_loss=1.5371, train_err=0.0769, 32_h1=0.0825, 32_l2=0.0456, 64_h1=0.1639, 64_l2=0.0569\n",
      "[68] time=2.44, avg_loss=1.4726, train_err=0.0736, 32_h1=0.0764, 32_l2=0.0386, 64_h1=0.1635, 64_l2=0.0532\n",
      "[69] time=2.45, avg_loss=1.4572, train_err=0.0729, 32_h1=0.0766, 32_l2=0.0395, 64_h1=0.1643, 64_l2=0.0528\n",
      "[70] time=2.46, avg_loss=1.4787, train_err=0.0739, 32_h1=0.0785, 32_l2=0.0405, 64_h1=0.1647, 64_l2=0.0584\n",
      "[71] time=2.50, avg_loss=1.4863, train_err=0.0743, 32_h1=0.0828, 32_l2=0.0458, 64_h1=0.1524, 64_l2=0.0505\n",
      "[72] time=2.42, avg_loss=1.4762, train_err=0.0738, 32_h1=0.0764, 32_l2=0.0391, 64_h1=0.1541, 64_l2=0.0487\n",
      "[73] time=2.45, avg_loss=1.4599, train_err=0.0730, 32_h1=0.0803, 32_l2=0.0452, 64_h1=0.1639, 64_l2=0.0587\n",
      "[74] time=2.39, avg_loss=1.5064, train_err=0.0753, 32_h1=0.0753, 32_l2=0.0366, 64_h1=0.1658, 64_l2=0.0548\n",
      "[75] time=2.40, avg_loss=1.4719, train_err=0.0736, 32_h1=0.0793, 32_l2=0.0434, 64_h1=0.1666, 64_l2=0.0578\n",
      "[76] time=2.44, avg_loss=1.4512, train_err=0.0726, 32_h1=0.0790, 32_l2=0.0424, 64_h1=0.1629, 64_l2=0.0571\n",
      "[77] time=2.41, avg_loss=1.4619, train_err=0.0731, 32_h1=0.0765, 32_l2=0.0386, 64_h1=0.1684, 64_l2=0.0579\n",
      "[78] time=2.43, avg_loss=1.4717, train_err=0.0736, 32_h1=0.0751, 32_l2=0.0364, 64_h1=0.1629, 64_l2=0.0534\n",
      "[79] time=2.39, avg_loss=1.4580, train_err=0.0729, 32_h1=0.0817, 32_l2=0.0445, 64_h1=0.1635, 64_l2=0.0587\n",
      "[80] time=2.40, avg_loss=1.4398, train_err=0.0720, 32_h1=0.0776, 32_l2=0.0400, 64_h1=0.1634, 64_l2=0.0488\n",
      "[81] time=2.40, avg_loss=1.4597, train_err=0.0730, 32_h1=0.0838, 32_l2=0.0482, 64_h1=0.1738, 64_l2=0.0647\n",
      "[82] time=2.43, avg_loss=1.4321, train_err=0.0716, 32_h1=0.0765, 32_l2=0.0396, 64_h1=0.1623, 64_l2=0.0524\n",
      "[83] time=2.48, avg_loss=1.4743, train_err=0.0737, 32_h1=0.0792, 32_l2=0.0438, 64_h1=0.1596, 64_l2=0.0560\n",
      "[84] time=2.44, avg_loss=1.4514, train_err=0.0726, 32_h1=0.0743, 32_l2=0.0386, 64_h1=0.1670, 64_l2=0.0551\n",
      "[85] time=2.47, avg_loss=1.4275, train_err=0.0714, 32_h1=0.0769, 32_l2=0.0393, 64_h1=0.1644, 64_l2=0.0527\n",
      "[86] time=2.47, avg_loss=1.4532, train_err=0.0727, 32_h1=0.0781, 32_l2=0.0393, 64_h1=0.1630, 64_l2=0.0541\n",
      "[87] time=2.42, avg_loss=1.4438, train_err=0.0722, 32_h1=0.0752, 32_l2=0.0381, 64_h1=0.1601, 64_l2=0.0565\n",
      "[88] time=2.46, avg_loss=1.4099, train_err=0.0705, 32_h1=0.0753, 32_l2=0.0393, 64_h1=0.1584, 64_l2=0.0556\n",
      "[89] time=2.47, avg_loss=1.4235, train_err=0.0712, 32_h1=0.0755, 32_l2=0.0380, 64_h1=0.1653, 64_l2=0.0566\n",
      "[90] time=2.44, avg_loss=1.4195, train_err=0.0710, 32_h1=0.0786, 32_l2=0.0416, 64_h1=0.1618, 64_l2=0.0532\n",
      "[91] time=2.47, avg_loss=1.4360, train_err=0.0718, 32_h1=0.0756, 32_l2=0.0390, 64_h1=0.1611, 64_l2=0.0520\n",
      "[92] time=2.42, avg_loss=1.4235, train_err=0.0712, 32_h1=0.0741, 32_l2=0.0362, 64_h1=0.1625, 64_l2=0.0522\n",
      "[93] time=2.43, avg_loss=1.4003, train_err=0.0700, 32_h1=0.0770, 32_l2=0.0397, 64_h1=0.1616, 64_l2=0.0583\n",
      "[94] time=2.43, avg_loss=1.4031, train_err=0.0702, 32_h1=0.0771, 32_l2=0.0406, 64_h1=0.1598, 64_l2=0.0562\n",
      "[95] time=2.44, avg_loss=1.4344, train_err=0.0717, 32_h1=0.0762, 32_l2=0.0384, 64_h1=0.1627, 64_l2=0.0571\n",
      "[96] time=2.45, avg_loss=1.3978, train_err=0.0699, 32_h1=0.0753, 32_l2=0.0385, 64_h1=0.1570, 64_l2=0.0510\n",
      "[97] time=2.42, avg_loss=1.3977, train_err=0.0699, 32_h1=0.0732, 32_l2=0.0349, 64_h1=0.1576, 64_l2=0.0494\n",
      "[98] time=2.39, avg_loss=1.4196, train_err=0.0710, 32_h1=0.0746, 32_l2=0.0376, 64_h1=0.1612, 64_l2=0.0543\n",
      "[99] time=2.43, avg_loss=1.3955, train_err=0.0698, 32_h1=0.0754, 32_l2=0.0401, 64_h1=0.1612, 64_l2=0.0566\n",
      "[100] time=2.42, avg_loss=1.3873, train_err=0.0694, 32_h1=0.0739, 32_l2=0.0359, 64_h1=0.1600, 64_l2=0.0502\n",
      "[101] time=2.45, avg_loss=1.3700, train_err=0.0685, 32_h1=0.0734, 32_l2=0.0370, 64_h1=0.1652, 64_l2=0.0521\n",
      "[102] time=2.46, avg_loss=1.3901, train_err=0.0695, 32_h1=0.0737, 32_l2=0.0356, 64_h1=0.1550, 64_l2=0.0519\n",
      "[103] time=2.40, avg_loss=1.3813, train_err=0.0691, 32_h1=0.0734, 32_l2=0.0355, 64_h1=0.1585, 64_l2=0.0494\n",
      "[104] time=2.34, avg_loss=1.4042, train_err=0.0702, 32_h1=0.0763, 32_l2=0.0406, 64_h1=0.1657, 64_l2=0.0529\n",
      "[105] time=2.19, avg_loss=1.3852, train_err=0.0693, 32_h1=0.0739, 32_l2=0.0367, 64_h1=0.1597, 64_l2=0.0530\n",
      "[106] time=2.09, avg_loss=1.3852, train_err=0.0693, 32_h1=0.0743, 32_l2=0.0371, 64_h1=0.1615, 64_l2=0.0538\n",
      "[107] time=2.13, avg_loss=1.4120, train_err=0.0706, 32_h1=0.0816, 32_l2=0.0481, 64_h1=0.1635, 64_l2=0.0625\n",
      "[108] time=2.17, avg_loss=1.4169, train_err=0.0708, 32_h1=0.0747, 32_l2=0.0378, 64_h1=0.1563, 64_l2=0.0498\n",
      "[109] time=2.13, avg_loss=1.3571, train_err=0.0679, 32_h1=0.0740, 32_l2=0.0376, 64_h1=0.1706, 64_l2=0.0576\n",
      "[110] time=2.13, avg_loss=1.3705, train_err=0.0685, 32_h1=0.0741, 32_l2=0.0364, 64_h1=0.1632, 64_l2=0.0517\n",
      "[111] time=2.26, avg_loss=1.3721, train_err=0.0686, 32_h1=0.0742, 32_l2=0.0374, 64_h1=0.1566, 64_l2=0.0467\n",
      "[112] time=2.24, avg_loss=1.3619, train_err=0.0681, 32_h1=0.0749, 32_l2=0.0378, 64_h1=0.1599, 64_l2=0.0504\n",
      "[113] time=2.10, avg_loss=1.3562, train_err=0.0678, 32_h1=0.0735, 32_l2=0.0360, 64_h1=0.1627, 64_l2=0.0529\n",
      "[114] time=2.10, avg_loss=1.3582, train_err=0.0679, 32_h1=0.0740, 32_l2=0.0375, 64_h1=0.1605, 64_l2=0.0510\n",
      "[115] time=2.16, avg_loss=1.3488, train_err=0.0674, 32_h1=0.0736, 32_l2=0.0367, 64_h1=0.1588, 64_l2=0.0501\n",
      "[116] time=2.26, avg_loss=1.3706, train_err=0.0685, 32_h1=0.0757, 32_l2=0.0372, 64_h1=0.1636, 64_l2=0.0584\n",
      "[117] time=2.20, avg_loss=1.3619, train_err=0.0681, 32_h1=0.0733, 32_l2=0.0379, 64_h1=0.1571, 64_l2=0.0524\n",
      "[118] time=2.11, avg_loss=1.3501, train_err=0.0675, 32_h1=0.0757, 32_l2=0.0429, 64_h1=0.1673, 64_l2=0.0598\n",
      "[119] time=2.16, avg_loss=1.3554, train_err=0.0678, 32_h1=0.0717, 32_l2=0.0348, 64_h1=0.1653, 64_l2=0.0553\n",
      "[120] time=2.20, avg_loss=1.3588, train_err=0.0679, 32_h1=0.0730, 32_l2=0.0347, 64_h1=0.1565, 64_l2=0.0481\n",
      "[121] time=2.28, avg_loss=1.3457, train_err=0.0673, 32_h1=0.0726, 32_l2=0.0347, 64_h1=0.1629, 64_l2=0.0534\n",
      "[122] time=2.26, avg_loss=1.3517, train_err=0.0676, 32_h1=0.0761, 32_l2=0.0389, 64_h1=0.1650, 64_l2=0.0554\n",
      "[123] time=2.18, avg_loss=1.3599, train_err=0.0680, 32_h1=0.0735, 32_l2=0.0350, 64_h1=0.1636, 64_l2=0.0533\n",
      "[124] time=2.09, avg_loss=1.3299, train_err=0.0665, 32_h1=0.0717, 32_l2=0.0346, 64_h1=0.1591, 64_l2=0.0508\n",
      "[125] time=2.11, avg_loss=1.3427, train_err=0.0671, 32_h1=0.0731, 32_l2=0.0357, 64_h1=0.1616, 64_l2=0.0536\n",
      "[126] time=2.10, avg_loss=1.3231, train_err=0.0662, 32_h1=0.0731, 32_l2=0.0353, 64_h1=0.1621, 64_l2=0.0491\n",
      "[127] time=2.09, avg_loss=1.3346, train_err=0.0667, 32_h1=0.0720, 32_l2=0.0348, 64_h1=0.1587, 64_l2=0.0476\n",
      "[128] time=2.19, avg_loss=1.3452, train_err=0.0673, 32_h1=0.0725, 32_l2=0.0351, 64_h1=0.1624, 64_l2=0.0507\n",
      "[129] time=2.24, avg_loss=1.3571, train_err=0.0679, 32_h1=0.0720, 32_l2=0.0344, 64_h1=0.1580, 64_l2=0.0497\n",
      "[130] time=2.11, avg_loss=1.3268, train_err=0.0663, 32_h1=0.0711, 32_l2=0.0335, 64_h1=0.1612, 64_l2=0.0514\n",
      "[131] time=2.09, avg_loss=1.3238, train_err=0.0662, 32_h1=0.0722, 32_l2=0.0343, 64_h1=0.1670, 64_l2=0.0551\n",
      "[132] time=2.15, avg_loss=1.3144, train_err=0.0657, 32_h1=0.0727, 32_l2=0.0354, 64_h1=0.1601, 64_l2=0.0532\n",
      "[133] time=2.43, avg_loss=1.3310, train_err=0.0665, 32_h1=0.0729, 32_l2=0.0352, 64_h1=0.1628, 64_l2=0.0544\n",
      "[134] time=2.47, avg_loss=1.3051, train_err=0.0653, 32_h1=0.0739, 32_l2=0.0385, 64_h1=0.1637, 64_l2=0.0566\n",
      "[135] time=2.49, avg_loss=1.3366, train_err=0.0668, 32_h1=0.0714, 32_l2=0.0333, 64_h1=0.1620, 64_l2=0.0509\n",
      "[136] time=2.40, avg_loss=1.3202, train_err=0.0660, 32_h1=0.0714, 32_l2=0.0330, 64_h1=0.1590, 64_l2=0.0500\n",
      "[137] time=2.38, avg_loss=1.3094, train_err=0.0655, 32_h1=0.0726, 32_l2=0.0346, 64_h1=0.1651, 64_l2=0.0489\n",
      "[138] time=2.39, avg_loss=1.3281, train_err=0.0664, 32_h1=0.0717, 32_l2=0.0339, 64_h1=0.1612, 64_l2=0.0507\n",
      "[139] time=2.43, avg_loss=1.3022, train_err=0.0651, 32_h1=0.0732, 32_l2=0.0368, 64_h1=0.1588, 64_l2=0.0507\n",
      "[140] time=2.44, avg_loss=1.3184, train_err=0.0659, 32_h1=0.0733, 32_l2=0.0368, 64_h1=0.1606, 64_l2=0.0491\n",
      "[141] time=2.46, avg_loss=1.3201, train_err=0.0660, 32_h1=0.0725, 32_l2=0.0351, 64_h1=0.1637, 64_l2=0.0526\n",
      "[142] time=2.42, avg_loss=1.2970, train_err=0.0648, 32_h1=0.0703, 32_l2=0.0321, 64_h1=0.1589, 64_l2=0.0499\n",
      "[143] time=2.48, avg_loss=1.2922, train_err=0.0646, 32_h1=0.0716, 32_l2=0.0334, 64_h1=0.1608, 64_l2=0.0486\n",
      "[144] time=2.40, avg_loss=1.3131, train_err=0.0657, 32_h1=0.0716, 32_l2=0.0339, 64_h1=0.1682, 64_l2=0.0529\n",
      "[145] time=2.40, avg_loss=1.3088, train_err=0.0654, 32_h1=0.0759, 32_l2=0.0437, 64_h1=0.1611, 64_l2=0.0603\n",
      "[146] time=2.40, avg_loss=1.2948, train_err=0.0647, 32_h1=0.0716, 32_l2=0.0354, 64_h1=0.1647, 64_l2=0.0525\n",
      "[147] time=2.41, avg_loss=1.2957, train_err=0.0648, 32_h1=0.0710, 32_l2=0.0340, 64_h1=0.1607, 64_l2=0.0509\n",
      "[148] time=2.39, avg_loss=1.2916, train_err=0.0646, 32_h1=0.0716, 32_l2=0.0345, 64_h1=0.1626, 64_l2=0.0505\n",
      "[149] time=2.41, avg_loss=1.2883, train_err=0.0644, 32_h1=0.0711, 32_l2=0.0337, 64_h1=0.1602, 64_l2=0.0523\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.07\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 62161\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(15, 15, 3, 3))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f983c59d6a0>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f9757717dc0>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f9757717dc0>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f983c59d700>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.42, avg_loss=10.6020, train_err=0.5301, 32_h1=0.3360, 32_l2=0.2334, 64_h1=0.3994, 64_l2=0.2423\n",
      "[1] time=2.36, avg_loss=5.4636, train_err=0.2732, 32_h1=0.2811, 32_l2=0.2128, 64_h1=0.3214, 64_l2=0.2124\n",
      "[2] time=2.38, avg_loss=4.2736, train_err=0.2137, 32_h1=0.2758, 32_l2=0.2159, 64_h1=0.3087, 64_l2=0.2180\n",
      "[3] time=2.43, avg_loss=3.8788, train_err=0.1939, 32_h1=0.1789, 32_l2=0.1202, 64_h1=0.2560, 64_l2=0.1299\n",
      "[4] time=2.39, avg_loss=3.4750, train_err=0.1738, 32_h1=0.1691, 32_l2=0.1259, 64_h1=0.2374, 64_l2=0.1358\n",
      "[5] time=2.57, avg_loss=3.1976, train_err=0.1599, 32_h1=0.1474, 32_l2=0.0935, 64_h1=0.1978, 64_l2=0.0947\n",
      "[6] time=2.47, avg_loss=2.9399, train_err=0.1470, 32_h1=0.1847, 32_l2=0.1444, 64_h1=0.2540, 64_l2=0.1527\n",
      "[7] time=2.35, avg_loss=2.7113, train_err=0.1356, 32_h1=0.1418, 32_l2=0.0952, 64_h1=0.2058, 64_l2=0.1001\n",
      "[8] time=2.38, avg_loss=2.7874, train_err=0.1394, 32_h1=0.1441, 32_l2=0.0942, 64_h1=0.2158, 64_l2=0.1034\n",
      "[9] time=2.47, avg_loss=2.4964, train_err=0.1248, 32_h1=0.1178, 32_l2=0.0671, 64_h1=0.1863, 64_l2=0.0788\n",
      "[10] time=2.41, avg_loss=2.3392, train_err=0.1170, 32_h1=0.1171, 32_l2=0.0757, 64_h1=0.1920, 64_l2=0.0869\n",
      "[11] time=2.39, avg_loss=2.3261, train_err=0.1163, 32_h1=0.1336, 32_l2=0.0861, 64_h1=0.1898, 64_l2=0.0923\n",
      "[12] time=2.44, avg_loss=2.2212, train_err=0.1111, 32_h1=0.1052, 32_l2=0.0580, 64_h1=0.1757, 64_l2=0.0683\n",
      "[13] time=2.43, avg_loss=2.1631, train_err=0.1082, 32_h1=0.1049, 32_l2=0.0602, 64_h1=0.1783, 64_l2=0.0755\n",
      "[14] time=2.38, avg_loss=2.0703, train_err=0.1035, 32_h1=0.1075, 32_l2=0.0624, 64_h1=0.1833, 64_l2=0.0740\n",
      "[15] time=2.45, avg_loss=2.0726, train_err=0.1036, 32_h1=0.1186, 32_l2=0.0790, 64_h1=0.1847, 64_l2=0.0896\n",
      "[16] time=2.38, avg_loss=2.0984, train_err=0.1049, 32_h1=0.1032, 32_l2=0.0610, 64_h1=0.1807, 64_l2=0.0727\n",
      "[17] time=2.44, avg_loss=1.9243, train_err=0.0962, 32_h1=0.0973, 32_l2=0.0550, 64_h1=0.1719, 64_l2=0.0670\n",
      "[18] time=2.37, avg_loss=1.9977, train_err=0.0999, 32_h1=0.1033, 32_l2=0.0632, 64_h1=0.1686, 64_l2=0.0684\n",
      "[19] time=2.42, avg_loss=1.9066, train_err=0.0953, 32_h1=0.0946, 32_l2=0.0500, 64_h1=0.1711, 64_l2=0.0660\n",
      "[20] time=2.40, avg_loss=1.9105, train_err=0.0955, 32_h1=0.1126, 32_l2=0.0776, 64_h1=0.1871, 64_l2=0.0890\n",
      "[21] time=2.20, avg_loss=1.8918, train_err=0.0946, 32_h1=0.0946, 32_l2=0.0533, 64_h1=0.1741, 64_l2=0.0670\n",
      "[22] time=2.25, avg_loss=1.8271, train_err=0.0914, 32_h1=0.0878, 32_l2=0.0442, 64_h1=0.1697, 64_l2=0.0561\n",
      "[23] time=2.24, avg_loss=1.8138, train_err=0.0907, 32_h1=0.0944, 32_l2=0.0531, 64_h1=0.1667, 64_l2=0.0617\n",
      "[24] time=2.25, avg_loss=1.8293, train_err=0.0915, 32_h1=0.0927, 32_l2=0.0543, 64_h1=0.1774, 64_l2=0.0723\n",
      "[25] time=2.12, avg_loss=1.7903, train_err=0.0895, 32_h1=0.0951, 32_l2=0.0557, 64_h1=0.1726, 64_l2=0.0687\n",
      "[26] time=2.09, avg_loss=1.8302, train_err=0.0915, 32_h1=0.0998, 32_l2=0.0614, 64_h1=0.1632, 64_l2=0.0690\n",
      "[27] time=2.09, avg_loss=1.7675, train_err=0.0884, 32_h1=0.0881, 32_l2=0.0454, 64_h1=0.1655, 64_l2=0.0590\n",
      "[28] time=2.12, avg_loss=1.8081, train_err=0.0904, 32_h1=0.0891, 32_l2=0.0508, 64_h1=0.1679, 64_l2=0.0620\n",
      "[29] time=2.18, avg_loss=1.7945, train_err=0.0897, 32_h1=0.0873, 32_l2=0.0467, 64_h1=0.1690, 64_l2=0.0651\n",
      "[30] time=2.25, avg_loss=1.7446, train_err=0.0872, 32_h1=0.0860, 32_l2=0.0455, 64_h1=0.1614, 64_l2=0.0599\n",
      "[31] time=2.21, avg_loss=1.6870, train_err=0.0843, 32_h1=0.0878, 32_l2=0.0465, 64_h1=0.1678, 64_l2=0.0609\n",
      "[32] time=2.25, avg_loss=1.7520, train_err=0.0876, 32_h1=0.0848, 32_l2=0.0435, 64_h1=0.1669, 64_l2=0.0534\n",
      "[33] time=2.26, avg_loss=1.6932, train_err=0.0847, 32_h1=0.0843, 32_l2=0.0444, 64_h1=0.1681, 64_l2=0.0576\n",
      "[34] time=2.26, avg_loss=1.7232, train_err=0.0862, 32_h1=0.0851, 32_l2=0.0428, 64_h1=0.1636, 64_l2=0.0550\n",
      "[35] time=2.22, avg_loss=1.6933, train_err=0.0847, 32_h1=0.0864, 32_l2=0.0456, 64_h1=0.1682, 64_l2=0.0626\n",
      "[36] time=2.17, avg_loss=1.6689, train_err=0.0834, 32_h1=0.0840, 32_l2=0.0439, 64_h1=0.1696, 64_l2=0.0621\n",
      "[37] time=2.18, avg_loss=1.6846, train_err=0.0842, 32_h1=0.0929, 32_l2=0.0599, 64_h1=0.1668, 64_l2=0.0703\n",
      "[38] time=2.13, avg_loss=1.6729, train_err=0.0836, 32_h1=0.0855, 32_l2=0.0470, 64_h1=0.1612, 64_l2=0.0568\n",
      "[39] time=2.10, avg_loss=1.6678, train_err=0.0834, 32_h1=0.0817, 32_l2=0.0402, 64_h1=0.1562, 64_l2=0.0522\n",
      "[40] time=2.26, avg_loss=1.6464, train_err=0.0823, 32_h1=0.0869, 32_l2=0.0487, 64_h1=0.1608, 64_l2=0.0534\n",
      "[41] time=2.29, avg_loss=1.6756, train_err=0.0838, 32_h1=0.0822, 32_l2=0.0417, 64_h1=0.1675, 64_l2=0.0624\n",
      "[42] time=2.16, avg_loss=1.5993, train_err=0.0800, 32_h1=0.0871, 32_l2=0.0523, 64_h1=0.1646, 64_l2=0.0676\n",
      "[43] time=2.24, avg_loss=1.6072, train_err=0.0804, 32_h1=0.0802, 32_l2=0.0401, 64_h1=0.1669, 64_l2=0.0586\n",
      "[44] time=2.20, avg_loss=1.5884, train_err=0.0794, 32_h1=0.0810, 32_l2=0.0410, 64_h1=0.1660, 64_l2=0.0604\n",
      "[45] time=2.09, avg_loss=1.5827, train_err=0.0791, 32_h1=0.0900, 32_l2=0.0562, 64_h1=0.1688, 64_l2=0.0666\n",
      "[46] time=2.17, avg_loss=1.6155, train_err=0.0808, 32_h1=0.0835, 32_l2=0.0434, 64_h1=0.1570, 64_l2=0.0538\n",
      "[47] time=2.24, avg_loss=1.6282, train_err=0.0814, 32_h1=0.0921, 32_l2=0.0640, 64_h1=0.1691, 64_l2=0.0711\n",
      "[48] time=2.16, avg_loss=1.5919, train_err=0.0796, 32_h1=0.0800, 32_l2=0.0396, 64_h1=0.1636, 64_l2=0.0547\n",
      "[49] time=2.47, avg_loss=1.5716, train_err=0.0786, 32_h1=0.0865, 32_l2=0.0505, 64_h1=0.1691, 64_l2=0.0622\n",
      "[50] time=2.45, avg_loss=1.5825, train_err=0.0791, 32_h1=0.0816, 32_l2=0.0444, 64_h1=0.1659, 64_l2=0.0550\n",
      "[51] time=2.41, avg_loss=1.5948, train_err=0.0797, 32_h1=0.0812, 32_l2=0.0443, 64_h1=0.1571, 64_l2=0.0561\n",
      "[52] time=2.40, avg_loss=1.5712, train_err=0.0786, 32_h1=0.0808, 32_l2=0.0420, 64_h1=0.1638, 64_l2=0.0634\n",
      "[53] time=2.43, avg_loss=1.5352, train_err=0.0768, 32_h1=0.0799, 32_l2=0.0411, 64_h1=0.1617, 64_l2=0.0560\n",
      "[54] time=2.44, avg_loss=1.5578, train_err=0.0779, 32_h1=0.0845, 32_l2=0.0465, 64_h1=0.1564, 64_l2=0.0616\n",
      "[55] time=2.36, avg_loss=1.5705, train_err=0.0785, 32_h1=0.0774, 32_l2=0.0378, 64_h1=0.1593, 64_l2=0.0506\n",
      "[56] time=2.44, avg_loss=1.5097, train_err=0.0755, 32_h1=0.0800, 32_l2=0.0424, 64_h1=0.1613, 64_l2=0.0578\n",
      "[57] time=2.43, avg_loss=1.5346, train_err=0.0767, 32_h1=0.0831, 32_l2=0.0501, 64_h1=0.1694, 64_l2=0.0655\n",
      "[58] time=2.40, avg_loss=1.5331, train_err=0.0767, 32_h1=0.0795, 32_l2=0.0411, 64_h1=0.1600, 64_l2=0.0557\n",
      "[59] time=2.45, avg_loss=1.5136, train_err=0.0757, 32_h1=0.0824, 32_l2=0.0496, 64_h1=0.1652, 64_l2=0.0627\n",
      "[60] time=2.45, avg_loss=1.5024, train_err=0.0751, 32_h1=0.0773, 32_l2=0.0395, 64_h1=0.1554, 64_l2=0.0521\n",
      "[61] time=2.42, avg_loss=1.5096, train_err=0.0755, 32_h1=0.0771, 32_l2=0.0384, 64_h1=0.1601, 64_l2=0.0535\n",
      "[62] time=2.37, avg_loss=1.5040, train_err=0.0752, 32_h1=0.0783, 32_l2=0.0390, 64_h1=0.1562, 64_l2=0.0528\n",
      "[63] time=2.43, avg_loss=1.5150, train_err=0.0757, 32_h1=0.0835, 32_l2=0.0470, 64_h1=0.1627, 64_l2=0.0576\n",
      "[64] time=2.41, avg_loss=1.5430, train_err=0.0771, 32_h1=0.0797, 32_l2=0.0416, 64_h1=0.1613, 64_l2=0.0558\n",
      "[65] time=2.43, avg_loss=1.4625, train_err=0.0731, 32_h1=0.0751, 32_l2=0.0360, 64_h1=0.1626, 64_l2=0.0562\n",
      "[66] time=2.38, avg_loss=1.4835, train_err=0.0742, 32_h1=0.0820, 32_l2=0.0458, 64_h1=0.1576, 64_l2=0.0547\n",
      "[67] time=2.39, avg_loss=1.4794, train_err=0.0740, 32_h1=0.0797, 32_l2=0.0436, 64_h1=0.1525, 64_l2=0.0542\n",
      "[68] time=2.40, avg_loss=1.4864, train_err=0.0743, 32_h1=0.0751, 32_l2=0.0369, 64_h1=0.1525, 64_l2=0.0507\n",
      "[69] time=2.46, avg_loss=1.4857, train_err=0.0743, 32_h1=0.0769, 32_l2=0.0383, 64_h1=0.1621, 64_l2=0.0531\n",
      "[70] time=2.37, avg_loss=1.4680, train_err=0.0734, 32_h1=0.0760, 32_l2=0.0366, 64_h1=0.1563, 64_l2=0.0514\n",
      "[71] time=2.55, avg_loss=1.4749, train_err=0.0737, 32_h1=0.0761, 32_l2=0.0383, 64_h1=0.1553, 64_l2=0.0543\n",
      "[72] time=2.45, avg_loss=1.4974, train_err=0.0749, 32_h1=0.0752, 32_l2=0.0373, 64_h1=0.1561, 64_l2=0.0504\n",
      "[73] time=2.40, avg_loss=1.4762, train_err=0.0738, 32_h1=0.0754, 32_l2=0.0377, 64_h1=0.1531, 64_l2=0.0545\n",
      "[74] time=2.38, avg_loss=1.4395, train_err=0.0720, 32_h1=0.0783, 32_l2=0.0407, 64_h1=0.1620, 64_l2=0.0550\n",
      "[75] time=2.40, avg_loss=1.4673, train_err=0.0734, 32_h1=0.0762, 32_l2=0.0390, 64_h1=0.1576, 64_l2=0.0558\n",
      "[76] time=2.42, avg_loss=1.4577, train_err=0.0729, 32_h1=0.0739, 32_l2=0.0355, 64_h1=0.1579, 64_l2=0.0542\n",
      "[77] time=2.41, avg_loss=1.4519, train_err=0.0726, 32_h1=0.0763, 32_l2=0.0378, 64_h1=0.1571, 64_l2=0.0519\n",
      "[78] time=2.43, avg_loss=1.4530, train_err=0.0726, 32_h1=0.0743, 32_l2=0.0363, 64_h1=0.1536, 64_l2=0.0514\n",
      "[79] time=2.41, avg_loss=1.4424, train_err=0.0721, 32_h1=0.0775, 32_l2=0.0399, 64_h1=0.1542, 64_l2=0.0512\n",
      "[80] time=2.37, avg_loss=1.4489, train_err=0.0724, 32_h1=0.0772, 32_l2=0.0387, 64_h1=0.1550, 64_l2=0.0551\n",
      "[81] time=2.40, avg_loss=1.4274, train_err=0.0714, 32_h1=0.0753, 32_l2=0.0368, 64_h1=0.1642, 64_l2=0.0584\n",
      "[82] time=2.43, avg_loss=1.4405, train_err=0.0720, 32_h1=0.0735, 32_l2=0.0367, 64_h1=0.1568, 64_l2=0.0506\n",
      "[83] time=2.41, avg_loss=1.4349, train_err=0.0717, 32_h1=0.0783, 32_l2=0.0417, 64_h1=0.1601, 64_l2=0.0589\n",
      "[84] time=2.46, avg_loss=1.4563, train_err=0.0728, 32_h1=0.0746, 32_l2=0.0379, 64_h1=0.1578, 64_l2=0.0543\n",
      "[85] time=2.45, avg_loss=1.4397, train_err=0.0720, 32_h1=0.0726, 32_l2=0.0342, 64_h1=0.1537, 64_l2=0.0499\n",
      "[86] time=2.46, avg_loss=1.4396, train_err=0.0720, 32_h1=0.0792, 32_l2=0.0424, 64_h1=0.1648, 64_l2=0.0625\n",
      "[87] time=2.36, avg_loss=1.5032, train_err=0.0752, 32_h1=0.0740, 32_l2=0.0359, 64_h1=0.1499, 64_l2=0.0490\n",
      "[88] time=2.37, avg_loss=1.3986, train_err=0.0699, 32_h1=0.0733, 32_l2=0.0346, 64_h1=0.1525, 64_l2=0.0491\n",
      "[89] time=2.29, avg_loss=1.3932, train_err=0.0697, 32_h1=0.0757, 32_l2=0.0395, 64_h1=0.1513, 64_l2=0.0511\n",
      "[90] time=2.11, avg_loss=1.4030, train_err=0.0701, 32_h1=0.0751, 32_l2=0.0375, 64_h1=0.1602, 64_l2=0.0561\n",
      "[91] time=2.14, avg_loss=1.4105, train_err=0.0705, 32_h1=0.0768, 32_l2=0.0424, 64_h1=0.1547, 64_l2=0.0585\n",
      "[92] time=2.12, avg_loss=1.4051, train_err=0.0703, 32_h1=0.0727, 32_l2=0.0350, 64_h1=0.1532, 64_l2=0.0500\n",
      "[93] time=2.30, avg_loss=1.4074, train_err=0.0704, 32_h1=0.0749, 32_l2=0.0381, 64_h1=0.1539, 64_l2=0.0549\n",
      "[94] time=2.24, avg_loss=1.3880, train_err=0.0694, 32_h1=0.0762, 32_l2=0.0399, 64_h1=0.1530, 64_l2=0.0526\n",
      "[95] time=2.15, avg_loss=1.4408, train_err=0.0720, 32_h1=0.0775, 32_l2=0.0443, 64_h1=0.1578, 64_l2=0.0538\n",
      "[96] time=2.09, avg_loss=1.4296, train_err=0.0715, 32_h1=0.0756, 32_l2=0.0399, 64_h1=0.1562, 64_l2=0.0517\n",
      "[97] time=2.12, avg_loss=1.3880, train_err=0.0694, 32_h1=0.0744, 32_l2=0.0369, 64_h1=0.1609, 64_l2=0.0570\n",
      "[98] time=2.16, avg_loss=1.3868, train_err=0.0693, 32_h1=0.0769, 32_l2=0.0405, 64_h1=0.1527, 64_l2=0.0554\n",
      "[99] time=2.28, avg_loss=1.3855, train_err=0.0693, 32_h1=0.0739, 32_l2=0.0352, 64_h1=0.1615, 64_l2=0.0519\n",
      "[100] time=2.16, avg_loss=1.4483, train_err=0.0724, 32_h1=0.0740, 32_l2=0.0388, 64_h1=0.1526, 64_l2=0.0558\n",
      "[101] time=2.28, avg_loss=1.3839, train_err=0.0692, 32_h1=0.0728, 32_l2=0.0355, 64_h1=0.1602, 64_l2=0.0521\n",
      "[102] time=2.14, avg_loss=1.3767, train_err=0.0688, 32_h1=0.0759, 32_l2=0.0382, 64_h1=0.1663, 64_l2=0.0595\n",
      "[103] time=2.09, avg_loss=1.4227, train_err=0.0711, 32_h1=0.0753, 32_l2=0.0384, 64_h1=0.1549, 64_l2=0.0550\n",
      "[104] time=2.14, avg_loss=1.3839, train_err=0.0692, 32_h1=0.0717, 32_l2=0.0339, 64_h1=0.1578, 64_l2=0.0512\n",
      "[105] time=2.14, avg_loss=1.3755, train_err=0.0688, 32_h1=0.0729, 32_l2=0.0359, 64_h1=0.1575, 64_l2=0.0559\n",
      "[106] time=2.24, avg_loss=1.3661, train_err=0.0683, 32_h1=0.0729, 32_l2=0.0349, 64_h1=0.1528, 64_l2=0.0494\n",
      "[107] time=2.11, avg_loss=1.3617, train_err=0.0681, 32_h1=0.0789, 32_l2=0.0424, 64_h1=0.1517, 64_l2=0.0564\n",
      "[108] time=2.11, avg_loss=1.3844, train_err=0.0692, 32_h1=0.0730, 32_l2=0.0359, 64_h1=0.1529, 64_l2=0.0514\n",
      "[109] time=2.21, avg_loss=1.3609, train_err=0.0680, 32_h1=0.0738, 32_l2=0.0368, 64_h1=0.1561, 64_l2=0.0560\n",
      "[110] time=2.11, avg_loss=1.3619, train_err=0.0681, 32_h1=0.0726, 32_l2=0.0348, 64_h1=0.1568, 64_l2=0.0534\n",
      "[111] time=2.28, avg_loss=1.3627, train_err=0.0681, 32_h1=0.0718, 32_l2=0.0341, 64_h1=0.1543, 64_l2=0.0499\n",
      "[112] time=2.30, avg_loss=1.3496, train_err=0.0675, 32_h1=0.0746, 32_l2=0.0393, 64_h1=0.1497, 64_l2=0.0495\n",
      "[113] time=2.15, avg_loss=1.3514, train_err=0.0676, 32_h1=0.0723, 32_l2=0.0346, 64_h1=0.1538, 64_l2=0.0496\n",
      "[114] time=2.12, avg_loss=1.3346, train_err=0.0667, 32_h1=0.0729, 32_l2=0.0367, 64_h1=0.1574, 64_l2=0.0530\n",
      "[115] time=2.13, avg_loss=1.3462, train_err=0.0673, 32_h1=0.0726, 32_l2=0.0364, 64_h1=0.1555, 64_l2=0.0552\n",
      "[116] time=2.32, avg_loss=1.3455, train_err=0.0673, 32_h1=0.0751, 32_l2=0.0412, 64_h1=0.1621, 64_l2=0.0564\n",
      "[117] time=2.54, avg_loss=1.3486, train_err=0.0674, 32_h1=0.0711, 32_l2=0.0339, 64_h1=0.1550, 64_l2=0.0498\n",
      "[118] time=2.41, avg_loss=1.3635, train_err=0.0682, 32_h1=0.0728, 32_l2=0.0374, 64_h1=0.1577, 64_l2=0.0546\n",
      "[119] time=2.38, avg_loss=1.3476, train_err=0.0674, 32_h1=0.0718, 32_l2=0.0348, 64_h1=0.1555, 64_l2=0.0495\n",
      "[120] time=2.41, avg_loss=1.3483, train_err=0.0674, 32_h1=0.0724, 32_l2=0.0346, 64_h1=0.1573, 64_l2=0.0486\n",
      "[121] time=2.37, avg_loss=1.3461, train_err=0.0673, 32_h1=0.0726, 32_l2=0.0350, 64_h1=0.1543, 64_l2=0.0507\n",
      "[122] time=2.43, avg_loss=1.3646, train_err=0.0682, 32_h1=0.0755, 32_l2=0.0418, 64_h1=0.1527, 64_l2=0.0584\n",
      "[123] time=2.43, avg_loss=1.3287, train_err=0.0664, 32_h1=0.0724, 32_l2=0.0358, 64_h1=0.1565, 64_l2=0.0540\n",
      "[124] time=2.41, avg_loss=1.3564, train_err=0.0678, 32_h1=0.0725, 32_l2=0.0350, 64_h1=0.1557, 64_l2=0.0516\n",
      "[125] time=2.40, avg_loss=1.3167, train_err=0.0658, 32_h1=0.0715, 32_l2=0.0351, 64_h1=0.1560, 64_l2=0.0555\n",
      "[126] time=2.40, avg_loss=1.3156, train_err=0.0658, 32_h1=0.0714, 32_l2=0.0349, 64_h1=0.1561, 64_l2=0.0513\n",
      "[127] time=2.38, avg_loss=1.3473, train_err=0.0674, 32_h1=0.0712, 32_l2=0.0337, 64_h1=0.1588, 64_l2=0.0510\n",
      "[128] time=2.42, avg_loss=1.3237, train_err=0.0662, 32_h1=0.0727, 32_l2=0.0361, 64_h1=0.1594, 64_l2=0.0555\n",
      "[129] time=2.44, avg_loss=1.3340, train_err=0.0667, 32_h1=0.0751, 32_l2=0.0397, 64_h1=0.1587, 64_l2=0.0566\n",
      "[130] time=2.41, avg_loss=1.3253, train_err=0.0663, 32_h1=0.0732, 32_l2=0.0360, 64_h1=0.1533, 64_l2=0.0533\n",
      "[131] time=2.43, avg_loss=1.3193, train_err=0.0660, 32_h1=0.0715, 32_l2=0.0357, 64_h1=0.1574, 64_l2=0.0509\n",
      "[132] time=2.43, avg_loss=1.3146, train_err=0.0657, 32_h1=0.0703, 32_l2=0.0332, 64_h1=0.1545, 64_l2=0.0512\n",
      "[133] time=2.44, avg_loss=1.3195, train_err=0.0660, 32_h1=0.0773, 32_l2=0.0425, 64_h1=0.1657, 64_l2=0.0592\n",
      "[134] time=2.44, avg_loss=1.3319, train_err=0.0666, 32_h1=0.0719, 32_l2=0.0371, 64_h1=0.1590, 64_l2=0.0530\n",
      "[135] time=2.42, avg_loss=1.3209, train_err=0.0660, 32_h1=0.0744, 32_l2=0.0392, 64_h1=0.1505, 64_l2=0.0540\n",
      "[136] time=2.41, avg_loss=1.3062, train_err=0.0653, 32_h1=0.0719, 32_l2=0.0349, 64_h1=0.1553, 64_l2=0.0511\n",
      "[137] time=2.40, avg_loss=1.2936, train_err=0.0647, 32_h1=0.0698, 32_l2=0.0324, 64_h1=0.1526, 64_l2=0.0485\n",
      "[138] time=2.45, avg_loss=1.3046, train_err=0.0652, 32_h1=0.0707, 32_l2=0.0336, 64_h1=0.1542, 64_l2=0.0525\n",
      "[139] time=2.49, avg_loss=1.3107, train_err=0.0655, 32_h1=0.0705, 32_l2=0.0331, 64_h1=0.1508, 64_l2=0.0475\n",
      "[140] time=2.40, avg_loss=1.3168, train_err=0.0658, 32_h1=0.0726, 32_l2=0.0367, 64_h1=0.1593, 64_l2=0.0537\n",
      "[141] time=2.38, avg_loss=1.3179, train_err=0.0659, 32_h1=0.0714, 32_l2=0.0348, 64_h1=0.1624, 64_l2=0.0549\n",
      "[142] time=2.41, avg_loss=1.2923, train_err=0.0646, 32_h1=0.0709, 32_l2=0.0341, 64_h1=0.1562, 64_l2=0.0524\n",
      "[143] time=2.39, avg_loss=1.2871, train_err=0.0644, 32_h1=0.0699, 32_l2=0.0333, 64_h1=0.1549, 64_l2=0.0483\n",
      "[144] time=2.40, avg_loss=1.2978, train_err=0.0649, 32_h1=0.0719, 32_l2=0.0345, 64_h1=0.1537, 64_l2=0.0494\n",
      "[145] time=2.42, avg_loss=1.2937, train_err=0.0647, 32_h1=0.0708, 32_l2=0.0352, 64_h1=0.1586, 64_l2=0.0532\n",
      "[146] time=2.39, avg_loss=1.2811, train_err=0.0641, 32_h1=0.0711, 32_l2=0.0341, 64_h1=0.1531, 64_l2=0.0489\n",
      "[147] time=2.38, avg_loss=1.2840, train_err=0.0642, 32_h1=0.0717, 32_l2=0.0347, 64_h1=0.1576, 64_l2=0.0512\n",
      "[148] time=2.36, avg_loss=1.2906, train_err=0.0645, 32_h1=0.0709, 32_l2=0.0340, 64_h1=0.1530, 64_l2=0.0516\n",
      "[149] time=2.42, avg_loss=1.2851, train_err=0.0643, 32_h1=0.0712, 32_l2=0.0353, 64_h1=0.1547, 64_l2=0.0536\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.1\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 67649\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(16, 16, 3, 3))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f975765a9a0>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f983c59da90>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f983c59da90>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f9751424250>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.37, avg_loss=10.9468, train_err=0.5473, 32_h1=0.3280, 32_l2=0.2195, 64_h1=0.3741, 64_l2=0.2198\n",
      "[1] time=2.45, avg_loss=5.5712, train_err=0.2786, 32_h1=0.2387, 32_l2=0.1648, 64_h1=0.3047, 64_l2=0.1761\n",
      "[2] time=2.48, avg_loss=4.5012, train_err=0.2251, 32_h1=0.2135, 32_l2=0.1518, 64_h1=0.2827, 64_l2=0.1642\n",
      "[3] time=2.42, avg_loss=3.9064, train_err=0.1953, 32_h1=0.1811, 32_l2=0.1202, 64_h1=0.2336, 64_l2=0.1230\n",
      "[4] time=2.38, avg_loss=3.5594, train_err=0.1780, 32_h1=0.1729, 32_l2=0.1156, 64_h1=0.2209, 64_l2=0.1197\n",
      "[5] time=2.13, avg_loss=3.2548, train_err=0.1627, 32_h1=0.1717, 32_l2=0.1265, 64_h1=0.2437, 64_l2=0.1356\n",
      "[6] time=2.25, avg_loss=3.0246, train_err=0.1512, 32_h1=0.1472, 32_l2=0.0928, 64_h1=0.2185, 64_l2=0.1023\n",
      "[7] time=2.17, avg_loss=2.8532, train_err=0.1427, 32_h1=0.1317, 32_l2=0.0780, 64_h1=0.2058, 64_l2=0.0852\n",
      "[8] time=2.11, avg_loss=2.7207, train_err=0.1360, 32_h1=0.1283, 32_l2=0.0768, 64_h1=0.1966, 64_l2=0.0878\n",
      "[9] time=2.10, avg_loss=2.6258, train_err=0.1313, 32_h1=0.1221, 32_l2=0.0734, 64_h1=0.1960, 64_l2=0.0836\n",
      "[10] time=2.09, avg_loss=2.4443, train_err=0.1222, 32_h1=0.1188, 32_l2=0.0692, 64_h1=0.1948, 64_l2=0.0807\n",
      "[11] time=2.09, avg_loss=2.4162, train_err=0.1208, 32_h1=0.1146, 32_l2=0.0647, 64_h1=0.1923, 64_l2=0.0791\n",
      "[12] time=2.09, avg_loss=2.3030, train_err=0.1152, 32_h1=0.1184, 32_l2=0.0685, 64_h1=0.1819, 64_l2=0.0818\n",
      "[13] time=2.18, avg_loss=2.2598, train_err=0.1130, 32_h1=0.1258, 32_l2=0.0870, 64_h1=0.1902, 64_l2=0.0931\n",
      "[14] time=2.27, avg_loss=2.2614, train_err=0.1131, 32_h1=0.1229, 32_l2=0.0845, 64_h1=0.1835, 64_l2=0.0902\n",
      "[15] time=2.28, avg_loss=2.1603, train_err=0.1080, 32_h1=0.1125, 32_l2=0.0729, 64_h1=0.1859, 64_l2=0.0790\n",
      "[16] time=2.26, avg_loss=2.1472, train_err=0.1074, 32_h1=0.1060, 32_l2=0.0620, 64_h1=0.1880, 64_l2=0.0776\n",
      "[17] time=2.26, avg_loss=2.0273, train_err=0.1014, 32_h1=0.1056, 32_l2=0.0612, 64_h1=0.1849, 64_l2=0.0764\n",
      "[18] time=2.16, avg_loss=2.0328, train_err=0.1016, 32_h1=0.1006, 32_l2=0.0546, 64_h1=0.1810, 64_l2=0.0645\n",
      "[19] time=2.09, avg_loss=1.9966, train_err=0.0998, 32_h1=0.0998, 32_l2=0.0553, 64_h1=0.1746, 64_l2=0.0661\n",
      "[20] time=2.09, avg_loss=2.0593, train_err=0.1030, 32_h1=0.1051, 32_l2=0.0634, 64_h1=0.1677, 64_l2=0.0707\n",
      "[21] time=2.16, avg_loss=1.9648, train_err=0.0982, 32_h1=0.0960, 32_l2=0.0530, 64_h1=0.1769, 64_l2=0.0667\n",
      "[22] time=2.21, avg_loss=1.8921, train_err=0.0946, 32_h1=0.1000, 32_l2=0.0541, 64_h1=0.1814, 64_l2=0.0728\n",
      "[23] time=2.17, avg_loss=1.9338, train_err=0.0967, 32_h1=0.0936, 32_l2=0.0501, 64_h1=0.1693, 64_l2=0.0650\n",
      "[24] time=2.16, avg_loss=1.9032, train_err=0.0952, 32_h1=0.0959, 32_l2=0.0546, 64_h1=0.1672, 64_l2=0.0632\n",
      "[25] time=2.23, avg_loss=1.8512, train_err=0.0926, 32_h1=0.0940, 32_l2=0.0507, 64_h1=0.1698, 64_l2=0.0600\n",
      "[26] time=2.15, avg_loss=1.8201, train_err=0.0910, 32_h1=0.0939, 32_l2=0.0503, 64_h1=0.1693, 64_l2=0.0620\n",
      "[27] time=2.20, avg_loss=1.8244, train_err=0.0912, 32_h1=0.1039, 32_l2=0.0716, 64_h1=0.1701, 64_l2=0.0790\n",
      "[28] time=2.13, avg_loss=1.8233, train_err=0.0912, 32_h1=0.0967, 32_l2=0.0539, 64_h1=0.1662, 64_l2=0.0583\n",
      "[29] time=2.11, avg_loss=1.7471, train_err=0.0874, 32_h1=0.0899, 32_l2=0.0459, 64_h1=0.1764, 64_l2=0.0612\n",
      "[30] time=2.11, avg_loss=1.8087, train_err=0.0904, 32_h1=0.0945, 32_l2=0.0569, 64_h1=0.1667, 64_l2=0.0703\n",
      "[31] time=2.16, avg_loss=1.7294, train_err=0.0865, 32_h1=0.0927, 32_l2=0.0548, 64_h1=0.1712, 64_l2=0.0674\n",
      "[32] time=2.24, avg_loss=1.6992, train_err=0.0850, 32_h1=0.0866, 32_l2=0.0436, 64_h1=0.1650, 64_l2=0.0584\n",
      "[33] time=2.62, avg_loss=1.8170, train_err=0.0909, 32_h1=0.0996, 32_l2=0.0571, 64_h1=0.1695, 64_l2=0.0641\n",
      "[34] time=2.41, avg_loss=1.7229, train_err=0.0861, 32_h1=0.0937, 32_l2=0.0517, 64_h1=0.1764, 64_l2=0.0660\n",
      "[35] time=2.39, avg_loss=1.6932, train_err=0.0847, 32_h1=0.0855, 32_l2=0.0462, 64_h1=0.1675, 64_l2=0.0592\n",
      "[36] time=2.39, avg_loss=1.7401, train_err=0.0870, 32_h1=0.0864, 32_l2=0.0445, 64_h1=0.1664, 64_l2=0.0559\n",
      "[37] time=2.38, avg_loss=1.6712, train_err=0.0836, 32_h1=0.0860, 32_l2=0.0468, 64_h1=0.1636, 64_l2=0.0529\n",
      "[38] time=2.40, avg_loss=1.6476, train_err=0.0824, 32_h1=0.0910, 32_l2=0.0523, 64_h1=0.1663, 64_l2=0.0631\n",
      "[39] time=2.39, avg_loss=1.6623, train_err=0.0831, 32_h1=0.0863, 32_l2=0.0473, 64_h1=0.1645, 64_l2=0.0558\n",
      "[40] time=2.39, avg_loss=1.6381, train_err=0.0819, 32_h1=0.0860, 32_l2=0.0449, 64_h1=0.1763, 64_l2=0.0659\n",
      "[41] time=2.42, avg_loss=1.6523, train_err=0.0826, 32_h1=0.0830, 32_l2=0.0422, 64_h1=0.1674, 64_l2=0.0590\n",
      "[42] time=2.39, avg_loss=1.6089, train_err=0.0804, 32_h1=0.0804, 32_l2=0.0392, 64_h1=0.1662, 64_l2=0.0554\n",
      "[43] time=2.41, avg_loss=1.6405, train_err=0.0820, 32_h1=0.0835, 32_l2=0.0426, 64_h1=0.1637, 64_l2=0.0567\n",
      "[44] time=2.36, avg_loss=1.6230, train_err=0.0811, 32_h1=0.0871, 32_l2=0.0511, 64_h1=0.1665, 64_l2=0.0663\n",
      "[45] time=2.37, avg_loss=1.6353, train_err=0.0818, 32_h1=0.0828, 32_l2=0.0457, 64_h1=0.1586, 64_l2=0.0604\n",
      "[46] time=2.40, avg_loss=1.5778, train_err=0.0789, 32_h1=0.0837, 32_l2=0.0437, 64_h1=0.1629, 64_l2=0.0599\n",
      "[47] time=2.41, avg_loss=1.5843, train_err=0.0792, 32_h1=0.0894, 32_l2=0.0548, 64_h1=0.1688, 64_l2=0.0656\n",
      "[48] time=2.42, avg_loss=1.6047, train_err=0.0802, 32_h1=0.0899, 32_l2=0.0544, 64_h1=0.1671, 64_l2=0.0649\n",
      "[49] time=2.41, avg_loss=1.5687, train_err=0.0784, 32_h1=0.0789, 32_l2=0.0389, 64_h1=0.1596, 64_l2=0.0493\n",
      "[50] time=2.41, avg_loss=1.5476, train_err=0.0774, 32_h1=0.0832, 32_l2=0.0448, 64_h1=0.1608, 64_l2=0.0545\n",
      "[51] time=2.41, avg_loss=1.5499, train_err=0.0775, 32_h1=0.0822, 32_l2=0.0442, 64_h1=0.1638, 64_l2=0.0590\n",
      "[52] time=2.46, avg_loss=1.5585, train_err=0.0779, 32_h1=0.0803, 32_l2=0.0418, 64_h1=0.1602, 64_l2=0.0570\n",
      "[53] time=2.38, avg_loss=1.5390, train_err=0.0770, 32_h1=0.0836, 32_l2=0.0480, 64_h1=0.1575, 64_l2=0.0569\n",
      "[54] time=2.41, avg_loss=1.6063, train_err=0.0803, 32_h1=0.0823, 32_l2=0.0437, 64_h1=0.1552, 64_l2=0.0512\n",
      "[55] time=2.44, avg_loss=1.5530, train_err=0.0777, 32_h1=0.0811, 32_l2=0.0411, 64_h1=0.1655, 64_l2=0.0596\n",
      "[56] time=2.44, avg_loss=1.5366, train_err=0.0768, 32_h1=0.0845, 32_l2=0.0509, 64_h1=0.1618, 64_l2=0.0648\n",
      "[57] time=2.40, avg_loss=1.5232, train_err=0.0762, 32_h1=0.0788, 32_l2=0.0402, 64_h1=0.1637, 64_l2=0.0526\n",
      "[58] time=2.36, avg_loss=1.5744, train_err=0.0787, 32_h1=0.0784, 32_l2=0.0386, 64_h1=0.1544, 64_l2=0.0475\n",
      "[59] time=2.48, avg_loss=1.5107, train_err=0.0755, 32_h1=0.0778, 32_l2=0.0384, 64_h1=0.1580, 64_l2=0.0498\n",
      "[60] time=2.38, avg_loss=1.4879, train_err=0.0744, 32_h1=0.0769, 32_l2=0.0384, 64_h1=0.1623, 64_l2=0.0507\n",
      "[61] time=2.40, avg_loss=1.4972, train_err=0.0749, 32_h1=0.0765, 32_l2=0.0379, 64_h1=0.1579, 64_l2=0.0536\n",
      "[62] time=2.40, avg_loss=1.4911, train_err=0.0746, 32_h1=0.0797, 32_l2=0.0405, 64_h1=0.1568, 64_l2=0.0524\n",
      "[63] time=2.40, avg_loss=1.5282, train_err=0.0764, 32_h1=0.0779, 32_l2=0.0394, 64_h1=0.1649, 64_l2=0.0528\n",
      "[64] time=2.38, avg_loss=1.5274, train_err=0.0764, 32_h1=0.0818, 32_l2=0.0439, 64_h1=0.1644, 64_l2=0.0538\n",
      "[65] time=2.41, avg_loss=1.5274, train_err=0.0764, 32_h1=0.0770, 32_l2=0.0380, 64_h1=0.1629, 64_l2=0.0561\n",
      "[66] time=2.40, avg_loss=1.4635, train_err=0.0732, 32_h1=0.0763, 32_l2=0.0372, 64_h1=0.1639, 64_l2=0.0562\n",
      "[67] time=2.37, avg_loss=1.5759, train_err=0.0788, 32_h1=0.0833, 32_l2=0.0447, 64_h1=0.1656, 64_l2=0.0537\n",
      "[68] time=2.41, avg_loss=1.4955, train_err=0.0748, 32_h1=0.0762, 32_l2=0.0381, 64_h1=0.1573, 64_l2=0.0534\n",
      "[69] time=2.41, avg_loss=1.4587, train_err=0.0729, 32_h1=0.0770, 32_l2=0.0381, 64_h1=0.1634, 64_l2=0.0544\n",
      "[70] time=2.42, avg_loss=1.4867, train_err=0.0743, 32_h1=0.0779, 32_l2=0.0420, 64_h1=0.1593, 64_l2=0.0549\n",
      "[71] time=2.44, avg_loss=1.4795, train_err=0.0740, 32_h1=0.0859, 32_l2=0.0490, 64_h1=0.1673, 64_l2=0.0648\n",
      "[72] time=2.22, avg_loss=1.4735, train_err=0.0737, 32_h1=0.0761, 32_l2=0.0397, 64_h1=0.1604, 64_l2=0.0535\n",
      "[73] time=2.20, avg_loss=1.4870, train_err=0.0743, 32_h1=0.0763, 32_l2=0.0372, 64_h1=0.1561, 64_l2=0.0529\n",
      "[74] time=2.11, avg_loss=1.4471, train_err=0.0724, 32_h1=0.0768, 32_l2=0.0376, 64_h1=0.1671, 64_l2=0.0522\n",
      "[75] time=2.14, avg_loss=1.4525, train_err=0.0726, 32_h1=0.0776, 32_l2=0.0415, 64_h1=0.1549, 64_l2=0.0477\n",
      "[76] time=2.28, avg_loss=1.4698, train_err=0.0735, 32_h1=0.0793, 32_l2=0.0443, 64_h1=0.1585, 64_l2=0.0545\n",
      "[77] time=2.21, avg_loss=1.4519, train_err=0.0726, 32_h1=0.0773, 32_l2=0.0393, 64_h1=0.1605, 64_l2=0.0540\n",
      "[78] time=2.24, avg_loss=1.4544, train_err=0.0727, 32_h1=0.0778, 32_l2=0.0406, 64_h1=0.1582, 64_l2=0.0496\n",
      "[79] time=2.30, avg_loss=1.4387, train_err=0.0719, 32_h1=0.0754, 32_l2=0.0376, 64_h1=0.1579, 64_l2=0.0535\n",
      "[80] time=2.30, avg_loss=1.4438, train_err=0.0722, 32_h1=0.0736, 32_l2=0.0349, 64_h1=0.1583, 64_l2=0.0473\n",
      "[81] time=2.29, avg_loss=1.4260, train_err=0.0713, 32_h1=0.0766, 32_l2=0.0392, 64_h1=0.1612, 64_l2=0.0556\n",
      "[82] time=2.09, avg_loss=1.4423, train_err=0.0721, 32_h1=0.0763, 32_l2=0.0381, 64_h1=0.1548, 64_l2=0.0501\n",
      "[83] time=2.09, avg_loss=1.4534, train_err=0.0727, 32_h1=0.0749, 32_l2=0.0370, 64_h1=0.1567, 64_l2=0.0534\n",
      "[84] time=2.20, avg_loss=1.4541, train_err=0.0727, 32_h1=0.0764, 32_l2=0.0380, 64_h1=0.1575, 64_l2=0.0454\n",
      "[85] time=2.26, avg_loss=1.4395, train_err=0.0720, 32_h1=0.0749, 32_l2=0.0367, 64_h1=0.1579, 64_l2=0.0522\n",
      "[86] time=2.14, avg_loss=1.4126, train_err=0.0706, 32_h1=0.0738, 32_l2=0.0368, 64_h1=0.1584, 64_l2=0.0507\n",
      "[87] time=2.11, avg_loss=1.4632, train_err=0.0732, 32_h1=0.0792, 32_l2=0.0419, 64_h1=0.1635, 64_l2=0.0567\n",
      "[88] time=2.19, avg_loss=1.4298, train_err=0.0715, 32_h1=0.0748, 32_l2=0.0366, 64_h1=0.1540, 64_l2=0.0493\n",
      "[89] time=2.13, avg_loss=1.4169, train_err=0.0708, 32_h1=0.0804, 32_l2=0.0477, 64_h1=0.1617, 64_l2=0.0567\n",
      "[90] time=2.25, avg_loss=1.4303, train_err=0.0715, 32_h1=0.0733, 32_l2=0.0355, 64_h1=0.1600, 64_l2=0.0499\n",
      "[91] time=2.27, avg_loss=1.3958, train_err=0.0698, 32_h1=0.0737, 32_l2=0.0351, 64_h1=0.1568, 64_l2=0.0516\n",
      "[92] time=2.29, avg_loss=1.4281, train_err=0.0714, 32_h1=0.0739, 32_l2=0.0351, 64_h1=0.1549, 64_l2=0.0486\n",
      "[93] time=2.15, avg_loss=1.4296, train_err=0.0715, 32_h1=0.0789, 32_l2=0.0442, 64_h1=0.1669, 64_l2=0.0588\n",
      "[94] time=2.28, avg_loss=1.3991, train_err=0.0700, 32_h1=0.0753, 32_l2=0.0373, 64_h1=0.1701, 64_l2=0.0583\n",
      "[95] time=2.23, avg_loss=1.4050, train_err=0.0703, 32_h1=0.0751, 32_l2=0.0385, 64_h1=0.1582, 64_l2=0.0535\n",
      "[96] time=2.21, avg_loss=1.3782, train_err=0.0689, 32_h1=0.0742, 32_l2=0.0356, 64_h1=0.1612, 64_l2=0.0484\n",
      "[97] time=2.14, avg_loss=1.3914, train_err=0.0696, 32_h1=0.0759, 32_l2=0.0397, 64_h1=0.1620, 64_l2=0.0567\n",
      "[98] time=2.16, avg_loss=1.3944, train_err=0.0697, 32_h1=0.0750, 32_l2=0.0362, 64_h1=0.1628, 64_l2=0.0487\n",
      "[99] time=2.29, avg_loss=1.3873, train_err=0.0694, 32_h1=0.0772, 32_l2=0.0408, 64_h1=0.1665, 64_l2=0.0572\n",
      "[100] time=2.58, avg_loss=1.3973, train_err=0.0699, 32_h1=0.0764, 32_l2=0.0393, 64_h1=0.1592, 64_l2=0.0537\n",
      "[101] time=2.43, avg_loss=1.4069, train_err=0.0703, 32_h1=0.0752, 32_l2=0.0380, 64_h1=0.1625, 64_l2=0.0522\n",
      "[102] time=2.36, avg_loss=1.3723, train_err=0.0686, 32_h1=0.0742, 32_l2=0.0379, 64_h1=0.1652, 64_l2=0.0560\n",
      "[103] time=2.42, avg_loss=1.3592, train_err=0.0680, 32_h1=0.0723, 32_l2=0.0342, 64_h1=0.1617, 64_l2=0.0525\n",
      "[104] time=2.40, avg_loss=1.3621, train_err=0.0681, 32_h1=0.0741, 32_l2=0.0371, 64_h1=0.1568, 64_l2=0.0479\n",
      "[105] time=2.38, avg_loss=1.3778, train_err=0.0689, 32_h1=0.0758, 32_l2=0.0379, 64_h1=0.1556, 64_l2=0.0466\n",
      "[106] time=2.41, avg_loss=1.3605, train_err=0.0680, 32_h1=0.0720, 32_l2=0.0334, 64_h1=0.1560, 64_l2=0.0497\n",
      "[107] time=2.40, avg_loss=1.3450, train_err=0.0672, 32_h1=0.0782, 32_l2=0.0419, 64_h1=0.1633, 64_l2=0.0561\n",
      "[108] time=2.40, avg_loss=1.3717, train_err=0.0686, 32_h1=0.0747, 32_l2=0.0373, 64_h1=0.1549, 64_l2=0.0495\n",
      "[109] time=2.43, avg_loss=1.3708, train_err=0.0685, 32_h1=0.0753, 32_l2=0.0398, 64_h1=0.1566, 64_l2=0.0543\n",
      "[110] time=2.44, avg_loss=1.3720, train_err=0.0686, 32_h1=0.0726, 32_l2=0.0351, 64_h1=0.1555, 64_l2=0.0492\n",
      "[111] time=2.39, avg_loss=1.3482, train_err=0.0674, 32_h1=0.0731, 32_l2=0.0372, 64_h1=0.1574, 64_l2=0.0531\n",
      "[112] time=2.41, avg_loss=1.3508, train_err=0.0675, 32_h1=0.0741, 32_l2=0.0366, 64_h1=0.1615, 64_l2=0.0518\n",
      "[113] time=2.38, avg_loss=1.3400, train_err=0.0670, 32_h1=0.0735, 32_l2=0.0361, 64_h1=0.1579, 64_l2=0.0551\n",
      "[114] time=2.42, avg_loss=1.3325, train_err=0.0666, 32_h1=0.0714, 32_l2=0.0331, 64_h1=0.1559, 64_l2=0.0490\n",
      "[115] time=2.39, avg_loss=1.3573, train_err=0.0679, 32_h1=0.0748, 32_l2=0.0378, 64_h1=0.1612, 64_l2=0.0517\n",
      "[116] time=2.37, avg_loss=1.3754, train_err=0.0688, 32_h1=0.0769, 32_l2=0.0420, 64_h1=0.1611, 64_l2=0.0573\n",
      "[117] time=2.41, avg_loss=1.3484, train_err=0.0674, 32_h1=0.0751, 32_l2=0.0403, 64_h1=0.1587, 64_l2=0.0549\n",
      "[118] time=2.42, avg_loss=1.3347, train_err=0.0667, 32_h1=0.0735, 32_l2=0.0358, 64_h1=0.1584, 64_l2=0.0554\n",
      "[119] time=2.44, avg_loss=1.3338, train_err=0.0667, 32_h1=0.0732, 32_l2=0.0351, 64_h1=0.1606, 64_l2=0.0549\n",
      "[120] time=2.41, avg_loss=1.3281, train_err=0.0664, 32_h1=0.0716, 32_l2=0.0347, 64_h1=0.1587, 64_l2=0.0513\n",
      "[121] time=2.43, avg_loss=1.3437, train_err=0.0672, 32_h1=0.0731, 32_l2=0.0374, 64_h1=0.1591, 64_l2=0.0521\n",
      "[122] time=2.49, avg_loss=1.3321, train_err=0.0666, 32_h1=0.0754, 32_l2=0.0370, 64_h1=0.1578, 64_l2=0.0474\n",
      "[123] time=2.49, avg_loss=1.3375, train_err=0.0669, 32_h1=0.0729, 32_l2=0.0346, 64_h1=0.1592, 64_l2=0.0506\n",
      "[124] time=2.41, avg_loss=1.3163, train_err=0.0658, 32_h1=0.0726, 32_l2=0.0354, 64_h1=0.1600, 64_l2=0.0507\n",
      "[125] time=2.40, avg_loss=1.3319, train_err=0.0666, 32_h1=0.0726, 32_l2=0.0354, 64_h1=0.1614, 64_l2=0.0537\n",
      "[126] time=2.39, avg_loss=1.3647, train_err=0.0682, 32_h1=0.0763, 32_l2=0.0417, 64_h1=0.1534, 64_l2=0.0537\n",
      "[127] time=2.39, avg_loss=1.3110, train_err=0.0655, 32_h1=0.0717, 32_l2=0.0345, 64_h1=0.1562, 64_l2=0.0486\n",
      "[128] time=2.39, avg_loss=1.3164, train_err=0.0658, 32_h1=0.0772, 32_l2=0.0442, 64_h1=0.1589, 64_l2=0.0540\n",
      "[129] time=2.41, avg_loss=1.3049, train_err=0.0652, 32_h1=0.0715, 32_l2=0.0339, 64_h1=0.1607, 64_l2=0.0505\n",
      "[130] time=2.40, avg_loss=1.3275, train_err=0.0664, 32_h1=0.0755, 32_l2=0.0410, 64_h1=0.1568, 64_l2=0.0571\n",
      "[131] time=2.40, avg_loss=1.3302, train_err=0.0665, 32_h1=0.0727, 32_l2=0.0347, 64_h1=0.1548, 64_l2=0.0494\n",
      "[132] time=2.37, avg_loss=1.3190, train_err=0.0660, 32_h1=0.0720, 32_l2=0.0345, 64_h1=0.1559, 64_l2=0.0484\n",
      "[133] time=2.40, avg_loss=1.2879, train_err=0.0644, 32_h1=0.0719, 32_l2=0.0350, 64_h1=0.1560, 64_l2=0.0489\n",
      "[134] time=2.40, avg_loss=1.2888, train_err=0.0644, 32_h1=0.0702, 32_l2=0.0326, 64_h1=0.1536, 64_l2=0.0475\n",
      "[135] time=2.38, avg_loss=1.3107, train_err=0.0655, 32_h1=0.0719, 32_l2=0.0343, 64_h1=0.1617, 64_l2=0.0543\n",
      "[136] time=2.40, avg_loss=1.2946, train_err=0.0647, 32_h1=0.0723, 32_l2=0.0358, 64_h1=0.1601, 64_l2=0.0516\n",
      "[137] time=2.33, avg_loss=1.3010, train_err=0.0650, 32_h1=0.0714, 32_l2=0.0345, 64_h1=0.1560, 64_l2=0.0500\n",
      "[138] time=2.13, avg_loss=1.2963, train_err=0.0648, 32_h1=0.0706, 32_l2=0.0327, 64_h1=0.1525, 64_l2=0.0482\n",
      "[139] time=2.09, avg_loss=1.2869, train_err=0.0643, 32_h1=0.0735, 32_l2=0.0368, 64_h1=0.1586, 64_l2=0.0528\n",
      "[140] time=2.09, avg_loss=1.2952, train_err=0.0648, 32_h1=0.0720, 32_l2=0.0340, 64_h1=0.1622, 64_l2=0.0532\n",
      "[141] time=2.28, avg_loss=1.2910, train_err=0.0645, 32_h1=0.0762, 32_l2=0.0422, 64_h1=0.1616, 64_l2=0.0559\n",
      "[142] time=2.11, avg_loss=1.3319, train_err=0.0666, 32_h1=0.0714, 32_l2=0.0337, 64_h1=0.1575, 64_l2=0.0494\n",
      "[143] time=2.19, avg_loss=1.2872, train_err=0.0644, 32_h1=0.0737, 32_l2=0.0373, 64_h1=0.1624, 64_l2=0.0578\n",
      "[144] time=2.28, avg_loss=1.2870, train_err=0.0644, 32_h1=0.0704, 32_l2=0.0327, 64_h1=0.1590, 64_l2=0.0494\n",
      "[145] time=2.23, avg_loss=1.2933, train_err=0.0647, 32_h1=0.0709, 32_l2=0.0342, 64_h1=0.1595, 64_l2=0.0514\n",
      "[146] time=2.22, avg_loss=1.2742, train_err=0.0637, 32_h1=0.0721, 32_l2=0.0344, 64_h1=0.1580, 64_l2=0.0513\n",
      "[147] time=2.23, avg_loss=1.2755, train_err=0.0638, 32_h1=0.0723, 32_l2=0.0343, 64_h1=0.1554, 64_l2=0.0460\n",
      "[148] time=2.24, avg_loss=1.3133, train_err=0.0657, 32_h1=0.0742, 32_l2=0.0389, 64_h1=0.1598, 64_l2=0.0545\n",
      "[149] time=2.23, avg_loss=1.2846, train_err=0.0642, 32_h1=0.0729, 32_l2=0.0369, 64_h1=0.1549, 64_l2=0.0507\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.11\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 73425\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(17, 17, 3, 3))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(17, 17, 3, 3))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(17, 17, 3, 3))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(17, 17, 3, 3))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(17, 17, 3, 3))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(17, 17, 3, 3))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(17, 17, 3, 3))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(17, 17, 3, 3))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f98669d69d0>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f975765a850>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f975765a850>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f975765a9a0>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.19, avg_loss=11.4059, train_err=0.5703, 32_h1=0.3462, 32_l2=0.2426, 64_h1=0.3820, 64_l2=0.2421\n",
      "[1] time=2.18, avg_loss=5.1479, train_err=0.2574, 32_h1=0.2285, 32_l2=0.1583, 64_h1=0.2888, 64_l2=0.1626\n",
      "[2] time=2.26, avg_loss=4.1833, train_err=0.2092, 32_h1=0.2052, 32_l2=0.1461, 64_h1=0.2647, 64_l2=0.1514\n",
      "[3] time=2.19, avg_loss=3.7859, train_err=0.1893, 32_h1=0.1650, 32_l2=0.1106, 64_h1=0.2328, 64_l2=0.1166\n",
      "[4] time=2.23, avg_loss=3.2786, train_err=0.1639, 32_h1=0.1526, 32_l2=0.0970, 64_h1=0.2238, 64_l2=0.1098\n",
      "[5] time=2.11, avg_loss=2.9843, train_err=0.1492, 32_h1=0.1419, 32_l2=0.0864, 64_h1=0.2148, 64_l2=0.0904\n",
      "[6] time=2.26, avg_loss=2.8701, train_err=0.1435, 32_h1=0.1328, 32_l2=0.0804, 64_h1=0.2141, 64_l2=0.0941\n",
      "[7] time=2.17, avg_loss=2.7062, train_err=0.1353, 32_h1=0.1417, 32_l2=0.0912, 64_h1=0.2171, 64_l2=0.0991\n",
      "[8] time=2.12, avg_loss=2.5408, train_err=0.1270, 32_h1=0.1226, 32_l2=0.0705, 64_h1=0.2060, 64_l2=0.0793\n",
      "[9] time=2.09, avg_loss=2.4452, train_err=0.1223, 32_h1=0.1244, 32_l2=0.0748, 64_h1=0.1930, 64_l2=0.0775\n",
      "[10] time=2.11, avg_loss=2.4016, train_err=0.1201, 32_h1=0.1321, 32_l2=0.0923, 64_h1=0.2064, 64_l2=0.0957\n",
      "[11] time=2.10, avg_loss=2.3392, train_err=0.1170, 32_h1=0.1113, 32_l2=0.0636, 64_h1=0.1945, 64_l2=0.0786\n",
      "[12] time=2.09, avg_loss=2.1730, train_err=0.1086, 32_h1=0.1276, 32_l2=0.0836, 64_h1=0.2143, 64_l2=0.0917\n",
      "[13] time=2.12, avg_loss=2.1689, train_err=0.1084, 32_h1=0.1189, 32_l2=0.0735, 64_h1=0.1945, 64_l2=0.0867\n",
      "[14] time=2.10, avg_loss=2.0976, train_err=0.1049, 32_h1=0.1068, 32_l2=0.0640, 64_h1=0.1996, 64_l2=0.0796\n",
      "[15] time=2.11, avg_loss=2.0806, train_err=0.1040, 32_h1=0.1246, 32_l2=0.0838, 64_h1=0.1977, 64_l2=0.0988\n",
      "[16] time=2.47, avg_loss=2.0563, train_err=0.1028, 32_h1=0.0996, 32_l2=0.0548, 64_h1=0.1882, 64_l2=0.0703\n",
      "[17] time=2.52, avg_loss=2.0007, train_err=0.1000, 32_h1=0.1065, 32_l2=0.0603, 64_h1=0.1856, 64_l2=0.0760\n",
      "[18] time=2.43, avg_loss=1.9446, train_err=0.0972, 32_h1=0.0962, 32_l2=0.0543, 64_h1=0.1834, 64_l2=0.0675\n",
      "[19] time=2.43, avg_loss=1.9258, train_err=0.0963, 32_h1=0.1018, 32_l2=0.0626, 64_h1=0.1771, 64_l2=0.0710\n",
      "[20] time=2.43, avg_loss=1.9706, train_err=0.0985, 32_h1=0.0981, 32_l2=0.0541, 64_h1=0.1694, 64_l2=0.0621\n",
      "[21] time=2.47, avg_loss=1.9165, train_err=0.0958, 32_h1=0.0914, 32_l2=0.0467, 64_h1=0.1826, 64_l2=0.0633\n",
      "[22] time=2.40, avg_loss=1.8241, train_err=0.0912, 32_h1=0.0958, 32_l2=0.0542, 64_h1=0.1800, 64_l2=0.0723\n",
      "[23] time=2.40, avg_loss=1.8496, train_err=0.0925, 32_h1=0.1041, 32_l2=0.0664, 64_h1=0.1781, 64_l2=0.0765\n",
      "[24] time=2.42, avg_loss=1.8345, train_err=0.0917, 32_h1=0.0927, 32_l2=0.0499, 64_h1=0.1882, 64_l2=0.0724\n",
      "[25] time=2.39, avg_loss=1.7734, train_err=0.0887, 32_h1=0.0941, 32_l2=0.0520, 64_h1=0.1763, 64_l2=0.0708\n",
      "[26] time=2.38, avg_loss=1.7965, train_err=0.0898, 32_h1=0.0905, 32_l2=0.0492, 64_h1=0.1751, 64_l2=0.0654\n",
      "[27] time=2.38, avg_loss=1.7757, train_err=0.0888, 32_h1=0.0960, 32_l2=0.0557, 64_h1=0.1837, 64_l2=0.0722\n",
      "[28] time=2.38, avg_loss=1.7704, train_err=0.0885, 32_h1=0.0921, 32_l2=0.0520, 64_h1=0.1755, 64_l2=0.0639\n",
      "[29] time=2.41, avg_loss=1.7361, train_err=0.0868, 32_h1=0.0914, 32_l2=0.0518, 64_h1=0.1774, 64_l2=0.0682\n",
      "[30] time=2.37, avg_loss=1.7091, train_err=0.0855, 32_h1=0.0861, 32_l2=0.0460, 64_h1=0.1710, 64_l2=0.0637\n",
      "[31] time=2.41, avg_loss=1.7658, train_err=0.0883, 32_h1=0.0871, 32_l2=0.0476, 64_h1=0.1698, 64_l2=0.0602\n",
      "[32] time=2.41, avg_loss=1.7776, train_err=0.0889, 32_h1=0.0835, 32_l2=0.0419, 64_h1=0.1721, 64_l2=0.0565\n",
      "[33] time=2.40, avg_loss=1.6802, train_err=0.0840, 32_h1=0.0846, 32_l2=0.0436, 64_h1=0.1750, 64_l2=0.0566\n",
      "[34] time=2.37, avg_loss=1.6560, train_err=0.0828, 32_h1=0.0856, 32_l2=0.0441, 64_h1=0.1748, 64_l2=0.0627\n",
      "[35] time=2.39, avg_loss=1.6785, train_err=0.0839, 32_h1=0.0840, 32_l2=0.0429, 64_h1=0.1755, 64_l2=0.0563\n",
      "[36] time=2.44, avg_loss=1.6617, train_err=0.0831, 32_h1=0.0854, 32_l2=0.0452, 64_h1=0.1731, 64_l2=0.0630\n",
      "[37] time=2.39, avg_loss=1.6504, train_err=0.0825, 32_h1=0.0847, 32_l2=0.0461, 64_h1=0.1713, 64_l2=0.0624\n",
      "[38] time=2.47, avg_loss=1.6498, train_err=0.0825, 32_h1=0.0900, 32_l2=0.0522, 64_h1=0.1726, 64_l2=0.0624\n",
      "[39] time=2.50, avg_loss=1.6074, train_err=0.0804, 32_h1=0.0811, 32_l2=0.0424, 64_h1=0.1645, 64_l2=0.0587\n",
      "[40] time=2.43, avg_loss=1.6547, train_err=0.0827, 32_h1=0.0983, 32_l2=0.0617, 64_h1=0.1724, 64_l2=0.0679\n",
      "[41] time=2.41, avg_loss=1.7239, train_err=0.0862, 32_h1=0.0814, 32_l2=0.0413, 64_h1=0.1640, 64_l2=0.0518\n",
      "[42] time=2.44, avg_loss=1.6200, train_err=0.0810, 32_h1=0.0837, 32_l2=0.0450, 64_h1=0.1621, 64_l2=0.0542\n",
      "[43] time=2.40, avg_loss=1.6011, train_err=0.0801, 32_h1=0.0837, 32_l2=0.0436, 64_h1=0.1683, 64_l2=0.0548\n",
      "[44] time=2.46, avg_loss=1.5968, train_err=0.0798, 32_h1=0.0823, 32_l2=0.0426, 64_h1=0.1703, 64_l2=0.0619\n",
      "[45] time=2.41, avg_loss=1.6142, train_err=0.0807, 32_h1=0.0837, 32_l2=0.0447, 64_h1=0.1663, 64_l2=0.0587\n",
      "[46] time=2.40, avg_loss=1.5740, train_err=0.0787, 32_h1=0.0839, 32_l2=0.0482, 64_h1=0.1676, 64_l2=0.0662\n",
      "[47] time=2.40, avg_loss=1.5922, train_err=0.0796, 32_h1=0.0803, 32_l2=0.0404, 64_h1=0.1673, 64_l2=0.0551\n",
      "[48] time=2.39, avg_loss=1.5699, train_err=0.0785, 32_h1=0.0894, 32_l2=0.0521, 64_h1=0.1723, 64_l2=0.0676\n",
      "[49] time=2.41, avg_loss=1.5969, train_err=0.0798, 32_h1=0.0824, 32_l2=0.0428, 64_h1=0.1681, 64_l2=0.0582\n",
      "[50] time=2.42, avg_loss=1.6393, train_err=0.0820, 32_h1=0.0844, 32_l2=0.0450, 64_h1=0.1718, 64_l2=0.0660\n",
      "[51] time=2.52, avg_loss=1.5690, train_err=0.0785, 32_h1=0.0791, 32_l2=0.0405, 64_h1=0.1664, 64_l2=0.0543\n",
      "[52] time=2.37, avg_loss=1.5593, train_err=0.0780, 32_h1=0.0814, 32_l2=0.0446, 64_h1=0.1666, 64_l2=0.0602\n",
      "[53] time=2.41, avg_loss=1.5343, train_err=0.0767, 32_h1=0.0785, 32_l2=0.0395, 64_h1=0.1743, 64_l2=0.0592\n",
      "[54] time=2.26, avg_loss=1.5586, train_err=0.0779, 32_h1=0.0854, 32_l2=0.0485, 64_h1=0.1739, 64_l2=0.0640\n",
      "[55] time=2.23, avg_loss=1.5866, train_err=0.0793, 32_h1=0.0798, 32_l2=0.0405, 64_h1=0.1669, 64_l2=0.0559\n",
      "[56] time=2.09, avg_loss=1.5470, train_err=0.0774, 32_h1=0.0791, 32_l2=0.0403, 64_h1=0.1687, 64_l2=0.0571\n",
      "[57] time=2.09, avg_loss=1.5298, train_err=0.0765, 32_h1=0.0789, 32_l2=0.0395, 64_h1=0.1609, 64_l2=0.0518\n",
      "[58] time=2.27, avg_loss=1.5129, train_err=0.0756, 32_h1=0.0804, 32_l2=0.0424, 64_h1=0.1647, 64_l2=0.0557\n",
      "[59] time=2.14, avg_loss=1.5376, train_err=0.0769, 32_h1=0.0773, 32_l2=0.0389, 64_h1=0.1666, 64_l2=0.0560\n",
      "[60] time=2.09, avg_loss=1.5178, train_err=0.0759, 32_h1=0.0814, 32_l2=0.0464, 64_h1=0.1727, 64_l2=0.0622\n",
      "[61] time=2.10, avg_loss=1.5062, train_err=0.0753, 32_h1=0.0769, 32_l2=0.0382, 64_h1=0.1662, 64_l2=0.0577\n",
      "[62] time=2.11, avg_loss=1.5190, train_err=0.0759, 32_h1=0.0777, 32_l2=0.0402, 64_h1=0.1653, 64_l2=0.0558\n",
      "[63] time=2.19, avg_loss=1.5698, train_err=0.0785, 32_h1=0.0947, 32_l2=0.0573, 64_h1=0.1677, 64_l2=0.0649\n",
      "[64] time=2.32, avg_loss=1.5294, train_err=0.0765, 32_h1=0.0765, 32_l2=0.0374, 64_h1=0.1654, 64_l2=0.0571\n",
      "[65] time=2.19, avg_loss=1.4841, train_err=0.0742, 32_h1=0.0792, 32_l2=0.0414, 64_h1=0.1645, 64_l2=0.0501\n",
      "[66] time=2.32, avg_loss=1.4887, train_err=0.0744, 32_h1=0.0774, 32_l2=0.0397, 64_h1=0.1658, 64_l2=0.0547\n",
      "[67] time=2.25, avg_loss=1.5271, train_err=0.0764, 32_h1=0.0834, 32_l2=0.0475, 64_h1=0.1621, 64_l2=0.0595\n",
      "[68] time=2.26, avg_loss=1.4775, train_err=0.0739, 32_h1=0.0762, 32_l2=0.0371, 64_h1=0.1680, 64_l2=0.0584\n",
      "[69] time=2.16, avg_loss=1.5134, train_err=0.0757, 32_h1=0.0791, 32_l2=0.0406, 64_h1=0.1618, 64_l2=0.0562\n",
      "[70] time=2.16, avg_loss=1.5011, train_err=0.0751, 32_h1=0.0775, 32_l2=0.0383, 64_h1=0.1553, 64_l2=0.0544\n",
      "[71] time=2.09, avg_loss=1.4827, train_err=0.0741, 32_h1=0.0785, 32_l2=0.0436, 64_h1=0.1587, 64_l2=0.0527\n",
      "[72] time=2.09, avg_loss=1.4988, train_err=0.0749, 32_h1=0.0779, 32_l2=0.0404, 64_h1=0.1628, 64_l2=0.0582\n",
      "[73] time=2.10, avg_loss=1.4706, train_err=0.0735, 32_h1=0.0819, 32_l2=0.0449, 64_h1=0.1694, 64_l2=0.0618\n",
      "[74] time=2.12, avg_loss=1.4426, train_err=0.0721, 32_h1=0.0768, 32_l2=0.0384, 64_h1=0.1598, 64_l2=0.0542\n",
      "[75] time=2.16, avg_loss=1.4422, train_err=0.0721, 32_h1=0.0772, 32_l2=0.0384, 64_h1=0.1579, 64_l2=0.0553\n",
      "[76] time=2.09, avg_loss=1.4650, train_err=0.0732, 32_h1=0.0798, 32_l2=0.0439, 64_h1=0.1612, 64_l2=0.0615\n",
      "[77] time=2.10, avg_loss=1.4737, train_err=0.0737, 32_h1=0.0774, 32_l2=0.0387, 64_h1=0.1749, 64_l2=0.0599\n",
      "[78] time=2.28, avg_loss=1.4176, train_err=0.0709, 32_h1=0.0756, 32_l2=0.0380, 64_h1=0.1624, 64_l2=0.0544\n",
      "[79] time=2.18, avg_loss=1.4537, train_err=0.0727, 32_h1=0.0791, 32_l2=0.0409, 64_h1=0.1663, 64_l2=0.0623\n",
      "[80] time=2.09, avg_loss=1.4549, train_err=0.0727, 32_h1=0.0744, 32_l2=0.0360, 64_h1=0.1737, 64_l2=0.0574\n",
      "[81] time=2.09, avg_loss=1.4433, train_err=0.0722, 32_h1=0.0772, 32_l2=0.0377, 64_h1=0.1730, 64_l2=0.0604\n",
      "[82] time=2.27, avg_loss=1.4648, train_err=0.0732, 32_h1=0.0756, 32_l2=0.0367, 64_h1=0.1616, 64_l2=0.0498\n",
      "[83] time=2.43, avg_loss=1.4500, train_err=0.0725, 32_h1=0.0777, 32_l2=0.0417, 64_h1=0.1631, 64_l2=0.0562\n",
      "[84] time=2.39, avg_loss=1.4329, train_err=0.0716, 32_h1=0.0736, 32_l2=0.0351, 64_h1=0.1608, 64_l2=0.0511\n",
      "[85] time=2.38, avg_loss=1.4143, train_err=0.0707, 32_h1=0.0745, 32_l2=0.0365, 64_h1=0.1629, 64_l2=0.0522\n",
      "[86] time=2.40, avg_loss=1.4522, train_err=0.0726, 32_h1=0.0802, 32_l2=0.0445, 64_h1=0.1578, 64_l2=0.0550\n",
      "[87] time=2.42, avg_loss=1.4402, train_err=0.0720, 32_h1=0.0768, 32_l2=0.0399, 64_h1=0.1632, 64_l2=0.0585\n",
      "[88] time=2.42, avg_loss=1.4013, train_err=0.0701, 32_h1=0.0734, 32_l2=0.0364, 64_h1=0.1628, 64_l2=0.0545\n",
      "[89] time=2.48, avg_loss=1.4197, train_err=0.0710, 32_h1=0.0748, 32_l2=0.0363, 64_h1=0.1672, 64_l2=0.0601\n",
      "[90] time=2.44, avg_loss=1.4470, train_err=0.0724, 32_h1=0.0766, 32_l2=0.0396, 64_h1=0.1618, 64_l2=0.0534\n",
      "[91] time=2.37, avg_loss=1.3944, train_err=0.0697, 32_h1=0.0737, 32_l2=0.0367, 64_h1=0.1670, 64_l2=0.0558\n",
      "[92] time=2.46, avg_loss=1.4230, train_err=0.0711, 32_h1=0.0764, 32_l2=0.0396, 64_h1=0.1591, 64_l2=0.0573\n",
      "[93] time=2.38, avg_loss=1.4342, train_err=0.0717, 32_h1=0.0737, 32_l2=0.0359, 64_h1=0.1643, 64_l2=0.0535\n",
      "[94] time=2.37, avg_loss=1.4023, train_err=0.0701, 32_h1=0.0754, 32_l2=0.0389, 64_h1=0.1637, 64_l2=0.0555\n",
      "[95] time=2.40, avg_loss=1.3994, train_err=0.0700, 32_h1=0.0784, 32_l2=0.0426, 64_h1=0.1641, 64_l2=0.0552\n",
      "[96] time=2.40, avg_loss=1.4138, train_err=0.0707, 32_h1=0.0740, 32_l2=0.0361, 64_h1=0.1696, 64_l2=0.0593\n",
      "[97] time=2.41, avg_loss=1.3874, train_err=0.0694, 32_h1=0.0728, 32_l2=0.0351, 64_h1=0.1657, 64_l2=0.0538\n",
      "[98] time=2.38, avg_loss=1.3944, train_err=0.0697, 32_h1=0.0744, 32_l2=0.0367, 64_h1=0.1650, 64_l2=0.0520\n",
      "[99] time=2.39, avg_loss=1.3858, train_err=0.0693, 32_h1=0.0746, 32_l2=0.0378, 64_h1=0.1644, 64_l2=0.0528\n",
      "[100] time=2.40, avg_loss=1.3904, train_err=0.0695, 32_h1=0.0739, 32_l2=0.0358, 64_h1=0.1675, 64_l2=0.0582\n",
      "[101] time=2.37, avg_loss=1.3771, train_err=0.0689, 32_h1=0.0818, 32_l2=0.0461, 64_h1=0.1653, 64_l2=0.0662\n",
      "[102] time=2.35, avg_loss=1.4141, train_err=0.0707, 32_h1=0.0758, 32_l2=0.0421, 64_h1=0.1676, 64_l2=0.0588\n",
      "[103] time=2.38, avg_loss=1.4128, train_err=0.0706, 32_h1=0.0752, 32_l2=0.0367, 64_h1=0.1568, 64_l2=0.0515\n",
      "[104] time=2.38, avg_loss=1.4067, train_err=0.0703, 32_h1=0.0733, 32_l2=0.0361, 64_h1=0.1598, 64_l2=0.0500\n",
      "[105] time=2.51, avg_loss=1.3766, train_err=0.0688, 32_h1=0.0744, 32_l2=0.0378, 64_h1=0.1643, 64_l2=0.0534\n",
      "[106] time=2.42, avg_loss=1.3779, train_err=0.0689, 32_h1=0.0719, 32_l2=0.0342, 64_h1=0.1660, 64_l2=0.0550\n",
      "[107] time=2.39, avg_loss=1.3678, train_err=0.0684, 32_h1=0.0726, 32_l2=0.0347, 64_h1=0.1618, 64_l2=0.0551\n",
      "[108] time=2.42, avg_loss=1.3488, train_err=0.0674, 32_h1=0.0751, 32_l2=0.0396, 64_h1=0.1664, 64_l2=0.0591\n",
      "[109] time=2.40, avg_loss=1.3645, train_err=0.0682, 32_h1=0.0766, 32_l2=0.0425, 64_h1=0.1726, 64_l2=0.0607\n",
      "[110] time=2.43, avg_loss=1.3753, train_err=0.0688, 32_h1=0.0777, 32_l2=0.0430, 64_h1=0.1689, 64_l2=0.0626\n",
      "[111] time=2.39, avg_loss=1.4000, train_err=0.0700, 32_h1=0.0756, 32_l2=0.0399, 64_h1=0.1616, 64_l2=0.0549\n",
      "[112] time=2.46, avg_loss=1.3804, train_err=0.0690, 32_h1=0.0749, 32_l2=0.0385, 64_h1=0.1581, 64_l2=0.0538\n",
      "[113] time=2.38, avg_loss=1.3707, train_err=0.0685, 32_h1=0.0756, 32_l2=0.0372, 64_h1=0.1631, 64_l2=0.0554\n",
      "[114] time=2.43, avg_loss=1.3674, train_err=0.0684, 32_h1=0.0760, 32_l2=0.0402, 64_h1=0.1665, 64_l2=0.0565\n",
      "[115] time=2.40, avg_loss=1.3824, train_err=0.0691, 32_h1=0.0716, 32_l2=0.0341, 64_h1=0.1628, 64_l2=0.0507\n",
      "[116] time=2.42, avg_loss=1.3659, train_err=0.0683, 32_h1=0.0739, 32_l2=0.0361, 64_h1=0.1652, 64_l2=0.0538\n",
      "[117] time=2.38, avg_loss=1.3692, train_err=0.0685, 32_h1=0.0750, 32_l2=0.0386, 64_h1=0.1576, 64_l2=0.0498\n",
      "[118] time=2.42, avg_loss=1.3466, train_err=0.0673, 32_h1=0.0738, 32_l2=0.0362, 64_h1=0.1613, 64_l2=0.0528\n",
      "[119] time=2.37, avg_loss=1.3381, train_err=0.0669, 32_h1=0.0720, 32_l2=0.0352, 64_h1=0.1613, 64_l2=0.0518\n",
      "[120] time=2.42, avg_loss=1.3349, train_err=0.0667, 32_h1=0.0715, 32_l2=0.0346, 64_h1=0.1642, 64_l2=0.0534\n",
      "[121] time=2.37, avg_loss=1.3432, train_err=0.0672, 32_h1=0.0727, 32_l2=0.0351, 64_h1=0.1592, 64_l2=0.0489\n",
      "[122] time=2.29, avg_loss=1.3481, train_err=0.0674, 32_h1=0.0723, 32_l2=0.0355, 64_h1=0.1660, 64_l2=0.0542\n",
      "[123] time=2.27, avg_loss=1.3330, train_err=0.0667, 32_h1=0.0721, 32_l2=0.0350, 64_h1=0.1640, 64_l2=0.0561\n",
      "[124] time=2.28, avg_loss=1.3342, train_err=0.0667, 32_h1=0.0718, 32_l2=0.0349, 64_h1=0.1620, 64_l2=0.0541\n",
      "[125] time=2.13, avg_loss=1.3355, train_err=0.0668, 32_h1=0.0725, 32_l2=0.0353, 64_h1=0.1633, 64_l2=0.0528\n",
      "[126] time=2.09, avg_loss=1.3751, train_err=0.0688, 32_h1=0.0729, 32_l2=0.0352, 64_h1=0.1535, 64_l2=0.0513\n",
      "[127] time=2.10, avg_loss=1.3521, train_err=0.0676, 32_h1=0.0726, 32_l2=0.0349, 64_h1=0.1601, 64_l2=0.0512\n",
      "[128] time=2.28, avg_loss=1.3182, train_err=0.0659, 32_h1=0.0734, 32_l2=0.0366, 64_h1=0.1634, 64_l2=0.0544\n",
      "[129] time=2.21, avg_loss=1.3325, train_err=0.0666, 32_h1=0.0720, 32_l2=0.0345, 64_h1=0.1636, 64_l2=0.0529\n",
      "[130] time=2.13, avg_loss=1.3223, train_err=0.0661, 32_h1=0.0725, 32_l2=0.0362, 64_h1=0.1606, 64_l2=0.0528\n",
      "[131] time=2.13, avg_loss=1.3129, train_err=0.0656, 32_h1=0.0717, 32_l2=0.0352, 64_h1=0.1695, 64_l2=0.0557\n",
      "[132] time=2.19, avg_loss=1.3301, train_err=0.0665, 32_h1=0.0724, 32_l2=0.0349, 64_h1=0.1583, 64_l2=0.0479\n",
      "[133] time=2.23, avg_loss=1.3158, train_err=0.0658, 32_h1=0.0722, 32_l2=0.0358, 64_h1=0.1604, 64_l2=0.0572\n",
      "[134] time=2.31, avg_loss=1.3194, train_err=0.0660, 32_h1=0.0732, 32_l2=0.0367, 64_h1=0.1657, 64_l2=0.0593\n",
      "[135] time=2.25, avg_loss=1.3187, train_err=0.0659, 32_h1=0.0768, 32_l2=0.0436, 64_h1=0.1711, 64_l2=0.0601\n",
      "[136] time=2.23, avg_loss=1.3298, train_err=0.0665, 32_h1=0.0720, 32_l2=0.0350, 64_h1=0.1557, 64_l2=0.0493\n",
      "[137] time=2.14, avg_loss=1.3381, train_err=0.0669, 32_h1=0.0733, 32_l2=0.0361, 64_h1=0.1673, 64_l2=0.0517\n",
      "[138] time=2.21, avg_loss=1.2984, train_err=0.0649, 32_h1=0.0710, 32_l2=0.0341, 64_h1=0.1620, 64_l2=0.0489\n",
      "[139] time=2.19, avg_loss=1.2975, train_err=0.0649, 32_h1=0.0715, 32_l2=0.0342, 64_h1=0.1608, 64_l2=0.0497\n",
      "[140] time=2.29, avg_loss=1.3241, train_err=0.0662, 32_h1=0.0739, 32_l2=0.0374, 64_h1=0.1725, 64_l2=0.0585\n",
      "[141] time=2.23, avg_loss=1.3160, train_err=0.0658, 32_h1=0.0706, 32_l2=0.0328, 64_h1=0.1620, 64_l2=0.0483\n",
      "[142] time=2.27, avg_loss=1.3029, train_err=0.0651, 32_h1=0.0740, 32_l2=0.0372, 64_h1=0.1625, 64_l2=0.0528\n",
      "[143] time=2.26, avg_loss=1.3190, train_err=0.0659, 32_h1=0.0722, 32_l2=0.0343, 64_h1=0.1594, 64_l2=0.0507\n",
      "[144] time=2.26, avg_loss=1.3193, train_err=0.0660, 32_h1=0.0713, 32_l2=0.0336, 64_h1=0.1635, 64_l2=0.0528\n",
      "[145] time=2.10, avg_loss=1.2838, train_err=0.0642, 32_h1=0.0697, 32_l2=0.0326, 64_h1=0.1636, 64_l2=0.0511\n",
      "[146] time=2.13, avg_loss=1.2890, train_err=0.0645, 32_h1=0.0743, 32_l2=0.0375, 64_h1=0.1604, 64_l2=0.0527\n",
      "[147] time=2.09, avg_loss=1.2984, train_err=0.0649, 32_h1=0.0708, 32_l2=0.0335, 64_h1=0.1648, 64_l2=0.0526\n",
      "[148] time=2.15, avg_loss=1.2815, train_err=0.0641, 32_h1=0.0705, 32_l2=0.0328, 64_h1=0.1633, 64_l2=0.0524\n",
      "[149] time=2.24, avg_loss=1.2999, train_err=0.0650, 32_h1=0.0712, 32_l2=0.0339, 64_h1=0.1654, 64_l2=0.0535\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.15\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 126465\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(19, 19, 4, 4))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(19, 19, 4, 4))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(19, 19, 4, 4))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(19, 19, 4, 4))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(19, 19, 4, 4))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(19, 19, 4, 4))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(19, 19, 4, 4))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(19, 19, 4, 4))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f9751424550>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f986ea1cdf0>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f986ea1cdf0>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f98669d69d0>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.42, avg_loss=10.2378, train_err=0.5119, 32_h1=0.2942, 32_l2=0.2003, 64_h1=0.3418, 64_l2=0.2064\n",
      "[1] time=2.45, avg_loss=4.8902, train_err=0.2445, 32_h1=0.2341, 32_l2=0.1674, 64_h1=0.2929, 64_l2=0.1782\n",
      "[2] time=2.40, avg_loss=4.0387, train_err=0.2019, 32_h1=0.2217, 32_l2=0.1555, 64_h1=0.2674, 64_l2=0.1520\n",
      "[3] time=2.39, avg_loss=3.4723, train_err=0.1736, 32_h1=0.1565, 32_l2=0.0979, 64_h1=0.2266, 64_l2=0.1064\n",
      "[4] time=2.47, avg_loss=3.0184, train_err=0.1509, 32_h1=0.1478, 32_l2=0.0936, 64_h1=0.2156, 64_l2=0.1008\n",
      "[5] time=2.40, avg_loss=2.7971, train_err=0.1399, 32_h1=0.1416, 32_l2=0.0979, 64_h1=0.2133, 64_l2=0.1065\n",
      "[6] time=2.44, avg_loss=2.6490, train_err=0.1324, 32_h1=0.1440, 32_l2=0.0966, 64_h1=0.2041, 64_l2=0.0963\n",
      "[7] time=2.44, avg_loss=2.4328, train_err=0.1216, 32_h1=0.1223, 32_l2=0.0708, 64_h1=0.1966, 64_l2=0.0835\n",
      "[8] time=2.43, avg_loss=2.4785, train_err=0.1239, 32_h1=0.1325, 32_l2=0.0827, 64_h1=0.2049, 64_l2=0.0965\n",
      "[9] time=2.43, avg_loss=2.3318, train_err=0.1166, 32_h1=0.1319, 32_l2=0.0858, 64_h1=0.2005, 64_l2=0.0938\n",
      "[10] time=2.37, avg_loss=2.1810, train_err=0.1091, 32_h1=0.1067, 32_l2=0.0621, 64_h1=0.1921, 64_l2=0.0763\n",
      "[11] time=2.40, avg_loss=2.1524, train_err=0.1076, 32_h1=0.1023, 32_l2=0.0559, 64_h1=0.1813, 64_l2=0.0598\n",
      "[12] time=2.44, avg_loss=2.0606, train_err=0.1030, 32_h1=0.1071, 32_l2=0.0651, 64_h1=0.1946, 64_l2=0.0851\n",
      "[13] time=2.41, avg_loss=2.0418, train_err=0.1021, 32_h1=0.0985, 32_l2=0.0517, 64_h1=0.1772, 64_l2=0.0660\n",
      "[14] time=2.46, avg_loss=1.9656, train_err=0.0983, 32_h1=0.1042, 32_l2=0.0609, 64_h1=0.1751, 64_l2=0.0636\n",
      "[15] time=2.39, avg_loss=2.0038, train_err=0.1002, 32_h1=0.1065, 32_l2=0.0671, 64_h1=0.1833, 64_l2=0.0805\n",
      "[16] time=2.41, avg_loss=1.9372, train_err=0.0969, 32_h1=0.0938, 32_l2=0.0497, 64_h1=0.1675, 64_l2=0.0636\n",
      "[17] time=2.43, avg_loss=1.8393, train_err=0.0920, 32_h1=0.0930, 32_l2=0.0501, 64_h1=0.1704, 64_l2=0.0609\n",
      "[18] time=2.42, avg_loss=1.9005, train_err=0.0950, 32_h1=0.0993, 32_l2=0.0588, 64_h1=0.1777, 64_l2=0.0715\n",
      "[19] time=2.42, avg_loss=1.7972, train_err=0.0899, 32_h1=0.0901, 32_l2=0.0478, 64_h1=0.1646, 64_l2=0.0563\n",
      "[20] time=2.41, avg_loss=1.8526, train_err=0.0926, 32_h1=0.0932, 32_l2=0.0508, 64_h1=0.1745, 64_l2=0.0686\n",
      "[21] time=2.39, avg_loss=1.7772, train_err=0.0889, 32_h1=0.0981, 32_l2=0.0573, 64_h1=0.1704, 64_l2=0.0700\n",
      "[22] time=2.49, avg_loss=1.7952, train_err=0.0898, 32_h1=0.0917, 32_l2=0.0508, 64_h1=0.1723, 64_l2=0.0634\n",
      "[23] time=2.48, avg_loss=1.7204, train_err=0.0860, 32_h1=0.0863, 32_l2=0.0441, 64_h1=0.1638, 64_l2=0.0575\n",
      "[24] time=2.41, avg_loss=1.7314, train_err=0.0866, 32_h1=0.0878, 32_l2=0.0462, 64_h1=0.1623, 64_l2=0.0531\n",
      "[25] time=2.42, avg_loss=1.7628, train_err=0.0881, 32_h1=0.0886, 32_l2=0.0478, 64_h1=0.1783, 64_l2=0.0671\n",
      "[26] time=2.45, avg_loss=1.8038, train_err=0.0902, 32_h1=0.0890, 32_l2=0.0482, 64_h1=0.1664, 64_l2=0.0639\n",
      "[27] time=2.41, avg_loss=1.6991, train_err=0.0850, 32_h1=0.0940, 32_l2=0.0585, 64_h1=0.1716, 64_l2=0.0680\n",
      "[28] time=2.43, avg_loss=1.7167, train_err=0.0858, 32_h1=0.0854, 32_l2=0.0464, 64_h1=0.1616, 64_l2=0.0627\n",
      "[29] time=2.43, avg_loss=1.6476, train_err=0.0824, 32_h1=0.0855, 32_l2=0.0451, 64_h1=0.1718, 64_l2=0.0585\n",
      "[30] time=2.45, avg_loss=1.6212, train_err=0.0811, 32_h1=0.0827, 32_l2=0.0421, 64_h1=0.1584, 64_l2=0.0523\n",
      "[31] time=2.41, avg_loss=1.6394, train_err=0.0820, 32_h1=0.0926, 32_l2=0.0536, 64_h1=0.1653, 64_l2=0.0668\n",
      "[32] time=2.38, avg_loss=1.6486, train_err=0.0824, 32_h1=0.0829, 32_l2=0.0412, 64_h1=0.1632, 64_l2=0.0566\n",
      "[33] time=2.46, avg_loss=1.6904, train_err=0.0845, 32_h1=0.0858, 32_l2=0.0483, 64_h1=0.1688, 64_l2=0.0633\n",
      "[34] time=2.44, avg_loss=1.6238, train_err=0.0812, 32_h1=0.0840, 32_l2=0.0431, 64_h1=0.1684, 64_l2=0.0622\n",
      "[35] time=2.39, avg_loss=1.6308, train_err=0.0815, 32_h1=0.0825, 32_l2=0.0435, 64_h1=0.1565, 64_l2=0.0535\n",
      "[36] time=2.39, avg_loss=1.5831, train_err=0.0792, 32_h1=0.0857, 32_l2=0.0444, 64_h1=0.1729, 64_l2=0.0589\n",
      "[37] time=2.36, avg_loss=1.6008, train_err=0.0800, 32_h1=0.0803, 32_l2=0.0403, 64_h1=0.1614, 64_l2=0.0514\n",
      "[38] time=2.28, avg_loss=1.5837, train_err=0.0792, 32_h1=0.0802, 32_l2=0.0416, 64_h1=0.1531, 64_l2=0.0481\n",
      "[39] time=2.12, avg_loss=1.6081, train_err=0.0804, 32_h1=0.0832, 32_l2=0.0438, 64_h1=0.1574, 64_l2=0.0543\n",
      "[40] time=2.26, avg_loss=1.5879, train_err=0.0794, 32_h1=0.0770, 32_l2=0.0365, 64_h1=0.1608, 64_l2=0.0515\n",
      "[41] time=2.31, avg_loss=1.5686, train_err=0.0784, 32_h1=0.0870, 32_l2=0.0488, 64_h1=0.1582, 64_l2=0.0591\n",
      "[42] time=2.14, avg_loss=1.5885, train_err=0.0794, 32_h1=0.0817, 32_l2=0.0426, 64_h1=0.1566, 64_l2=0.0505\n",
      "[43] time=2.29, avg_loss=1.5644, train_err=0.0782, 32_h1=0.0836, 32_l2=0.0450, 64_h1=0.1677, 64_l2=0.0650\n",
      "[44] time=2.30, avg_loss=1.5992, train_err=0.0800, 32_h1=0.0832, 32_l2=0.0467, 64_h1=0.1604, 64_l2=0.0605\n",
      "[45] time=2.26, avg_loss=1.5453, train_err=0.0773, 32_h1=0.0842, 32_l2=0.0461, 64_h1=0.1633, 64_l2=0.0608\n",
      "[46] time=2.29, avg_loss=1.5283, train_err=0.0764, 32_h1=0.0808, 32_l2=0.0431, 64_h1=0.1570, 64_l2=0.0531\n",
      "[47] time=2.16, avg_loss=1.6297, train_err=0.0815, 32_h1=0.0906, 32_l2=0.0569, 64_h1=0.1666, 64_l2=0.0692\n",
      "[48] time=2.26, avg_loss=1.5517, train_err=0.0776, 32_h1=0.0843, 32_l2=0.0460, 64_h1=0.1707, 64_l2=0.0652\n",
      "[49] time=2.19, avg_loss=1.5111, train_err=0.0756, 32_h1=0.0778, 32_l2=0.0391, 64_h1=0.1509, 64_l2=0.0475\n",
      "[50] time=2.12, avg_loss=1.5227, train_err=0.0761, 32_h1=0.0775, 32_l2=0.0398, 64_h1=0.1591, 64_l2=0.0556\n",
      "[51] time=2.20, avg_loss=1.5114, train_err=0.0756, 32_h1=0.0802, 32_l2=0.0428, 64_h1=0.1494, 64_l2=0.0512\n",
      "[52] time=2.26, avg_loss=1.5132, train_err=0.0757, 32_h1=0.0878, 32_l2=0.0542, 64_h1=0.1682, 64_l2=0.0678\n",
      "[53] time=2.31, avg_loss=1.5154, train_err=0.0758, 32_h1=0.0816, 32_l2=0.0453, 64_h1=0.1638, 64_l2=0.0650\n",
      "[54] time=2.30, avg_loss=1.5234, train_err=0.0762, 32_h1=0.0844, 32_l2=0.0476, 64_h1=0.1608, 64_l2=0.0577\n",
      "[55] time=2.27, avg_loss=1.5337, train_err=0.0767, 32_h1=0.0783, 32_l2=0.0423, 64_h1=0.1604, 64_l2=0.0544\n",
      "[56] time=2.22, avg_loss=1.4966, train_err=0.0748, 32_h1=0.0796, 32_l2=0.0431, 64_h1=0.1627, 64_l2=0.0594\n",
      "[57] time=2.13, avg_loss=1.5477, train_err=0.0774, 32_h1=0.0759, 32_l2=0.0364, 64_h1=0.1555, 64_l2=0.0520\n",
      "[58] time=2.12, avg_loss=1.4646, train_err=0.0732, 32_h1=0.0796, 32_l2=0.0409, 64_h1=0.1569, 64_l2=0.0547\n",
      "[59] time=2.21, avg_loss=1.4916, train_err=0.0746, 32_h1=0.0806, 32_l2=0.0431, 64_h1=0.1597, 64_l2=0.0581\n",
      "[60] time=2.12, avg_loss=1.4598, train_err=0.0730, 32_h1=0.0793, 32_l2=0.0414, 64_h1=0.1514, 64_l2=0.0498\n",
      "[61] time=2.14, avg_loss=1.5177, train_err=0.0759, 32_h1=0.0756, 32_l2=0.0373, 64_h1=0.1598, 64_l2=0.0498\n",
      "[62] time=2.30, avg_loss=1.4994, train_err=0.0750, 32_h1=0.0812, 32_l2=0.0431, 64_h1=0.1649, 64_l2=0.0620\n",
      "[63] time=2.30, avg_loss=1.4753, train_err=0.0738, 32_h1=0.0766, 32_l2=0.0383, 64_h1=0.1595, 64_l2=0.0544\n",
      "[64] time=2.12, avg_loss=1.4721, train_err=0.0736, 32_h1=0.0786, 32_l2=0.0407, 64_h1=0.1604, 64_l2=0.0586\n",
      "[65] time=2.10, avg_loss=1.4543, train_err=0.0727, 32_h1=0.0773, 32_l2=0.0388, 64_h1=0.1559, 64_l2=0.0540\n",
      "[66] time=2.29, avg_loss=1.4658, train_err=0.0733, 32_h1=0.0771, 32_l2=0.0385, 64_h1=0.1537, 64_l2=0.0527\n",
      "[67] time=2.53, avg_loss=1.4530, train_err=0.0726, 32_h1=0.0805, 32_l2=0.0454, 64_h1=0.1604, 64_l2=0.0623\n",
      "[68] time=2.39, avg_loss=1.4798, train_err=0.0740, 32_h1=0.0758, 32_l2=0.0379, 64_h1=0.1644, 64_l2=0.0550\n",
      "[69] time=2.36, avg_loss=1.4313, train_err=0.0716, 32_h1=0.0757, 32_l2=0.0380, 64_h1=0.1581, 64_l2=0.0521\n",
      "[70] time=2.39, avg_loss=1.4791, train_err=0.0740, 32_h1=0.0765, 32_l2=0.0398, 64_h1=0.1639, 64_l2=0.0535\n",
      "[71] time=2.41, avg_loss=1.4658, train_err=0.0733, 32_h1=0.0821, 32_l2=0.0490, 64_h1=0.1647, 64_l2=0.0616\n",
      "[72] time=2.39, avg_loss=1.4603, train_err=0.0730, 32_h1=0.0755, 32_l2=0.0384, 64_h1=0.1618, 64_l2=0.0563\n",
      "[73] time=2.38, avg_loss=1.4600, train_err=0.0730, 32_h1=0.0742, 32_l2=0.0355, 64_h1=0.1611, 64_l2=0.0527\n",
      "[74] time=2.37, avg_loss=1.4595, train_err=0.0730, 32_h1=0.0765, 32_l2=0.0387, 64_h1=0.1527, 64_l2=0.0528\n",
      "[75] time=2.39, avg_loss=1.4199, train_err=0.0710, 32_h1=0.0782, 32_l2=0.0412, 64_h1=0.1599, 64_l2=0.0551\n",
      "[76] time=2.43, avg_loss=1.4518, train_err=0.0726, 32_h1=0.0842, 32_l2=0.0494, 64_h1=0.1643, 64_l2=0.0671\n",
      "[77] time=2.40, avg_loss=1.4360, train_err=0.0718, 32_h1=0.0777, 32_l2=0.0402, 64_h1=0.1544, 64_l2=0.0519\n",
      "[78] time=2.44, avg_loss=1.4442, train_err=0.0722, 32_h1=0.0792, 32_l2=0.0424, 64_h1=0.1687, 64_l2=0.0597\n",
      "[79] time=2.45, avg_loss=1.4079, train_err=0.0704, 32_h1=0.0765, 32_l2=0.0405, 64_h1=0.1624, 64_l2=0.0593\n",
      "[80] time=2.40, avg_loss=1.4010, train_err=0.0700, 32_h1=0.0749, 32_l2=0.0373, 64_h1=0.1628, 64_l2=0.0538\n",
      "[81] time=2.38, avg_loss=1.4292, train_err=0.0715, 32_h1=0.0793, 32_l2=0.0471, 64_h1=0.1570, 64_l2=0.0604\n",
      "[82] time=2.40, avg_loss=1.4030, train_err=0.0702, 32_h1=0.0751, 32_l2=0.0372, 64_h1=0.1584, 64_l2=0.0540\n",
      "[83] time=2.40, avg_loss=1.3869, train_err=0.0693, 32_h1=0.0752, 32_l2=0.0384, 64_h1=0.1568, 64_l2=0.0565\n",
      "[84] time=2.38, avg_loss=1.3832, train_err=0.0692, 32_h1=0.0751, 32_l2=0.0378, 64_h1=0.1642, 64_l2=0.0576\n",
      "[85] time=2.39, avg_loss=1.4272, train_err=0.0714, 32_h1=0.0771, 32_l2=0.0395, 64_h1=0.1549, 64_l2=0.0523\n",
      "[86] time=2.39, avg_loss=1.3951, train_err=0.0698, 32_h1=0.0782, 32_l2=0.0425, 64_h1=0.1582, 64_l2=0.0561\n",
      "[87] time=2.38, avg_loss=1.3753, train_err=0.0688, 32_h1=0.0760, 32_l2=0.0382, 64_h1=0.1525, 64_l2=0.0530\n",
      "[88] time=2.42, avg_loss=1.3724, train_err=0.0686, 32_h1=0.0782, 32_l2=0.0450, 64_h1=0.1585, 64_l2=0.0610\n",
      "[89] time=2.48, avg_loss=1.3835, train_err=0.0692, 32_h1=0.0786, 32_l2=0.0408, 64_h1=0.1646, 64_l2=0.0561\n",
      "[90] time=2.38, avg_loss=1.4082, train_err=0.0704, 32_h1=0.0745, 32_l2=0.0367, 64_h1=0.1600, 64_l2=0.0519\n",
      "[91] time=2.39, avg_loss=1.3938, train_err=0.0697, 32_h1=0.0741, 32_l2=0.0368, 64_h1=0.1553, 64_l2=0.0506\n",
      "[92] time=2.42, avg_loss=1.3504, train_err=0.0675, 32_h1=0.0733, 32_l2=0.0357, 64_h1=0.1638, 64_l2=0.0527\n",
      "[93] time=2.37, avg_loss=1.3519, train_err=0.0676, 32_h1=0.0730, 32_l2=0.0345, 64_h1=0.1583, 64_l2=0.0508\n",
      "[94] time=2.38, avg_loss=1.3823, train_err=0.0691, 32_h1=0.0732, 32_l2=0.0348, 64_h1=0.1556, 64_l2=0.0500\n",
      "[95] time=2.37, avg_loss=1.3702, train_err=0.0685, 32_h1=0.0731, 32_l2=0.0358, 64_h1=0.1602, 64_l2=0.0540\n",
      "[96] time=2.38, avg_loss=1.3610, train_err=0.0681, 32_h1=0.0746, 32_l2=0.0374, 64_h1=0.1561, 64_l2=0.0505\n",
      "[97] time=2.42, avg_loss=1.3455, train_err=0.0673, 32_h1=0.0753, 32_l2=0.0370, 64_h1=0.1634, 64_l2=0.0533\n",
      "[98] time=2.40, avg_loss=1.3606, train_err=0.0680, 32_h1=0.0731, 32_l2=0.0357, 64_h1=0.1573, 64_l2=0.0505\n",
      "[99] time=2.44, avg_loss=1.3391, train_err=0.0670, 32_h1=0.0759, 32_l2=0.0404, 64_h1=0.1610, 64_l2=0.0613\n",
      "[100] time=2.42, avg_loss=1.3527, train_err=0.0676, 32_h1=0.0724, 32_l2=0.0347, 64_h1=0.1565, 64_l2=0.0513\n",
      "[101] time=2.43, avg_loss=1.3669, train_err=0.0683, 32_h1=0.0760, 32_l2=0.0410, 64_h1=0.1619, 64_l2=0.0559\n",
      "[102] time=2.41, avg_loss=1.3417, train_err=0.0671, 32_h1=0.0743, 32_l2=0.0379, 64_h1=0.1578, 64_l2=0.0543\n",
      "[103] time=2.41, avg_loss=1.3447, train_err=0.0672, 32_h1=0.0726, 32_l2=0.0349, 64_h1=0.1603, 64_l2=0.0531\n",
      "[104] time=2.40, avg_loss=1.3250, train_err=0.0662, 32_h1=0.0753, 32_l2=0.0385, 64_h1=0.1588, 64_l2=0.0548\n",
      "[105] time=2.19, avg_loss=1.3335, train_err=0.0667, 32_h1=0.0725, 32_l2=0.0346, 64_h1=0.1516, 64_l2=0.0481\n",
      "[106] time=2.13, avg_loss=1.3690, train_err=0.0684, 32_h1=0.0738, 32_l2=0.0373, 64_h1=0.1565, 64_l2=0.0516\n",
      "[107] time=2.26, avg_loss=1.3155, train_err=0.0658, 32_h1=0.0724, 32_l2=0.0349, 64_h1=0.1608, 64_l2=0.0549\n",
      "[108] time=2.15, avg_loss=1.3100, train_err=0.0655, 32_h1=0.0732, 32_l2=0.0376, 64_h1=0.1599, 64_l2=0.0566\n",
      "[109] time=2.25, avg_loss=1.3299, train_err=0.0665, 32_h1=0.0749, 32_l2=0.0376, 64_h1=0.1579, 64_l2=0.0565\n",
      "[110] time=2.28, avg_loss=1.3491, train_err=0.0675, 32_h1=0.0747, 32_l2=0.0395, 64_h1=0.1634, 64_l2=0.0539\n",
      "[111] time=2.26, avg_loss=1.3015, train_err=0.0651, 32_h1=0.0755, 32_l2=0.0378, 64_h1=0.1562, 64_l2=0.0548\n",
      "[112] time=2.28, avg_loss=1.3299, train_err=0.0665, 32_h1=0.0742, 32_l2=0.0375, 64_h1=0.1606, 64_l2=0.0549\n",
      "[113] time=2.27, avg_loss=1.3215, train_err=0.0661, 32_h1=0.0753, 32_l2=0.0382, 64_h1=0.1548, 64_l2=0.0495\n",
      "[114] time=2.21, avg_loss=1.3219, train_err=0.0661, 32_h1=0.0748, 32_l2=0.0384, 64_h1=0.1545, 64_l2=0.0521\n",
      "[115] time=2.10, avg_loss=1.2954, train_err=0.0648, 32_h1=0.0731, 32_l2=0.0358, 64_h1=0.1585, 64_l2=0.0510\n",
      "[116] time=2.12, avg_loss=1.2941, train_err=0.0647, 32_h1=0.0729, 32_l2=0.0352, 64_h1=0.1549, 64_l2=0.0508\n",
      "[117] time=2.25, avg_loss=1.3075, train_err=0.0654, 32_h1=0.0736, 32_l2=0.0368, 64_h1=0.1569, 64_l2=0.0509\n",
      "[118] time=2.23, avg_loss=1.3161, train_err=0.0658, 32_h1=0.0737, 32_l2=0.0357, 64_h1=0.1528, 64_l2=0.0501\n",
      "[119] time=2.26, avg_loss=1.2836, train_err=0.0642, 32_h1=0.0766, 32_l2=0.0410, 64_h1=0.1604, 64_l2=0.0553\n",
      "[120] time=2.25, avg_loss=1.2880, train_err=0.0644, 32_h1=0.0725, 32_l2=0.0351, 64_h1=0.1592, 64_l2=0.0509\n",
      "[121] time=2.20, avg_loss=1.2862, train_err=0.0643, 32_h1=0.0745, 32_l2=0.0377, 64_h1=0.1527, 64_l2=0.0481\n",
      "[122] time=2.16, avg_loss=1.2972, train_err=0.0649, 32_h1=0.0732, 32_l2=0.0351, 64_h1=0.1599, 64_l2=0.0517\n",
      "[123] time=2.22, avg_loss=1.2736, train_err=0.0637, 32_h1=0.0751, 32_l2=0.0396, 64_h1=0.1579, 64_l2=0.0515\n",
      "[124] time=2.11, avg_loss=1.2838, train_err=0.0642, 32_h1=0.0733, 32_l2=0.0378, 64_h1=0.1596, 64_l2=0.0537\n",
      "[125] time=2.18, avg_loss=1.2776, train_err=0.0639, 32_h1=0.0731, 32_l2=0.0356, 64_h1=0.1616, 64_l2=0.0523\n",
      "[126] time=2.31, avg_loss=1.2850, train_err=0.0643, 32_h1=0.0735, 32_l2=0.0354, 64_h1=0.1589, 64_l2=0.0560\n",
      "[127] time=2.29, avg_loss=1.2807, train_err=0.0640, 32_h1=0.0719, 32_l2=0.0355, 64_h1=0.1546, 64_l2=0.0475\n",
      "[128] time=2.12, avg_loss=1.2926, train_err=0.0646, 32_h1=0.0763, 32_l2=0.0393, 64_h1=0.1634, 64_l2=0.0544\n",
      "[129] time=2.30, avg_loss=1.2813, train_err=0.0641, 32_h1=0.0724, 32_l2=0.0354, 64_h1=0.1569, 64_l2=0.0489\n",
      "[130] time=2.29, avg_loss=1.2785, train_err=0.0639, 32_h1=0.0735, 32_l2=0.0370, 64_h1=0.1577, 64_l2=0.0541\n",
      "[131] time=2.30, avg_loss=1.2661, train_err=0.0633, 32_h1=0.0731, 32_l2=0.0359, 64_h1=0.1609, 64_l2=0.0541\n",
      "[132] time=2.18, avg_loss=1.2987, train_err=0.0649, 32_h1=0.0728, 32_l2=0.0358, 64_h1=0.1582, 64_l2=0.0530\n",
      "[133] time=2.49, avg_loss=1.2517, train_err=0.0626, 32_h1=0.0729, 32_l2=0.0357, 64_h1=0.1599, 64_l2=0.0548\n",
      "[134] time=2.41, avg_loss=1.2358, train_err=0.0618, 32_h1=0.0718, 32_l2=0.0340, 64_h1=0.1609, 64_l2=0.0507\n",
      "[135] time=2.39, avg_loss=1.2562, train_err=0.0628, 32_h1=0.0728, 32_l2=0.0350, 64_h1=0.1569, 64_l2=0.0505\n",
      "[136] time=2.46, avg_loss=1.2710, train_err=0.0636, 32_h1=0.0763, 32_l2=0.0399, 64_h1=0.1599, 64_l2=0.0528\n",
      "[137] time=2.39, avg_loss=1.2636, train_err=0.0632, 32_h1=0.0731, 32_l2=0.0356, 64_h1=0.1557, 64_l2=0.0509\n",
      "[138] time=2.41, avg_loss=1.2556, train_err=0.0628, 32_h1=0.0728, 32_l2=0.0358, 64_h1=0.1583, 64_l2=0.0545\n",
      "[139] time=2.41, avg_loss=1.2507, train_err=0.0625, 32_h1=0.0724, 32_l2=0.0350, 64_h1=0.1573, 64_l2=0.0509\n",
      "[140] time=2.40, avg_loss=1.2524, train_err=0.0626, 32_h1=0.0714, 32_l2=0.0335, 64_h1=0.1605, 64_l2=0.0522\n",
      "[141] time=2.41, avg_loss=1.2690, train_err=0.0635, 32_h1=0.0751, 32_l2=0.0384, 64_h1=0.1549, 64_l2=0.0532\n",
      "[142] time=2.39, avg_loss=1.2470, train_err=0.0624, 32_h1=0.0723, 32_l2=0.0347, 64_h1=0.1570, 64_l2=0.0503\n",
      "[143] time=2.40, avg_loss=1.2451, train_err=0.0623, 32_h1=0.0737, 32_l2=0.0373, 64_h1=0.1559, 64_l2=0.0544\n",
      "[144] time=2.40, avg_loss=1.2291, train_err=0.0615, 32_h1=0.0719, 32_l2=0.0341, 64_h1=0.1577, 64_l2=0.0510\n",
      "[145] time=2.37, avg_loss=1.2486, train_err=0.0624, 32_h1=0.0724, 32_l2=0.0343, 64_h1=0.1572, 64_l2=0.0516\n",
      "[146] time=2.43, avg_loss=1.2189, train_err=0.0609, 32_h1=0.0723, 32_l2=0.0344, 64_h1=0.1587, 64_l2=0.0522\n",
      "[147] time=2.40, avg_loss=1.2248, train_err=0.0612, 32_h1=0.0738, 32_l2=0.0367, 64_h1=0.1634, 64_l2=0.0579\n",
      "[148] time=2.45, avg_loss=1.2253, train_err=0.0613, 32_h1=0.0738, 32_l2=0.0365, 64_h1=0.1630, 64_l2=0.0553\n",
      "[149] time=2.41, avg_loss=1.2219, train_err=0.0611, 32_h1=0.0721, 32_l2=0.0349, 64_h1=0.1591, 64_l2=0.0508\n",
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./tfno_darcy_config.yaml, config_name=default, config_folder=./config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "tfno2d.lifting_channels=32\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.n_modes_height=12\n",
      "tfno2d.n_modes_width=12\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.projection_channels=32\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=None\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=tucker\n",
      "tfno2d.rank=0.2\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "opt.n_epochs=150\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=h1\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=300\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=CosineAnnealingLR\n",
      "opt.step_size=50\n",
      "opt.gamma=0.5\n",
      "data.folder=/dli/task/bootcamp/data/darcy_flow/\n",
      "data.batch_size=32\n",
      "data.n_train=3000\n",
      "data.train_resolution=32\n",
      "data.n_tests=[500, 500]\n",
      "data.test_resolutions=[32, 64]\n",
      "data.test_batch_sizes=[32, 32]\n",
      "data.positional_encoding=True\n",
      "data.encode_input=True\n",
      "data.encode_output=False\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=False\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "UnitGaussianNormalizer init on 3000, reducing over [0, 1, 2, 3], samples of shape [1, 32, 32].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "Loading test db at resolution 64 with 500 samples and batch-size=32\n",
      "Given argument key='dropout' that is not in TFNO2d's signature.\n",
      "Given argument key='tensor_lasso_penalty' that is not in TFNO2d's signature.\n",
      "Keyword argument out_channels not specified for model TFNO2d, using default=1.\n",
      "Keyword argument non_linearity not specified for model TFNO2d, using default=<built-in function gelu>.\n",
      "Keyword argument decomposition_kwargs not specified for model TFNO2d, using default={}.\n",
      "\n",
      "n_params: 137473\n",
      "\n",
      "### MODEL ###\n",
      " TFNO2d(\n",
      "  (convs): FactorizedSpectralConv2d(\n",
      "    (weight): ModuleList(\n",
      "      (0): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (1): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (2): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (3): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (4): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (5): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (6): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "      (7): ComplexTuckerTensor(shape=(32, 32, 6, 6), rank=(20, 20, 4, 4))\n",
      "    )\n",
      "  )\n",
      "  (fno_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_skips): ModuleList(\n",
      "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (lifting): Lifting(\n",
      "    (fc): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (projection): Projection(\n",
      "    (fc1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fc2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.005\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f97576c0a90>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f96fddb3d30>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f96fddb3d30>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f9751424550>}\n",
      "\n",
      "### Beginning Training...\n",
      "\n",
      "Training on regular inputs (no multi-grid patching).\n",
      "Training on 3000 samples\n",
      "Testing on [500, 500] samples         on resolutions [32, 64].\n",
      "[0] time=2.40, avg_loss=11.7243, train_err=0.5862, 32_h1=0.3668, 32_l2=0.2546, 64_h1=0.4100, 64_l2=0.2509\n",
      "[1] time=2.39, avg_loss=5.4922, train_err=0.2746, 32_h1=0.2289, 32_l2=0.1542, 64_h1=0.2872, 64_l2=0.1618\n",
      "[2] time=2.40, avg_loss=4.2325, train_err=0.2116, 32_h1=0.2333, 32_l2=0.1774, 64_h1=0.2933, 64_l2=0.1834\n",
      "[3] time=2.40, avg_loss=3.7818, train_err=0.1891, 32_h1=0.1674, 32_l2=0.1069, 64_h1=0.2313, 64_l2=0.1157\n",
      "[4] time=2.37, avg_loss=3.3677, train_err=0.1684, 32_h1=0.1503, 32_l2=0.0955, 64_h1=0.2224, 64_l2=0.1099\n",
      "[5] time=2.39, avg_loss=2.9991, train_err=0.1500, 32_h1=0.1524, 32_l2=0.0994, 64_h1=0.2037, 64_l2=0.1057\n",
      "[6] time=2.44, avg_loss=2.8449, train_err=0.1422, 32_h1=0.1348, 32_l2=0.0850, 64_h1=0.2071, 64_l2=0.0953\n",
      "[7] time=2.38, avg_loss=2.6816, train_err=0.1341, 32_h1=0.1204, 32_l2=0.0712, 64_h1=0.1908, 64_l2=0.0833\n",
      "[8] time=2.41, avg_loss=2.4244, train_err=0.1212, 32_h1=0.1160, 32_l2=0.0682, 64_h1=0.1902, 64_l2=0.0796\n",
      "[9] time=2.38, avg_loss=2.2923, train_err=0.1146, 32_h1=0.1299, 32_l2=0.0886, 64_h1=0.1870, 64_l2=0.0923\n",
      "[10] time=2.39, avg_loss=2.3178, train_err=0.1159, 32_h1=0.1331, 32_l2=0.0970, 64_h1=0.1952, 64_l2=0.1036\n",
      "[11] time=2.36, avg_loss=2.2651, train_err=0.1133, 32_h1=0.1057, 32_l2=0.0644, 64_h1=0.1768, 64_l2=0.0748\n",
      "[12] time=2.41, avg_loss=2.1149, train_err=0.1057, 32_h1=0.1311, 32_l2=0.0864, 64_h1=0.1901, 64_l2=0.0963\n",
      "[13] time=2.40, avg_loss=2.1241, train_err=0.1062, 32_h1=0.0995, 32_l2=0.0560, 64_h1=0.1655, 64_l2=0.0594\n",
      "[14] time=2.38, avg_loss=1.9949, train_err=0.0997, 32_h1=0.1192, 32_l2=0.0834, 64_h1=0.1902, 64_l2=0.0942\n",
      "[15] time=2.38, avg_loss=2.0040, train_err=0.1002, 32_h1=0.1023, 32_l2=0.0601, 64_h1=0.1799, 64_l2=0.0775\n",
      "[16] time=2.40, avg_loss=2.0323, train_err=0.1016, 32_h1=0.0994, 32_l2=0.0563, 64_h1=0.1722, 64_l2=0.0708\n",
      "[17] time=2.44, avg_loss=1.9322, train_err=0.0966, 32_h1=0.1060, 32_l2=0.0677, 64_h1=0.1789, 64_l2=0.0788\n",
      "[18] time=2.43, avg_loss=1.9143, train_err=0.0957, 32_h1=0.0914, 32_l2=0.0490, 64_h1=0.1655, 64_l2=0.0636\n",
      "[19] time=2.40, avg_loss=1.8487, train_err=0.0924, 32_h1=0.0902, 32_l2=0.0493, 64_h1=0.1609, 64_l2=0.0587\n",
      "[20] time=2.42, avg_loss=1.9377, train_err=0.0969, 32_h1=0.1023, 32_l2=0.0654, 64_h1=0.1732, 64_l2=0.0745\n",
      "[21] time=2.29, avg_loss=1.8829, train_err=0.0941, 32_h1=0.0918, 32_l2=0.0510, 64_h1=0.1639, 64_l2=0.0620\n",
      "[22] time=2.19, avg_loss=1.8383, train_err=0.0919, 32_h1=0.0930, 32_l2=0.0550, 64_h1=0.1538, 64_l2=0.0597\n",
      "[23] time=2.21, avg_loss=1.8133, train_err=0.0907, 32_h1=0.1053, 32_l2=0.0642, 64_h1=0.1767, 64_l2=0.0774\n",
      "[24] time=2.09, avg_loss=1.7449, train_err=0.0872, 32_h1=0.0893, 32_l2=0.0500, 64_h1=0.1621, 64_l2=0.0587\n",
      "[25] time=2.10, avg_loss=1.8036, train_err=0.0902, 32_h1=0.0980, 32_l2=0.0599, 64_h1=0.1672, 64_l2=0.0740\n",
      "[26] time=2.10, avg_loss=1.8832, train_err=0.0942, 32_h1=0.0956, 32_l2=0.0526, 64_h1=0.1580, 64_l2=0.0594\n",
      "[27] time=2.20, avg_loss=1.7579, train_err=0.0879, 32_h1=0.0860, 32_l2=0.0466, 64_h1=0.1692, 64_l2=0.0607\n",
      "[28] time=2.27, avg_loss=1.7295, train_err=0.0865, 32_h1=0.0935, 32_l2=0.0531, 64_h1=0.1701, 64_l2=0.0674\n",
      "[29] time=2.29, avg_loss=1.7637, train_err=0.0882, 32_h1=0.0864, 32_l2=0.0511, 64_h1=0.1600, 64_l2=0.0593\n",
      "[30] time=2.27, avg_loss=1.6987, train_err=0.0849, 32_h1=0.0871, 32_l2=0.0492, 64_h1=0.1640, 64_l2=0.0620\n",
      "[31] time=2.22, avg_loss=1.6798, train_err=0.0840, 32_h1=0.0924, 32_l2=0.0542, 64_h1=0.1621, 64_l2=0.0656\n",
      "[32] time=2.09, avg_loss=1.6717, train_err=0.0836, 32_h1=0.0869, 32_l2=0.0494, 64_h1=0.1630, 64_l2=0.0615\n",
      "[33] time=2.17, avg_loss=1.6483, train_err=0.0824, 32_h1=0.0862, 32_l2=0.0500, 64_h1=0.1701, 64_l2=0.0691\n",
      "[34] time=2.17, avg_loss=1.6095, train_err=0.0805, 32_h1=0.0861, 32_l2=0.0474, 64_h1=0.1584, 64_l2=0.0576\n",
      "[35] time=2.11, avg_loss=1.6775, train_err=0.0839, 32_h1=0.0865, 32_l2=0.0473, 64_h1=0.1502, 64_l2=0.0569\n",
      "[36] time=2.12, avg_loss=1.6858, train_err=0.0843, 32_h1=0.0877, 32_l2=0.0509, 64_h1=0.1625, 64_l2=0.0603\n",
      "[37] time=2.24, avg_loss=1.6913, train_err=0.0846, 32_h1=0.0893, 32_l2=0.0561, 64_h1=0.1572, 64_l2=0.0669\n",
      "[38] time=2.12, avg_loss=1.6051, train_err=0.0803, 32_h1=0.0810, 32_l2=0.0430, 64_h1=0.1539, 64_l2=0.0566\n",
      "[39] time=2.09, avg_loss=1.6128, train_err=0.0806, 32_h1=0.0812, 32_l2=0.0409, 64_h1=0.1528, 64_l2=0.0503\n",
      "[40] time=2.09, avg_loss=1.5903, train_err=0.0795, 32_h1=0.0824, 32_l2=0.0474, 64_h1=0.1641, 64_l2=0.0618\n",
      "[41] time=2.09, avg_loss=1.5628, train_err=0.0781, 32_h1=0.0829, 32_l2=0.0455, 64_h1=0.1631, 64_l2=0.0588\n",
      "[42] time=2.10, avg_loss=1.5532, train_err=0.0777, 32_h1=0.0890, 32_l2=0.0521, 64_h1=0.1561, 64_l2=0.0598\n",
      "[43] time=2.15, avg_loss=1.6158, train_err=0.0808, 32_h1=0.0803, 32_l2=0.0414, 64_h1=0.1553, 64_l2=0.0551\n",
      "[44] time=2.16, avg_loss=1.5384, train_err=0.0769, 32_h1=0.0780, 32_l2=0.0395, 64_h1=0.1572, 64_l2=0.0499\n",
      "[45] time=2.16, avg_loss=1.5081, train_err=0.0754, 32_h1=0.0819, 32_l2=0.0446, 64_h1=0.1544, 64_l2=0.0563\n",
      "[46] time=2.17, avg_loss=1.6295, train_err=0.0815, 32_h1=0.0834, 32_l2=0.0466, 64_h1=0.1588, 64_l2=0.0574\n",
      "[47] time=2.27, avg_loss=1.5103, train_err=0.0755, 32_h1=0.0794, 32_l2=0.0410, 64_h1=0.1500, 64_l2=0.0496\n",
      "[48] time=2.13, avg_loss=1.5230, train_err=0.0761, 32_h1=0.0777, 32_l2=0.0396, 64_h1=0.1575, 64_l2=0.0552\n",
      "[49] time=2.10, avg_loss=1.5987, train_err=0.0799, 32_h1=0.0804, 32_l2=0.0429, 64_h1=0.1550, 64_l2=0.0506\n",
      "[50] time=2.51, avg_loss=1.5515, train_err=0.0776, 32_h1=0.0872, 32_l2=0.0542, 64_h1=0.1623, 64_l2=0.0677\n",
      "[51] time=2.43, avg_loss=1.5312, train_err=0.0766, 32_h1=0.0824, 32_l2=0.0457, 64_h1=0.1589, 64_l2=0.0637\n",
      "[52] time=2.39, avg_loss=1.5217, train_err=0.0761, 32_h1=0.0823, 32_l2=0.0464, 64_h1=0.1642, 64_l2=0.0665\n",
      "[53] time=2.38, avg_loss=1.5329, train_err=0.0766, 32_h1=0.0765, 32_l2=0.0383, 64_h1=0.1510, 64_l2=0.0513\n",
      "[54] time=2.43, avg_loss=1.4744, train_err=0.0737, 32_h1=0.0809, 32_l2=0.0437, 64_h1=0.1641, 64_l2=0.0630\n",
      "[55] time=2.37, avg_loss=1.5387, train_err=0.0769, 32_h1=0.0804, 32_l2=0.0431, 64_h1=0.1603, 64_l2=0.0611\n",
      "[56] time=2.39, avg_loss=1.5304, train_err=0.0765, 32_h1=0.0804, 32_l2=0.0432, 64_h1=0.1513, 64_l2=0.0551\n",
      "[57] time=2.41, avg_loss=1.4839, train_err=0.0742, 32_h1=0.0818, 32_l2=0.0439, 64_h1=0.1483, 64_l2=0.0511\n",
      "[58] time=2.40, avg_loss=1.4821, train_err=0.0741, 32_h1=0.0764, 32_l2=0.0402, 64_h1=0.1576, 64_l2=0.0563\n",
      "[59] time=2.36, avg_loss=1.4994, train_err=0.0750, 32_h1=0.0773, 32_l2=0.0399, 64_h1=0.1628, 64_l2=0.0593\n",
      "[60] time=2.37, avg_loss=1.4592, train_err=0.0730, 32_h1=0.0766, 32_l2=0.0385, 64_h1=0.1465, 64_l2=0.0506\n",
      "[61] time=2.37, avg_loss=1.4685, train_err=0.0734, 32_h1=0.0788, 32_l2=0.0420, 64_h1=0.1594, 64_l2=0.0593\n",
      "[62] time=2.39, avg_loss=1.5452, train_err=0.0773, 32_h1=0.0829, 32_l2=0.0488, 64_h1=0.1561, 64_l2=0.0621\n",
      "[63] time=2.38, avg_loss=1.4587, train_err=0.0729, 32_h1=0.0753, 32_l2=0.0370, 64_h1=0.1566, 64_l2=0.0555\n",
      "[64] time=2.42, avg_loss=1.4801, train_err=0.0740, 32_h1=0.0794, 32_l2=0.0425, 64_h1=0.1538, 64_l2=0.0503\n",
      "[65] time=2.38, avg_loss=1.4879, train_err=0.0744, 32_h1=0.0755, 32_l2=0.0364, 64_h1=0.1508, 64_l2=0.0525\n",
      "[66] time=2.36, avg_loss=1.4435, train_err=0.0722, 32_h1=0.0811, 32_l2=0.0451, 64_h1=0.1582, 64_l2=0.0614\n",
      "[67] time=2.46, avg_loss=1.4644, train_err=0.0732, 32_h1=0.0772, 32_l2=0.0402, 64_h1=0.1525, 64_l2=0.0485\n",
      "[68] time=2.39, avg_loss=1.4504, train_err=0.0725, 32_h1=0.0863, 32_l2=0.0535, 64_h1=0.1600, 64_l2=0.0647\n",
      "[69] time=2.41, avg_loss=1.4701, train_err=0.0735, 32_h1=0.0819, 32_l2=0.0489, 64_h1=0.1602, 64_l2=0.0646\n",
      "[70] time=2.38, avg_loss=1.4383, train_err=0.0719, 32_h1=0.0771, 32_l2=0.0405, 64_h1=0.1529, 64_l2=0.0523\n",
      "[71] time=2.41, avg_loss=1.4621, train_err=0.0731, 32_h1=0.0880, 32_l2=0.0569, 64_h1=0.1650, 64_l2=0.0705\n",
      "[72] time=2.42, avg_loss=1.4532, train_err=0.0727, 32_h1=0.0738, 32_l2=0.0360, 64_h1=0.1580, 64_l2=0.0527\n",
      "[73] time=2.40, avg_loss=1.4303, train_err=0.0715, 32_h1=0.0761, 32_l2=0.0393, 64_h1=0.1501, 64_l2=0.0530\n",
      "[74] time=2.36, avg_loss=1.3974, train_err=0.0699, 32_h1=0.0782, 32_l2=0.0407, 64_h1=0.1526, 64_l2=0.0518\n",
      "[75] time=2.42, avg_loss=1.4288, train_err=0.0714, 32_h1=0.0757, 32_l2=0.0375, 64_h1=0.1601, 64_l2=0.0561\n",
      "[76] time=2.43, avg_loss=1.4552, train_err=0.0728, 32_h1=0.0753, 32_l2=0.0375, 64_h1=0.1567, 64_l2=0.0534\n",
      "[77] time=2.39, avg_loss=1.4454, train_err=0.0723, 32_h1=0.0833, 32_l2=0.0483, 64_h1=0.1570, 64_l2=0.0564\n",
      "[78] time=2.40, avg_loss=1.4420, train_err=0.0721, 32_h1=0.0754, 32_l2=0.0388, 64_h1=0.1613, 64_l2=0.0549\n",
      "[79] time=2.41, avg_loss=1.4210, train_err=0.0711, 32_h1=0.0764, 32_l2=0.0394, 64_h1=0.1560, 64_l2=0.0483\n",
      "[80] time=2.41, avg_loss=1.3942, train_err=0.0697, 32_h1=0.0899, 32_l2=0.0611, 64_h1=0.1674, 64_l2=0.0726\n",
      "[81] time=2.39, avg_loss=1.4238, train_err=0.0712, 32_h1=0.0742, 32_l2=0.0363, 64_h1=0.1590, 64_l2=0.0526\n",
      "[82] time=2.41, avg_loss=1.3990, train_err=0.0699, 32_h1=0.0754, 32_l2=0.0406, 64_h1=0.1553, 64_l2=0.0558\n",
      "[83] time=2.36, avg_loss=1.4067, train_err=0.0703, 32_h1=0.0777, 32_l2=0.0427, 64_h1=0.1600, 64_l2=0.0544\n",
      "[84] time=2.36, avg_loss=1.4164, train_err=0.0708, 32_h1=0.0748, 32_l2=0.0369, 64_h1=0.1549, 64_l2=0.0523\n",
      "[85] time=2.38, avg_loss=1.3866, train_err=0.0693, 32_h1=0.0752, 32_l2=0.0374, 64_h1=0.1549, 64_l2=0.0484\n",
      "[86] time=2.39, avg_loss=1.4239, train_err=0.0712, 32_h1=0.0797, 32_l2=0.0456, 64_h1=0.1582, 64_l2=0.0640\n",
      "[87] time=2.39, avg_loss=1.3968, train_err=0.0698, 32_h1=0.0761, 32_l2=0.0442, 64_h1=0.1579, 64_l2=0.0557\n",
      "[88] time=2.40, avg_loss=1.3981, train_err=0.0699, 32_h1=0.0767, 32_l2=0.0401, 64_h1=0.1581, 64_l2=0.0543\n",
      "[89] time=2.14, avg_loss=1.3923, train_err=0.0696, 32_h1=0.0727, 32_l2=0.0350, 64_h1=0.1554, 64_l2=0.0499\n",
      "[90] time=2.29, avg_loss=1.3685, train_err=0.0684, 32_h1=0.0727, 32_l2=0.0352, 64_h1=0.1493, 64_l2=0.0513\n",
      "[91] time=2.28, avg_loss=1.3823, train_err=0.0691, 32_h1=0.0735, 32_l2=0.0368, 64_h1=0.1604, 64_l2=0.0558\n",
      "[92] time=2.14, avg_loss=1.3811, train_err=0.0691, 32_h1=0.0775, 32_l2=0.0418, 64_h1=0.1537, 64_l2=0.0535\n",
      "[93] time=2.21, avg_loss=1.3728, train_err=0.0686, 32_h1=0.0768, 32_l2=0.0417, 64_h1=0.1623, 64_l2=0.0599\n",
      "[94] time=2.13, avg_loss=1.3709, train_err=0.0685, 32_h1=0.0744, 32_l2=0.0367, 64_h1=0.1458, 64_l2=0.0492\n",
      "[95] time=2.26, avg_loss=1.3880, train_err=0.0694, 32_h1=0.0735, 32_l2=0.0356, 64_h1=0.1571, 64_l2=0.0520\n",
      "[96] time=2.14, avg_loss=1.3466, train_err=0.0673, 32_h1=0.0758, 32_l2=0.0397, 64_h1=0.1676, 64_l2=0.0567\n",
      "[97] time=2.30, avg_loss=1.4021, train_err=0.0701, 32_h1=0.0804, 32_l2=0.0465, 64_h1=0.1585, 64_l2=0.0613\n",
      "[98] time=2.25, avg_loss=1.3717, train_err=0.0686, 32_h1=0.0806, 32_l2=0.0480, 64_h1=0.1588, 64_l2=0.0587\n",
      "[99] time=2.26, avg_loss=1.3695, train_err=0.0685, 32_h1=0.0735, 32_l2=0.0362, 64_h1=0.1515, 64_l2=0.0526\n",
      "[100] time=2.29, avg_loss=1.3951, train_err=0.0698, 32_h1=0.0752, 32_l2=0.0376, 64_h1=0.1518, 64_l2=0.0497\n",
      "[101] time=2.27, avg_loss=1.3418, train_err=0.0671, 32_h1=0.0719, 32_l2=0.0338, 64_h1=0.1556, 64_l2=0.0514\n",
      "[102] time=2.26, avg_loss=1.3439, train_err=0.0672, 32_h1=0.0724, 32_l2=0.0352, 64_h1=0.1580, 64_l2=0.0550\n",
      "[103] time=2.25, avg_loss=1.3479, train_err=0.0674, 32_h1=0.0751, 32_l2=0.0375, 64_h1=0.1558, 64_l2=0.0506\n",
      "[104] time=2.09, avg_loss=1.3383, train_err=0.0669, 32_h1=0.0724, 32_l2=0.0342, 64_h1=0.1621, 64_l2=0.0530\n",
      "[105] time=2.18, avg_loss=1.3158, train_err=0.0658, 32_h1=0.0745, 32_l2=0.0381, 64_h1=0.1577, 64_l2=0.0536\n",
      "[106] time=2.10, avg_loss=1.3509, train_err=0.0675, 32_h1=0.0757, 32_l2=0.0396, 64_h1=0.1467, 64_l2=0.0492\n",
      "[107] time=2.12, avg_loss=1.3500, train_err=0.0675, 32_h1=0.0750, 32_l2=0.0383, 64_h1=0.1615, 64_l2=0.0549\n",
      "[108] time=2.09, avg_loss=1.3429, train_err=0.0671, 32_h1=0.0726, 32_l2=0.0352, 64_h1=0.1573, 64_l2=0.0520\n",
      "[109] time=2.28, avg_loss=1.3325, train_err=0.0666, 32_h1=0.0732, 32_l2=0.0370, 64_h1=0.1571, 64_l2=0.0535\n",
      "[110] time=2.23, avg_loss=1.3459, train_err=0.0673, 32_h1=0.0751, 32_l2=0.0373, 64_h1=0.1631, 64_l2=0.0539\n",
      "[111] time=2.09, avg_loss=1.3478, train_err=0.0674, 32_h1=0.0760, 32_l2=0.0381, 64_h1=0.1555, 64_l2=0.0558\n",
      "[112] time=2.13, avg_loss=1.3463, train_err=0.0673, 32_h1=0.0728, 32_l2=0.0349, 64_h1=0.1581, 64_l2=0.0522\n",
      "[113] time=2.16, avg_loss=1.3071, train_err=0.0654, 32_h1=0.0722, 32_l2=0.0349, 64_h1=0.1589, 64_l2=0.0534\n",
      "[114] time=2.14, avg_loss=1.3075, train_err=0.0654, 32_h1=0.0730, 32_l2=0.0357, 64_h1=0.1588, 64_l2=0.0512\n",
      "[115] time=2.12, avg_loss=1.3136, train_err=0.0657, 32_h1=0.0739, 32_l2=0.0365, 64_h1=0.1595, 64_l2=0.0507\n",
      "[116] time=2.12, avg_loss=1.3120, train_err=0.0656, 32_h1=0.0716, 32_l2=0.0342, 64_h1=0.1528, 64_l2=0.0497\n",
      "[117] time=2.54, avg_loss=1.2964, train_err=0.0648, 32_h1=0.0732, 32_l2=0.0361, 64_h1=0.1498, 64_l2=0.0486\n",
      "[118] time=2.41, avg_loss=1.3076, train_err=0.0654, 32_h1=0.0730, 32_l2=0.0362, 64_h1=0.1572, 64_l2=0.0522\n",
      "[119] time=2.40, avg_loss=1.3077, train_err=0.0654, 32_h1=0.0739, 32_l2=0.0380, 64_h1=0.1553, 64_l2=0.0478\n",
      "[120] time=2.41, avg_loss=1.3002, train_err=0.0650, 32_h1=0.0730, 32_l2=0.0356, 64_h1=0.1526, 64_l2=0.0490\n",
      "[121] time=2.37, avg_loss=1.3016, train_err=0.0651, 32_h1=0.0743, 32_l2=0.0375, 64_h1=0.1564, 64_l2=0.0509\n",
      "[122] time=2.43, avg_loss=1.2852, train_err=0.0643, 32_h1=0.0728, 32_l2=0.0353, 64_h1=0.1589, 64_l2=0.0507\n",
      "[123] time=2.40, avg_loss=1.3099, train_err=0.0655, 32_h1=0.0714, 32_l2=0.0337, 64_h1=0.1553, 64_l2=0.0499\n",
      "[124] time=2.41, avg_loss=1.2950, train_err=0.0647, 32_h1=0.0764, 32_l2=0.0431, 64_h1=0.1619, 64_l2=0.0602\n",
      "[125] time=2.38, avg_loss=1.2890, train_err=0.0644, 32_h1=0.0729, 32_l2=0.0354, 64_h1=0.1589, 64_l2=0.0505\n",
      "[126] time=2.40, avg_loss=1.3196, train_err=0.0660, 32_h1=0.0727, 32_l2=0.0355, 64_h1=0.1620, 64_l2=0.0510\n",
      "[127] time=2.42, avg_loss=1.3014, train_err=0.0651, 32_h1=0.0761, 32_l2=0.0401, 64_h1=0.1577, 64_l2=0.0523\n",
      "[128] time=2.39, avg_loss=1.2679, train_err=0.0634, 32_h1=0.0738, 32_l2=0.0375, 64_h1=0.1569, 64_l2=0.0541\n",
      "[129] time=2.42, avg_loss=1.2814, train_err=0.0641, 32_h1=0.0714, 32_l2=0.0336, 64_h1=0.1602, 64_l2=0.0531\n",
      "[130] time=2.37, avg_loss=1.2600, train_err=0.0630, 32_h1=0.0717, 32_l2=0.0346, 64_h1=0.1553, 64_l2=0.0513\n",
      "[131] time=2.40, avg_loss=1.3056, train_err=0.0653, 32_h1=0.0730, 32_l2=0.0356, 64_h1=0.1586, 64_l2=0.0509\n",
      "[132] time=2.43, avg_loss=1.2780, train_err=0.0639, 32_h1=0.0723, 32_l2=0.0354, 64_h1=0.1586, 64_l2=0.0538\n",
      "[133] time=2.40, avg_loss=1.2817, train_err=0.0641, 32_h1=0.0718, 32_l2=0.0347, 64_h1=0.1563, 64_l2=0.0505\n",
      "[134] time=2.38, avg_loss=1.2575, train_err=0.0629, 32_h1=0.0740, 32_l2=0.0368, 64_h1=0.1650, 64_l2=0.0579\n",
      "[135] time=2.38, avg_loss=1.2590, train_err=0.0630, 32_h1=0.0737, 32_l2=0.0357, 64_h1=0.1614, 64_l2=0.0523\n",
      "[136] time=2.43, avg_loss=1.2742, train_err=0.0637, 32_h1=0.0729, 32_l2=0.0365, 64_h1=0.1606, 64_l2=0.0542\n",
      "[137] time=2.44, avg_loss=1.2595, train_err=0.0630, 32_h1=0.0718, 32_l2=0.0339, 64_h1=0.1579, 64_l2=0.0499\n",
      "[138] time=2.43, avg_loss=1.2619, train_err=0.0631, 32_h1=0.0777, 32_l2=0.0424, 64_h1=0.1631, 64_l2=0.0582\n",
      "[139] time=2.52, avg_loss=1.2840, train_err=0.0642, 32_h1=0.0722, 32_l2=0.0344, 64_h1=0.1618, 64_l2=0.0529\n",
      "[140] time=2.43, avg_loss=1.2555, train_err=0.0628, 32_h1=0.0749, 32_l2=0.0371, 64_h1=0.1591, 64_l2=0.0533\n",
      "[141] time=2.43, avg_loss=1.2743, train_err=0.0637, 32_h1=0.0720, 32_l2=0.0342, 64_h1=0.1596, 64_l2=0.0513\n",
      "[142] time=2.38, avg_loss=1.2569, train_err=0.0628, 32_h1=0.0744, 32_l2=0.0374, 64_h1=0.1523, 64_l2=0.0507\n",
      "[143] time=2.40, avg_loss=1.2501, train_err=0.0625, 32_h1=0.0722, 32_l2=0.0341, 64_h1=0.1567, 64_l2=0.0498\n",
      "[144] time=2.39, avg_loss=1.2404, train_err=0.0620, 32_h1=0.0715, 32_l2=0.0341, 64_h1=0.1570, 64_l2=0.0511\n",
      "[145] time=2.38, avg_loss=1.2455, train_err=0.0623, 32_h1=0.0726, 32_l2=0.0351, 64_h1=0.1543, 64_l2=0.0506\n",
      "[146] time=2.41, avg_loss=1.2494, train_err=0.0625, 32_h1=0.0715, 32_l2=0.0341, 64_h1=0.1574, 64_l2=0.0500\n",
      "[147] time=2.37, avg_loss=1.2339, train_err=0.0617, 32_h1=0.0716, 32_l2=0.0352, 64_h1=0.1580, 64_l2=0.0515\n",
      "[148] time=2.38, avg_loss=1.2332, train_err=0.0617, 32_h1=0.0724, 32_l2=0.0370, 64_h1=0.1636, 64_l2=0.0552\n",
      "[149] time=2.38, avg_loss=1.2432, train_err=0.0622, 32_h1=0.0731, 32_l2=0.0368, 64_h1=0.1610, 64_l2=0.0558\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in [0.02, 0.03, 0.06, 0.07, 0.1, 0.11, 0.15, 0.2]:\n",
    "    # Read the configuration\n",
    "    config_name = 'default'\n",
    "    pipe = ConfigPipeline([YamlConfig('./tfno_darcy_config.yaml', config_name='default', config_folder='./config'),\n",
    "                          ])\n",
    "    config = pipe.read_conf()\n",
    "    config_name = pipe.steps[-1].config_name\n",
    "    \n",
    "    config.tfno2d.rank = i\n",
    "    \n",
    "    # Set-up distributed communication, if using\n",
    "    device, is_logger = setup(config)\n",
    "    \n",
    "    # Make sure we only print information when needed\n",
    "    config.verbose = config.verbose and is_logger\n",
    "\n",
    "    #Print config to screen\n",
    "    if config.verbose and is_logger:\n",
    "        pipe.log()\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    # Loading the Darcy flow training set in 32x32 resolution, test set in 32x32 and 64x64 resolutions\n",
    "    train_loader, test_loaders, output_encoder = load_darcy_pt(\n",
    "            config.data.folder, train_resolution=config.data.train_resolution, n_train=config.data.n_train, batch_size=config.data.batch_size, \n",
    "            positional_encoding=config.data.positional_encoding,\n",
    "            test_resolutions=config.data.test_resolutions, n_tests=config.data.n_tests, test_batch_sizes=config.data.test_batch_sizes,\n",
    "            encode_input=config.data.encode_input, encode_output=config.data.encode_output,\n",
    "            )\n",
    "    \n",
    "    model = get_model(config)\n",
    "    model = model.to(device)\n",
    "\n",
    "    #Log parameter count\n",
    "    if is_logger:\n",
    "        n_params = count_params(model)\n",
    "\n",
    "        if config.verbose:\n",
    "            print(f'\\nn_params: {n_params}')\n",
    "            sys.stdout.flush()\n",
    "    \n",
    "    #Create the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                    lr=config.opt.learning_rate, \n",
    "                                    weight_decay=config.opt.weight_decay)\n",
    "\n",
    "    if config.opt.scheduler == 'ReduceLROnPlateau':\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=config.opt.gamma, patience=config.opt.scheduler_patience, mode='min')\n",
    "    elif config.opt.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.opt.scheduler_T_max)\n",
    "    elif config.opt.scheduler == 'StepLR':\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n",
    "                                                    step_size=config.opt.step_size,\n",
    "                                                    gamma=config.opt.gamma)\n",
    "    else:\n",
    "        raise ValueError(f'Got {config.opt.scheduler=}')\n",
    "    \n",
    "    # Creating the losses\n",
    "    l2loss = LpLoss(d=2, p=2)\n",
    "    h1loss = H1Loss(d=2)\n",
    "    if config.opt.training_loss == 'l2':\n",
    "        train_loss = l2loss\n",
    "    elif config.opt.training_loss == 'h1':\n",
    "        train_loss = h1loss\n",
    "    else:\n",
    "        raise ValueError(f'Got training_loss={config.opt.training_loss} but expected one of [\"l2\", \"h1\"]')\n",
    "    eval_losses={'h1': h1loss, 'l2': l2loss}\n",
    "    \n",
    "    if config.verbose and is_logger:\n",
    "        print('\\n### MODEL ###\\n', model)\n",
    "        print('\\n### OPTIMIZER ###\\n', optimizer)\n",
    "        print('\\n### SCHEDULER ###\\n', scheduler)\n",
    "        print('\\n### LOSSES ###')\n",
    "        print(f'\\n * Train: {train_loss}')\n",
    "        print(f'\\n * Test: {eval_losses}')\n",
    "        print(f'\\n### Beginning Training...\\n')\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    trainer = Trainer(model, n_epochs=config.opt.n_epochs,\n",
    "                      device=device,\n",
    "                      mg_patching_levels=config.patching.levels,\n",
    "                      mg_patching_padding=config.patching.padding,\n",
    "                      mg_patching_stitching=config.patching.stitching,\n",
    "                      wandb_log=config.wandb.log,\n",
    "                      log_test_interval=config.wandb.log_test_interval,\n",
    "                      log_output=False,\n",
    "                      use_distributed=config.distributed.use_distributed,\n",
    "                      verbose=config.verbose and is_logger)\n",
    "    \n",
    "    trainer.train(train_loader, test_loaders,\n",
    "                  output_encoder,\n",
    "                  model, \n",
    "                  optimizer,\n",
    "                  scheduler, \n",
    "                  regularizer=False, \n",
    "                  training_loss=train_loss,\n",
    "                  eval_losses=eval_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21693a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c3ead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
