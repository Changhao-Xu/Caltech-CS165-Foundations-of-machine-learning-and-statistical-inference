 docker run --gpus all deterministic

=============
== PyTorch ==
=============

NVIDIA Release 22.07 (build 40241807)
PyTorch Version 1.13.0a0+08820cb

Container image Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

Copyright (c) 2014-2022 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

[2023-03-17 16:31:41,226] ---------------------------------------------------
[2023-03-17 16:31:41,226] -----Launching full-batch computation job! --------
[2023-03-17 16:31:41,240] data:
  db:
    name: null
  name: CIFAR10
  path: ~/data
  size: 50000
  channels: 3
  classes: 10
  pixels: 32
  normalize: true
  mean:
  - 0.4914672374725342
  - 0.4822617471218109
  - 0.4467701315879822
  std:
  - 0.24703224003314972
  - 0.24348513782024384
  - 0.26158785820007324
  batch_size: 128
  augmentations_train:
    RandomCrop:
    - 32
    - 4
    RandomHorizontalFlip: 0.5
  augmentations_val: null
  caching: null
model:
  name: ResNet18
  depth: 18
  width: 64
  stem: CIFAR
  convolution: Standard
  nonlin_fn: ReLU
  normalization: BatchNorm2d
  downsample: C
  initialization: skip-residual
impl:
  setup:
    dist: false
    backend: nccl
    strategy: file_system
    world_size: null
    rank: null
    url: null
  dtype: float
  memory: contiguous
  non_blocking: true
  benchmark: true
  deterministic: false
  pin_memory: true
  threads: 8
  persistent_workers: true
  mixed_precision: false
  grad_scaling: false
  JIT: null
  accumulation_dtype: float
  validate_every_nth_step: 100
  checkpoint:
    name: null
    save_every_nth_step: 1
hyp:
  optim:
    name: Gradient Descent
    lr: 0.8
    momentum: 0.9
    weight_decay: 0.0005
    dampening: 0.0
    nesterov: true
    line_search: none
  optim_modification:
    name: none
  shuffle: false
  sample_with_replacement: false
  train_stochastic: false
  train_switch_stochastic: null
  train_semi_stochastic: false
  steps: 3000
  scheduler: cosine-4000
  stop_at_full_training_accuracy: 0
  warmup: 400
  only_linear_layers_weight_decay: false
  evaluate_ema: false
  eval_ema_momentum: 0.99
  grad_clip: 0.25
  batch_clip: null
  grad_clip_norm: 2
  grad_noise:
    additive: null
    multiplicative: null
  grad_reg:
    norm: 2
    block_strength: 0.5
    acc_strength: 0.0
    eps: 0.01
    implementation: forward-differences
  sub_batch: 128
  label_smoothing: 0.0
  loss_modification: null
  norm_bias:
    strength: 0.0
    norm_type: 1
    bias: 0
  test_time_flips: false
  template_name: fbgradreg
analysis:
  type: null
  check_every_nth_step: 10000000
  measure_param_norm: false
  measure_grad_norm: false
  check_momentum: false
  internal_batch_size_chunks: 1
  record_gradient_norm_per_batch: false
  compute_gradient_SNR: false
  compute_gradient_noise_scale: false
  compute_flatness: false
  flatness_step_size: 0.1
  flatness_threshold: 1.0
  flatness_norm: filter
  save_model_every_nth_step: null
viz:
  type: 1d
  database_name: null
  rebuild_existing_database: false
  compute_full_loss: true
  ignore_layers: biasbn
  norm: filter
  coordinates:
    x:
      min: -1
      max: 1
      num: 51
    'y':
      min: 0
      max: 0
      num: 1
  model_eval: true
  max_readers: 128
  readahead: true
  meminit: false
  max_spare_txns: 128
  map_size: 1000000000.0
base_dir: outputs
seed: 1315371875
name: fbaug_gradaug_lr08
dryrun: false

[2023-03-17 16:31:41,245] Platform: linux, Python: 3.8.13 | packaged by conda-forge |, PyTorch: 1.13.0a0+08820cb
[2023-03-17 16:31:41,245] CPUs: 64, GPUs: 5 on 74ca2e2efb2b.
[2023-03-17 16:31:41,250] GPU : NVIDIA A100-SXM4-80GB
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/data/cifar-10-python.tar.gz
100%|██████████| 170498071/170498071 [00:05<00:00, 32611929.13it/s]Extracting /root/data/cifar-10-python.tar.gz to /root/data
Files already downloaded and verified
sub identity init a conv1x1
sub identity init a conv1x1
sub identity init a conv1x1

[2023-03-17 16:32:15,716] Step: 1   | lr: 0.0020 | Time: 19.42s |TRAIN loss  2.3026 | TRAIN Acc:  10.01% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:32:29,486] Gradient total norm was 0.6502044200897217. Clipping to 0.25.
[2023-03-17 16:32:29,490] Step: 2   | lr: 0.0040 | Time: 13.76s |TRAIN loss  2.3026 | TRAIN Acc:  10.01% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:32:43,356] Gradient total norm was 0.609318196773529. Clipping to 0.25.
[2023-03-17 16:32:43,360] Step: 3   | lr: 0.0060 | Time: 13.85s |TRAIN loss  2.3025 | TRAIN Acc:  16.86% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:32:57,275] Gradient total norm was 1.868849515914917. Clipping to 0.25.
[2023-03-17 16:32:57,278] Step: 4   | lr: 0.0080 | Time: 13.90s |TRAIN loss  2.3024 | TRAIN Acc:  11.83% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:33:11,153] Gradient total norm was 0.9814065098762512. Clipping to 0.25.
[2023-03-17 16:33:11,156] Step: 5   | lr: 0.0100 | Time: 13.86s |TRAIN loss  2.3014 | TRAIN Acc:  17.70% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:33:25,037] Gradient total norm was 0.9507701992988586. Clipping to 0.25.
[2023-03-17 16:33:25,040] Step: 6   | lr: 0.0120 | Time: 13.87s |TRAIN loss  2.2991 | TRAIN Acc:  19.07% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:33:38,977] Gradient total norm was 1.2370489835739136. Clipping to 0.25.
[2023-03-17 16:33:38,980] Step: 7   | lr: 0.0140 | Time: 13.93s |TRAIN loss  2.2941 | TRAIN Acc:  19.06% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:33:52,863] Gradient total norm was 2.0315122604370117. Clipping to 0.25.
[2023-03-17 16:33:52,866] Step: 8   | lr: 0.0160 | Time: 13.87s |TRAIN loss  2.2878 | TRAIN Acc:  19.30% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:34:06,770] Gradient total norm was 1.9456243515014648. Clipping to 0.25.
[2023-03-17 16:34:06,774] Step: 9   | lr: 0.0180 | Time: 13.89s |TRAIN loss  2.2773 | TRAIN Acc:  20.09% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:34:20,731] Gradient total norm was 1.7546724081039429. Clipping to 0.25.
[2023-03-17 16:34:20,735] Step: 10  | lr: 0.0200 | Time: 13.95s |TRAIN loss  2.2660 | TRAIN Acc:  19.99% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:34:34,670] Gradient total norm was 1.7485449314117432. Clipping to 0.25.
[2023-03-17 16:34:34,674] Step: 11  | lr: 0.0220 | Time: 13.93s |TRAIN loss  2.2498 | TRAIN Acc:  19.97% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:34:48,578] Gradient total norm was 1.810752511024475. Clipping to 0.25.
[2023-03-17 16:34:48,581] Step: 12  | lr: 0.0240 | Time: 13.89s |TRAIN loss  2.2306 | TRAIN Acc:  20.27% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:35:02,546] Gradient total norm was 1.9264293909072876. Clipping to 0.25.
[2023-03-17 16:35:02,550] Step: 13  | lr: 0.0260 | Time: 13.96s |TRAIN loss  2.2116 | TRAIN Acc:  19.95% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:35:16,465] Gradient total norm was 1.7775858640670776. Clipping to 0.25.
[2023-03-17 16:35:16,468] Step: 14  | lr: 0.0280 | Time: 13.90s |TRAIN loss  2.1860 | TRAIN Acc:  20.48% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:35:30,412] Gradient total norm was 1.7184243202209473. Clipping to 0.25.
[2023-03-17 16:35:30,416] Step: 15  | lr: 0.0300 | Time: 13.93s |TRAIN loss  2.1602 | TRAIN Acc:  20.32% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:35:44,288] Gradient total norm was 1.5059336423873901. Clipping to 0.25.
[2023-03-17 16:35:44,291] Step: 16  | lr: 0.0320 | Time: 13.86s |TRAIN loss  2.1323 | TRAIN Acc:  20.73% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:35:58,233] Gradient total norm was 1.4615808725357056. Clipping to 0.25.
[2023-03-17 16:35:58,236] Step: 17  | lr: 0.0340 | Time: 13.93s |TRAIN loss  2.1047 | TRAIN Acc:  20.52% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:36:12,121] Gradient total norm was 1.3708442449569702. Clipping to 0.25.
[2023-03-17 16:36:12,125] Step: 18  | lr: 0.0360 | Time: 13.88s |TRAIN loss  2.0790 | TRAIN Acc:  21.37% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:36:26,057] Gradient total norm was 1.6311135292053223. Clipping to 0.25.
[2023-03-17 16:36:26,060] Step: 19  | lr: 0.0380 | Time: 13.92s |TRAIN loss  2.0587 | TRAIN Acc:  21.66% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:36:40,051] Gradient total norm was 1.4428656101226807. Clipping to 0.25.
[2023-03-17 16:36:40,055] Step: 20  | lr: 0.0400 | Time: 13.98s |TRAIN loss  2.0401 | TRAIN Acc:  22.35% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:36:53,997] Gradient total norm was 1.2590843439102173. Clipping to 0.25.
[2023-03-17 16:36:54,000] Step: 21  | lr: 0.0420 | Time: 13.93s |TRAIN loss  2.0228 | TRAIN Acc:  22.67% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:37:07,953] Gradient total norm was 1.3984352350234985. Clipping to 0.25.
[2023-03-17 16:37:07,956] Step: 22  | lr: 0.0440 | Time: 13.94s |TRAIN loss  2.0080 | TRAIN Acc:  23.14% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:37:21,900] Gradient total norm was 1.0323050022125244. Clipping to 0.25.
[2023-03-17 16:37:21,903] Step: 23  | lr: 0.0460 | Time: 13.93s |TRAIN loss  1.9934 | TRAIN Acc:  23.93% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:37:35,864] Gradient total norm was 2.657058000564575. Clipping to 0.25.
[2023-03-17 16:37:35,868] Step: 24  | lr: 0.0480 | Time: 13.95s |TRAIN loss  1.9797 | TRAIN Acc:  24.81% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:37:49,796] Gradient total norm was 0.8384185433387756. Clipping to 0.25.
[2023-03-17 16:37:49,800] Step: 25  | lr: 0.0500 | Time: 13.92s |TRAIN loss  1.9666 | TRAIN Acc:  25.28% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:38:03,757] Gradient total norm was 1.5666393041610718. Clipping to 0.25.
[2023-03-17 16:38:03,760] Step: 26  | lr: 0.0520 | Time: 13.95s |TRAIN loss  1.9499 | TRAIN Acc:  26.25% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:38:17,674] Gradient total norm was 1.3005256652832031. Clipping to 0.25.
[2023-03-17 16:38:17,677] Step: 27  | lr: 0.0540 | Time: 13.90s |TRAIN loss  1.9384 | TRAIN Acc:  26.61% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:38:31,603] Gradient total norm was 1.394182562828064. Clipping to 0.25.
[2023-03-17 16:38:31,606] Step: 28  | lr: 0.0560 | Time: 13.92s |TRAIN loss  1.9233 | TRAIN Acc:  27.34% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:38:45,551] Gradient total norm was 1.5023971796035767. Clipping to 0.25.
[2023-03-17 16:38:45,554] Step: 29  | lr: 0.0580 | Time: 13.93s |TRAIN loss  1.9113 | TRAIN Acc:  27.96% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:38:59,543] Gradient total norm was 1.3931149244308472. Clipping to 0.25.
[2023-03-17 16:38:59,547] Step: 30  | lr: 0.0600 | Time: 13.98s |TRAIN loss  1.8946 | TRAIN Acc:  28.62% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:39:13,548] Gradient total norm was 1.599443793296814. Clipping to 0.25.
[2023-03-17 16:39:13,551] Step: 31  | lr: 0.0620 | Time: 13.99s |TRAIN loss  1.8818 | TRAIN Acc:  29.13% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:39:27,479] Gradient total norm was 1.5356225967407227. Clipping to 0.25.
[2023-03-17 16:39:27,483] Step: 32  | lr: 0.0640 | Time: 13.92s |TRAIN loss  1.8672 | TRAIN Acc:  29.57% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:39:41,459] Gradient total norm was 1.613750696182251. Clipping to 0.25.
[2023-03-17 16:39:41,463] Step: 33  | lr: 0.0660 | Time: 13.97s |TRAIN loss  1.8547 | TRAIN Acc:  30.03% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:39:55,385] Gradient total norm was 1.8663522005081177. Clipping to 0.25.
[2023-03-17 16:39:55,389] Step: 34  | lr: 0.0680 | Time: 13.91s |TRAIN loss  1.8405 | TRAIN Acc:  30.25% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:40:09,374] Gradient total norm was 1.6131234169006348. Clipping to 0.25.
[2023-03-17 16:40:09,378] Step: 35  | lr: 0.0700 | Time: 13.98s |TRAIN loss  1.8281 | TRAIN Acc:  30.76% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:40:23,264] Gradient total norm was 1.8610376119613647. Clipping to 0.25.
[2023-03-17 16:40:23,267] Step: 36  | lr: 0.0720 | Time: 13.88s |TRAIN loss  1.8163 | TRAIN Acc:  31.01% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:40:37,262] Gradient total norm was 1.4970929622650146. Clipping to 0.25.
[2023-03-17 16:40:37,266] Step: 37  | lr: 0.0740 | Time: 13.98s |TRAIN loss  1.8051 | TRAIN Acc:  31.51% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:40:51,167] Gradient total norm was 1.880695104598999. Clipping to 0.25.
[2023-03-17 16:40:51,171] Step: 38  | lr: 0.0760 | Time: 13.89s |TRAIN loss  1.7927 | TRAIN Acc:  31.73% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:41:05,080] Gradient total norm was 1.3644212484359741. Clipping to 0.25.
[2023-03-17 16:41:05,083] Step: 39  | lr: 0.0780 | Time: 13.90s |TRAIN loss  1.7804 | TRAIN Acc:  32.22% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:41:19,094] Gradient total norm was 1.7255864143371582. Clipping to 0.25.
[2023-03-17 16:41:19,097] Step: 40  | lr: 0.0800 | Time: 14.00s |TRAIN loss  1.7677 | TRAIN Acc:  32.47% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:41:33,051] Gradient total norm was 1.4127120971679688. Clipping to 0.25.
[2023-03-17 16:41:33,055] Step: 41  | lr: 0.0820 | Time: 13.94s |TRAIN loss  1.7554 | TRAIN Acc:  33.04% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:41:47,007] Gradient total norm was 1.6717923879623413. Clipping to 0.25.
[2023-03-17 16:41:47,010] Step: 42  | lr: 0.0840 | Time: 13.94s |TRAIN loss  1.7434 | TRAIN Acc:  33.54% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:42:00,928] Gradient total norm was 1.5822150707244873. Clipping to 0.25.
[2023-03-17 16:42:00,931] Step: 43  | lr: 0.0860 | Time: 13.91s |TRAIN loss  1.7330 | TRAIN Acc:  34.01% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:42:14,931] Gradient total norm was 2.1601381301879883. Clipping to 0.25.
[2023-03-17 16:42:14,934] Step: 44  | lr: 0.0880 | Time: 13.99s |TRAIN loss  1.7249 | TRAIN Acc:  34.74% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:42:28,921] Gradient total norm was 2.2012064456939697. Clipping to 0.25.
[2023-03-17 16:42:28,924] Step: 45  | lr: 0.0900 | Time: 13.98s |TRAIN loss  1.7153 | TRAIN Acc:  34.77% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:42:42,903] Gradient total norm was 1.8115264177322388. Clipping to 0.25.
[2023-03-17 16:42:42,906] Step: 46  | lr: 0.0920 | Time: 13.97s |TRAIN loss  1.7068 | TRAIN Acc:  35.67% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:42:56,899] Gradient total norm was 1.8577587604522705. Clipping to 0.25.
[2023-03-17 16:42:56,902] Step: 47  | lr: 0.0940 | Time: 13.98s |TRAIN loss  1.7000 | TRAIN Acc:  35.61% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:43:10,853] Gradient total norm was 1.5418174266815186. Clipping to 0.25.
[2023-03-17 16:43:10,857] Step: 48  | lr: 0.0960 | Time: 13.94s |TRAIN loss  1.6863 | TRAIN Acc:  36.74% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:43:24,782] Gradient total norm was 1.8044301271438599. Clipping to 0.25.
[2023-03-17 16:43:24,786] Step: 49  | lr: 0.0980 | Time: 13.92s |TRAIN loss  1.6806 | TRAIN Acc:  36.50% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:43:38,704] Gradient total norm was 1.4124290943145752. Clipping to 0.25.
[2023-03-17 16:43:38,708] Step: 50  | lr: 0.1000 | Time: 13.91s |TRAIN loss  1.6688 | TRAIN Acc:  37.54% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:43:52,703] Gradient total norm was 1.7581206560134888. Clipping to 0.25.
[2023-03-17 16:43:52,706] Step: 51  | lr: 0.1020 | Time: 13.99s |TRAIN loss  1.6607 | TRAIN Acc:  37.47% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:44:06,662] Gradient total norm was 1.371421217918396. Clipping to 0.25.
[2023-03-17 16:44:06,666] Step: 52  | lr: 0.1040 | Time: 13.95s |TRAIN loss  1.6493 | TRAIN Acc:  38.45% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:44:20,761] Gradient total norm was 1.7023570537567139. Clipping to 0.25.
[2023-03-17 16:44:20,764] Step: 53  | lr: 0.1060 | Time: 14.09s |TRAIN loss  1.6406 | TRAIN Acc:  38.35% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:44:34,712] Gradient total norm was 1.4594290256500244. Clipping to 0.25.
[2023-03-17 16:44:34,715] Step: 54  | lr: 0.1080 | Time: 13.94s |TRAIN loss  1.6309 | TRAIN Acc:  39.14% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:44:48,690] Gradient total norm was 1.7490758895874023. Clipping to 0.25.
[2023-03-17 16:44:48,693] Step: 55  | lr: 0.1100 | Time: 13.96s |TRAIN loss  1.6230 | TRAIN Acc:  38.93% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:45:02,575] Gradient total norm was 1.5142054557800293. Clipping to 0.25.
[2023-03-17 16:45:02,579] Step: 56  | lr: 0.1120 | Time: 13.87s |TRAIN loss  1.6134 | TRAIN Acc:  39.66% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:45:16,532] Gradient total norm was 1.6476460695266724. Clipping to 0.25.
[2023-03-17 16:45:16,535] Step: 57  | lr: 0.1140 | Time: 13.94s |TRAIN loss  1.6049 | TRAIN Acc:  40.11% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:45:30,488] Gradient total norm was 1.370590329170227. Clipping to 0.25.
[2023-03-17 16:45:30,492] Step: 58  | lr: 0.1160 | Time: 13.94s |TRAIN loss  1.5970 | TRAIN Acc:  40.48% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:45:44,431] Gradient total norm was 1.444083571434021. Clipping to 0.25.
[2023-03-17 16:45:44,434] Step: 59  | lr: 0.1180 | Time: 13.93s |TRAIN loss  1.5850 | TRAIN Acc:  40.93% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:45:58,442] Gradient total norm was 1.331994891166687. Clipping to 0.25.
[2023-03-17 16:45:58,446] Step: 60  | lr: 0.1200 | Time: 14.00s |TRAIN loss  1.5757 | TRAIN Acc:  41.49% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:46:12,391] Gradient total norm was 1.3906259536743164. Clipping to 0.25.
[2023-03-17 16:46:12,394] Step: 61  | lr: 0.1220 | Time: 13.93s |TRAIN loss  1.5654 | TRAIN Acc:  41.79% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:46:26,355] Gradient total norm was 1.7647998332977295. Clipping to 0.25.
[2023-03-17 16:46:26,358] Step: 62  | lr: 0.1240 | Time: 13.95s |TRAIN loss  1.5604 | TRAIN Acc:  42.04% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:46:40,294] Gradient total norm was 2.093003511428833. Clipping to 0.25.
[2023-03-17 16:46:40,297] Step: 63  | lr: 0.1260 | Time: 13.93s |TRAIN loss  1.5546 | TRAIN Acc:  41.95% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:46:54,280] Gradient total norm was 1.791807770729065. Clipping to 0.25.
[2023-03-17 16:46:54,283] Step: 64  | lr: 0.1280 | Time: 13.97s |TRAIN loss  1.5432 | TRAIN Acc:  42.53% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:47:08,425] Gradient total norm was 1.8013628721237183. Clipping to 0.25.
[2023-03-17 16:47:08,428] Step: 65  | lr: 0.1300 | Time: 14.13s |TRAIN loss  1.5351 | TRAIN Acc:  43.19% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:47:22,405] Gradient total norm was 1.8172311782836914. Clipping to 0.25.
[2023-03-17 16:47:22,409] Step: 66  | lr: 0.1320 | Time: 13.97s |TRAIN loss  1.5302 | TRAIN Acc:  43.02% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:47:36,395] Gradient total norm was 1.5889440774917603. Clipping to 0.25.
[2023-03-17 16:47:36,398] Step: 67  | lr: 0.1340 | Time: 13.98s |TRAIN loss  1.5204 | TRAIN Acc:  43.97% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:47:50,391] Gradient total norm was 1.7940057516098022. Clipping to 0.25.
[2023-03-17 16:47:50,394] Step: 68  | lr: 0.1360 | Time: 13.98s |TRAIN loss  1.5118 | TRAIN Acc:  44.09% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:48:04,344] Gradient total norm was 1.49419105052948. Clipping to 0.25.
[2023-03-17 16:48:04,347] Step: 69  | lr: 0.1380 | Time: 13.94s |TRAIN loss  1.5024 | TRAIN Acc:  44.98% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:48:18,292] Gradient total norm was 1.7868895530700684. Clipping to 0.25.
[2023-03-17 16:48:18,296] Step: 70  | lr: 0.1400 | Time: 13.94s |TRAIN loss  1.4935 | TRAIN Acc:  44.73% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:48:32,299] Gradient total norm was 1.5477038621902466. Clipping to 0.25.
[2023-03-17 16:48:32,303] Step: 71  | lr: 0.1420 | Time: 13.99s |TRAIN loss  1.4840 | TRAIN Acc:  45.73% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:48:46,267] Gradient total norm was 1.7751219272613525. Clipping to 0.25.
[2023-03-17 16:48:46,270] Step: 72  | lr: 0.1440 | Time: 13.95s |TRAIN loss  1.4798 | TRAIN Acc:  45.41% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:49:00,284] Gradient total norm was 1.5148119926452637. Clipping to 0.25.
[2023-03-17 16:49:00,288] Step: 73  | lr: 0.1460 | Time: 14.00s |TRAIN loss  1.4683 | TRAIN Acc:  46.49% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:49:14,251] Gradient total norm was 1.8335028886795044. Clipping to 0.25.
[2023-03-17 16:49:14,255] Step: 74  | lr: 0.1480 | Time: 13.95s |TRAIN loss  1.4629 | TRAIN Acc:  46.34% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:49:28,305] Gradient total norm was 1.5598437786102295. Clipping to 0.25.
[2023-03-17 16:49:28,309] Step: 75  | lr: 0.1500 | Time: 14.04s |TRAIN loss  1.4517 | TRAIN Acc:  47.13% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:49:42,279] Gradient total norm was 2.1570019721984863. Clipping to 0.25.
[2023-03-17 16:49:42,283] Step: 76  | lr: 0.1520 | Time: 13.96s |TRAIN loss  1.4485 | TRAIN Acc:  47.09% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:49:56,263] Gradient total norm was 1.3435927629470825. Clipping to 0.25.
[2023-03-17 16:49:56,266] Step: 77  | lr: 0.1540 | Time: 13.97s |TRAIN loss  1.4402 | TRAIN Acc:  47.68% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:50:10,170] Gradient total norm was 1.7686933279037476. Clipping to 0.25.
[2023-03-17 16:50:10,173] Step: 78  | lr: 0.1560 | Time: 13.89s |TRAIN loss  1.4402 | TRAIN Acc:  47.63% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:50:24,100] Gradient total norm was 1.447666049003601. Clipping to 0.25.
[2023-03-17 16:50:24,103] Step: 79  | lr: 0.1580 | Time: 13.92s |TRAIN loss  1.4231 | TRAIN Acc:  48.24% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:50:38,160] Gradient total norm was 2.157994508743286. Clipping to 0.25.
[2023-03-17 16:50:38,164] Step: 80  | lr: 0.1600 | Time: 14.05s |TRAIN loss  1.4253 | TRAIN Acc:  48.39% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:50:52,135] Gradient total norm was 1.421282410621643. Clipping to 0.25.
[2023-03-17 16:50:52,138] Step: 81  | lr: 0.1620 | Time: 13.96s |TRAIN loss  1.4089 | TRAIN Acc:  48.75% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:51:06,100] Gradient total norm was 2.578092336654663. Clipping to 0.25.
[2023-03-17 16:51:06,103] Step: 82  | lr: 0.1640 | Time: 13.95s |TRAIN loss  1.4151 | TRAIN Acc:  48.87% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:51:20,008] Gradient total norm was 1.267398715019226. Clipping to 0.25.
[2023-03-17 16:51:20,011] Step: 83  | lr: 0.1660 | Time: 13.89s |TRAIN loss  1.3933 | TRAIN Acc:  49.50% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:51:33,966] Gradient total norm was 2.2029433250427246. Clipping to 0.25.
[2023-03-17 16:51:33,969] Step: 84  | lr: 0.1680 | Time: 13.94s |TRAIN loss  1.4045 | TRAIN Acc:  48.95% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:51:47,975] Gradient total norm was 1.0583442449569702. Clipping to 0.25.
[2023-03-17 16:51:47,978] Step: 85  | lr: 0.1700 | Time: 14.00s |TRAIN loss  1.3802 | TRAIN Acc:  50.19% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:52:01,979] Gradient total norm was 2.619593381881714. Clipping to 0.25.
[2023-03-17 16:52:01,983] Step: 86  | lr: 0.1720 | Time: 13.99s |TRAIN loss  1.3938 | TRAIN Acc:  49.43% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:52:15,925] Gradient total norm was 0.9609731435775757. Clipping to 0.25.
[2023-03-17 16:52:15,928] Step: 87  | lr: 0.1740 | Time: 13.93s |TRAIN loss  1.3604 | TRAIN Acc:  51.11% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:52:29,869] Gradient total norm was 3.266265630722046. Clipping to 0.25.
[2023-03-17 16:52:29,873] Step: 88  | lr: 0.1760 | Time: 13.93s |TRAIN loss  1.3814 | TRAIN Acc:  49.73% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:52:43,879] Gradient total norm was 0.7779541611671448. Clipping to 0.25.
[2023-03-17 16:52:43,882] Step: 89  | lr: 0.1780 | Time: 14.00s |TRAIN loss  1.3447 | TRAIN Acc:  51.67% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:52:57,873] Gradient total norm was 4.916798114776611. Clipping to 0.25.
[2023-03-17 16:52:57,876] Step: 90  | lr: 0.1800 | Time: 13.98s |TRAIN loss  1.3611 | TRAIN Acc:  50.63% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:53:11,913] Gradient total norm was 1.5298885107040405. Clipping to 0.25.
[2023-03-17 16:53:11,916] Step: 91  | lr: 0.1820 | Time: 14.03s |TRAIN loss  1.3411 | TRAIN Acc:  51.91% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:53:25,951] Gradient total norm was 2.3066799640655518. Clipping to 0.25.
[2023-03-17 16:53:25,954] Step: 92  | lr: 0.1840 | Time: 14.02s |TRAIN loss  1.3509 | TRAIN Acc:  51.15% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:53:39,966] Gradient total norm was 1.2974259853363037. Clipping to 0.25.
[2023-03-17 16:53:39,969] Step: 93  | lr: 0.1860 | Time: 14.00s |TRAIN loss  1.3301 | TRAIN Acc:  52.10% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:53:53,895] Gradient total norm was 1.923190951347351. Clipping to 0.25.
[2023-03-17 16:53:53,899] Step: 94  | lr: 0.1880 | Time: 13.92s |TRAIN loss  1.3291 | TRAIN Acc:  52.07% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:54:07,912] Gradient total norm was 1.238983392715454. Clipping to 0.25.
[2023-03-17 16:54:07,915] Step: 95  | lr: 0.1900 | Time: 14.00s |TRAIN loss  1.3161 | TRAIN Acc:  52.68% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:54:21,852] Gradient total norm was 1.7150219678878784. Clipping to 0.25.
[2023-03-17 16:54:21,855] Step: 96  | lr: 0.1920 | Time: 13.93s |TRAIN loss  1.3118 | TRAIN Acc:  53.06% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:54:35,899] Gradient total norm was 1.5056593418121338. Clipping to 0.25.
[2023-03-17 16:54:35,903] Step: 97  | lr: 0.1940 | Time: 14.03s |TRAIN loss  1.3047 | TRAIN Acc:  53.32% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:54:49,835] Gradient total norm was 2.2716212272644043. Clipping to 0.25.
[2023-03-17 16:54:49,838] Step: 98  | lr: 0.1960 | Time: 13.92s |TRAIN loss  1.3023 | TRAIN Acc:  53.25% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:55:03,766] Gradient total norm was 1.517204761505127. Clipping to 0.25.
[2023-03-17 16:55:03,769] Step: 99  | lr: 0.1980 | Time: 13.92s |TRAIN loss  1.2889 | TRAIN Acc:  53.56% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:55:17,738] Gradient total norm was 1.8587255477905273. Clipping to 0.25.
[2023-03-17 16:55:17,742] Step: 100 | lr: 0.2000 | Time: 13.96s |TRAIN loss  1.2879 | TRAIN Acc:  53.70% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 16:55:31,716] Gradient total norm was 1.3596433401107788. Clipping to 0.25.
[2023-03-17 16:55:36,820] Step: 101 | lr: 0.2020 | Time: 13.96s |TRAIN loss  1.2770 | TRAIN Acc:  54.21% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 16:55:50,777] Gradient total norm was 1.7584835290908813. Clipping to 0.25.
[2023-03-17 16:55:50,781] Step: 102 | lr: 0.2040 | Time: 13.95s |TRAIN loss  1.2715 | TRAIN Acc:  54.35% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 16:56:04,729] Gradient total norm was 1.3777673244476318. Clipping to 0.25.
[2023-03-17 16:56:04,732] Step: 103 | lr: 0.2060 | Time: 13.94s |TRAIN loss  1.2583 | TRAIN Acc:  54.88% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 16:56:18,739] Gradient total norm was 1.8199878931045532. Clipping to 0.25.
[2023-03-17 16:56:18,742] Step: 104 | lr: 0.2080 | Time: 14.00s |TRAIN loss  1.2576 | TRAIN Acc:  54.97% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 16:56:32,712] Gradient total norm was 1.7385084629058838. Clipping to 0.25.
[2023-03-17 16:56:32,716] Step: 105 | lr: 0.2100 | Time: 13.96s |TRAIN loss  1.2473 | TRAIN Acc:  55.23% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 16:56:46,709] Gradient total norm was 3.389596462249756. Clipping to 0.25.
[2023-03-17 16:56:46,713] Step: 106 | lr: 0.2120 | Time: 13.98s |TRAIN loss  1.2539 | TRAIN Acc:  54.89% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 16:57:00,671] Gradient total norm was 1.5069072246551514. Clipping to 0.25.
[2023-03-17 16:57:00,675] Step: 107 | lr: 0.2140 | Time: 13.95s |TRAIN loss  1.2426 | TRAIN Acc:  55.84% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 16:57:14,645] Gradient total norm was 1.6236406564712524. Clipping to 0.25.
[2023-03-17 16:57:14,648] Step: 108 | lr: 0.2160 | Time: 13.96s |TRAIN loss  1.2450 | TRAIN Acc:  55.27% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 16:57:28,641] Gradient total norm was 1.0489723682403564. Clipping to 0.25.
[2023-03-17 16:57:28,645] Step: 109 | lr: 0.2180 | Time: 13.98s |TRAIN loss  1.2297 | TRAIN Acc:  56.35% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 16:57:42,666] Gradient total norm was 1.7217628955841064. Clipping to 0.25.
[2023-03-17 16:57:42,669] Step: 110 | lr: 0.2200 | Time: 14.01s |TRAIN loss  1.2354 | TRAIN Acc:  55.38% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 16:57:56,640] Gradient total norm was 1.2465534210205078. Clipping to 0.25.
[2023-03-17 16:57:56,644] Step: 111 | lr: 0.2220 | Time: 13.96s |TRAIN loss  1.2163 | TRAIN Acc:  56.54% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 16:58:10,656] Gradient total norm was 1.9125728607177734. Clipping to 0.25.
[2023-03-17 16:58:10,659] Step: 112 | lr: 0.2240 | Time: 14.00s |TRAIN loss  1.2212 | TRAIN Acc:  55.81% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 16:58:24,651] Gradient total norm was 0.9009853601455688. Clipping to 0.25.
[2023-03-17 16:58:24,654] Step: 113 | lr: 0.2260 | Time: 13.98s |TRAIN loss  1.1996 | TRAIN Acc:  57.26% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 16:58:38,570] Gradient total norm was 1.7005151510238647. Clipping to 0.25.
[2023-03-17 16:58:38,573] Step: 114 | lr: 0.2280 | Time: 13.91s |TRAIN loss  1.2051 | TRAIN Acc:  56.58% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 16:58:52,556] Gradient total norm was 0.9988030195236206. Clipping to 0.25.
[2023-03-17 16:58:52,560] Step: 115 | lr: 0.2300 | Time: 13.97s |TRAIN loss  1.1808 | TRAIN Acc:  57.99% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 16:59:06,515] Gradient total norm was 2.08793306350708. Clipping to 0.25.
[2023-03-17 16:59:06,519] Step: 116 | lr: 0.2320 | Time: 13.95s |TRAIN loss  1.1951 | TRAIN Acc:  56.86% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 16:59:20,506] Gradient total norm was 1.215420126914978. Clipping to 0.25.
[2023-03-17 16:59:20,509] Step: 117 | lr: 0.2340 | Time: 13.98s |TRAIN loss  1.1672 | TRAIN Acc:  58.34% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 16:59:34,468] Gradient total norm was 2.8148245811462402. Clipping to 0.25.
[2023-03-17 16:59:34,471] Step: 118 | lr: 0.2360 | Time: 13.95s |TRAIN loss  1.1924 | TRAIN Acc:  56.79% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 16:59:48,435] Gradient total norm was 1.04111909866333. Clipping to 0.25.
[2023-03-17 16:59:48,439] Step: 119 | lr: 0.2380 | Time: 13.95s |TRAIN loss  1.1562 | TRAIN Acc:  59.02% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 17:00:02,419] Gradient total norm was 2.6805505752563477. Clipping to 0.25.
[2023-03-17 17:00:02,422] Step: 120 | lr: 0.2400 | Time: 13.97s |TRAIN loss  1.1790 | TRAIN Acc:  57.84% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 17:00:16,400] Gradient total norm was 1.2122893333435059. Clipping to 0.25.
[2023-03-17 17:00:16,403] Step: 121 | lr: 0.2420 | Time: 13.97s |TRAIN loss  1.1487 | TRAIN Acc:  59.36% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 17:00:30,375] Gradient total norm was 1.9022092819213867. Clipping to 0.25.
[2023-03-17 17:00:30,378] Step: 122 | lr: 0.2440 | Time: 13.96s |TRAIN loss  1.1640 | TRAIN Acc:  58.94% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 17:00:44,357] Gradient total norm was 0.8133624792098999. Clipping to 0.25.
[2023-03-17 17:00:44,360] Step: 123 | lr: 0.2460 | Time: 13.97s |TRAIN loss  1.1342 | TRAIN Acc:  59.82% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 17:00:58,323] Gradient total norm was 1.944072961807251. Clipping to 0.25.
[2023-03-17 17:00:58,326] Step: 124 | lr: 0.2480 | Time: 13.95s |TRAIN loss  1.1438 | TRAIN Acc:  59.44% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 17:01:12,264] Gradient total norm was 1.238255262374878. Clipping to 0.25.
[2023-03-17 17:01:12,267] Step: 125 | lr: 0.2500 | Time: 13.93s |TRAIN loss  1.1194 | TRAIN Acc:  60.23% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 17:01:26,331] Gradient total norm was 2.0349316596984863. Clipping to 0.25.
[2023-03-17 17:01:26,335] Step: 126 | lr: 0.2520 | Time: 14.05s |TRAIN loss  1.1333 | TRAIN Acc:  59.79% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 17:01:40,299] Gradient total norm was 0.9205543994903564. Clipping to 0.25.
[2023-03-17 17:01:40,303] Step: 127 | lr: 0.2540 | Time: 13.95s |TRAIN loss  1.1060 | TRAIN Acc:  61.04% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 17:01:54,310] Gradient total norm was 2.232943296432495. Clipping to 0.25.
[2023-03-17 17:01:54,314] Step: 128 | lr: 0.2560 | Time: 14.00s |TRAIN loss  1.1190 | TRAIN Acc:  59.93% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 17:02:08,278] Gradient total norm was 1.2274819612503052. Clipping to 0.25.
[2023-03-17 17:02:08,281] Step: 129 | lr: 0.2580 | Time: 13.95s |TRAIN loss  1.0902 | TRAIN Acc:  61.24% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 17:02:22,227] Gradient total norm was 2.4381725788116455. Clipping to 0.25.
[2023-03-17 17:02:22,230] Step: 130 | lr: 0.2600 | Time: 13.93s |TRAIN loss  1.1147 | TRAIN Acc:  60.27% |VAL loss  1.2865 | VAL Acc:  52.52% |
[2023-03-17 17:02:36,323] Gradient total norm was 0.8894580602645874. Clipping to 0.25.
[2023-03-17 17:02:36,326] Step: 131 | lr: 0.2620 | Time: 14.08s |TRAIN loss  1.0743 | TRAIN Acc:  62.07% |VAL loss  1.2865 | VAL Acc:  52.52% |
Killed
changhao@tensorlab-DGX-Station-A100-920-23487-2531-000:~$ nvidia-smi
Fri Mar 17 10:22:09 2023
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:01:00.0 Off |                    0 |
| N/A   34C    P0    64W / 275W |    495MiB / 81920MiB |      3%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA A100-SXM...  On   | 00000000:47:00.0 Off |                    0 |
| N/A   34C    P0    58W / 275W |      8MiB / 81920MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA A100-SXM...  On   | 00000000:81:00.0 Off |                    0 |
| N/A   34C    P0    62W / 275W |      8MiB / 81920MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA DGX Display  On   | 00000000:C1:00.0 Off |                  N/A |
| 35%   36C    P8    N/A /  50W |      8MiB /  4096MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   4  NVIDIA A100-SXM...  On   | 00000000:C2:00.0 Off |                    0 |
| N/A   35C    P0    64W / 275W |      8MiB / 81920MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      5418      G   /usr/lib/xorg/Xorg                  4MiB |
|    0   N/A  N/A    760714      C   python3                           493MiB |
|    1   N/A  N/A      5418      G   /usr/lib/xorg/Xorg                  4MiB |
|    2   N/A  N/A      5418      G   /usr/lib/xorg/Xorg                  4MiB |
|    3   N/A  N/A      5418      G   /usr/lib/xorg/Xorg                  4MiB |
|    4   N/A  N/A      5418      G   /usr/lib/xorg/Xorg                  4MiB |
+-----------------------------------------------------------------------------+
changhao@tensorlab-DGX-Station-A100-920-23487-2531-000:~$ docker ps
CONTAINER ID   IMAGE                                                       COMMAND                  CREATED             STATUS             PORTS                                                       NAMES
dff8a70d80ec   python                                                      "python3"                About an hour ago   Up About an hour                                                               python_base
1e1f968e47a8   fly-version                                                 "/opt/nvidia/nvidia_…"   13 hours ago        Up 13 hours        6006/tcp, 8888/tcp                                          inspiring_wing
00325ed1111c   moby/buildkit:buildx-stable-1                               "buildkitd"              41 hours ago        Up 41 hours                                                                    buildx_buildkit_mybuilder0
9ec3679ed483   fly-version                                                 "/opt/nvidia/nvidia_…"   2 days ago          Up 2 days          6006/tcp, 8888/tcp, 0.0.0.0:5002->80/tcp, :::5002->80/tcp   robert_test3
d6f6caf793bd   nvcr.io/nvidia/pytorch:22.07-py3                            "/opt/nvidia/nvidia_…"   5 days ago          Up 5 days          6006/tcp, 8888/tcp                                          laughing_robinson
07a086c41565   vsc-incremental-nn-4-eec81fdd1566e5b3d820d1c93f54f104-uid   "/bin/sh -c 'echo Co…"   5 days ago          Up 5 days          6006/tcp, 8888/tcp                                          stupefied_wescoff
changhao@tensorlab-DGX-Station-A100-920-23487-2531-000:~$ nvidia-smi
Fri Mar 17 10:27:15 2023
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:01:00.0 Off |                    0 |
| N/A   32C    P0    61W / 275W |      4MiB / 81920MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA A100-SXM...  On   | 00000000:47:00.0 Off |                    0 |
| N/A   33C    P0    58W / 275W |      4MiB / 81920MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA A100-SXM...  On   | 00000000:81:00.0 Off |                    0 |
| N/A   33C    P0    62W / 275W |      4MiB / 81920MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA DGX Display  On   | 00000000:C1:00.0 Off |                  N/A |
| 35%   36C    P8    N/A /  50W |      5MiB /  4096MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   4  NVIDIA A100-SXM...  On   | 00000000:C2:00.0 Off |                    0 |
| N/A   33C    P0    63W / 275W |      4MiB / 81920MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      5418      G   /usr/lib/xorg/Xorg                  4MiB |
|    1   N/A  N/A      5418      G   /usr/lib/xorg/Xorg                  4MiB |
|    2   N/A  N/A      5418      G   /usr/lib/xorg/Xorg                  4MiB |
|    3   N/A  N/A      5418      G   /usr/lib/xorg/Xorg                  4MiB |
|    4   N/A  N/A      5418      G   /usr/lib/xorg/Xorg                  4MiB |
+-----------------------------------------------------------------------------+
changhao@tensorlab-DGX-Station-A100-920-23487-2531-000:~$ docker run --gpus all deterministic

=============
== PyTorch ==
=============

NVIDIA Release 22.07 (build 40241807)
PyTorch Version 1.13.0a0+08820cb

Container image Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

Copyright (c) 2014-2022 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

[2023-03-17 17:27:36,122] ---------------------------------------------------
[2023-03-17 17:27:36,123] -----Launching full-batch computation job! --------
[2023-03-17 17:27:36,157] data:
  db:
    name: null
  name: CIFAR10
  path: ~/data
  size: 50000
  channels: 3
  classes: 10
  pixels: 32
  normalize: true
  mean:
  - 0.4914672374725342
  - 0.4822617471218109
  - 0.4467701315879822
  std:
  - 0.24703224003314972
  - 0.24348513782024384
  - 0.26158785820007324
  batch_size: 128
  augmentations_train:
    RandomCrop:
    - 32
    - 4
    RandomHorizontalFlip: 0.5
  augmentations_val: null
  caching: null
model:
  name: ResNet18
  depth: 18
  width: 64
  stem: CIFAR
  convolution: Standard
  nonlin_fn: ReLU
  normalization: BatchNorm2d
  downsample: C
  initialization: skip-residual
impl:
  setup:
    dist: false
    backend: nccl
    strategy: file_system
    world_size: null
    rank: null
    url: null
  dtype: float
  memory: contiguous
  non_blocking: true
  benchmark: true
  deterministic: false
  pin_memory: true
  threads: 8
  persistent_workers: true
  mixed_precision: false
  grad_scaling: false
  JIT: null
  accumulation_dtype: float
  validate_every_nth_step: 100
  checkpoint:
    name: null
    save_every_nth_step: 1
hyp:
  optim:
    name: Gradient Descent
    lr: 0.8
    momentum: 0.9
    weight_decay: 0.0005
    dampening: 0.0
    nesterov: true
    line_search: none
  optim_modification:
    name: none
  shuffle: false
  sample_with_replacement: false
  train_stochastic: false
  train_switch_stochastic: null
  train_semi_stochastic: false
  steps: 3000
  scheduler: cosine-4000
  stop_at_full_training_accuracy: 0
  warmup: 400
  only_linear_layers_weight_decay: false
  evaluate_ema: false
  eval_ema_momentum: 0.99
  grad_clip: 0.25
  batch_clip: null
  grad_clip_norm: 2
  grad_noise:
    additive: null
    multiplicative: null
  grad_reg:
    norm: 2
    block_strength: 0.5
    acc_strength: 0.0
    eps: 0.01
    implementation: forward-differences
  sub_batch: 128
  label_smoothing: 0.0
  loss_modification: null
  norm_bias:
    strength: 0.0
    norm_type: 1
    bias: 0
  test_time_flips: false
  template_name: fbgradreg
analysis:
  type: null
  check_every_nth_step: 10000000
  measure_param_norm: false
  measure_grad_norm: false
  check_momentum: false
  internal_batch_size_chunks: 1
  record_gradient_norm_per_batch: false
  compute_gradient_SNR: false
  compute_gradient_noise_scale: false
  compute_flatness: false
  flatness_step_size: 0.1
  flatness_threshold: 1.0
  flatness_norm: filter
  save_model_every_nth_step: null
viz:
  type: 1d
  database_name: null
  rebuild_existing_database: false
  compute_full_loss: true
  ignore_layers: biasbn
  norm: filter
  coordinates:
    x:
      min: -1
      max: 1
      num: 51
    'y':
      min: 0
      max: 0
      num: 1
  model_eval: true
  max_readers: 128
  readahead: true
  meminit: false
  max_spare_txns: 128
  map_size: 1000000000.0
base_dir: outputs
seed: 3651708989
name: fbaug_gradaug_lr08
dryrun: false

[2023-03-17 17:27:36,162] Platform: linux, Python: 3.8.13 | packaged by conda-forge |, PyTorch: 1.13.0a0+08820cb
[2023-03-17 17:27:36,162] CPUs: 64, GPUs: 5 on c0cfc51f413e.
[2023-03-17 17:27:36,169] GPU : NVIDIA A100-SXM4-80GB
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/data/cifar-10-python.tar.gz
100%|██████████| 170498071/170498071 [00:05<00:00, 31457807.41it/s]Extracting /root/data/cifar-10-python.tar.gz to /root/data
Files already downloaded and verified
sub identity init a conv1x1
sub identity init a conv1x1
sub identity init a conv1x1

[2023-03-17 17:28:10,178] Step: 1   | lr: 0.0020 | Time: 19.18s |TRAIN loss  2.3026 | TRAIN Acc:  10.01% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:28:23,939] Gradient total norm was 0.7184154987335205. Clipping to 0.25.
[2023-03-17 17:28:23,942] Step: 2   | lr: 0.0040 | Time: 13.75s |TRAIN loss  2.3026 | TRAIN Acc:  10.01% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:28:37,560] Gradient total norm was 0.6123294830322266. Clipping to 0.25.
[2023-03-17 17:28:37,564] Step: 3   | lr: 0.0060 | Time: 13.61s |TRAIN loss  2.3025 | TRAIN Acc:  16.93% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:28:51,141] Gradient total norm was 1.9066745042800903. Clipping to 0.25.
[2023-03-17 17:28:51,145] Step: 4   | lr: 0.0080 | Time: 13.57s |TRAIN loss  2.3023 | TRAIN Acc:  13.64% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:29:04,760] Gradient total norm was 1.0409955978393555. Clipping to 0.25.
[2023-03-17 17:29:04,763] Step: 5   | lr: 0.0100 | Time: 13.60s |TRAIN loss  2.3013 | TRAIN Acc:  18.57% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:29:18,346] Gradient total norm was 1.1493028402328491. Clipping to 0.25.
[2023-03-17 17:29:18,350] Step: 6   | lr: 0.0120 | Time: 13.57s |TRAIN loss  2.2989 | TRAIN Acc:  18.47% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:29:31,952] Gradient total norm was 1.131653070449829. Clipping to 0.25.
[2023-03-17 17:29:31,956] Step: 7   | lr: 0.0140 | Time: 13.59s |TRAIN loss  2.2944 | TRAIN Acc:  19.48% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:29:45,535] Gradient total norm was 1.5279407501220703. Clipping to 0.25.
[2023-03-17 17:29:45,539] Step: 8   | lr: 0.0160 | Time: 13.57s |TRAIN loss  2.2870 | TRAIN Acc:  19.74% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:29:59,168] Gradient total norm was 1.7986083030700684. Clipping to 0.25.
[2023-03-17 17:29:59,172] Step: 9   | lr: 0.0180 | Time: 13.62s |TRAIN loss  2.2768 | TRAIN Acc:  20.03% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:30:12,821] Gradient total norm was 1.7666999101638794. Clipping to 0.25.
[2023-03-17 17:30:12,824] Step: 10  | lr: 0.0200 | Time: 13.64s |TRAIN loss  2.2633 | TRAIN Acc:  20.40% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:30:26,484] Gradient total norm was 1.6786338090896606. Clipping to 0.25.
[2023-03-17 17:30:26,487] Step: 11  | lr: 0.0220 | Time: 13.65s |TRAIN loss  2.2486 | TRAIN Acc:  20.02% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:30:40,083] Gradient total norm was 1.7206133604049683. Clipping to 0.25.
[2023-03-17 17:30:40,087] Step: 12  | lr: 0.0240 | Time: 13.59s |TRAIN loss  2.2288 | TRAIN Acc:  20.79% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:30:53,728] Gradient total norm was 1.6156013011932373. Clipping to 0.25.
[2023-03-17 17:30:53,732] Step: 13  | lr: 0.0260 | Time: 13.63s |TRAIN loss  2.2079 | TRAIN Acc:  20.66% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:31:07,398] Gradient total norm was 1.7263052463531494. Clipping to 0.25.
[2023-03-17 17:31:07,401] Step: 14  | lr: 0.0280 | Time: 13.66s |TRAIN loss  2.1814 | TRAIN Acc:  21.05% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:31:21,016] Gradient total norm was 1.785780429840088. Clipping to 0.25.
[2023-03-17 17:31:21,019] Step: 15  | lr: 0.0300 | Time: 13.60s |TRAIN loss  2.1556 | TRAIN Acc:  20.94% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:31:34,691] Gradient total norm was 1.6148428916931152. Clipping to 0.25.
[2023-03-17 17:31:34,694] Step: 16  | lr: 0.0320 | Time: 13.66s |TRAIN loss  2.1268 | TRAIN Acc:  21.13% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:31:48,369] Gradient total norm was 1.4891507625579834. Clipping to 0.25.
[2023-03-17 17:31:48,372] Step: 17  | lr: 0.0340 | Time: 13.66s |TRAIN loss  2.1005 | TRAIN Acc:  21.30% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:32:02,089] Gradient total norm was 1.664723515510559. Clipping to 0.25.
[2023-03-17 17:32:02,092] Step: 18  | lr: 0.0360 | Time: 13.71s |TRAIN loss  2.0747 | TRAIN Acc:  21.41% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:32:15,772] Gradient total norm was 1.5421503782272339. Clipping to 0.25.
[2023-03-17 17:32:15,776] Step: 19  | lr: 0.0380 | Time: 13.67s |TRAIN loss  2.0546 | TRAIN Acc:  21.85% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:32:29,422] Gradient total norm was 1.19687020778656. Clipping to 0.25.
[2023-03-17 17:32:29,425] Step: 20  | lr: 0.0400 | Time: 13.64s |TRAIN loss  2.0345 | TRAIN Acc:  22.79% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:32:43,059] Gradient total norm was 1.168695330619812. Clipping to 0.25.
[2023-03-17 17:32:43,063] Step: 21  | lr: 0.0420 | Time: 13.62s |TRAIN loss  2.0179 | TRAIN Acc:  23.48% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:32:56,683] Gradient total norm was 1.842307448387146. Clipping to 0.25.
[2023-03-17 17:32:56,687] Step: 22  | lr: 0.0440 | Time: 13.61s |TRAIN loss  2.0003 | TRAIN Acc:  23.85% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:33:10,299] Gradient total norm was 0.974679172039032. Clipping to 0.25.
[2023-03-17 17:33:10,302] Step: 23  | lr: 0.0460 | Time: 13.60s |TRAIN loss  1.9881 | TRAIN Acc:  24.49% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:33:23,962] Gradient total norm was 1.5429002046585083. Clipping to 0.25.
[2023-03-17 17:33:23,965] Step: 24  | lr: 0.0480 | Time: 13.65s |TRAIN loss  1.9720 | TRAIN Acc:  25.38% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:33:37,628] Gradient total norm was 1.1205860376358032. Clipping to 0.25.
[2023-03-17 17:33:37,632] Step: 25  | lr: 0.0500 | Time: 13.65s |TRAIN loss  1.9588 | TRAIN Acc:  25.90% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:33:51,360] Gradient total norm was 1.473816156387329. Clipping to 0.25.
[2023-03-17 17:33:51,364] Step: 26  | lr: 0.0520 | Time: 13.72s |TRAIN loss  1.9442 | TRAIN Acc:  26.29% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:34:05,063] Gradient total norm was 1.2071409225463867. Clipping to 0.25.
[2023-03-17 17:34:05,066] Step: 27  | lr: 0.0540 | Time: 13.69s |TRAIN loss  1.9314 | TRAIN Acc:  27.23% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:34:18,725] Gradient total norm was 1.6619837284088135. Clipping to 0.25.
[2023-03-17 17:34:18,728] Step: 28  | lr: 0.0560 | Time: 13.65s |TRAIN loss  1.9181 | TRAIN Acc:  27.64% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:34:32,408] Gradient total norm was 1.4122408628463745. Clipping to 0.25.
[2023-03-17 17:34:32,411] Step: 29  | lr: 0.0580 | Time: 13.67s |TRAIN loss  1.9052 | TRAIN Acc:  28.43% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:34:46,123] Gradient total norm was 1.5213831663131714. Clipping to 0.25.
[2023-03-17 17:34:46,126] Step: 30  | lr: 0.0600 | Time: 13.70s |TRAIN loss  1.8917 | TRAIN Acc:  28.71% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:34:59,815] Gradient total norm was 1.5565603971481323. Clipping to 0.25.
[2023-03-17 17:34:59,819] Step: 31  | lr: 0.0620 | Time: 13.68s |TRAIN loss  1.8792 | TRAIN Acc:  29.65% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:35:13,548] Gradient total norm was 1.589202642440796. Clipping to 0.25.
[2023-03-17 17:35:13,552] Step: 32  | lr: 0.0640 | Time: 13.72s |TRAIN loss  1.8662 | TRAIN Acc:  29.69% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:35:27,251] Gradient total norm was 1.4954744577407837. Clipping to 0.25.
[2023-03-17 17:35:27,255] Step: 33  | lr: 0.0660 | Time: 13.69s |TRAIN loss  1.8551 | TRAIN Acc:  30.00% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:35:40,983] Gradient total norm was 1.6920093297958374. Clipping to 0.25.
[2023-03-17 17:35:40,987] Step: 34  | lr: 0.0680 | Time: 13.72s |TRAIN loss  1.8411 | TRAIN Acc:  30.59% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:35:54,668] Gradient total norm was 1.513547420501709. Clipping to 0.25.
[2023-03-17 17:35:54,671] Step: 35  | lr: 0.0700 | Time: 13.67s |TRAIN loss  1.8309 | TRAIN Acc:  30.93% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:36:08,385] Gradient total norm was 1.7709683179855347. Clipping to 0.25.
[2023-03-17 17:36:08,389] Step: 36  | lr: 0.0720 | Time: 13.70s |TRAIN loss  1.8181 | TRAIN Acc:  30.88% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:36:22,102] Gradient total norm was 1.3916287422180176. Clipping to 0.25.
[2023-03-17 17:36:22,106] Step: 37  | lr: 0.0740 | Time: 13.70s |TRAIN loss  1.8085 | TRAIN Acc:  31.56% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:36:35,777] Gradient total norm was 1.7844959497451782. Clipping to 0.25.
[2023-03-17 17:36:35,781] Step: 38  | lr: 0.0760 | Time: 13.66s |TRAIN loss  1.7963 | TRAIN Acc:  31.48% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:36:49,524] Gradient total norm was 1.4995094537734985. Clipping to 0.25.
[2023-03-17 17:36:49,528] Step: 39  | lr: 0.0780 | Time: 13.73s |TRAIN loss  1.7848 | TRAIN Acc:  32.22% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:37:03,244] Gradient total norm was 2.0750367641448975. Clipping to 0.25.
[2023-03-17 17:37:03,248] Step: 40  | lr: 0.0800 | Time: 13.71s |TRAIN loss  1.7765 | TRAIN Acc:  31.99% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:37:16,960] Gradient total norm was 1.7702088356018066. Clipping to 0.25.
[2023-03-17 17:37:16,963] Step: 41  | lr: 0.0820 | Time: 13.70s |TRAIN loss  1.7633 | TRAIN Acc:  33.16% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:37:30,653] Gradient total norm was 1.9079277515411377. Clipping to 0.25.
[2023-03-17 17:37:30,656] Step: 42  | lr: 0.0840 | Time: 13.68s |TRAIN loss  1.7537 | TRAIN Acc:  33.41% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:37:44,373] Gradient total norm was 1.5322858095169067. Clipping to 0.25.
[2023-03-17 17:37:44,377] Step: 43  | lr: 0.0860 | Time: 13.71s |TRAIN loss  1.7415 | TRAIN Acc:  34.12% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:37:58,084] Gradient total norm was 1.6587224006652832. Clipping to 0.25.
[2023-03-17 17:37:58,087] Step: 44  | lr: 0.0880 | Time: 13.70s |TRAIN loss  1.7331 | TRAIN Acc:  34.62% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:38:11,768] Gradient total norm was 1.443150520324707. Clipping to 0.25.
[2023-03-17 17:38:11,773] Step: 45  | lr: 0.0900 | Time: 13.67s |TRAIN loss  1.7204 | TRAIN Acc:  34.90% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:38:25,468] Gradient total norm was 1.7230165004730225. Clipping to 0.25.
[2023-03-17 17:38:25,472] Step: 46  | lr: 0.0920 | Time: 13.68s |TRAIN loss  1.7104 | TRAIN Acc:  35.70% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:38:39,147] Gradient total norm was 1.5108264684677124. Clipping to 0.25.
[2023-03-17 17:38:39,150] Step: 47  | lr: 0.0940 | Time: 13.66s |TRAIN loss  1.6977 | TRAIN Acc:  36.39% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:38:52,862] Gradient total norm was 1.9525675773620605. Clipping to 0.25.
[2023-03-17 17:38:52,865] Step: 48  | lr: 0.0960 | Time: 13.70s |TRAIN loss  1.6885 | TRAIN Acc:  36.63% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:39:06,528] Gradient total norm was 1.5833799839019775. Clipping to 0.25.
[2023-03-17 17:39:06,531] Step: 49  | lr: 0.0980 | Time: 13.65s |TRAIN loss  1.6755 | TRAIN Acc:  37.40% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:39:20,223] Gradient total norm was 2.0851829051971436. Clipping to 0.25.
[2023-03-17 17:39:20,226] Step: 50  | lr: 0.1000 | Time: 13.68s |TRAIN loss  1.6700 | TRAIN Acc:  37.35% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:39:33,902] Gradient total norm was 1.5201661586761475. Clipping to 0.25.
[2023-03-17 17:39:33,905] Step: 51  | lr: 0.1020 | Time: 13.67s |TRAIN loss  1.6573 | TRAIN Acc:  38.09% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:39:47,662] Gradient total norm was 1.9204081296920776. Clipping to 0.25.
[2023-03-17 17:39:47,665] Step: 52  | lr: 0.1040 | Time: 13.75s |TRAIN loss  1.6527 | TRAIN Acc:  38.07% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:40:01,367] Gradient total norm was 1.4764281511306763. Clipping to 0.25.
[2023-03-17 17:40:01,370] Step: 53  | lr: 0.1060 | Time: 13.69s |TRAIN loss  1.6387 | TRAIN Acc:  38.75% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:40:15,036] Gradient total norm was 1.7948417663574219. Clipping to 0.25.
[2023-03-17 17:40:15,039] Step: 54  | lr: 0.1080 | Time: 13.66s |TRAIN loss  1.6308 | TRAIN Acc:  39.14% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:40:28,769] Gradient total norm was 1.4485653638839722. Clipping to 0.25.
[2023-03-17 17:40:28,773] Step: 55  | lr: 0.1100 | Time: 13.72s |TRAIN loss  1.6203 | TRAIN Acc:  39.74% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:40:42,471] Gradient total norm was 1.7020074129104614. Clipping to 0.25.
[2023-03-17 17:40:42,474] Step: 56  | lr: 0.1120 | Time: 13.69s |TRAIN loss  1.6130 | TRAIN Acc:  39.86% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:40:56,189] Gradient total norm was 1.4142509698867798. Clipping to 0.25.
[2023-03-17 17:40:56,192] Step: 57  | lr: 0.1140 | Time: 13.70s |TRAIN loss  1.6019 | TRAIN Acc:  40.50% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:41:09,881] Gradient total norm was 1.6813234090805054. Clipping to 0.25.
[2023-03-17 17:41:09,885] Step: 58  | lr: 0.1160 | Time: 13.68s |TRAIN loss  1.5934 | TRAIN Acc:  40.32% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:41:23,615] Gradient total norm was 1.4848510026931763. Clipping to 0.25.
[2023-03-17 17:41:23,618] Step: 59  | lr: 0.1180 | Time: 13.72s |TRAIN loss  1.5850 | TRAIN Acc:  40.94% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:41:37,313] Gradient total norm was 1.753100872039795. Clipping to 0.25.
[2023-03-17 17:41:37,317] Step: 60  | lr: 0.1200 | Time: 13.68s |TRAIN loss  1.5781 | TRAIN Acc:  41.34% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:41:51,052] Gradient total norm was 1.5902202129364014. Clipping to 0.25.
[2023-03-17 17:41:51,056] Step: 61  | lr: 0.1220 | Time: 13.73s |TRAIN loss  1.5673 | TRAIN Acc:  41.81% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:42:04,689] Gradient total norm was 1.6868386268615723. Clipping to 0.25.
[2023-03-17 17:42:04,692] Step: 62  | lr: 0.1240 | Time: 13.62s |TRAIN loss  1.5586 | TRAIN Acc:  42.26% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:42:18,371] Gradient total norm was 1.5535045862197876. Clipping to 0.25.
[2023-03-17 17:42:18,374] Step: 63  | lr: 0.1260 | Time: 13.67s |TRAIN loss  1.5518 | TRAIN Acc:  42.56% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:42:32,063] Gradient total norm was 1.5788743495941162. Clipping to 0.25.
[2023-03-17 17:42:32,066] Step: 64  | lr: 0.1280 | Time: 13.68s |TRAIN loss  1.5408 | TRAIN Acc:  43.06% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:42:45,923] Gradient total norm was 1.5248316526412964. Clipping to 0.25.
[2023-03-17 17:42:45,926] Step: 65  | lr: 0.1300 | Time: 13.85s |TRAIN loss  1.5334 | TRAIN Acc:  43.30% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:42:59,578] Gradient total norm was 1.5815587043762207. Clipping to 0.25.
[2023-03-17 17:42:59,581] Step: 66  | lr: 0.1320 | Time: 13.64s |TRAIN loss  1.5233 | TRAIN Acc:  43.88% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:43:13,245] Gradient total norm was 1.7159923315048218. Clipping to 0.25.
[2023-03-17 17:43:13,248] Step: 67  | lr: 0.1340 | Time: 13.65s |TRAIN loss  1.5173 | TRAIN Acc:  44.12% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:43:26,913] Gradient total norm was 1.5523329973220825. Clipping to 0.25.
[2023-03-17 17:43:26,917] Step: 68  | lr: 0.1360 | Time: 13.65s |TRAIN loss  1.5072 | TRAIN Acc:  44.50% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:43:40,582] Gradient total norm was 1.8459439277648926. Clipping to 0.25.
[2023-03-17 17:43:40,586] Step: 69  | lr: 0.1380 | Time: 13.66s |TRAIN loss  1.4994 | TRAIN Acc:  44.59% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:43:54,245] Gradient total norm was 1.7731945514678955. Clipping to 0.25.
[2023-03-17 17:43:54,248] Step: 70  | lr: 0.1400 | Time: 13.65s |TRAIN loss  1.4915 | TRAIN Acc:  45.27% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:44:07,942] Gradient total norm was 1.8916212320327759. Clipping to 0.25.
[2023-03-17 17:44:07,945] Step: 71  | lr: 0.1420 | Time: 13.68s |TRAIN loss  1.4830 | TRAIN Acc:  45.46% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:44:21,617] Gradient total norm was 1.5548421144485474. Clipping to 0.25.
[2023-03-17 17:44:21,620] Step: 72  | lr: 0.1440 | Time: 13.66s |TRAIN loss  1.4763 | TRAIN Acc:  46.03% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:44:35,352] Gradient total norm was 1.8012583255767822. Clipping to 0.25.
[2023-03-17 17:44:35,355] Step: 73  | lr: 0.1460 | Time: 13.72s |TRAIN loss  1.4694 | TRAIN Acc:  45.99% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:44:49,050] Gradient total norm was 1.5016652345657349. Clipping to 0.25.
[2023-03-17 17:44:49,054] Step: 74  | lr: 0.1480 | Time: 13.68s |TRAIN loss  1.4597 | TRAIN Acc:  46.93% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:45:02,808] Gradient total norm was 1.8310587406158447. Clipping to 0.25.
[2023-03-17 17:45:02,811] Step: 75  | lr: 0.1500 | Time: 13.74s |TRAIN loss  1.4538 | TRAIN Acc:  46.77% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:45:16,446] Gradient total norm was 1.3991996049880981. Clipping to 0.25.
[2023-03-17 17:45:16,449] Step: 76  | lr: 0.1520 | Time: 13.62s |TRAIN loss  1.4425 | TRAIN Acc:  47.54% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:45:30,153] Gradient total norm was 1.4913877248764038. Clipping to 0.25.
[2023-03-17 17:45:30,156] Step: 77  | lr: 0.1540 | Time: 13.69s |TRAIN loss  1.4366 | TRAIN Acc:  47.59% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:45:43,836] Gradient total norm was 1.3266302347183228. Clipping to 0.25.
[2023-03-17 17:45:43,840] Step: 78  | lr: 0.1560 | Time: 13.67s |TRAIN loss  1.4259 | TRAIN Acc:  48.28% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:45:57,515] Gradient total norm was 1.7089866399765015. Clipping to 0.25.
[2023-03-17 17:45:57,518] Step: 79  | lr: 0.1580 | Time: 13.66s |TRAIN loss  1.4186 | TRAIN Acc:  48.25% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:46:11,192] Gradient total norm was 1.703475832939148. Clipping to 0.25.
[2023-03-17 17:46:11,195] Step: 80  | lr: 0.1600 | Time: 13.66s |TRAIN loss  1.4089 | TRAIN Acc:  49.02% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:46:24,877] Gradient total norm was 2.0296640396118164. Clipping to 0.25.
[2023-03-17 17:46:24,880] Step: 81  | lr: 0.1620 | Time: 13.67s |TRAIN loss  1.4054 | TRAIN Acc:  48.81% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:46:38,595] Gradient total norm was 2.605937957763672. Clipping to 0.25.
[2023-03-17 17:46:38,598] Step: 82  | lr: 0.1640 | Time: 13.70s |TRAIN loss  1.3996 | TRAIN Acc:  49.32% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:46:52,256] Gradient total norm was 1.3853873014450073. Clipping to 0.25.
[2023-03-17 17:46:52,260] Step: 83  | lr: 0.1660 | Time: 13.65s |TRAIN loss  1.3935 | TRAIN Acc:  49.76% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:47:05,979] Gradient total norm was 1.5044420957565308. Clipping to 0.25.
[2023-03-17 17:47:05,983] Step: 84  | lr: 0.1680 | Time: 13.71s |TRAIN loss  1.3914 | TRAIN Acc:  49.53% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:47:19,708] Gradient total norm was 1.066447138786316. Clipping to 0.25.
[2023-03-17 17:47:19,712] Step: 85  | lr: 0.1700 | Time: 13.72s |TRAIN loss  1.3746 | TRAIN Acc:  50.47% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:47:33,430] Gradient total norm was 2.008758068084717. Clipping to 0.25.
[2023-03-17 17:47:33,433] Step: 86  | lr: 0.1720 | Time: 13.71s |TRAIN loss  1.3823 | TRAIN Acc:  49.83% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:47:47,170] Gradient total norm was 1.3643256425857544. Clipping to 0.25.
[2023-03-17 17:47:47,174] Step: 87  | lr: 0.1740 | Time: 13.73s |TRAIN loss  1.3615 | TRAIN Acc:  50.92% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:48:00,854] Gradient total norm was 2.1345553398132324. Clipping to 0.25.
[2023-03-17 17:48:00,857] Step: 88  | lr: 0.1760 | Time: 13.67s |TRAIN loss  1.3647 | TRAIN Acc:  50.84% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:48:14,555] Gradient total norm was 1.4065638780593872. Clipping to 0.25.
[2023-03-17 17:48:14,558] Step: 89  | lr: 0.1780 | Time: 13.69s |TRAIN loss  1.3439 | TRAIN Acc:  51.47% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:48:28,195] Gradient total norm was 2.1367082595825195. Clipping to 0.25.
[2023-03-17 17:48:28,199] Step: 90  | lr: 0.1800 | Time: 13.63s |TRAIN loss  1.3515 | TRAIN Acc:  51.50% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:48:41,951] Gradient total norm was 1.2735410928726196. Clipping to 0.25.
[2023-03-17 17:48:41,954] Step: 91  | lr: 0.1820 | Time: 13.74s |TRAIN loss  1.3282 | TRAIN Acc:  52.15% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:48:55,625] Gradient total norm was 2.2841849327087402. Clipping to 0.25.
[2023-03-17 17:48:55,628] Step: 92  | lr: 0.1840 | Time: 13.66s |TRAIN loss  1.3361 | TRAIN Acc:  52.05% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:49:09,374] Gradient total norm was 1.0870252847671509. Clipping to 0.25.
[2023-03-17 17:49:09,377] Step: 93  | lr: 0.1860 | Time: 13.74s |TRAIN loss  1.3125 | TRAIN Acc:  52.70% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:49:23,091] Gradient total norm was 2.0030558109283447. Clipping to 0.25.
[2023-03-17 17:49:23,095] Step: 94  | lr: 0.1880 | Time: 13.70s |TRAIN loss  1.3200 | TRAIN Acc:  52.48% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:49:36,896] Gradient total norm was 1.2443561553955078. Clipping to 0.25.
[2023-03-17 17:49:36,900] Step: 95  | lr: 0.1900 | Time: 13.79s |TRAIN loss  1.2971 | TRAIN Acc:  53.41% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:49:50,591] Gradient total norm was 1.9002182483673096. Clipping to 0.25.
[2023-03-17 17:49:50,594] Step: 96  | lr: 0.1920 | Time: 13.68s |TRAIN loss  1.3003 | TRAIN Acc:  53.50% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:50:04,264] Gradient total norm was 1.4438670873641968. Clipping to 0.25.
[2023-03-17 17:50:04,267] Step: 97  | lr: 0.1940 | Time: 13.66s |TRAIN loss  1.2836 | TRAIN Acc:  53.66% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:50:18,024] Gradient total norm was 1.9007716178894043. Clipping to 0.25.
[2023-03-17 17:50:18,028] Step: 98  | lr: 0.1960 | Time: 13.75s |TRAIN loss  1.2878 | TRAIN Acc:  53.97% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:50:31,716] Gradient total norm was 1.1765313148498535. Clipping to 0.25.
[2023-03-17 17:50:31,719] Step: 99  | lr: 0.1980 | Time: 13.68s |TRAIN loss  1.2718 | TRAIN Acc:  54.21% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:50:45,453] Gradient total norm was 1.5715548992156982. Clipping to 0.25.
[2023-03-17 17:50:45,457] Step: 100 | lr: 0.2000 | Time: 13.72s |TRAIN loss  1.2712 | TRAIN Acc:  54.78% |VAL loss  2.3026 | VAL Acc:  10.00% |
[2023-03-17 17:50:59,165] Gradient total norm was 1.1198487281799316. Clipping to 0.25.
[2023-03-17 17:51:04,599] Step: 101 | lr: 0.2020 | Time: 13.70s |TRAIN loss  1.2564 | TRAIN Acc:  55.04% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:51:18,315] Gradient total norm was 1.5688389539718628. Clipping to 0.25.
[2023-03-17 17:51:18,318] Step: 102 | lr: 0.2040 | Time: 13.71s |TRAIN loss  1.2554 | TRAIN Acc:  55.18% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:51:32,035] Gradient total norm was 1.2066208124160767. Clipping to 0.25.
[2023-03-17 17:51:32,038] Step: 103 | lr: 0.2060 | Time: 13.71s |TRAIN loss  1.2426 | TRAIN Acc:  55.28% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:51:45,737] Gradient total norm was 1.7677513360977173. Clipping to 0.25.
[2023-03-17 17:51:45,740] Step: 104 | lr: 0.2080 | Time: 13.69s |TRAIN loss  1.2402 | TRAIN Acc:  55.24% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:51:59,476] Gradient total norm was 1.4891977310180664. Clipping to 0.25.
[2023-03-17 17:51:59,479] Step: 105 | lr: 0.2100 | Time: 13.73s |TRAIN loss  1.2302 | TRAIN Acc:  56.07% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:52:13,188] Gradient total norm was 2.1914408206939697. Clipping to 0.25.
[2023-03-17 17:52:13,191] Step: 106 | lr: 0.2120 | Time: 13.70s |TRAIN loss  1.2341 | TRAIN Acc:  55.57% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:52:26,904] Gradient total norm was 1.3503981828689575. Clipping to 0.25.
[2023-03-17 17:52:26,908] Step: 107 | lr: 0.2140 | Time: 13.70s |TRAIN loss  1.2162 | TRAIN Acc:  56.72% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:52:40,641] Gradient total norm was 1.8711732625961304. Clipping to 0.25.
[2023-03-17 17:52:40,644] Step: 108 | lr: 0.2160 | Time: 13.72s |TRAIN loss  1.2218 | TRAIN Acc:  56.05% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:52:54,395] Gradient total norm was 1.0022779703140259. Clipping to 0.25.
[2023-03-17 17:52:54,399] Step: 109 | lr: 0.2180 | Time: 13.74s |TRAIN loss  1.2011 | TRAIN Acc:  57.15% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:53:08,093] Gradient total norm was 2.1144275665283203. Clipping to 0.25.
[2023-03-17 17:53:08,097] Step: 110 | lr: 0.2200 | Time: 13.68s |TRAIN loss  1.2096 | TRAIN Acc:  56.54% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:53:21,857] Gradient total norm was 1.2584471702575684. Clipping to 0.25.
[2023-03-17 17:53:21,861] Step: 111 | lr: 0.2220 | Time: 13.75s |TRAIN loss  1.1897 | TRAIN Acc:  57.78% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:53:35,557] Gradient total norm was 1.763535976409912. Clipping to 0.25.
[2023-03-17 17:53:35,560] Step: 112 | lr: 0.2240 | Time: 13.69s |TRAIN loss  1.1912 | TRAIN Acc:  57.44% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:53:49,282] Gradient total norm was 1.5753250122070312. Clipping to 0.25.
[2023-03-17 17:53:49,286] Step: 113 | lr: 0.2260 | Time: 13.71s |TRAIN loss  1.1808 | TRAIN Acc:  58.18% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:54:02,978] Gradient total norm was 1.7053898572921753. Clipping to 0.25.
[2023-03-17 17:54:02,981] Step: 114 | lr: 0.2280 | Time: 13.68s |TRAIN loss  1.1726 | TRAIN Acc:  58.21% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:54:16,718] Gradient total norm was 2.528062343597412. Clipping to 0.25.
[2023-03-17 17:54:16,721] Step: 115 | lr: 0.2300 | Time: 13.73s |TRAIN loss  1.1832 | TRAIN Acc:  57.72% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:54:30,413] Gradient total norm was 0.6834465265274048. Clipping to 0.25.
[2023-03-17 17:54:30,416] Step: 116 | lr: 0.2320 | Time: 13.68s |TRAIN loss  1.1564 | TRAIN Acc:  58.93% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:54:44,137] Gradient total norm was 2.870683193206787. Clipping to 0.25.
[2023-03-17 17:54:44,141] Step: 117 | lr: 0.2340 | Time: 13.71s |TRAIN loss  1.1705 | TRAIN Acc:  57.91% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:54:57,887] Gradient total norm was 0.7904532551765442. Clipping to 0.25.
[2023-03-17 17:54:57,891] Step: 118 | lr: 0.2360 | Time: 13.74s |TRAIN loss  1.1405 | TRAIN Acc:  59.50% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:55:11,601] Gradient total norm was 1.745202898979187. Clipping to 0.25.
[2023-03-17 17:55:11,605] Step: 119 | lr: 0.2380 | Time: 13.70s |TRAIN loss  1.1485 | TRAIN Acc:  59.39% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:55:25,365] Gradient total norm was 1.4546830654144287. Clipping to 0.25.
[2023-03-17 17:55:25,368] Step: 120 | lr: 0.2400 | Time: 13.75s |TRAIN loss  1.1313 | TRAIN Acc:  59.75% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:55:39,075] Gradient total norm was 1.7264978885650635. Clipping to 0.25.
[2023-03-17 17:55:39,078] Step: 121 | lr: 0.2420 | Time: 13.70s |TRAIN loss  1.1334 | TRAIN Acc:  59.96% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:55:52,781] Gradient total norm was 1.3856463432312012. Clipping to 0.25.
[2023-03-17 17:55:52,784] Step: 122 | lr: 0.2440 | Time: 13.69s |TRAIN loss  1.1172 | TRAIN Acc:  60.14% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:56:06,508] Gradient total norm was 1.7524263858795166. Clipping to 0.25.
[2023-03-17 17:56:06,512] Step: 123 | lr: 0.2460 | Time: 13.71s |TRAIN loss  1.1209 | TRAIN Acc:  60.06% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:56:20,203] Gradient total norm was 1.2734850645065308. Clipping to 0.25.
[2023-03-17 17:56:20,206] Step: 124 | lr: 0.2480 | Time: 13.68s |TRAIN loss  1.0980 | TRAIN Acc:  61.11% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:56:33,901] Gradient total norm was 1.6749097108840942. Clipping to 0.25.
[2023-03-17 17:56:33,904] Step: 125 | lr: 0.2500 | Time: 13.69s |TRAIN loss  1.1059 | TRAIN Acc:  60.32% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:56:47,605] Gradient total norm was 1.5039124488830566. Clipping to 0.25.
[2023-03-17 17:56:47,609] Step: 126 | lr: 0.2520 | Time: 13.69s |TRAIN loss  1.0885 | TRAIN Acc:  61.48% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:57:01,307] Gradient total norm was 1.9723783731460571. Clipping to 0.25.
[2023-03-17 17:57:01,310] Step: 127 | lr: 0.2540 | Time: 13.69s |TRAIN loss  1.1032 | TRAIN Acc:  60.94% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:57:15,017] Gradient total norm was 1.0070666074752808. Clipping to 0.25.
[2023-03-17 17:57:15,020] Step: 128 | lr: 0.2560 | Time: 13.70s |TRAIN loss  1.0796 | TRAIN Acc:  61.83% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:57:28,743] Gradient total norm was 1.885810375213623. Clipping to 0.25.
[2023-03-17 17:57:28,747] Step: 129 | lr: 0.2580 | Time: 13.71s |TRAIN loss  1.0887 | TRAIN Acc:  61.38% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:57:42,446] Gradient total norm was 0.9116290807723999. Clipping to 0.25.
[2023-03-17 17:57:42,449] Step: 130 | lr: 0.2600 | Time: 13.69s |TRAIN loss  1.0694 | TRAIN Acc:  62.26% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:57:56,183] Gradient total norm was 1.5748273134231567. Clipping to 0.25.
[2023-03-17 17:57:56,187] Step: 131 | lr: 0.2620 | Time: 13.72s |TRAIN loss  1.0726 | TRAIN Acc:  62.08% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:58:09,846] Gradient total norm was 1.123907208442688. Clipping to 0.25.
[2023-03-17 17:58:09,849] Step: 132 | lr: 0.2640 | Time: 13.65s |TRAIN loss  1.0559 | TRAIN Acc:  62.62% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:58:23,608] Gradient total norm was 1.5548163652420044. Clipping to 0.25.
[2023-03-17 17:58:23,612] Step: 133 | lr: 0.2660 | Time: 13.75s |TRAIN loss  1.0587 | TRAIN Acc:  62.51% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:58:37,299] Gradient total norm was 1.190160870552063. Clipping to 0.25.
[2023-03-17 17:58:37,303] Step: 134 | lr: 0.2680 | Time: 13.68s |TRAIN loss  1.0430 | TRAIN Acc:  63.43% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:58:51,030] Gradient total norm was 1.7063376903533936. Clipping to 0.25.
[2023-03-17 17:58:51,033] Step: 135 | lr: 0.2700 | Time: 13.72s |TRAIN loss  1.0493 | TRAIN Acc:  63.15% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:59:04,772] Gradient total norm was 1.1859188079833984. Clipping to 0.25.
[2023-03-17 17:59:04,775] Step: 136 | lr: 0.2720 | Time: 13.73s |TRAIN loss  1.0265 | TRAIN Acc:  63.77% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:59:18,448] Gradient total norm was 1.911600112915039. Clipping to 0.25.
[2023-03-17 17:59:18,451] Step: 137 | lr: 0.2740 | Time: 13.66s |TRAIN loss  1.0429 | TRAIN Acc:  63.32% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:59:32,185] Gradient total norm was 0.9889565110206604. Clipping to 0.25.
[2023-03-17 17:59:32,189] Step: 138 | lr: 0.2760 | Time: 13.72s |TRAIN loss  1.0129 | TRAIN Acc:  64.44% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:59:45,844] Gradient total norm was 1.9530925750732422. Clipping to 0.25.
[2023-03-17 17:59:45,848] Step: 139 | lr: 0.2780 | Time: 13.65s |TRAIN loss  1.0288 | TRAIN Acc:  63.61% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 17:59:59,520] Gradient total norm was 0.9920454025268555. Clipping to 0.25.
[2023-03-17 17:59:59,523] Step: 140 | lr: 0.2800 | Time: 13.66s |TRAIN loss  0.9977 | TRAIN Acc:  65.11% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:00:13,275] Gradient total norm was 2.0281944274902344. Clipping to 0.25.
[2023-03-17 18:00:13,279] Step: 141 | lr: 0.2820 | Time: 13.74s |TRAIN loss  1.0149 | TRAIN Acc:  64.54% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:00:26,922] Gradient total norm was 0.9177675247192383. Clipping to 0.25.
[2023-03-17 18:00:26,926] Step: 142 | lr: 0.2840 | Time: 13.63s |TRAIN loss  0.9844 | TRAIN Acc:  65.44% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:00:40,626] Gradient total norm was 2.29060959815979. Clipping to 0.25.
[2023-03-17 18:00:40,630] Step: 143 | lr: 0.2860 | Time: 13.69s |TRAIN loss  1.0052 | TRAIN Acc:  64.73% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:00:54,298] Gradient total norm was 0.7849754095077515. Clipping to 0.25.
[2023-03-17 18:00:54,301] Step: 144 | lr: 0.2880 | Time: 13.65s |TRAIN loss  0.9757 | TRAIN Acc:  65.96% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:01:08,003] Gradient total norm was 1.9069185256958008. Clipping to 0.25.
[2023-03-17 18:01:08,007] Step: 145 | lr: 0.2900 | Time: 13.69s |TRAIN loss  0.9987 | TRAIN Acc:  64.61% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:01:21,651] Gradient total norm was 0.6944236159324646. Clipping to 0.25.
[2023-03-17 18:01:21,654] Step: 146 | lr: 0.2920 | Time: 13.63s |TRAIN loss  0.9630 | TRAIN Acc:  66.38% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:01:35,344] Gradient total norm was 1.6213260889053345. Clipping to 0.25.
[2023-03-17 18:01:35,348] Step: 147 | lr: 0.2940 | Time: 13.68s |TRAIN loss  0.9763 | TRAIN Acc:  65.75% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:01:49,035] Gradient total norm was 0.8938091397285461. Clipping to 0.25.
[2023-03-17 18:01:49,039] Step: 148 | lr: 0.2960 | Time: 13.68s |TRAIN loss  0.9509 | TRAIN Acc:  66.80% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:02:02,745] Gradient total norm was 1.7419766187667847. Clipping to 0.25.
[2023-03-17 18:02:02,748] Step: 149 | lr: 0.2980 | Time: 13.70s |TRAIN loss  0.9639 | TRAIN Acc:  66.18% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:02:16,499] Gradient total norm was 1.0832780599594116. Clipping to 0.25.
[2023-03-17 18:02:16,503] Step: 150 | lr: 0.3000 | Time: 13.74s |TRAIN loss  0.9459 | TRAIN Acc:  67.00% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:02:30,205] Gradient total norm was 1.5281769037246704. Clipping to 0.25.
[2023-03-17 18:02:30,209] Step: 151 | lr: 0.3020 | Time: 13.69s |TRAIN loss  0.9487 | TRAIN Acc:  66.78% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:02:43,932] Gradient total norm was 1.0769474506378174. Clipping to 0.25.
[2023-03-17 18:02:43,936] Step: 152 | lr: 0.3040 | Time: 13.71s |TRAIN loss  0.9360 | TRAIN Acc:  67.58% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:02:57,639] Gradient total norm was 1.4387978315353394. Clipping to 0.25.
[2023-03-17 18:02:57,642] Step: 153 | lr: 0.3060 | Time: 13.69s |TRAIN loss  0.9371 | TRAIN Acc:  67.28% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:03:11,332] Gradient total norm was 1.0755382776260376. Clipping to 0.25.
[2023-03-17 18:03:11,336] Step: 154 | lr: 0.3080 | Time: 13.68s |TRAIN loss  0.9244 | TRAIN Acc:  68.19% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:03:24,994] Gradient total norm was 1.4511479139328003. Clipping to 0.25.
[2023-03-17 18:03:24,997] Step: 155 | lr: 0.3100 | Time: 13.65s |TRAIN loss  0.9245 | TRAIN Acc:  67.72% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:03:38,690] Gradient total norm was 1.1290926933288574. Clipping to 0.25.
[2023-03-17 18:03:38,694] Step: 156 | lr: 0.3120 | Time: 13.68s |TRAIN loss  0.9131 | TRAIN Acc:  68.39% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:03:52,389] Gradient total norm was 1.4232478141784668. Clipping to 0.25.
[2023-03-17 18:03:52,392] Step: 157 | lr: 0.3140 | Time: 13.69s |TRAIN loss  0.9145 | TRAIN Acc:  68.02% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:04:06,117] Gradient total norm was 1.047544240951538. Clipping to 0.25.
[2023-03-17 18:04:06,121] Step: 158 | lr: 0.3160 | Time: 13.71s |TRAIN loss  0.9003 | TRAIN Acc:  68.82% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:04:19,871] Gradient total norm was 1.3335307836532593. Clipping to 0.25.
[2023-03-17 18:04:19,874] Step: 159 | lr: 0.3180 | Time: 13.74s |TRAIN loss  0.9045 | TRAIN Acc:  68.36% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:04:33,521] Gradient total norm was 1.0201629400253296. Clipping to 0.25.
[2023-03-17 18:04:33,524] Step: 160 | lr: 0.3200 | Time: 13.64s |TRAIN loss  0.8917 | TRAIN Acc:  69.28% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:04:47,264] Gradient total norm was 1.3317140340805054. Clipping to 0.25.
[2023-03-17 18:04:47,267] Step: 161 | lr: 0.3220 | Time: 13.73s |TRAIN loss  0.8954 | TRAIN Acc:  68.95% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:05:00,949] Gradient total norm was 0.8417474031448364. Clipping to 0.25.
[2023-03-17 18:05:00,953] Step: 162 | lr: 0.3240 | Time: 13.67s |TRAIN loss  0.8821 | TRAIN Acc:  69.53% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:05:14,720] Gradient total norm was 1.2123397588729858. Clipping to 0.25.
[2023-03-17 18:05:14,723] Step: 163 | lr: 0.3260 | Time: 13.76s |TRAIN loss  0.8849 | TRAIN Acc:  69.29% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:05:28,376] Gradient total norm was 1.0582820177078247. Clipping to 0.25.
[2023-03-17 18:05:28,379] Step: 164 | lr: 0.3280 | Time: 13.64s |TRAIN loss  0.8766 | TRAIN Acc:  69.70% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:05:42,139] Gradient total norm was 1.2426667213439941. Clipping to 0.25.
[2023-03-17 18:05:42,143] Step: 165 | lr: 0.3300 | Time: 13.75s |TRAIN loss  0.8818 | TRAIN Acc:  69.68% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:05:55,854] Gradient total norm was 1.2549105882644653. Clipping to 0.25.
[2023-03-17 18:05:55,857] Step: 166 | lr: 0.3320 | Time: 13.70s |TRAIN loss  0.8706 | TRAIN Acc:  69.67% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:06:09,499] Gradient total norm was 1.3252276182174683. Clipping to 0.25.
[2023-03-17 18:06:09,503] Step: 167 | lr: 0.3340 | Time: 13.63s |TRAIN loss  0.8719 | TRAIN Acc:  70.00% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:06:23,264] Gradient total norm was 1.0827431678771973. Clipping to 0.25.
[2023-03-17 18:06:23,267] Step: 168 | lr: 0.3360 | Time: 13.75s |TRAIN loss  0.8721 | TRAIN Acc:  70.02% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:06:36,992] Gradient total norm was 1.4367953538894653. Clipping to 0.25.
[2023-03-17 18:06:36,995] Step: 169 | lr: 0.3380 | Time: 13.72s |TRAIN loss  0.8698 | TRAIN Acc:  70.01% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:06:50,688] Gradient total norm was 1.0190116167068481. Clipping to 0.25.
[2023-03-17 18:06:50,691] Step: 170 | lr: 0.3400 | Time: 13.68s |TRAIN loss  0.8583 | TRAIN Acc:  70.51% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:07:04,380] Gradient total norm was 1.1435731649398804. Clipping to 0.25.
[2023-03-17 18:07:04,383] Step: 171 | lr: 0.3420 | Time: 13.68s |TRAIN loss  0.8617 | TRAIN Acc:  70.31% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:07:18,089] Gradient total norm was 0.9233676195144653. Clipping to 0.25.
[2023-03-17 18:07:18,092] Step: 172 | lr: 0.3440 | Time: 13.70s |TRAIN loss  0.8488 | TRAIN Acc:  70.93% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:07:31,759] Gradient total norm was 1.1292355060577393. Clipping to 0.25.
[2023-03-17 18:07:31,762] Step: 173 | lr: 0.3460 | Time: 13.66s |TRAIN loss  0.8527 | TRAIN Acc:  70.70% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:07:45,440] Gradient total norm was 1.0189769268035889. Clipping to 0.25.
[2023-03-17 18:07:45,443] Step: 174 | lr: 0.3480 | Time: 13.67s |TRAIN loss  0.8405 | TRAIN Acc:  71.03% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:07:59,155] Gradient total norm was 1.2530595064163208. Clipping to 0.25.
[2023-03-17 18:07:59,158] Step: 175 | lr: 0.3500 | Time: 13.70s |TRAIN loss  0.8426 | TRAIN Acc:  71.05% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:08:12,839] Gradient total norm was 1.0517741441726685. Clipping to 0.25.
[2023-03-17 18:08:12,843] Step: 176 | lr: 0.3520 | Time: 13.67s |TRAIN loss  0.8302 | TRAIN Acc:  71.47% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:08:26,548] Gradient total norm was 1.3401660919189453. Clipping to 0.25.
[2023-03-17 18:08:26,552] Step: 177 | lr: 0.3540 | Time: 13.70s |TRAIN loss  0.8324 | TRAIN Acc:  71.26% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:08:40,275] Gradient total norm was 0.9134618639945984. Clipping to 0.25.
[2023-03-17 18:08:40,279] Step: 178 | lr: 0.3560 | Time: 13.71s |TRAIN loss  0.8195 | TRAIN Acc:  71.64% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:08:54,047] Gradient total norm was 1.1662614345550537. Clipping to 0.25.
[2023-03-17 18:08:54,050] Step: 179 | lr: 0.3580 | Time: 13.76s |TRAIN loss  0.8250 | TRAIN Acc:  71.64% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:09:07,698] Gradient total norm was 0.8685247302055359. Clipping to 0.25.
[2023-03-17 18:09:07,701] Step: 180 | lr: 0.3600 | Time: 13.64s |TRAIN loss  0.8114 | TRAIN Acc:  71.88% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:09:21,432] Gradient total norm was 1.2051774263381958. Clipping to 0.25.
[2023-03-17 18:09:21,435] Step: 181 | lr: 0.3620 | Time: 13.72s |TRAIN loss  0.8180 | TRAIN Acc:  71.72% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:09:35,113] Gradient total norm was 0.7950357794761658. Clipping to 0.25.
[2023-03-17 18:09:35,116] Step: 182 | lr: 0.3640 | Time: 13.67s |TRAIN loss  0.8010 | TRAIN Acc:  72.43% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:09:48,898] Gradient total norm was 1.1678168773651123. Clipping to 0.25.
[2023-03-17 18:09:48,902] Step: 183 | lr: 0.3660 | Time: 13.77s |TRAIN loss  0.8105 | TRAIN Acc:  72.05% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:10:02,627] Gradient total norm was 0.893304169178009. Clipping to 0.25.
[2023-03-17 18:10:02,631] Step: 184 | lr: 0.3680 | Time: 13.72s |TRAIN loss  0.7942 | TRAIN Acc:  72.68% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:10:16,362] Gradient total norm was 1.1223831176757812. Clipping to 0.25.
[2023-03-17 18:10:16,366] Step: 185 | lr: 0.3700 | Time: 13.72s |TRAIN loss  0.8015 | TRAIN Acc:  72.38% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:10:30,059] Gradient total norm was 0.8158509135246277. Clipping to 0.25.
[2023-03-17 18:10:30,063] Step: 186 | lr: 0.3720 | Time: 13.68s |TRAIN loss  0.7865 | TRAIN Acc:  72.97% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:10:43,758] Gradient total norm was 1.0831081867218018. Clipping to 0.25.
[2023-03-17 18:10:43,761] Step: 187 | lr: 0.3740 | Time: 13.69s |TRAIN loss  0.7956 | TRAIN Acc:  72.61% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:10:57,498] Gradient total norm was 0.7985037565231323. Clipping to 0.25.
[2023-03-17 18:10:57,502] Step: 188 | lr: 0.3760 | Time: 13.73s |TRAIN loss  0.7781 | TRAIN Acc:  73.29% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:11:11,170] Gradient total norm was 1.2607208490371704. Clipping to 0.25.
[2023-03-17 18:11:11,174] Step: 189 | lr: 0.3780 | Time: 13.66s |TRAIN loss  0.7907 | TRAIN Acc:  72.81% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:11:24,884] Gradient total norm was 0.7582658529281616. Clipping to 0.25.
[2023-03-17 18:11:24,887] Step: 190 | lr: 0.3800 | Time: 13.70s |TRAIN loss  0.7685 | TRAIN Acc:  73.76% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:11:38,577] Gradient total norm was 1.3510514497756958. Clipping to 0.25.
[2023-03-17 18:11:38,581] Step: 191 | lr: 0.3820 | Time: 13.68s |TRAIN loss  0.7837 | TRAIN Acc:  73.01% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:11:52,302] Gradient total norm was 0.7176165580749512. Clipping to 0.25.
[2023-03-17 18:11:52,305] Step: 192 | lr: 0.3840 | Time: 13.71s |TRAIN loss  0.7572 | TRAIN Acc:  74.28% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:12:05,994] Gradient total norm was 1.5653799772262573. Clipping to 0.25.
[2023-03-17 18:12:05,997] Step: 193 | lr: 0.3860 | Time: 13.68s |TRAIN loss  0.7822 | TRAIN Acc:  73.15% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:12:19,711] Gradient total norm was 0.7015182971954346. Clipping to 0.25.
[2023-03-17 18:12:19,714] Step: 194 | lr: 0.3880 | Time: 13.70s |TRAIN loss  0.7472 | TRAIN Acc:  74.68% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:12:33,436] Gradient total norm was 1.4983896017074585. Clipping to 0.25.
[2023-03-17 18:12:33,439] Step: 195 | lr: 0.3900 | Time: 13.71s |TRAIN loss  0.7775 | TRAIN Acc:  73.27% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:12:47,144] Gradient total norm was 0.543267011642456. Clipping to 0.25.
[2023-03-17 18:12:47,147] Step: 196 | lr: 0.3920 | Time: 13.69s |TRAIN loss  0.7382 | TRAIN Acc:  75.11% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:13:00,825] Gradient total norm was 1.4428366422653198. Clipping to 0.25.
[2023-03-17 18:13:00,828] Step: 197 | lr: 0.3940 | Time: 13.67s |TRAIN loss  0.7638 | TRAIN Acc:  73.52% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:13:14,566] Gradient total norm was 0.6128753423690796. Clipping to 0.25.
[2023-03-17 18:13:14,569] Step: 198 | lr: 0.3960 | Time: 13.73s |TRAIN loss  0.7285 | TRAIN Acc:  75.26% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:13:28,295] Gradient total norm was 1.2832567691802979. Clipping to 0.25.
[2023-03-17 18:13:28,299] Step: 199 | lr: 0.3980 | Time: 13.72s |TRAIN loss  0.7506 | TRAIN Acc:  74.32% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:13:41,987] Gradient total norm was 0.7159478664398193. Clipping to 0.25.
[2023-03-17 18:13:41,990] Step: 200 | lr: 0.4000 | Time: 13.68s |TRAIN loss  0.7278 | TRAIN Acc:  75.24% |VAL loss  1.3355 | VAL Acc:  50.10% |
[2023-03-17 18:13:55,696] Gradient total norm was 1.08055579662323. Clipping to 0.25.
[2023-03-17 18:14:01,017] Step: 201 | lr: 0.4020 | Time: 13.69s |TRAIN loss  0.7320 | TRAIN Acc:  75.16% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:14:14,717] Gradient total norm was 0.7258644700050354. Clipping to 0.25.
[2023-03-17 18:14:14,720] Step: 202 | lr: 0.4040 | Time: 13.69s |TRAIN loss  0.7191 | TRAIN Acc:  75.64% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:14:28,400] Gradient total norm was 1.3012042045593262. Clipping to 0.25.
[2023-03-17 18:14:28,403] Step: 203 | lr: 0.4060 | Time: 13.67s |TRAIN loss  0.7348 | TRAIN Acc:  75.11% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:14:42,144] Gradient total norm was 0.6217653155326843. Clipping to 0.25.
[2023-03-17 18:14:42,147] Step: 204 | lr: 0.4080 | Time: 13.73s |TRAIN loss  0.7073 | TRAIN Acc:  76.04% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:14:55,860] Gradient total norm was 1.2118825912475586. Clipping to 0.25.
[2023-03-17 18:14:55,863] Step: 205 | lr: 0.4100 | Time: 13.70s |TRAIN loss  0.7249 | TRAIN Acc:  75.24% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:15:09,571] Gradient total norm was 0.7338434457778931. Clipping to 0.25.
[2023-03-17 18:15:09,575] Step: 206 | lr: 0.4120 | Time: 13.70s |TRAIN loss  0.7016 | TRAIN Acc:  76.18% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:15:23,233] Gradient total norm was 1.0649372339248657. Clipping to 0.25.
[2023-03-17 18:15:23,236] Step: 207 | lr: 0.4140 | Time: 13.65s |TRAIN loss  0.7110 | TRAIN Acc:  75.82% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:15:36,987] Gradient total norm was 0.7032341957092285. Clipping to 0.25.
[2023-03-17 18:15:36,991] Step: 208 | lr: 0.4160 | Time: 13.74s |TRAIN loss  0.6945 | TRAIN Acc:  76.31% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:15:50,673] Gradient total norm was 1.0772331953048706. Clipping to 0.25.
[2023-03-17 18:15:50,677] Step: 209 | lr: 0.4180 | Time: 13.67s |TRAIN loss  0.7029 | TRAIN Acc:  76.01% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:16:04,424] Gradient total norm was 0.7405104637145996. Clipping to 0.25.
[2023-03-17 18:16:04,428] Step: 210 | lr: 0.4200 | Time: 13.74s |TRAIN loss  0.6863 | TRAIN Acc:  76.93% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:16:18,136] Gradient total norm was 1.1091519594192505. Clipping to 0.25.
[2023-03-17 18:16:18,140] Step: 211 | lr: 0.4220 | Time: 13.70s |TRAIN loss  0.6942 | TRAIN Acc:  76.23% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:16:31,865] Gradient total norm was 0.8008431196212769. Clipping to 0.25.
[2023-03-17 18:16:31,868] Step: 212 | lr: 0.4240 | Time: 13.72s |TRAIN loss  0.6788 | TRAIN Acc:  77.36% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:16:45,574] Gradient total norm was 1.1526967287063599. Clipping to 0.25.
[2023-03-17 18:16:45,577] Step: 213 | lr: 0.4260 | Time: 13.70s |TRAIN loss  0.6875 | TRAIN Acc:  76.64% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:16:59,283] Gradient total norm was 0.6912156343460083. Clipping to 0.25.
[2023-03-17 18:16:59,287] Step: 214 | lr: 0.4280 | Time: 13.70s |TRAIN loss  0.6697 | TRAIN Acc:  77.68% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:17:13,049] Gradient total norm was 1.0745885372161865. Clipping to 0.25.
[2023-03-17 18:17:13,053] Step: 215 | lr: 0.4300 | Time: 13.75s |TRAIN loss  0.6780 | TRAIN Acc:  76.87% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:17:26,759] Gradient total norm was 0.6354042291641235. Clipping to 0.25.
[2023-03-17 18:17:26,762] Step: 216 | lr: 0.4320 | Time: 13.70s |TRAIN loss  0.6595 | TRAIN Acc:  78.09% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:17:40,457] Gradient total norm was 1.0669336318969727. Clipping to 0.25.
[2023-03-17 18:17:40,460] Step: 217 | lr: 0.4340 | Time: 13.68s |TRAIN loss  0.6725 | TRAIN Acc:  77.11% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:17:54,145] Gradient total norm was 0.6486943960189819. Clipping to 0.25.
[2023-03-17 18:17:54,148] Step: 218 | lr: 0.4360 | Time: 13.67s |TRAIN loss  0.6512 | TRAIN Acc:  78.20% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:18:07,875] Gradient total norm was 1.1373867988586426. Clipping to 0.25.
[2023-03-17 18:18:07,878] Step: 219 | lr: 0.4380 | Time: 13.72s |TRAIN loss  0.6646 | TRAIN Acc:  77.48% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:18:21,570] Gradient total norm was 0.6522253751754761. Clipping to 0.25.
[2023-03-17 18:18:21,574] Step: 220 | lr: 0.4400 | Time: 13.68s |TRAIN loss  0.6439 | TRAIN Acc:  78.30% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:18:35,298] Gradient total norm was 1.0105130672454834. Clipping to 0.25.
[2023-03-17 18:18:35,301] Step: 221 | lr: 0.4420 | Time: 13.71s |TRAIN loss  0.6520 | TRAIN Acc:  78.21% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:18:49,001] Gradient total norm was 0.6180412769317627. Clipping to 0.25.
[2023-03-17 18:18:49,005] Step: 222 | lr: 0.4440 | Time: 13.69s |TRAIN loss  0.6356 | TRAIN Acc:  78.81% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:19:02,694] Gradient total norm was 0.9936910271644592. Clipping to 0.25.
[2023-03-17 18:19:02,697] Step: 223 | lr: 0.4460 | Time: 13.68s |TRAIN loss  0.6432 | TRAIN Acc:  78.63% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:19:16,392] Gradient total norm was 0.6836691498756409. Clipping to 0.25.
[2023-03-17 18:19:16,395] Step: 224 | lr: 0.4480 | Time: 13.68s |TRAIN loss  0.6249 | TRAIN Acc:  79.24% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:19:30,100] Gradient total norm was 1.218059778213501. Clipping to 0.25.
[2023-03-17 18:19:30,103] Step: 225 | lr: 0.4500 | Time: 13.69s |TRAIN loss  0.6418 | TRAIN Acc:  78.55% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:19:43,855] Gradient total norm was 0.759008526802063. Clipping to 0.25.
[2023-03-17 18:19:43,859] Step: 226 | lr: 0.4520 | Time: 13.74s |TRAIN loss  0.6175 | TRAIN Acc:  79.55% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:19:57,531] Gradient total norm was 1.3977800607681274. Clipping to 0.25.
[2023-03-17 18:19:57,535] Step: 227 | lr: 0.4540 | Time: 13.66s |TRAIN loss  0.6378 | TRAIN Acc:  78.68% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:20:11,223] Gradient total norm was 0.623569905757904. Clipping to 0.25.
[2023-03-17 18:20:11,226] Step: 228 | lr: 0.4560 | Time: 13.68s |TRAIN loss  0.6081 | TRAIN Acc:  79.98% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:20:24,962] Gradient total norm was 1.3797236680984497. Clipping to 0.25.
[2023-03-17 18:20:24,966] Step: 229 | lr: 0.4580 | Time: 13.73s |TRAIN loss  0.6243 | TRAIN Acc:  79.25% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:20:38,687] Gradient total norm was 0.5756229162216187. Clipping to 0.25.
[2023-03-17 18:20:38,691] Step: 230 | lr: 0.4600 | Time: 13.71s |TRAIN loss  0.5979 | TRAIN Acc:  80.25% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:20:52,419] Gradient total norm was 1.177359938621521. Clipping to 0.25.
[2023-03-17 18:20:52,423] Step: 231 | lr: 0.4620 | Time: 13.72s |TRAIN loss  0.6130 | TRAIN Acc:  79.61% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:21:06,088] Gradient total norm was 0.5637326240539551. Clipping to 0.25.
[2023-03-17 18:21:06,092] Step: 232 | lr: 0.4640 | Time: 13.66s |TRAIN loss  0.5899 | TRAIN Acc:  80.74% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:21:19,855] Gradient total norm was 1.102879285812378. Clipping to 0.25.
[2023-03-17 18:21:19,859] Step: 233 | lr: 0.4660 | Time: 13.75s |TRAIN loss  0.6038 | TRAIN Acc:  79.88% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:21:33,520] Gradient total norm was 0.5757157802581787. Clipping to 0.25.
[2023-03-17 18:21:33,523] Step: 234 | lr: 0.4680 | Time: 13.65s |TRAIN loss  0.5829 | TRAIN Acc:  80.91% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:21:47,215] Gradient total norm was 1.083197832107544. Clipping to 0.25.
[2023-03-17 18:21:47,218] Step: 235 | lr: 0.4700 | Time: 13.68s |TRAIN loss  0.5963 | TRAIN Acc:  80.16% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:22:00,949] Gradient total norm was 0.5922436714172363. Clipping to 0.25.
[2023-03-17 18:22:00,952] Step: 236 | lr: 0.4720 | Time: 13.72s |TRAIN loss  0.5772 | TRAIN Acc:  81.14% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:22:14,595] Gradient total norm was 1.031180500984192. Clipping to 0.25.
[2023-03-17 18:22:14,598] Step: 237 | lr: 0.4740 | Time: 13.63s |TRAIN loss  0.5882 | TRAIN Acc:  80.85% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:22:28,312] Gradient total norm was 0.7225571274757385. Clipping to 0.25.
[2023-03-17 18:22:28,316] Step: 238 | lr: 0.4760 | Time: 13.70s |TRAIN loss  0.5724 | TRAIN Acc:  81.24% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:22:42,006] Gradient total norm was 1.0818727016448975. Clipping to 0.25.
[2023-03-17 18:22:42,010] Step: 239 | lr: 0.4780 | Time: 13.68s |TRAIN loss  0.5814 | TRAIN Acc:  80.90% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:22:55,756] Gradient total norm was 0.6302841901779175. Clipping to 0.25.
[2023-03-17 18:22:55,759] Step: 240 | lr: 0.4800 | Time: 13.74s |TRAIN loss  0.5635 | TRAIN Acc:  81.79% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:23:09,481] Gradient total norm was 0.9688262343406677. Clipping to 0.25.
[2023-03-17 18:23:09,484] Step: 241 | lr: 0.4820 | Time: 13.71s |TRAIN loss  0.5726 | TRAIN Acc:  81.33% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:23:23,219] Gradient total norm was 0.6255881190299988. Clipping to 0.25.
[2023-03-17 18:23:23,222] Step: 242 | lr: 0.4840 | Time: 13.72s |TRAIN loss  0.5559 | TRAIN Acc:  81.86% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:23:36,936] Gradient total norm was 0.9310653209686279. Clipping to 0.25.
[2023-03-17 18:23:36,940] Step: 243 | lr: 0.4860 | Time: 13.70s |TRAIN loss  0.5603 | TRAIN Acc:  81.65% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:23:50,637] Gradient total norm was 0.6109671592712402. Clipping to 0.25.
[2023-03-17 18:23:50,641] Step: 244 | lr: 0.4880 | Time: 13.69s |TRAIN loss  0.5463 | TRAIN Acc:  82.06% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:24:04,353] Gradient total norm was 0.9691032767295837. Clipping to 0.25.
[2023-03-17 18:24:04,356] Step: 245 | lr: 0.4900 | Time: 13.70s |TRAIN loss  0.5539 | TRAIN Acc:  81.59% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:24:18,089] Gradient total norm was 0.6884000301361084. Clipping to 0.25.
[2023-03-17 18:24:18,092] Step: 246 | lr: 0.4920 | Time: 13.72s |TRAIN loss  0.5381 | TRAIN Acc:  82.53% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:24:31,825] Gradient total norm was 1.0134475231170654. Clipping to 0.25.
[2023-03-17 18:24:31,828] Step: 247 | lr: 0.4940 | Time: 13.72s |TRAIN loss  0.5451 | TRAIN Acc:  82.09% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:24:45,507] Gradient total norm was 0.6886676549911499. Clipping to 0.25.
[2023-03-17 18:24:45,511] Step: 248 | lr: 0.4960 | Time: 13.67s |TRAIN loss  0.5297 | TRAIN Acc:  82.92% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:24:59,278] Gradient total norm was 1.0754027366638184. Clipping to 0.25.
[2023-03-17 18:24:59,281] Step: 249 | lr: 0.4980 | Time: 13.76s |TRAIN loss  0.5414 | TRAIN Acc:  82.15% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:25:12,979] Gradient total norm was 0.6520986557006836. Clipping to 0.25.
[2023-03-17 18:25:12,982] Step: 250 | lr: 0.5000 | Time: 13.69s |TRAIN loss  0.5232 | TRAIN Acc:  83.00% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:25:26,754] Gradient total norm was 1.1740773916244507. Clipping to 0.25.
[2023-03-17 18:25:26,757] Step: 251 | lr: 0.5020 | Time: 13.76s |TRAIN loss  0.5388 | TRAIN Acc:  82.37% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:25:40,503] Gradient total norm was 0.5613892078399658. Clipping to 0.25.
[2023-03-17 18:25:40,506] Step: 252 | lr: 0.5040 | Time: 13.74s |TRAIN loss  0.5162 | TRAIN Acc:  83.33% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:25:54,218] Gradient total norm was 0.9491745233535767. Clipping to 0.25.
[2023-03-17 18:25:54,222] Step: 253 | lr: 0.5060 | Time: 13.70s |TRAIN loss  0.5293 | TRAIN Acc:  82.87% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:26:07,987] Gradient total norm was 0.5621554851531982. Clipping to 0.25.
[2023-03-17 18:26:07,991] Step: 254 | lr: 0.5080 | Time: 13.76s |TRAIN loss  0.5115 | TRAIN Acc:  83.40% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:26:21,642] Gradient total norm was 0.9331696629524231. Clipping to 0.25.
[2023-03-17 18:26:21,646] Step: 255 | lr: 0.5100 | Time: 13.64s |TRAIN loss  0.5229 | TRAIN Acc:  83.07% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:26:35,375] Gradient total norm was 0.5478960871696472. Clipping to 0.25.
[2023-03-17 18:26:35,378] Step: 256 | lr: 0.5120 | Time: 13.72s |TRAIN loss  0.5020 | TRAIN Acc:  83.80% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:26:49,078] Gradient total norm was 0.8272675275802612. Clipping to 0.25.
[2023-03-17 18:26:49,081] Step: 257 | lr: 0.5140 | Time: 13.69s |TRAIN loss  0.5132 | TRAIN Acc:  83.55% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:27:02,833] Gradient total norm was 0.6724380254745483. Clipping to 0.25.
[2023-03-17 18:27:02,836] Step: 258 | lr: 0.5160 | Time: 13.74s |TRAIN loss  0.5003 | TRAIN Acc:  83.80% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:27:16,557] Gradient total norm was 0.7863025665283203. Clipping to 0.25.
[2023-03-17 18:27:16,560] Step: 259 | lr: 0.5180 | Time: 13.71s |TRAIN loss  0.4997 | TRAIN Acc:  84.14% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:27:30,287] Gradient total norm was 0.683906614780426. Clipping to 0.25.
[2023-03-17 18:27:30,291] Step: 260 | lr: 0.5200 | Time: 13.72s |TRAIN loss  0.4921 | TRAIN Acc:  84.17% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:27:43,970] Gradient total norm was 0.7666707038879395. Clipping to 0.25.
[2023-03-17 18:27:43,973] Step: 261 | lr: 0.5220 | Time: 13.67s |TRAIN loss  0.4924 | TRAIN Acc:  84.18% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:27:57,664] Gradient total norm was 0.88395756483078. Clipping to 0.25.
[2023-03-17 18:27:57,668] Step: 262 | lr: 0.5240 | Time: 13.68s |TRAIN loss  0.4914 | TRAIN Acc:  83.97% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:28:11,376] Gradient total norm was 0.8177152872085571. Clipping to 0.25.
[2023-03-17 18:28:11,380] Step: 263 | lr: 0.5260 | Time: 13.70s |TRAIN loss  0.4907 | TRAIN Acc:  84.17% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:28:25,109] Gradient total norm was 0.7133158445358276. Clipping to 0.25.
[2023-03-17 18:28:25,112] Step: 264 | lr: 0.5280 | Time: 13.72s |TRAIN loss  0.4838 | TRAIN Acc:  84.43% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:28:38,860] Gradient total norm was 0.7745097875595093. Clipping to 0.25.
[2023-03-17 18:28:38,863] Step: 265 | lr: 0.5300 | Time: 13.74s |TRAIN loss  0.4828 | TRAIN Acc:  84.37% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:28:52,583] Gradient total norm was 0.7211059331893921. Clipping to 0.25.
[2023-03-17 18:28:52,586] Step: 266 | lr: 0.5320 | Time: 13.71s |TRAIN loss  0.4767 | TRAIN Acc:  84.83% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:29:06,343] Gradient total norm was 0.8831101655960083. Clipping to 0.25.
[2023-03-17 18:29:06,347] Step: 267 | lr: 0.5340 | Time: 13.75s |TRAIN loss  0.4809 | TRAIN Acc:  84.45% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:29:20,039] Gradient total norm was 0.7135740518569946. Clipping to 0.25.
[2023-03-17 18:29:20,042] Step: 268 | lr: 0.5360 | Time: 13.68s |TRAIN loss  0.4705 | TRAIN Acc:  85.07% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:29:33,800] Gradient total norm was 0.8764331340789795. Clipping to 0.25.
[2023-03-17 18:29:33,804] Step: 269 | lr: 0.5380 | Time: 13.75s |TRAIN loss  0.4755 | TRAIN Acc:  84.76% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:29:47,532] Gradient total norm was 0.649130642414093. Clipping to 0.25.
[2023-03-17 18:29:47,535] Step: 270 | lr: 0.5400 | Time: 13.72s |TRAIN loss  0.4646 | TRAIN Acc:  85.34% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:30:01,259] Gradient total norm was 0.8601459264755249. Clipping to 0.25.
[2023-03-17 18:30:01,262] Step: 271 | lr: 0.5420 | Time: 13.71s |TRAIN loss  0.4696 | TRAIN Acc:  85.12% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:30:15,021] Gradient total norm was 0.597589373588562. Clipping to 0.25.
[2023-03-17 18:30:15,024] Step: 272 | lr: 0.5440 | Time: 13.75s |TRAIN loss  0.4578 | TRAIN Acc:  85.64% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:30:28,760] Gradient total norm was 0.8220430016517639. Clipping to 0.25.
[2023-03-17 18:30:28,764] Step: 273 | lr: 0.5460 | Time: 13.73s |TRAIN loss  0.4622 | TRAIN Acc:  85.34% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:30:42,512] Gradient total norm was 0.5777705311775208. Clipping to 0.25.
[2023-03-17 18:30:42,515] Step: 274 | lr: 0.5480 | Time: 13.74s |TRAIN loss  0.4481 | TRAIN Acc:  85.91% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:30:56,238] Gradient total norm was 0.8918166756629944. Clipping to 0.25.
[2023-03-17 18:30:56,242] Step: 275 | lr: 0.5500 | Time: 13.71s |TRAIN loss  0.4577 | TRAIN Acc:  85.43% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:31:09,992] Gradient total norm was 0.6879308819770813. Clipping to 0.25.
[2023-03-17 18:31:09,996] Step: 276 | lr: 0.5520 | Time: 13.74s |TRAIN loss  0.4443 | TRAIN Acc:  86.02% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:31:23,704] Gradient total norm was 0.847093403339386. Clipping to 0.25.
[2023-03-17 18:31:23,708] Step: 277 | lr: 0.5540 | Time: 13.70s |TRAIN loss  0.4514 | TRAIN Acc:  85.62% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:31:37,381] Gradient total norm was 0.5933632850646973. Clipping to 0.25.
[2023-03-17 18:31:37,384] Step: 278 | lr: 0.5560 | Time: 13.66s |TRAIN loss  0.4383 | TRAIN Acc:  86.14% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:31:51,183] Gradient total norm was 0.7725429534912109. Clipping to 0.25.
[2023-03-17 18:31:51,186] Step: 279 | lr: 0.5580 | Time: 13.79s |TRAIN loss  0.4472 | TRAIN Acc:  85.69% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:32:04,872] Gradient total norm was 0.543144941329956. Clipping to 0.25.
[2023-03-17 18:32:04,875] Step: 280 | lr: 0.5600 | Time: 13.67s |TRAIN loss  0.4334 | TRAIN Acc:  86.31% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:32:18,622] Gradient total norm was 0.7346807718276978. Clipping to 0.25.
[2023-03-17 18:32:18,626] Step: 281 | lr: 0.5620 | Time: 13.74s |TRAIN loss  0.4409 | TRAIN Acc:  85.93% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:32:32,416] Gradient total norm was 0.5533661246299744. Clipping to 0.25.
[2023-03-17 18:32:32,419] Step: 282 | lr: 0.5640 | Time: 13.78s |TRAIN loss  0.4263 | TRAIN Acc:  86.50% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:32:46,258] Gradient total norm was 0.6846781373023987. Clipping to 0.25.
[2023-03-17 18:32:46,261] Step: 283 | lr: 0.5660 | Time: 13.83s |TRAIN loss  0.4297 | TRAIN Acc:  86.56% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:32:59,972] Gradient total norm was 0.5510662198066711. Clipping to 0.25.
[2023-03-17 18:32:59,975] Step: 284 | lr: 0.5680 | Time: 13.70s |TRAIN loss  0.4186 | TRAIN Acc:  86.86% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:33:13,714] Gradient total norm was 0.7914975881576538. Clipping to 0.25.
[2023-03-17 18:33:13,718] Step: 285 | lr: 0.5700 | Time: 13.73s |TRAIN loss  0.4263 | TRAIN Acc:  86.71% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:33:27,467] Gradient total norm was 0.6587602496147156. Clipping to 0.25.
[2023-03-17 18:33:27,470] Step: 286 | lr: 0.5720 | Time: 13.74s |TRAIN loss  0.4148 | TRAIN Acc:  87.05% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:33:41,273] Gradient total norm was 0.7444875240325928. Clipping to 0.25.
[2023-03-17 18:33:41,277] Step: 287 | lr: 0.5740 | Time: 13.79s |TRAIN loss  0.4209 | TRAIN Acc:  86.96% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:33:55,002] Gradient total norm was 0.6423454880714417. Clipping to 0.25.
[2023-03-17 18:33:55,005] Step: 288 | lr: 0.5760 | Time: 13.71s |TRAIN loss  0.4127 | TRAIN Acc:  86.96% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:34:08,766] Gradient total norm was 0.7808760404586792. Clipping to 0.25.
[2023-03-17 18:34:08,770] Step: 289 | lr: 0.5780 | Time: 13.75s |TRAIN loss  0.4165 | TRAIN Acc:  86.84% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:34:22,529] Gradient total norm was 0.6502467393875122. Clipping to 0.25.
[2023-03-17 18:34:22,534] Step: 290 | lr: 0.5800 | Time: 13.75s |TRAIN loss  0.4076 | TRAIN Acc:  87.20% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:34:36,240] Gradient total norm was 0.8000891804695129. Clipping to 0.25.
[2023-03-17 18:34:36,244] Step: 291 | lr: 0.5820 | Time: 13.70s |TRAIN loss  0.4123 | TRAIN Acc:  86.96% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:34:50,081] Gradient total norm was 0.6024996638298035. Clipping to 0.25.
[2023-03-17 18:34:50,084] Step: 292 | lr: 0.5840 | Time: 13.83s |TRAIN loss  0.4000 | TRAIN Acc:  87.63% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:35:03,838] Gradient total norm was 0.8387585282325745. Clipping to 0.25.
[2023-03-17 18:35:03,841] Step: 293 | lr: 0.5860 | Time: 13.74s |TRAIN loss  0.4065 | TRAIN Acc:  87.20% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:35:17,522] Gradient total norm was 0.575524628162384. Clipping to 0.25.
[2023-03-17 18:35:17,526] Step: 294 | lr: 0.5880 | Time: 13.67s |TRAIN loss  0.3959 | TRAIN Acc:  87.90% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:35:31,304] Gradient total norm was 0.8615239858627319. Clipping to 0.25.
[2023-03-17 18:35:31,307] Step: 295 | lr: 0.5900 | Time: 13.77s |TRAIN loss  0.4035 | TRAIN Acc:  87.44% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:35:45,078] Gradient total norm was 0.5359472632408142. Clipping to 0.25.
[2023-03-17 18:35:45,081] Step: 296 | lr: 0.5920 | Time: 13.76s |TRAIN loss  0.3879 | TRAIN Acc:  88.19% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:35:58,889] Gradient total norm was 0.8392871618270874. Clipping to 0.25.
[2023-03-17 18:35:58,893] Step: 297 | lr: 0.5940 | Time: 13.80s |TRAIN loss  0.3990 | TRAIN Acc:  87.47% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:36:12,616] Gradient total norm was 0.5313548445701599. Clipping to 0.25.
[2023-03-17 18:36:12,620] Step: 298 | lr: 0.5960 | Time: 13.71s |TRAIN loss  0.3827 | TRAIN Acc:  88.37% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:36:26,338] Gradient total norm was 0.7756167650222778. Clipping to 0.25.
[2023-03-17 18:36:26,341] Step: 299 | lr: 0.5980 | Time: 13.71s |TRAIN loss  0.3931 | TRAIN Acc:  87.75% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:36:40,076] Gradient total norm was 0.5641412138938904. Clipping to 0.25.
[2023-03-17 18:36:40,080] Step: 300 | lr: 0.6000 | Time: 13.73s |TRAIN loss  0.3753 | TRAIN Acc:  88.62% |VAL loss  0.7554 | VAL Acc:  72.86% |
[2023-03-17 18:36:53,817] Gradient total norm was 0.7572253346443176. Clipping to 0.25.
[2023-03-17 18:36:59,092] Step: 301 | lr: 0.6020 | Time: 13.73s |TRAIN loss  0.3866 | TRAIN Acc:  87.84% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:37:12,791] Gradient total norm was 0.5706946849822998. Clipping to 0.25.
[2023-03-17 18:37:12,794] Step: 302 | lr: 0.6040 | Time: 13.69s |TRAIN loss  0.3706 | TRAIN Acc:  88.65% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:37:26,539] Gradient total norm was 0.7506627440452576. Clipping to 0.25.
[2023-03-17 18:37:26,543] Step: 303 | lr: 0.6060 | Time: 13.73s |TRAIN loss  0.3792 | TRAIN Acc:  88.28% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:37:40,246] Gradient total norm was 0.5666621923446655. Clipping to 0.25.
[2023-03-17 18:37:40,249] Step: 304 | lr: 0.6080 | Time: 13.69s |TRAIN loss  0.3688 | TRAIN Acc:  88.75% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:37:53,978] Gradient total norm was 0.8435469269752502. Clipping to 0.25.
[2023-03-17 18:37:53,982] Step: 305 | lr: 0.6100 | Time: 13.72s |TRAIN loss  0.3755 | TRAIN Acc:  88.40% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:38:07,638] Gradient total norm was 0.5707529187202454. Clipping to 0.25.
[2023-03-17 18:38:07,642] Step: 306 | lr: 0.6120 | Time: 13.65s |TRAIN loss  0.3643 | TRAIN Acc:  88.96% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:38:21,344] Gradient total norm was 0.7505263090133667. Clipping to 0.25.
[2023-03-17 18:38:21,348] Step: 307 | lr: 0.6140 | Time: 13.69s |TRAIN loss  0.3681 | TRAIN Acc:  88.59% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:38:35,095] Gradient total norm was 0.5413243770599365. Clipping to 0.25.
[2023-03-17 18:38:35,098] Step: 308 | lr: 0.6160 | Time: 13.74s |TRAIN loss  0.3590 | TRAIN Acc:  89.13% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:38:48,798] Gradient total norm was 0.6624408960342407. Clipping to 0.25.
[2023-03-17 18:38:48,801] Step: 309 | lr: 0.6180 | Time: 13.69s |TRAIN loss  0.3603 | TRAIN Acc:  88.89% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:39:02,540] Gradient total norm was 0.5446217060089111. Clipping to 0.25.
[2023-03-17 18:39:02,543] Step: 310 | lr: 0.6200 | Time: 13.73s |TRAIN loss  0.3530 | TRAIN Acc:  89.42% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:39:16,217] Gradient total norm was 0.6742141246795654. Clipping to 0.25.
[2023-03-17 18:39:16,220] Step: 311 | lr: 0.6220 | Time: 13.66s |TRAIN loss  0.3576 | TRAIN Acc:  89.03% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:39:29,948] Gradient total norm was 0.6267036199569702. Clipping to 0.25.
[2023-03-17 18:39:29,951] Step: 312 | lr: 0.6240 | Time: 13.71s |TRAIN loss  0.3509 | TRAIN Acc:  89.43% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:39:43,638] Gradient total norm was 0.6847075819969177. Clipping to 0.25.
[2023-03-17 18:39:43,641] Step: 313 | lr: 0.6260 | Time: 13.68s |TRAIN loss  0.3538 | TRAIN Acc:  89.12% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:39:57,329] Gradient total norm was 0.5923588275909424. Clipping to 0.25.
[2023-03-17 18:39:57,332] Step: 314 | lr: 0.6280 | Time: 13.68s |TRAIN loss  0.3463 | TRAIN Acc:  89.64% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:40:11,038] Gradient total norm was 0.7255754470825195. Clipping to 0.25.
[2023-03-17 18:40:11,041] Step: 315 | lr: 0.6300 | Time: 13.70s |TRAIN loss  0.3512 | TRAIN Acc:  89.47% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:40:24,713] Gradient total norm was 0.5453807711601257. Clipping to 0.25.
[2023-03-17 18:40:24,717] Step: 316 | lr: 0.6320 | Time: 13.66s |TRAIN loss  0.3402 | TRAIN Acc:  89.87% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:40:38,458] Gradient total norm was 0.6991018056869507. Clipping to 0.25.
[2023-03-17 18:40:38,461] Step: 317 | lr: 0.6340 | Time: 13.73s |TRAIN loss  0.3441 | TRAIN Acc:  89.66% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:40:52,150] Gradient total norm was 0.5594949126243591. Clipping to 0.25.
[2023-03-17 18:40:52,153] Step: 318 | lr: 0.6360 | Time: 13.68s |TRAIN loss  0.3351 | TRAIN Acc:  89.88% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:41:05,887] Gradient total norm was 0.763007640838623. Clipping to 0.25.
[2023-03-17 18:41:05,891] Step: 319 | lr: 0.6380 | Time: 13.72s |TRAIN loss  0.3413 | TRAIN Acc:  89.66% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:41:19,593] Gradient total norm was 0.5984615087509155. Clipping to 0.25.
[2023-03-17 18:41:19,597] Step: 320 | lr: 0.6400 | Time: 13.69s |TRAIN loss  0.3308 | TRAIN Acc:  90.11% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:41:33,344] Gradient total norm was 0.6987246870994568. Clipping to 0.25.
[2023-03-17 18:41:33,348] Step: 321 | lr: 0.6420 | Time: 13.74s |TRAIN loss  0.3336 | TRAIN Acc:  90.00% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:41:47,022] Gradient total norm was 0.5799081921577454. Clipping to 0.25.
[2023-03-17 18:41:47,025] Step: 322 | lr: 0.6440 | Time: 13.66s |TRAIN loss  0.3250 | TRAIN Acc:  90.37% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:42:00,796] Gradient total norm was 0.6718671321868896. Clipping to 0.25.
[2023-03-17 18:42:00,799] Step: 323 | lr: 0.6460 | Time: 13.76s |TRAIN loss  0.3272 | TRAIN Acc:  90.21% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:42:14,487] Gradient total norm was 0.5824480652809143. Clipping to 0.25.
[2023-03-17 18:42:14,491] Step: 324 | lr: 0.6480 | Time: 13.68s |TRAIN loss  0.3189 | TRAIN Acc:  90.42% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:42:28,123] Gradient total norm was 0.641771674156189. Clipping to 0.25.
[2023-03-17 18:42:28,126] Step: 325 | lr: 0.6500 | Time: 13.62s |TRAIN loss  0.3219 | TRAIN Acc:  90.35% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:42:41,921] Gradient total norm was 0.5728944540023804. Clipping to 0.25.
[2023-03-17 18:42:41,924] Step: 326 | lr: 0.6520 | Time: 13.78s |TRAIN loss  0.3128 | TRAIN Acc:  90.76% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:42:55,600] Gradient total norm was 0.6187188029289246. Clipping to 0.25.
[2023-03-17 18:42:55,603] Step: 327 | lr: 0.6540 | Time: 13.67s |TRAIN loss  0.3175 | TRAIN Acc:  90.46% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:43:09,349] Gradient total norm was 0.5430045127868652. Clipping to 0.25.
[2023-03-17 18:43:09,352] Step: 328 | lr: 0.6560 | Time: 13.74s |TRAIN loss  0.3099 | TRAIN Acc:  90.94% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:43:23,005] Gradient total norm was 0.599277913570404. Clipping to 0.25.
[2023-03-17 18:43:23,009] Step: 329 | lr: 0.6580 | Time: 13.64s |TRAIN loss  0.3127 | TRAIN Acc:  90.73% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:43:36,720] Gradient total norm was 0.5373207926750183. Clipping to 0.25.
[2023-03-17 18:43:36,724] Step: 330 | lr: 0.6600 | Time: 13.70s |TRAIN loss  0.3060 | TRAIN Acc:  91.16% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:43:50,367] Gradient total norm was 0.7398130893707275. Clipping to 0.25.
[2023-03-17 18:43:50,371] Step: 331 | lr: 0.6620 | Time: 13.63s |TRAIN loss  0.3127 | TRAIN Acc:  90.63% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:44:04,049] Gradient total norm was 0.4780476689338684. Clipping to 0.25.
[2023-03-17 18:44:04,052] Step: 332 | lr: 0.6640 | Time: 13.67s |TRAIN loss  0.3006 | TRAIN Acc:  91.20% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:44:17,762] Gradient total norm was 0.827981173992157. Clipping to 0.25.
[2023-03-17 18:44:17,765] Step: 333 | lr: 0.6660 | Time: 13.70s |TRAIN loss  0.3115 | TRAIN Acc:  90.78% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:44:31,467] Gradient total norm was 0.47140875458717346. Clipping to 0.25.
[2023-03-17 18:44:31,470] Step: 334 | lr: 0.6680 | Time: 13.69s |TRAIN loss  0.3012 | TRAIN Acc:  91.08% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:44:45,169] Gradient total norm was 0.7065379619598389. Clipping to 0.25.
[2023-03-17 18:44:45,173] Step: 335 | lr: 0.6700 | Time: 13.69s |TRAIN loss  0.3052 | TRAIN Acc:  91.07% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:44:58,849] Gradient total norm was 0.5102466344833374. Clipping to 0.25.
[2023-03-17 18:44:58,852] Step: 336 | lr: 0.6720 | Time: 13.67s |TRAIN loss  0.2949 | TRAIN Acc:  91.52% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:45:12,611] Gradient total norm was 0.6833537220954895. Clipping to 0.25.
[2023-03-17 18:45:12,614] Step: 337 | lr: 0.6740 | Time: 13.75s |TRAIN loss  0.3012 | TRAIN Acc:  91.28% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:45:26,321] Gradient total norm was 0.5387099981307983. Clipping to 0.25.
[2023-03-17 18:45:26,324] Step: 338 | lr: 0.6760 | Time: 13.70s |TRAIN loss  0.2883 | TRAIN Acc:  91.61% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:45:40,084] Gradient total norm was 0.6908131837844849. Clipping to 0.25.
[2023-03-17 18:45:40,087] Step: 339 | lr: 0.6780 | Time: 13.75s |TRAIN loss  0.2951 | TRAIN Acc:  91.34% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:45:53,766] Gradient total norm was 0.6632006764411926. Clipping to 0.25.
[2023-03-17 18:45:53,770] Step: 340 | lr: 0.6800 | Time: 13.67s |TRAIN loss  0.2860 | TRAIN Acc:  91.55% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:46:07,460] Gradient total norm was 0.832537055015564. Clipping to 0.25.
[2023-03-17 18:46:07,463] Step: 341 | lr: 0.6820 | Time: 13.68s |TRAIN loss  0.2932 | TRAIN Acc:  91.26% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:46:21,177] Gradient total norm was 0.6461794376373291. Clipping to 0.25.
[2023-03-17 18:46:21,180] Step: 342 | lr: 0.6840 | Time: 13.70s |TRAIN loss  0.2836 | TRAIN Acc:  91.67% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:46:34,913] Gradient total norm was 0.6827560663223267. Clipping to 0.25.
[2023-03-17 18:46:34,916] Step: 343 | lr: 0.6860 | Time: 13.72s |TRAIN loss  0.2861 | TRAIN Acc:  91.47% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:46:48,689] Gradient total norm was 0.5160983204841614. Clipping to 0.25.
[2023-03-17 18:46:48,693] Step: 344 | lr: 0.6880 | Time: 13.76s |TRAIN loss  0.2754 | TRAIN Acc:  92.09% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:47:02,433] Gradient total norm was 0.6602266430854797. Clipping to 0.25.
[2023-03-17 18:47:02,436] Step: 345 | lr: 0.6900 | Time: 13.73s |TRAIN loss  0.2792 | TRAIN Acc:  91.87% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:47:16,200] Gradient total norm was 0.5701389908790588. Clipping to 0.25.
[2023-03-17 18:47:16,203] Step: 346 | lr: 0.6920 | Time: 13.75s |TRAIN loss  0.2724 | TRAIN Acc:  92.23% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:47:29,940] Gradient total norm was 0.7153916954994202. Clipping to 0.25.
[2023-03-17 18:47:29,943] Step: 347 | lr: 0.6940 | Time: 13.73s |TRAIN loss  0.2768 | TRAIN Acc:  91.88% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:47:43,692] Gradient total norm was 0.5278761386871338. Clipping to 0.25.
[2023-03-17 18:47:43,696] Step: 348 | lr: 0.6960 | Time: 13.74s |TRAIN loss  0.2676 | TRAIN Acc:  92.26% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:47:57,419] Gradient total norm was 0.6345623135566711. Clipping to 0.25.
[2023-03-17 18:47:57,422] Step: 349 | lr: 0.6980 | Time: 13.71s |TRAIN loss  0.2740 | TRAIN Acc:  91.96% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:48:11,121] Gradient total norm was 0.5125770568847656. Clipping to 0.25.
[2023-03-17 18:48:11,124] Step: 350 | lr: 0.7000 | Time: 13.69s |TRAIN loss  0.2647 | TRAIN Acc:  92.46% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:48:24,954] Gradient total norm was 0.6035590767860413. Clipping to 0.25.
[2023-03-17 18:48:24,958] Step: 351 | lr: 0.7020 | Time: 13.82s |TRAIN loss  0.2685 | TRAIN Acc:  92.23% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:48:38,671] Gradient total norm was 0.5428967475891113. Clipping to 0.25.
[2023-03-17 18:48:38,675] Step: 352 | lr: 0.7040 | Time: 13.70s |TRAIN loss  0.2596 | TRAIN Acc:  92.65% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:48:52,419] Gradient total norm was 0.6053481698036194. Clipping to 0.25.
[2023-03-17 18:48:52,423] Step: 353 | lr: 0.7060 | Time: 13.73s |TRAIN loss  0.2636 | TRAIN Acc:  92.54% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:49:06,198] Gradient total norm was 0.5687941908836365. Clipping to 0.25.
[2023-03-17 18:49:06,201] Step: 354 | lr: 0.7080 | Time: 13.76s |TRAIN loss  0.2551 | TRAIN Acc:  92.86% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:49:20,003] Gradient total norm was 0.6838043928146362. Clipping to 0.25.
[2023-03-17 18:49:20,006] Step: 355 | lr: 0.7100 | Time: 13.79s |TRAIN loss  0.2584 | TRAIN Acc:  92.72% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:49:33,724] Gradient total norm was 0.5576125383377075. Clipping to 0.25.
[2023-03-17 18:49:33,727] Step: 356 | lr: 0.7120 | Time: 13.71s |TRAIN loss  0.2535 | TRAIN Acc:  92.84% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:49:47,478] Gradient total norm was 0.7875085473060608. Clipping to 0.25.
[2023-03-17 18:49:47,482] Step: 357 | lr: 0.7140 | Time: 13.74s |TRAIN loss  0.2575 | TRAIN Acc:  92.74% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:50:01,269] Gradient total norm was 0.6394371390342712. Clipping to 0.25.
[2023-03-17 18:50:01,272] Step: 358 | lr: 0.7160 | Time: 13.78s |TRAIN loss  0.2517 | TRAIN Acc:  92.85% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:50:15,002] Gradient total norm was 0.666553795337677. Clipping to 0.25.
[2023-03-17 18:50:15,006] Step: 359 | lr: 0.7180 | Time: 13.72s |TRAIN loss  0.2525 | TRAIN Acc:  92.81% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:50:28,735] Gradient total norm was 0.5355528593063354. Clipping to 0.25.
[2023-03-17 18:50:28,738] Step: 360 | lr: 0.7200 | Time: 13.72s |TRAIN loss  0.2459 | TRAIN Acc:  93.12% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:50:42,425] Gradient total norm was 0.6299108266830444. Clipping to 0.25.
[2023-03-17 18:50:42,428] Step: 361 | lr: 0.7220 | Time: 13.68s |TRAIN loss  0.2468 | TRAIN Acc:  93.18% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:50:56,249] Gradient total norm was 0.5944259166717529. Clipping to 0.25.
[2023-03-17 18:50:56,252] Step: 362 | lr: 0.7240 | Time: 13.81s |TRAIN loss  0.2403 | TRAIN Acc:  93.35% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:51:10,065] Gradient total norm was 0.7261472940444946. Clipping to 0.25.
[2023-03-17 18:51:10,069] Step: 363 | lr: 0.7260 | Time: 13.80s |TRAIN loss  0.2431 | TRAIN Acc:  93.20% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:51:24,033] Gradient total norm was 0.6143073439598083. Clipping to 0.25.
[2023-03-17 18:51:24,037] Step: 364 | lr: 0.7280 | Time: 13.95s |TRAIN loss  0.2367 | TRAIN Acc:  93.55% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:51:37,975] Gradient total norm was 0.5983449816703796. Clipping to 0.25.
[2023-03-17 18:51:37,978] Step: 365 | lr: 0.7300 | Time: 13.93s |TRAIN loss  0.2376 | TRAIN Acc:  93.39% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:51:51,824] Gradient total norm was 0.595824122428894. Clipping to 0.25.
[2023-03-17 18:51:51,827] Step: 366 | lr: 0.7320 | Time: 13.84s |TRAIN loss  0.2324 | TRAIN Acc:  93.65% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:52:05,554] Gradient total norm was 0.6535828113555908. Clipping to 0.25.
[2023-03-17 18:52:05,557] Step: 367 | lr: 0.7340 | Time: 13.72s |TRAIN loss  0.2398 | TRAIN Acc:  93.11% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:52:19,291] Gradient total norm was 0.5828588604927063. Clipping to 0.25.
[2023-03-17 18:52:19,294] Step: 368 | lr: 0.7360 | Time: 13.72s |TRAIN loss  0.2324 | TRAIN Acc:  93.55% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:52:33,045] Gradient total norm was 0.6244744062423706. Clipping to 0.25.
[2023-03-17 18:52:33,048] Step: 369 | lr: 0.7380 | Time: 13.74s |TRAIN loss  0.2351 | TRAIN Acc:  93.32% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:52:46,811] Gradient total norm was 0.5353623628616333. Clipping to 0.25.
[2023-03-17 18:52:46,815] Step: 370 | lr: 0.7400 | Time: 13.75s |TRAIN loss  0.2283 | TRAIN Acc:  93.86% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:53:00,535] Gradient total norm was 0.6301991939544678. Clipping to 0.25.
[2023-03-17 18:53:00,538] Step: 371 | lr: 0.7420 | Time: 13.71s |TRAIN loss  0.2300 | TRAIN Acc:  93.59% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:53:14,286] Gradient total norm was 0.5678066611289978. Clipping to 0.25.
[2023-03-17 18:53:14,290] Step: 372 | lr: 0.7440 | Time: 13.74s |TRAIN loss  0.2239 | TRAIN Acc:  94.02% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:53:28,060] Gradient total norm was 0.6908435821533203. Clipping to 0.25.
[2023-03-17 18:53:28,063] Step: 373 | lr: 0.7460 | Time: 13.76s |TRAIN loss  0.2226 | TRAIN Acc:  93.88% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:53:41,761] Gradient total norm was 0.5448970794677734. Clipping to 0.25.
[2023-03-17 18:53:41,765] Step: 374 | lr: 0.7480 | Time: 13.69s |TRAIN loss  0.2184 | TRAIN Acc:  94.00% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:53:55,519] Gradient total norm was 0.6316542625427246. Clipping to 0.25.
[2023-03-17 18:53:55,522] Step: 375 | lr: 0.7500 | Time: 13.74s |TRAIN loss  0.2166 | TRAIN Acc:  94.11% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:54:09,231] Gradient total norm was 0.5730544924736023. Clipping to 0.25.
[2023-03-17 18:54:09,234] Step: 376 | lr: 0.7520 | Time: 13.70s |TRAIN loss  0.2145 | TRAIN Acc:  94.15% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:54:22,937] Gradient total norm was 0.6314950585365295. Clipping to 0.25.
[2023-03-17 18:54:22,940] Step: 377 | lr: 0.7540 | Time: 13.69s |TRAIN loss  0.2138 | TRAIN Acc:  93.99% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:54:36,737] Gradient total norm was 0.5986955165863037. Clipping to 0.25.
[2023-03-17 18:54:36,740] Step: 378 | lr: 0.7560 | Time: 13.79s |TRAIN loss  0.2105 | TRAIN Acc:  94.35% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:54:50,498] Gradient total norm was 0.6184560060501099. Clipping to 0.25.
[2023-03-17 18:54:50,502] Step: 379 | lr: 0.7580 | Time: 13.75s |TRAIN loss  0.2104 | TRAIN Acc:  94.32% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:55:04,376] Gradient total norm was 0.603661835193634. Clipping to 0.25.
[2023-03-17 18:55:04,380] Step: 380 | lr: 0.7600 | Time: 13.86s |TRAIN loss  0.2061 | TRAIN Acc:  94.65% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:55:18,105] Gradient total norm was 0.5824620127677917. Clipping to 0.25.
[2023-03-17 18:55:18,109] Step: 381 | lr: 0.7620 | Time: 13.72s |TRAIN loss  0.2051 | TRAIN Acc:  94.56% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:55:31,865] Gradient total norm was 0.5710532069206238. Clipping to 0.25.
[2023-03-17 18:55:31,868] Step: 382 | lr: 0.7640 | Time: 13.75s |TRAIN loss  0.2020 | TRAIN Acc:  94.70% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:55:45,605] Gradient total norm was 0.5631330609321594. Clipping to 0.25.
[2023-03-17 18:55:45,610] Step: 383 | lr: 0.7660 | Time: 13.73s |TRAIN loss  0.2011 | TRAIN Acc:  94.70% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:55:59,349] Gradient total norm was 0.6664385795593262. Clipping to 0.25.
[2023-03-17 18:55:59,354] Step: 384 | lr: 0.7680 | Time: 13.73s |TRAIN loss  0.2017 | TRAIN Acc:  94.71% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:56:13,081] Gradient total norm was 0.5703942179679871. Clipping to 0.25.
[2023-03-17 18:56:13,084] Step: 385 | lr: 0.7700 | Time: 13.72s |TRAIN loss  0.1958 | TRAIN Acc:  94.82% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:56:26,764] Gradient total norm was 0.6086180210113525. Clipping to 0.25.
[2023-03-17 18:56:26,767] Step: 386 | lr: 0.7720 | Time: 13.67s |TRAIN loss  0.1964 | TRAIN Acc:  94.97% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:56:40,503] Gradient total norm was 0.7657369375228882. Clipping to 0.25.
[2023-03-17 18:56:40,507] Step: 387 | lr: 0.7740 | Time: 13.73s |TRAIN loss  0.2005 | TRAIN Acc:  94.53% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:56:54,168] Gradient total norm was 0.6408154964447021. Clipping to 0.25.
[2023-03-17 18:56:54,172] Step: 388 | lr: 0.7760 | Time: 13.65s |TRAIN loss  0.1909 | TRAIN Acc:  95.04% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:57:07,879] Gradient total norm was 0.7351568341255188. Clipping to 0.25.
[2023-03-17 18:57:07,882] Step: 389 | lr: 0.7780 | Time: 13.70s |TRAIN loss  0.1980 | TRAIN Acc:  94.72% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:57:21,542] Gradient total norm was 0.502088189125061. Clipping to 0.25.
[2023-03-17 18:57:21,546] Step: 390 | lr: 0.7800 | Time: 13.65s |TRAIN loss  0.1860 | TRAIN Acc:  95.21% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:57:35,252] Gradient total norm was 0.6767167448997498. Clipping to 0.25.
[2023-03-17 18:57:35,256] Step: 391 | lr: 0.7820 | Time: 13.70s |TRAIN loss  0.1920 | TRAIN Acc:  95.01% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:57:48,940] Gradient total norm was 0.5723767876625061. Clipping to 0.25.
[2023-03-17 18:57:48,943] Step: 392 | lr: 0.7840 | Time: 13.67s |TRAIN loss  0.1854 | TRAIN Acc:  95.22% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:58:02,605] Gradient total norm was 0.8161162734031677. Clipping to 0.25.
[2023-03-17 18:58:02,609] Step: 393 | lr: 0.7860 | Time: 13.65s |TRAIN loss  0.1874 | TRAIN Acc:  95.19% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:58:16,242] Gradient total norm was 0.5655518770217896. Clipping to 0.25.
[2023-03-17 18:58:16,245] Step: 394 | lr: 0.7880 | Time: 13.62s |TRAIN loss  0.1856 | TRAIN Acc:  95.23% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:58:29,858] Gradient total norm was 0.6869988441467285. Clipping to 0.25.
[2023-03-17 18:58:29,862] Step: 395 | lr: 0.7900 | Time: 13.60s |TRAIN loss  0.1849 | TRAIN Acc:  95.21% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:58:43,496] Gradient total norm was 0.5365834832191467. Clipping to 0.25.
[2023-03-17 18:58:43,499] Step: 396 | lr: 0.7920 | Time: 13.62s |TRAIN loss  0.1822 | TRAIN Acc:  95.35% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:58:57,103] Gradient total norm was 0.6351298689842224. Clipping to 0.25.
[2023-03-17 18:58:57,106] Step: 397 | lr: 0.7940 | Time: 13.59s |TRAIN loss  0.1811 | TRAIN Acc:  95.39% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:59:10,779] Gradient total norm was 0.5994816422462463. Clipping to 0.25.
[2023-03-17 18:59:10,782] Step: 398 | lr: 0.7960 | Time: 13.66s |TRAIN loss  0.1787 | TRAIN Acc:  95.50% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:59:24,447] Gradient total norm was 0.6357358694076538. Clipping to 0.25.
[2023-03-17 18:59:24,451] Step: 399 | lr: 0.7980 | Time: 13.66s |TRAIN loss  0.1780 | TRAIN Acc:  95.43% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:59:38,140] Gradient total norm was 0.6412388682365417. Clipping to 0.25.
[2023-03-17 18:59:38,143] Step: 400 | lr: 0.8000 | Time: 13.68s |TRAIN loss  0.1740 | TRAIN Acc:  95.77% |VAL loss  0.4583 | VAL Acc:  84.16% |
[2023-03-17 18:59:51,854] Gradient total norm was 0.7108251452445984. Clipping to 0.25.
[2023-03-17 18:59:57,154] Step: 401 | lr: 0.8000 | Time: 13.70s |TRAIN loss  0.1741 | TRAIN Acc:  95.53% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:00:10,893] Gradient total norm was 0.649040699005127. Clipping to 0.25.
[2023-03-17 19:00:10,897] Step: 402 | lr: 0.8000 | Time: 13.73s |TRAIN loss  0.1703 | TRAIN Acc:  95.78% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:00:24,599] Gradient total norm was 0.5840813517570496. Clipping to 0.25.
[2023-03-17 19:00:24,603] Step: 403 | lr: 0.8000 | Time: 13.69s |TRAIN loss  0.1669 | TRAIN Acc:  95.85% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:00:38,304] Gradient total norm was 0.5830004811286926. Clipping to 0.25.
[2023-03-17 19:00:38,307] Step: 404 | lr: 0.8000 | Time: 13.69s |TRAIN loss  0.1650 | TRAIN Acc:  95.94% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:00:52,031] Gradient total norm was 0.7549605965614319. Clipping to 0.25.
[2023-03-17 19:00:52,035] Step: 405 | lr: 0.8000 | Time: 13.71s |TRAIN loss  0.1687 | TRAIN Acc:  95.62% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:01:05,712] Gradient total norm was 0.654666006565094. Clipping to 0.25.
[2023-03-17 19:01:05,716] Step: 406 | lr: 0.8000 | Time: 13.67s |TRAIN loss  0.1650 | TRAIN Acc:  95.88% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:01:19,437] Gradient total norm was 0.642403781414032. Clipping to 0.25.
[2023-03-17 19:01:19,441] Step: 407 | lr: 0.8000 | Time: 13.71s |TRAIN loss  0.1644 | TRAIN Acc:  95.83% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:01:33,153] Gradient total norm was 0.5670754313468933. Clipping to 0.25.
[2023-03-17 19:01:33,157] Step: 408 | lr: 0.8000 | Time: 13.70s |TRAIN loss  0.1599 | TRAIN Acc:  96.06% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:01:46,872] Gradient total norm was 0.5982087254524231. Clipping to 0.25.
[2023-03-17 19:01:46,875] Step: 409 | lr: 0.8000 | Time: 13.70s |TRAIN loss  0.1590 | TRAIN Acc:  96.03% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:02:00,559] Gradient total norm was 0.6550647616386414. Clipping to 0.25.
[2023-03-17 19:02:00,563] Step: 410 | lr: 0.8000 | Time: 13.67s |TRAIN loss  0.1574 | TRAIN Acc:  96.10% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:02:14,239] Gradient total norm was 0.6995289921760559. Clipping to 0.25.
[2023-03-17 19:02:14,243] Step: 411 | lr: 0.8000 | Time: 13.67s |TRAIN loss  0.1566 | TRAIN Acc:  96.19% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:02:27,992] Gradient total norm was 0.6850723028182983. Clipping to 0.25.
[2023-03-17 19:02:27,995] Step: 412 | lr: 0.8000 | Time: 13.74s |TRAIN loss  0.1551 | TRAIN Acc:  96.21% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:02:41,699] Gradient total norm was 0.8118877410888672. Clipping to 0.25.
[2023-03-17 19:02:41,702] Step: 413 | lr: 0.8000 | Time: 13.69s |TRAIN loss  0.1572 | TRAIN Acc:  95.99% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:02:55,424] Gradient total norm was 0.6964765787124634. Clipping to 0.25.
[2023-03-17 19:02:55,428] Step: 414 | lr: 0.8000 | Time: 13.71s |TRAIN loss  0.1536 | TRAIN Acc:  96.14% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:03:09,159] Gradient total norm was 0.7446978092193604. Clipping to 0.25.
[2023-03-17 19:03:09,162] Step: 415 | lr: 0.8000 | Time: 13.72s |TRAIN loss  0.1572 | TRAIN Acc:  95.82% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:03:22,956] Gradient total norm was 0.5181172490119934. Clipping to 0.25.
[2023-03-17 19:03:22,959] Step: 416 | lr: 0.8000 | Time: 13.78s |TRAIN loss  0.1461 | TRAIN Acc:  96.56% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:03:36,719] Gradient total norm was 0.8108769655227661. Clipping to 0.25.
[2023-03-17 19:03:36,722] Step: 417 | lr: 0.8000 | Time: 13.75s |TRAIN loss  0.1513 | TRAIN Acc:  96.16% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:03:50,450] Gradient total norm was 0.6091768145561218. Clipping to 0.25.
[2023-03-17 19:03:50,453] Step: 418 | lr: 0.8000 | Time: 13.72s |TRAIN loss  0.1432 | TRAIN Acc:  96.73% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:04:04,287] Gradient total norm was 0.7307679653167725. Clipping to 0.25.
[2023-03-17 19:04:04,290] Step: 419 | lr: 0.8000 | Time: 13.82s |TRAIN loss  0.1451 | TRAIN Acc:  96.52% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:04:18,031] Gradient total norm was 0.6307918429374695. Clipping to 0.25.
[2023-03-17 19:04:18,034] Step: 420 | lr: 0.8000 | Time: 13.73s |TRAIN loss  0.1401 | TRAIN Acc:  96.62% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:04:31,790] Gradient total norm was 0.6671799421310425. Clipping to 0.25.
[2023-03-17 19:04:31,793] Step: 421 | lr: 0.8000 | Time: 13.75s |TRAIN loss  0.1437 | TRAIN Acc:  96.59% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:04:45,510] Gradient total norm was 0.5708380937576294. Clipping to 0.25.
[2023-03-17 19:04:45,514] Step: 422 | lr: 0.7999 | Time: 13.71s |TRAIN loss  0.1383 | TRAIN Acc:  96.66% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:04:59,353] Gradient total norm was 0.6866922974586487. Clipping to 0.25.
[2023-03-17 19:04:59,356] Step: 423 | lr: 0.7999 | Time: 13.83s |TRAIN loss  0.1381 | TRAIN Acc:  96.77% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:05:13,123] Gradient total norm was 0.6657670140266418. Clipping to 0.25.
[2023-03-17 19:05:13,127] Step: 424 | lr: 0.7999 | Time: 13.76s |TRAIN loss  0.1354 | TRAIN Acc:  96.78% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:05:26,930] Gradient total norm was 0.7862086892127991. Clipping to 0.25.
[2023-03-17 19:05:26,933] Step: 425 | lr: 0.7999 | Time: 13.79s |TRAIN loss  0.1347 | TRAIN Acc:  96.88% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:05:40,724] Gradient total norm was 0.6555435657501221. Clipping to 0.25.
[2023-03-17 19:05:40,728] Step: 426 | lr: 0.7999 | Time: 13.78s |TRAIN loss  0.1321 | TRAIN Acc:  96.90% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:05:54,508] Gradient total norm was 0.5987266302108765. Clipping to 0.25.
[2023-03-17 19:05:54,512] Step: 427 | lr: 0.7999 | Time: 13.77s |TRAIN loss  0.1307 | TRAIN Acc:  96.90% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:06:08,295] Gradient total norm was 0.6674947738647461. Clipping to 0.25.
[2023-03-17 19:06:08,298] Step: 428 | lr: 0.7999 | Time: 13.77s |TRAIN loss  0.1288 | TRAIN Acc:  96.99% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:06:22,077] Gradient total norm was 0.6698675155639648. Clipping to 0.25.
[2023-03-17 19:06:22,080] Step: 429 | lr: 0.7999 | Time: 13.77s |TRAIN loss  0.1283 | TRAIN Acc:  97.08% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:06:35,924] Gradient total norm was 0.628348171710968. Clipping to 0.25.
[2023-03-17 19:06:35,927] Step: 430 | lr: 0.7999 | Time: 13.83s |TRAIN loss  0.1243 | TRAIN Acc:  97.17% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:06:49,710] Gradient total norm was 0.6755386590957642. Clipping to 0.25.
[2023-03-17 19:06:49,713] Step: 431 | lr: 0.7999 | Time: 13.77s |TRAIN loss  0.1254 | TRAIN Acc:  97.21% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:07:03,555] Gradient total norm was 0.6263025999069214. Clipping to 0.25.
[2023-03-17 19:07:03,559] Step: 432 | lr: 0.7999 | Time: 13.83s |TRAIN loss  0.1222 | TRAIN Acc:  97.24% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:07:17,461] Gradient total norm was 0.7177140712738037. Clipping to 0.25.
[2023-03-17 19:07:17,465] Step: 433 | lr: 0.7999 | Time: 13.89s |TRAIN loss  0.1221 | TRAIN Acc:  97.18% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:07:31,288] Gradient total norm was 0.6218863129615784. Clipping to 0.25.
[2023-03-17 19:07:31,292] Step: 434 | lr: 0.7999 | Time: 13.81s |TRAIN loss  0.1200 | TRAIN Acc:  97.27% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:07:45,123] Gradient total norm was 0.6170426607131958. Clipping to 0.25.
[2023-03-17 19:07:45,126] Step: 435 | lr: 0.7999 | Time: 13.82s |TRAIN loss  0.1183 | TRAIN Acc:  97.40% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:07:58,906] Gradient total norm was 0.595639705657959. Clipping to 0.25.
[2023-03-17 19:07:58,910] Step: 436 | lr: 0.7998 | Time: 13.77s |TRAIN loss  0.1157 | TRAIN Acc:  97.41% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:08:12,784] Gradient total norm was 0.6464906930923462. Clipping to 0.25.
[2023-03-17 19:08:12,788] Step: 437 | lr: 0.7998 | Time: 13.86s |TRAIN loss  0.1167 | TRAIN Acc:  97.40% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:08:26,634] Gradient total norm was 0.8109449148178101. Clipping to 0.25.
[2023-03-17 19:08:26,638] Step: 438 | lr: 0.7998 | Time: 13.84s |TRAIN loss  0.1181 | TRAIN Acc:  97.24% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:08:40,472] Gradient total norm was 0.6041267514228821. Clipping to 0.25.
[2023-03-17 19:08:40,475] Step: 439 | lr: 0.7998 | Time: 13.82s |TRAIN loss  0.1136 | TRAIN Acc:  97.38% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:08:54,287] Gradient total norm was 0.7284603118896484. Clipping to 0.25.
[2023-03-17 19:08:54,291] Step: 440 | lr: 0.7998 | Time: 13.80s |TRAIN loss  0.1148 | TRAIN Acc:  97.41% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:09:08,128] Gradient total norm was 0.6008456349372864. Clipping to 0.25.
[2023-03-17 19:09:08,131] Step: 441 | lr: 0.7998 | Time: 13.83s |TRAIN loss  0.1079 | TRAIN Acc:  97.60% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:09:21,981] Gradient total norm was 1.1034554243087769. Clipping to 0.25.
[2023-03-17 19:09:21,984] Step: 442 | lr: 0.7998 | Time: 13.84s |TRAIN loss  0.1153 | TRAIN Acc:  97.30% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:09:36,024] Gradient total norm was 0.6089304685592651. Clipping to 0.25.
[2023-03-17 19:09:36,027] Step: 443 | lr: 0.7998 | Time: 14.03s |TRAIN loss  0.1085 | TRAIN Acc:  97.51% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:09:49,943] Gradient total norm was 0.8272285461425781. Clipping to 0.25.
[2023-03-17 19:09:49,946] Step: 444 | lr: 0.7998 | Time: 13.91s |TRAIN loss  0.1141 | TRAIN Acc:  97.37% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:10:03,781] Gradient total norm was 0.5661395788192749. Clipping to 0.25.
[2023-03-17 19:10:03,784] Step: 445 | lr: 0.7998 | Time: 13.82s |TRAIN loss  0.1074 | TRAIN Acc:  97.75% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:10:17,662] Gradient total norm was 0.7343023419380188. Clipping to 0.25.
[2023-03-17 19:10:17,665] Step: 446 | lr: 0.7998 | Time: 13.87s |TRAIN loss  0.1086 | TRAIN Acc:  97.55% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:10:31,513] Gradient total norm was 0.5976499319076538. Clipping to 0.25.
[2023-03-17 19:10:31,517] Step: 447 | lr: 0.7997 | Time: 13.84s |TRAIN loss  0.1047 | TRAIN Acc:  97.78% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:10:45,374] Gradient total norm was 0.705578088760376. Clipping to 0.25.
[2023-03-17 19:10:45,377] Step: 448 | lr: 0.7997 | Time: 13.85s |TRAIN loss  0.1040 | TRAIN Acc:  97.65% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:10:59,211] Gradient total norm was 0.7171684503555298. Clipping to 0.25.
[2023-03-17 19:10:59,214] Step: 449 | lr: 0.7997 | Time: 13.82s |TRAIN loss  0.1021 | TRAIN Acc:  97.89% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:11:13,054] Gradient total norm was 1.0128464698791504. Clipping to 0.25.
[2023-03-17 19:11:13,058] Step: 450 | lr: 0.7997 | Time: 13.83s |TRAIN loss  0.1040 | TRAIN Acc:  97.62% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:11:26,928] Gradient total norm was 1.2607707977294922. Clipping to 0.25.
[2023-03-17 19:11:26,932] Step: 451 | lr: 0.7997 | Time: 13.86s |TRAIN loss  0.1051 | TRAIN Acc:  97.68% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:11:40,713] Gradient total norm was 0.7472907304763794. Clipping to 0.25.
[2023-03-17 19:11:40,717] Step: 452 | lr: 0.7997 | Time: 13.77s |TRAIN loss  0.1025 | TRAIN Acc:  97.80% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:11:54,549] Gradient total norm was 0.6937791705131531. Clipping to 0.25.
[2023-03-17 19:11:54,552] Step: 453 | lr: 0.7997 | Time: 13.82s |TRAIN loss  0.1005 | TRAIN Acc:  97.88% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:12:08,342] Gradient total norm was 0.9280703067779541. Clipping to 0.25.
[2023-03-17 19:12:08,345] Step: 454 | lr: 0.7997 | Time: 13.78s |TRAIN loss  0.1008 | TRAIN Acc:  97.91% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:12:22,142] Gradient total norm was 1.090366005897522. Clipping to 0.25.
[2023-03-17 19:12:22,146] Step: 455 | lr: 0.7996 | Time: 13.79s |TRAIN loss  0.1021 | TRAIN Acc:  97.86% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:12:35,902] Gradient total norm was 0.5666614174842834. Clipping to 0.25.
[2023-03-17 19:12:35,905] Step: 456 | lr: 0.7996 | Time: 13.75s |TRAIN loss  0.0976 | TRAIN Acc:  98.00% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:12:49,751] Gradient total norm was 0.6867608428001404. Clipping to 0.25.
[2023-03-17 19:12:49,754] Step: 457 | lr: 0.7996 | Time: 13.84s |TRAIN loss  0.0988 | TRAIN Acc:  97.97% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:13:03,551] Gradient total norm was 0.7393161058425903. Clipping to 0.25.
[2023-03-17 19:13:03,554] Step: 458 | lr: 0.7996 | Time: 13.79s |TRAIN loss  0.0977 | TRAIN Acc:  97.97% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:13:17,367] Gradient total norm was 0.8351198434829712. Clipping to 0.25.
[2023-03-17 19:13:17,370] Step: 459 | lr: 0.7996 | Time: 13.80s |TRAIN loss  0.1002 | TRAIN Acc:  97.70% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:13:31,184] Gradient total norm was 0.7031452655792236. Clipping to 0.25.
[2023-03-17 19:13:31,188] Step: 460 | lr: 0.7996 | Time: 13.80s |TRAIN loss  0.0976 | TRAIN Acc:  97.99% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:13:44,970] Gradient total norm was 0.7854524850845337. Clipping to 0.25.
[2023-03-17 19:13:44,973] Step: 461 | lr: 0.7996 | Time: 13.77s |TRAIN loss  0.0990 | TRAIN Acc:  97.96% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:13:58,679] Gradient total norm was 0.9081823229789734. Clipping to 0.25.
[2023-03-17 19:13:58,683] Step: 462 | lr: 0.7995 | Time: 13.70s |TRAIN loss  0.0982 | TRAIN Acc:  97.98% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:14:12,444] Gradient total norm was 0.6200314164161682. Clipping to 0.25.
[2023-03-17 19:14:12,448] Step: 463 | lr: 0.7995 | Time: 13.75s |TRAIN loss  0.0982 | TRAIN Acc:  97.90% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:14:26,275] Gradient total norm was 0.5559734106063843. Clipping to 0.25.
[2023-03-17 19:14:26,279] Step: 464 | lr: 0.7995 | Time: 13.82s |TRAIN loss  0.0946 | TRAIN Acc:  98.14% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:14:40,121] Gradient total norm was 0.7163078188896179. Clipping to 0.25.
[2023-03-17 19:14:40,125] Step: 465 | lr: 0.7995 | Time: 13.83s |TRAIN loss  0.0947 | TRAIN Acc:  98.21% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:14:53,924] Gradient total norm was 0.7374933958053589. Clipping to 0.25.
[2023-03-17 19:14:53,928] Step: 466 | lr: 0.7995 | Time: 13.79s |TRAIN loss  0.0929 | TRAIN Acc:  98.25% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:15:07,693] Gradient total norm was 0.7494159936904907. Clipping to 0.25.
[2023-03-17 19:15:07,696] Step: 467 | lr: 0.7995 | Time: 13.75s |TRAIN loss  0.0913 | TRAIN Acc:  98.28% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:15:21,501] Gradient total norm was 0.6921865344047546. Clipping to 0.25.
[2023-03-17 19:15:21,505] Step: 468 | lr: 0.7994 | Time: 13.80s |TRAIN loss  0.0899 | TRAIN Acc:  98.22% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:15:35,299] Gradient total norm was 0.6072961091995239. Clipping to 0.25.
[2023-03-17 19:15:35,302] Step: 469 | lr: 0.7994 | Time: 13.78s |TRAIN loss  0.0863 | TRAIN Acc:  98.44% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:15:49,110] Gradient total norm was 0.700282096862793. Clipping to 0.25.
[2023-03-17 19:15:49,113] Step: 470 | lr: 0.7994 | Time: 13.80s |TRAIN loss  0.0884 | TRAIN Acc:  98.14% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:16:02,891] Gradient total norm was 0.6343324780464172. Clipping to 0.25.
[2023-03-17 19:16:02,894] Step: 471 | lr: 0.7994 | Time: 13.77s |TRAIN loss  0.0831 | TRAIN Acc:  98.34% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:16:16,713] Gradient total norm was 0.7192738056182861. Clipping to 0.25.
[2023-03-17 19:16:16,716] Step: 472 | lr: 0.7994 | Time: 13.81s |TRAIN loss  0.0853 | TRAIN Acc:  98.20% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:16:30,565] Gradient total norm was 0.6935064196586609. Clipping to 0.25.
[2023-03-17 19:16:30,568] Step: 473 | lr: 0.7994 | Time: 13.84s |TRAIN loss  0.0799 | TRAIN Acc:  98.42% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:16:44,425] Gradient total norm was 0.6456806659698486. Clipping to 0.25.
[2023-03-17 19:16:44,428] Step: 474 | lr: 0.7993 | Time: 13.85s |TRAIN loss  0.0786 | TRAIN Acc:  98.45% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:16:58,269] Gradient total norm was 0.6633821725845337. Clipping to 0.25.
[2023-03-17 19:16:58,272] Step: 475 | lr: 0.7993 | Time: 13.83s |TRAIN loss  0.0757 | TRAIN Acc:  98.59% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:17:12,080] Gradient total norm was 0.9315111041069031. Clipping to 0.25.
[2023-03-17 19:17:12,083] Step: 476 | lr: 0.7993 | Time: 13.80s |TRAIN loss  0.0758 | TRAIN Acc:  98.56% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:17:26,008] Gradient total norm was 0.8961068987846375. Clipping to 0.25.
[2023-03-17 19:17:26,011] Step: 477 | lr: 0.7993 | Time: 13.92s |TRAIN loss  0.0787 | TRAIN Acc:  98.25% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:17:39,841] Gradient total norm was 0.7632031440734863. Clipping to 0.25.
[2023-03-17 19:17:39,844] Step: 478 | lr: 0.7993 | Time: 13.82s |TRAIN loss  0.0760 | TRAIN Acc:  98.56% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:17:53,706] Gradient total norm was 0.5876637101173401. Clipping to 0.25.
[2023-03-17 19:17:53,709] Step: 479 | lr: 0.7992 | Time: 13.85s |TRAIN loss  0.0770 | TRAIN Acc:  98.43% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:18:07,582] Gradient total norm was 0.545271635055542. Clipping to 0.25.
[2023-03-17 19:18:07,585] Step: 480 | lr: 0.7992 | Time: 13.86s |TRAIN loss  0.0730 | TRAIN Acc:  98.77% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:18:21,387] Gradient total norm was 0.8308110237121582. Clipping to 0.25.
[2023-03-17 19:18:21,390] Step: 481 | lr: 0.7992 | Time: 13.79s |TRAIN loss  0.0757 | TRAIN Acc:  98.36% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:18:35,208] Gradient total norm was 1.2217108011245728. Clipping to 0.25.
[2023-03-17 19:18:35,211] Step: 482 | lr: 0.7992 | Time: 13.81s |TRAIN loss  0.0763 | TRAIN Acc:  98.32% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:18:49,078] Gradient total norm was 2.40505051612854. Clipping to 0.25.
[2023-03-17 19:18:49,082] Step: 483 | lr: 0.7992 | Time: 13.86s |TRAIN loss  0.0895 | TRAIN Acc:  97.87% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:19:02,913] Gradient total norm was 0.7386903762817383. Clipping to 0.25.
[2023-03-17 19:19:02,917] Step: 484 | lr: 0.7992 | Time: 13.82s |TRAIN loss  0.0777 | TRAIN Acc:  98.43% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:19:16,769] Gradient total norm was 0.8697381019592285. Clipping to 0.25.
[2023-03-17 19:19:16,772] Step: 485 | lr: 0.7991 | Time: 13.84s |TRAIN loss  0.0846 | TRAIN Acc:  98.12% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:19:30,653] Gradient total norm was 0.5407164692878723. Clipping to 0.25.
[2023-03-17 19:19:30,656] Step: 486 | lr: 0.7991 | Time: 13.87s |TRAIN loss  0.0742 | TRAIN Acc:  98.66% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:19:44,532] Gradient total norm was 0.8503845930099487. Clipping to 0.25.
[2023-03-17 19:19:44,535] Step: 487 | lr: 0.7991 | Time: 13.87s |TRAIN loss  0.0763 | TRAIN Acc:  98.76% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:19:58,405] Gradient total norm was 0.7587239146232605. Clipping to 0.25.
[2023-03-17 19:19:58,408] Step: 488 | lr: 0.7991 | Time: 13.86s |TRAIN loss  0.0718 | TRAIN Acc:  98.71% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:20:12,254] Gradient total norm was 0.7681038975715637. Clipping to 0.25.
[2023-03-17 19:20:12,258] Step: 489 | lr: 0.7990 | Time: 13.84s |TRAIN loss  0.0713 | TRAIN Acc:  98.81% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:20:26,078] Gradient total norm was 0.9182043075561523. Clipping to 0.25.
[2023-03-17 19:20:26,082] Step: 490 | lr: 0.7990 | Time: 13.81s |TRAIN loss  0.0705 | TRAIN Acc:  98.74% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:20:39,971] Gradient total norm was 1.2746089696884155. Clipping to 0.25.
[2023-03-17 19:20:39,975] Step: 491 | lr: 0.7990 | Time: 13.88s |TRAIN loss  0.0783 | TRAIN Acc:  98.38% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:20:53,840] Gradient total norm was 0.7952448129653931. Clipping to 0.25.
[2023-03-17 19:20:53,843] Step: 492 | lr: 0.7990 | Time: 13.85s |TRAIN loss  0.0703 | TRAIN Acc:  98.86% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:21:07,722] Gradient total norm was 0.666225790977478. Clipping to 0.25.
[2023-03-17 19:21:07,726] Step: 493 | lr: 0.7990 | Time: 13.87s |TRAIN loss  0.0728 | TRAIN Acc:  98.66% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:21:21,591] Gradient total norm was 0.6114507913589478. Clipping to 0.25.
[2023-03-17 19:21:21,595] Step: 494 | lr: 0.7989 | Time: 13.86s |TRAIN loss  0.0691 | TRAIN Acc:  98.83% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:21:35,476] Gradient total norm was 0.746476411819458. Clipping to 0.25.
[2023-03-17 19:21:35,479] Step: 495 | lr: 0.7989 | Time: 13.87s |TRAIN loss  0.0734 | TRAIN Acc:  98.37% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:21:49,312] Gradient total norm was 0.6990786194801331. Clipping to 0.25.
[2023-03-17 19:21:49,315] Step: 496 | lr: 0.7989 | Time: 13.82s |TRAIN loss  0.0763 | TRAIN Acc:  98.15% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:22:03,191] Gradient total norm was 0.6670852303504944. Clipping to 0.25.
[2023-03-17 19:22:03,194] Step: 497 | lr: 0.7989 | Time: 13.87s |TRAIN loss  0.0767 | TRAIN Acc:  98.06% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:22:17,059] Gradient total norm was 0.6365460157394409. Clipping to 0.25.
[2023-03-17 19:22:17,062] Step: 498 | lr: 0.7988 | Time: 13.85s |TRAIN loss  0.0738 | TRAIN Acc:  98.28% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:22:30,906] Gradient total norm was 0.6748908758163452. Clipping to 0.25.
[2023-03-17 19:22:30,910] Step: 499 | lr: 0.7988 | Time: 13.83s |TRAIN loss  0.0703 | TRAIN Acc:  98.48% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:22:44,801] Gradient total norm was 1.400863766670227. Clipping to 0.25.
[2023-03-17 19:22:44,804] Step: 500 | lr: 0.7988 | Time: 13.88s |TRAIN loss  0.0727 | TRAIN Acc:  98.55% |VAL loss  0.3165 | VAL Acc:  89.49% |
[2023-03-17 19:22:58,689] Gradient total norm was 1.6981537342071533. Clipping to 0.25.
[2023-03-17 19:23:04,050] Step: 501 | lr: 0.7988 | Time: 13.87s |TRAIN loss  0.0892 | TRAIN Acc:  97.72% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:23:17,975] Gradient total norm was 0.5248687267303467. Clipping to 0.25.
[2023-03-17 19:23:17,979] Step: 502 | lr: 0.7987 | Time: 13.91s |TRAIN loss  0.0699 | TRAIN Acc:  98.80% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:23:31,841] Gradient total norm was 0.8553600311279297. Clipping to 0.25.
[2023-03-17 19:23:31,844] Step: 503 | lr: 0.7987 | Time: 13.85s |TRAIN loss  0.0730 | TRAIN Acc:  98.51% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:23:45,765] Gradient total norm was 0.71658855676651. Clipping to 0.25.
[2023-03-17 19:23:45,769] Step: 504 | lr: 0.7987 | Time: 13.91s |TRAIN loss  0.0658 | TRAIN Acc:  98.95% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:23:59,670] Gradient total norm was 0.9617966413497925. Clipping to 0.25.
[2023-03-17 19:23:59,673] Step: 505 | lr: 0.7987 | Time: 13.89s |TRAIN loss  0.0626 | TRAIN Acc:  98.98% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:24:13,572] Gradient total norm was 0.6110562086105347. Clipping to 0.25.
[2023-03-17 19:24:13,575] Step: 506 | lr: 0.7986 | Time: 13.89s |TRAIN loss  0.0599 | TRAIN Acc:  99.10% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:24:27,457] Gradient total norm was 0.824282169342041. Clipping to 0.25.
[2023-03-17 19:24:27,461] Step: 507 | lr: 0.7986 | Time: 13.87s |TRAIN loss  0.0608 | TRAIN Acc:  99.01% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:24:41,370] Gradient total norm was 1.283748745918274. Clipping to 0.25.
[2023-03-17 19:24:41,373] Step: 508 | lr: 0.7986 | Time: 13.90s |TRAIN loss  0.0634 | TRAIN Acc:  98.75% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:24:55,216] Gradient total norm was 1.1139229536056519. Clipping to 0.25.
[2023-03-17 19:24:55,219] Step: 509 | lr: 0.7986 | Time: 13.83s |TRAIN loss  0.0690 | TRAIN Acc:  98.43% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:25:09,096] Gradient total norm was 0.9200968146324158. Clipping to 0.25.
[2023-03-17 19:25:09,099] Step: 510 | lr: 0.7985 | Time: 13.87s |TRAIN loss  0.0677 | TRAIN Acc:  98.67% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:25:22,983] Gradient total norm was 0.6743821501731873. Clipping to 0.25.
[2023-03-17 19:25:22,986] Step: 511 | lr: 0.7985 | Time: 13.87s |TRAIN loss  0.0636 | TRAIN Acc:  98.89% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:25:36,923] Gradient total norm was 0.7665339708328247. Clipping to 0.25.
[2023-03-17 19:25:36,926] Step: 512 | lr: 0.7985 | Time: 13.93s |TRAIN loss  0.0647 | TRAIN Acc:  98.79% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:25:50,848] Gradient total norm was 0.7193728685379028. Clipping to 0.25.
[2023-03-17 19:25:50,851] Step: 513 | lr: 0.7985 | Time: 13.91s |TRAIN loss  0.0608 | TRAIN Acc:  99.12% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:26:04,803] Gradient total norm was 0.9083461165428162. Clipping to 0.25.
[2023-03-17 19:26:04,806] Step: 514 | lr: 0.7984 | Time: 13.94s |TRAIN loss  0.0617 | TRAIN Acc:  99.02% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:26:18,731] Gradient total norm was 0.6899945735931396. Clipping to 0.25.
[2023-03-17 19:26:18,735] Step: 515 | lr: 0.7984 | Time: 13.91s |TRAIN loss  0.0590 | TRAIN Acc:  99.08% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:26:32,611] Gradient total norm was 0.7127248048782349. Clipping to 0.25.
[2023-03-17 19:26:32,614] Step: 516 | lr: 0.7984 | Time: 13.87s |TRAIN loss  0.0589 | TRAIN Acc:  99.15% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:26:46,564] Gradient total norm was 0.7002583742141724. Clipping to 0.25.
[2023-03-17 19:26:46,568] Step: 517 | lr: 0.7983 | Time: 13.94s |TRAIN loss  0.0566 | TRAIN Acc:  99.16% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:27:00,437] Gradient total norm was 1.1336431503295898. Clipping to 0.25.
[2023-03-17 19:27:00,441] Step: 518 | lr: 0.7983 | Time: 13.86s |TRAIN loss  0.0591 | TRAIN Acc:  99.06% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:27:14,390] Gradient total norm was 1.9782817363739014. Clipping to 0.25.
[2023-03-17 19:27:14,393] Step: 519 | lr: 0.7983 | Time: 13.94s |TRAIN loss  0.0680 | TRAIN Acc:  98.64% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:27:28,244] Gradient total norm was 0.6514756679534912. Clipping to 0.25.
[2023-03-17 19:27:28,247] Step: 520 | lr: 0.7983 | Time: 13.84s |TRAIN loss  0.0602 | TRAIN Acc:  99.01% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:27:42,115] Gradient total norm was 0.8432793617248535. Clipping to 0.25.
[2023-03-17 19:27:42,118] Step: 521 | lr: 0.7982 | Time: 13.86s |TRAIN loss  0.0612 | TRAIN Acc:  99.08% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:27:56,006] Gradient total norm was 0.5514273643493652. Clipping to 0.25.
[2023-03-17 19:27:56,009] Step: 522 | lr: 0.7982 | Time: 13.88s |TRAIN loss  0.0564 | TRAIN Acc:  99.22% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:28:09,874] Gradient total norm was 1.031430721282959. Clipping to 0.25.
[2023-03-17 19:28:09,877] Step: 523 | lr: 0.7982 | Time: 13.85s |TRAIN loss  0.0606 | TRAIN Acc:  99.01% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:28:23,752] Gradient total norm was 0.6676884293556213. Clipping to 0.25.
[2023-03-17 19:28:23,755] Step: 524 | lr: 0.7981 | Time: 13.87s |TRAIN loss  0.0553 | TRAIN Acc:  99.24% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:28:37,617] Gradient total norm was 0.8907213807106018. Clipping to 0.25.
[2023-03-17 19:28:37,621] Step: 525 | lr: 0.7981 | Time: 13.85s |TRAIN loss  0.0584 | TRAIN Acc:  98.94% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:28:51,495] Gradient total norm was 0.7179514765739441. Clipping to 0.25.
[2023-03-17 19:28:51,499] Step: 526 | lr: 0.7981 | Time: 13.86s |TRAIN loss  0.0553 | TRAIN Acc:  99.24% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:29:05,366] Gradient total norm was 0.8388416767120361. Clipping to 0.25.
[2023-03-17 19:29:05,370] Step: 527 | lr: 0.7980 | Time: 13.86s |TRAIN loss  0.0552 | TRAIN Acc:  99.00% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:29:19,283] Gradient total norm was 0.7209632992744446. Clipping to 0.25.
[2023-03-17 19:29:19,286] Step: 528 | lr: 0.7980 | Time: 13.90s |TRAIN loss  0.0561 | TRAIN Acc:  98.99% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:29:33,168] Gradient total norm was 0.6262901425361633. Clipping to 0.25.
[2023-03-17 19:29:33,171] Step: 529 | lr: 0.7980 | Time: 13.87s |TRAIN loss  0.0571 | TRAIN Acc:  98.83% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:29:47,045] Gradient total norm was 0.5030449628829956. Clipping to 0.25.
[2023-03-17 19:29:47,048] Step: 530 | lr: 0.7979 | Time: 13.86s |TRAIN loss  0.0567 | TRAIN Acc:  98.80% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:30:00,991] Gradient total norm was 0.6242309212684631. Clipping to 0.25.
[2023-03-17 19:30:00,994] Step: 531 | lr: 0.7979 | Time: 13.93s |TRAIN loss  0.0551 | TRAIN Acc:  98.81% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:30:14,877] Gradient total norm was 0.6519418954849243. Clipping to 0.25.
[2023-03-17 19:30:14,880] Step: 532 | lr: 0.7979 | Time: 13.87s |TRAIN loss  0.0534 | TRAIN Acc:  99.01% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:30:28,764] Gradient total norm was 0.9666319489479065. Clipping to 0.25.
[2023-03-17 19:30:28,767] Step: 533 | lr: 0.7979 | Time: 13.87s |TRAIN loss  0.0542 | TRAIN Acc:  99.00% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:30:42,656] Gradient total norm was 0.986757218837738. Clipping to 0.25.
[2023-03-17 19:30:42,659] Step: 534 | lr: 0.7978 | Time: 13.88s |TRAIN loss  0.0526 | TRAIN Acc:  99.19% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:30:56,582] Gradient total norm was 0.6006455421447754. Clipping to 0.25.
[2023-03-17 19:30:56,585] Step: 535 | lr: 0.7978 | Time: 13.91s |TRAIN loss  0.0493 | TRAIN Acc:  99.28% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:31:10,456] Gradient total norm was 0.7002876400947571. Clipping to 0.25.
[2023-03-17 19:31:10,459] Step: 536 | lr: 0.7978 | Time: 13.86s |TRAIN loss  0.0488 | TRAIN Acc:  99.27% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:31:24,338] Gradient total norm was 0.5922088623046875. Clipping to 0.25.
[2023-03-17 19:31:24,342] Step: 537 | lr: 0.7977 | Time: 13.87s |TRAIN loss  0.0471 | TRAIN Acc:  99.31% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:31:38,257] Gradient total norm was 0.6924174427986145. Clipping to 0.25.
[2023-03-17 19:31:38,261] Step: 538 | lr: 0.7977 | Time: 13.90s |TRAIN loss  0.0460 | TRAIN Acc:  99.33% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:31:52,200] Gradient total norm was 0.7465490698814392. Clipping to 0.25.
[2023-03-17 19:31:52,203] Step: 539 | lr: 0.7977 | Time: 13.93s |TRAIN loss  0.0446 | TRAIN Acc:  99.33% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:32:06,155] Gradient total norm was 0.8485769033432007. Clipping to 0.25.
[2023-03-17 19:32:06,159] Step: 540 | lr: 0.7976 | Time: 13.94s |TRAIN loss  0.0439 | TRAIN Acc:  99.39% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:32:20,024] Gradient total norm was 1.0737684965133667. Clipping to 0.25.
[2023-03-17 19:32:20,027] Step: 541 | lr: 0.7976 | Time: 13.85s |TRAIN loss  0.0439 | TRAIN Acc:  99.33% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:32:33,960] Gradient total norm was 1.5993255376815796. Clipping to 0.25.
[2023-03-17 19:32:33,963] Step: 542 | lr: 0.7975 | Time: 13.92s |TRAIN loss  0.0486 | TRAIN Acc:  99.13% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:32:47,819] Gradient total norm was 0.9675495624542236. Clipping to 0.25.
[2023-03-17 19:32:47,822] Step: 543 | lr: 0.7975 | Time: 13.84s |TRAIN loss  0.0489 | TRAIN Acc:  99.04% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:33:01,730] Gradient total norm was 1.4956151247024536. Clipping to 0.25.
[2023-03-17 19:33:01,734] Step: 544 | lr: 0.7975 | Time: 13.90s |TRAIN loss  0.0643 | TRAIN Acc:  98.38% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:33:15,546] Gradient total norm was 0.5239096283912659. Clipping to 0.25.
[2023-03-17 19:33:15,549] Step: 545 | lr: 0.7974 | Time: 13.80s |TRAIN loss  0.0511 | TRAIN Acc:  99.26% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:33:29,431] Gradient total norm was 0.6792598366737366. Clipping to 0.25.
[2023-03-17 19:33:29,434] Step: 546 | lr: 0.7974 | Time: 13.87s |TRAIN loss  0.0519 | TRAIN Acc:  99.23% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:33:43,331] Gradient total norm was 0.7108044624328613. Clipping to 0.25.
[2023-03-17 19:33:43,334] Step: 547 | lr: 0.7974 | Time: 13.89s |TRAIN loss  0.0466 | TRAIN Acc:  99.35% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:33:57,214] Gradient total norm was 1.0365204811096191. Clipping to 0.25.
[2023-03-17 19:33:57,217] Step: 548 | lr: 0.7973 | Time: 13.87s |TRAIN loss  0.0491 | TRAIN Acc:  99.33% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:34:11,153] Gradient total norm was 0.7756364345550537. Clipping to 0.25.
[2023-03-17 19:34:11,156] Step: 549 | lr: 0.7973 | Time: 13.93s |TRAIN loss  0.0436 | TRAIN Acc:  99.44% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:34:25,079] Gradient total norm was 1.012309193611145. Clipping to 0.25.
[2023-03-17 19:34:25,083] Step: 550 | lr: 0.7973 | Time: 13.91s |TRAIN loss  0.0460 | TRAIN Acc:  99.38% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:34:39,030] Gradient total norm was 0.7570199370384216. Clipping to 0.25.
[2023-03-17 19:34:39,034] Step: 551 | lr: 0.7972 | Time: 13.94s |TRAIN loss  0.0412 | TRAIN Acc:  99.51% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:34:52,919] Gradient total norm was 0.9197782874107361. Clipping to 0.25.
[2023-03-17 19:34:52,923] Step: 552 | lr: 0.7972 | Time: 13.88s |TRAIN loss  0.0473 | TRAIN Acc:  99.23% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:35:06,868] Gradient total norm was 0.8892355561256409. Clipping to 0.25.
[2023-03-17 19:35:06,871] Step: 553 | lr: 0.7972 | Time: 13.93s |TRAIN loss  0.0431 | TRAIN Acc:  99.41% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:35:20,777] Gradient total norm was 0.8318468928337097. Clipping to 0.25.
[2023-03-17 19:35:20,780] Step: 554 | lr: 0.7971 | Time: 13.90s |TRAIN loss  0.0497 | TRAIN Acc:  99.26% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:35:34,752] Gradient total norm was 0.5853642821311951. Clipping to 0.25.
[2023-03-17 19:35:34,755] Step: 555 | lr: 0.7971 | Time: 13.96s |TRAIN loss  0.0436 | TRAIN Acc:  99.50% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:35:48,646] Gradient total norm was 0.9499250650405884. Clipping to 0.25.
[2023-03-17 19:35:48,650] Step: 556 | lr: 0.7970 | Time: 13.88s |TRAIN loss  0.0480 | TRAIN Acc:  99.40% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:36:02,549] Gradient total norm was 1.2851827144622803. Clipping to 0.25.
[2023-03-17 19:36:02,552] Step: 557 | lr: 0.7970 | Time: 13.89s |TRAIN loss  0.0475 | TRAIN Acc:  99.27% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:36:16,504] Gradient total norm was 1.180989384651184. Clipping to 0.25.
[2023-03-17 19:36:16,507] Step: 558 | lr: 0.7970 | Time: 13.94s |TRAIN loss  0.0605 | TRAIN Acc:  98.65% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:36:30,421] Gradient total norm was 0.5289539098739624. Clipping to 0.25.
[2023-03-17 19:36:30,424] Step: 559 | lr: 0.7969 | Time: 13.90s |TRAIN loss  0.0476 | TRAIN Acc:  99.46% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:36:44,382] Gradient total norm was 0.7583913207054138. Clipping to 0.25.
[2023-03-17 19:36:44,386] Step: 560 | lr: 0.7969 | Time: 13.95s |TRAIN loss  0.0469 | TRAIN Acc:  99.33% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:36:58,290] Gradient total norm was 0.7318277359008789. Clipping to 0.25.
[2023-03-17 19:36:58,294] Step: 561 | lr: 0.7968 | Time: 13.89s |TRAIN loss  0.0441 | TRAIN Acc:  99.58% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:37:12,289] Gradient total norm was 0.994733452796936. Clipping to 0.25.
[2023-03-17 19:37:12,292] Step: 562 | lr: 0.7968 | Time: 13.99s |TRAIN loss  0.0453 | TRAIN Acc:  99.41% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:37:26,268] Gradient total norm was 1.087669849395752. Clipping to 0.25.
[2023-03-17 19:37:26,272] Step: 563 | lr: 0.7968 | Time: 13.97s |TRAIN loss  0.0461 | TRAIN Acc:  99.34% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:37:40,210] Gradient total norm was 1.1345031261444092. Clipping to 0.25.
[2023-03-17 19:37:40,214] Step: 564 | lr: 0.7967 | Time: 13.93s |TRAIN loss  0.0558 | TRAIN Acc:  98.77% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:37:54,170] Gradient total norm was 0.8013135194778442. Clipping to 0.25.
[2023-03-17 19:37:54,173] Step: 565 | lr: 0.7967 | Time: 13.95s |TRAIN loss  0.0524 | TRAIN Acc:  99.01% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:38:08,121] Gradient total norm was 0.6111180782318115. Clipping to 0.25.
[2023-03-17 19:38:08,124] Step: 566 | lr: 0.7966 | Time: 13.94s |TRAIN loss  0.0516 | TRAIN Acc:  99.05% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:38:22,129] Gradient total norm was 0.6436758637428284. Clipping to 0.25.
[2023-03-17 19:38:22,133] Step: 567 | lr: 0.7966 | Time: 14.00s |TRAIN loss  0.0459 | TRAIN Acc:  99.44% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:38:36,113] Gradient total norm was 0.9381265640258789. Clipping to 0.25.
[2023-03-17 19:38:36,117] Step: 568 | lr: 0.7966 | Time: 13.97s |TRAIN loss  0.0411 | TRAIN Acc:  99.54% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:38:50,101] Gradient total norm was 0.7084997296333313. Clipping to 0.25.
[2023-03-17 19:38:50,104] Step: 569 | lr: 0.7965 | Time: 13.97s |TRAIN loss  0.0389 | TRAIN Acc:  99.66% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:39:04,048] Gradient total norm was 0.8422104716300964. Clipping to 0.25.
[2023-03-17 19:39:04,052] Step: 570 | lr: 0.7965 | Time: 13.93s |TRAIN loss  0.0383 | TRAIN Acc:  99.57% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:39:18,042] Gradient total norm was 1.0560959577560425. Clipping to 0.25.
[2023-03-17 19:39:18,045] Step: 571 | lr: 0.7964 | Time: 13.98s |TRAIN loss  0.0388 | TRAIN Acc:  99.54% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:39:32,064] Gradient total norm was 1.3606812953948975. Clipping to 0.25.
[2023-03-17 19:39:32,067] Step: 572 | lr: 0.7964 | Time: 14.01s |TRAIN loss  0.0478 | TRAIN Acc:  99.09% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:39:46,067] Gradient total norm was 0.9019315838813782. Clipping to 0.25.
[2023-03-17 19:39:46,071] Step: 573 | lr: 0.7964 | Time: 13.99s |TRAIN loss  0.0417 | TRAIN Acc:  99.51% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:40:00,058] Gradient total norm was 1.0945874452590942. Clipping to 0.25.
[2023-03-17 19:40:00,061] Step: 574 | lr: 0.7963 | Time: 13.98s |TRAIN loss  0.0460 | TRAIN Acc:  99.32% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:40:14,060] Gradient total norm was 0.9387826919555664. Clipping to 0.25.
[2023-03-17 19:40:14,064] Step: 575 | lr: 0.7963 | Time: 13.99s |TRAIN loss  0.0480 | TRAIN Acc:  99.20% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:40:28,072] Gradient total norm was 1.198294997215271. Clipping to 0.25.
[2023-03-17 19:40:28,076] Step: 576 | lr: 0.7962 | Time: 14.00s |TRAIN loss  0.0522 | TRAIN Acc:  98.88% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:40:42,044] Gradient total norm was 0.7258110642433167. Clipping to 0.25.
[2023-03-17 19:40:42,047] Step: 577 | lr: 0.7962 | Time: 13.96s |TRAIN loss  0.0620 | TRAIN Acc:  98.71% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:40:56,048] Gradient total norm was 0.5533503890037537. Clipping to 0.25.
[2023-03-17 19:40:56,051] Step: 578 | lr: 0.7961 | Time: 13.99s |TRAIN loss  0.0548 | TRAIN Acc:  98.82% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:41:10,030] Gradient total norm was 0.6700589656829834. Clipping to 0.25.
[2023-03-17 19:41:10,033] Step: 579 | lr: 0.7961 | Time: 13.97s |TRAIN loss  0.0517 | TRAIN Acc:  99.16% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:41:24,018] Gradient total norm was 0.7794640064239502. Clipping to 0.25.
[2023-03-17 19:41:24,021] Step: 580 | lr: 0.7961 | Time: 13.97s |TRAIN loss  0.0478 | TRAIN Acc:  99.47% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:41:37,943] Gradient total norm was 1.0846284627914429. Clipping to 0.25.
[2023-03-17 19:41:37,946] Step: 581 | lr: 0.7960 | Time: 13.91s |TRAIN loss  0.0453 | TRAIN Acc:  99.55% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:41:51,963] Gradient total norm was 0.7251236438751221. Clipping to 0.25.
[2023-03-17 19:41:51,966] Step: 582 | lr: 0.7960 | Time: 14.01s |TRAIN loss  0.0430 | TRAIN Acc:  99.60% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:42:05,925] Gradient total norm was 0.9275205731391907. Clipping to 0.25.
[2023-03-17 19:42:05,928] Step: 583 | lr: 0.7959 | Time: 13.95s |TRAIN loss  0.0426 | TRAIN Acc:  99.38% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:42:19,920] Gradient total norm was 0.683214545249939. Clipping to 0.25.
[2023-03-17 19:42:19,923] Step: 584 | lr: 0.7959 | Time: 13.98s |TRAIN loss  0.0435 | TRAIN Acc:  99.38% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:42:33,887] Gradient total norm was 0.6892368197441101. Clipping to 0.25.
[2023-03-17 19:42:33,890] Step: 585 | lr: 0.7958 | Time: 13.95s |TRAIN loss  0.0402 | TRAIN Acc:  99.56% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:42:47,898] Gradient total norm was 1.0675075054168701. Clipping to 0.25.
[2023-03-17 19:42:47,901] Step: 586 | lr: 0.7958 | Time: 14.00s |TRAIN loss  0.0401 | TRAIN Acc:  99.60% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:43:01,863] Gradient total norm was 1.3782126903533936. Clipping to 0.25.
[2023-03-17 19:43:01,866] Step: 587 | lr: 0.7957 | Time: 13.95s |TRAIN loss  0.0429 | TRAIN Acc:  99.39% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:43:15,856] Gradient total norm was 0.9275850653648376. Clipping to 0.25.
[2023-03-17 19:43:15,859] Step: 588 | lr: 0.7957 | Time: 13.98s |TRAIN loss  0.0417 | TRAIN Acc:  99.55% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:43:29,875] Gradient total norm was 1.4269862174987793. Clipping to 0.25.
[2023-03-17 19:43:29,879] Step: 589 | lr: 0.7956 | Time: 14.01s |TRAIN loss  0.0491 | TRAIN Acc:  99.35% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:43:43,865] Gradient total norm was 0.561042845249176. Clipping to 0.25.
[2023-03-17 19:43:43,868] Step: 590 | lr: 0.7956 | Time: 13.98s |TRAIN loss  0.0404 | TRAIN Acc:  99.63% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:43:57,854] Gradient total norm was 1.0639586448669434. Clipping to 0.25.
[2023-03-17 19:43:57,858] Step: 591 | lr: 0.7956 | Time: 13.98s |TRAIN loss  0.0419 | TRAIN Acc:  99.60% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:44:11,850] Gradient total norm was 1.4246751070022583. Clipping to 0.25.
[2023-03-17 19:44:11,853] Step: 592 | lr: 0.7955 | Time: 13.98s |TRAIN loss  0.0464 | TRAIN Acc:  99.35% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:44:25,903] Gradient total norm was 0.8258875608444214. Clipping to 0.25.
[2023-03-17 19:44:25,906] Step: 593 | lr: 0.7955 | Time: 14.04s |TRAIN loss  0.0440 | TRAIN Acc:  99.47% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:44:39,880] Gradient total norm was 0.7451837658882141. Clipping to 0.25.
[2023-03-17 19:44:39,884] Step: 594 | lr: 0.7954 | Time: 13.96s |TRAIN loss  0.0458 | TRAIN Acc:  99.45% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:44:53,893] Gradient total norm was 0.8133877515792847. Clipping to 0.25.
[2023-03-17 19:44:53,897] Step: 595 | lr: 0.7954 | Time: 14.00s |TRAIN loss  0.0418 | TRAIN Acc:  99.60% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:45:07,938] Gradient total norm was 1.3100084066390991. Clipping to 0.25.
[2023-03-17 19:45:07,941] Step: 596 | lr: 0.7953 | Time: 14.03s |TRAIN loss  0.0490 | TRAIN Acc:  99.22% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:45:21,945] Gradient total norm was 0.7199637293815613. Clipping to 0.25.
[2023-03-17 19:45:21,948] Step: 597 | lr: 0.7953 | Time: 13.99s |TRAIN loss  0.0442 | TRAIN Acc:  99.58% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:45:35,971] Gradient total norm was 0.965265154838562. Clipping to 0.25.
[2023-03-17 19:45:35,974] Step: 598 | lr: 0.7952 | Time: 14.01s |TRAIN loss  0.0476 | TRAIN Acc:  99.22% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:45:49,994] Gradient total norm was 0.9816137552261353. Clipping to 0.25.
[2023-03-17 19:45:49,997] Step: 599 | lr: 0.7952 | Time: 14.01s |TRAIN loss  0.0442 | TRAIN Acc:  99.58% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:46:04,000] Gradient total norm was 1.2625386714935303. Clipping to 0.25.
[2023-03-17 19:46:04,004] Step: 600 | lr: 0.7951 | Time: 13.99s |TRAIN loss  0.0465 | TRAIN Acc:  99.35% |VAL loss  0.2769 | VAL Acc:  90.43% |
[2023-03-17 19:46:18,048] Gradient total norm was 1.3887792825698853. Clipping to 0.25.
[2023-03-17 19:46:23,388] Step: 601 | lr: 0.7951 | Time: 14.03s |TRAIN loss  0.0487 | TRAIN Acc:  99.24% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:46:37,428] Gradient total norm was 0.717000424861908. Clipping to 0.25.
[2023-03-17 19:46:37,432] Step: 602 | lr: 0.7950 | Time: 14.03s |TRAIN loss  0.0488 | TRAIN Acc:  99.30% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:46:51,451] Gradient total norm was 0.619896650314331. Clipping to 0.25.
[2023-03-17 19:46:51,454] Step: 603 | lr: 0.7950 | Time: 14.01s |TRAIN loss  0.0460 | TRAIN Acc:  99.44% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:47:05,491] Gradient total norm was 0.9951215386390686. Clipping to 0.25.
[2023-03-17 19:47:05,494] Step: 604 | lr: 0.7949 | Time: 14.03s |TRAIN loss  0.0432 | TRAIN Acc:  99.44% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:47:19,484] Gradient total norm was 1.2956788539886475. Clipping to 0.25.
[2023-03-17 19:47:19,488] Step: 605 | lr: 0.7949 | Time: 13.98s |TRAIN loss  0.0562 | TRAIN Acc:  98.77% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:47:33,511] Gradient total norm was 0.6635323166847229. Clipping to 0.25.
[2023-03-17 19:47:33,515] Step: 606 | lr: 0.7948 | Time: 14.01s |TRAIN loss  0.0469 | TRAIN Acc:  99.43% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:47:47,493] Gradient total norm was 0.9371912479400635. Clipping to 0.25.
[2023-03-17 19:47:47,497] Step: 607 | lr: 0.7948 | Time: 13.97s |TRAIN loss  0.0488 | TRAIN Acc:  99.47% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:48:01,498] Gradient total norm was 0.7797957062721252. Clipping to 0.25.
[2023-03-17 19:48:01,501] Step: 608 | lr: 0.7947 | Time: 13.99s |TRAIN loss  0.0470 | TRAIN Acc:  99.58% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:48:15,455] Gradient total norm was 0.7745423316955566. Clipping to 0.25.
[2023-03-17 19:48:15,459] Step: 609 | lr: 0.7947 | Time: 13.94s |TRAIN loss  0.0437 | TRAIN Acc:  99.66% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:48:29,421] Gradient total norm was 1.016072154045105. Clipping to 0.25.
[2023-03-17 19:48:29,424] Step: 610 | lr: 0.7946 | Time: 13.95s |TRAIN loss  0.0426 | TRAIN Acc:  99.54% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:48:43,422] Gradient total norm was 0.8346965312957764. Clipping to 0.25.
[2023-03-17 19:48:43,425] Step: 611 | lr: 0.7946 | Time: 13.99s |TRAIN loss  0.0402 | TRAIN Acc:  99.66% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:48:57,356] Gradient total norm was 0.8636590838432312. Clipping to 0.25.
[2023-03-17 19:48:57,360] Step: 612 | lr: 0.7945 | Time: 13.92s |TRAIN loss  0.0394 | TRAIN Acc:  99.55% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:49:11,298] Gradient total norm was 0.7085206508636475. Clipping to 0.25.
[2023-03-17 19:49:11,301] Step: 613 | lr: 0.7945 | Time: 13.93s |TRAIN loss  0.0375 | TRAIN Acc:  99.66% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:49:25,209] Gradient total norm was 0.7563902735710144. Clipping to 0.25.
[2023-03-17 19:49:25,212] Step: 614 | lr: 0.7944 | Time: 13.90s |TRAIN loss  0.0362 | TRAIN Acc:  99.68% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:49:39,169] Gradient total norm was 0.6257902383804321. Clipping to 0.25.
[2023-03-17 19:49:39,172] Step: 615 | lr: 0.7944 | Time: 13.95s |TRAIN loss  0.0321 | TRAIN Acc:  99.78% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:49:53,093] Gradient total norm was 0.8648154735565186. Clipping to 0.25.
[2023-03-17 19:49:53,097] Step: 616 | lr: 0.7943 | Time: 13.91s |TRAIN loss  0.0316 | TRAIN Acc:  99.70% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:50:07,093] Gradient total norm was 1.0472216606140137. Clipping to 0.25.
[2023-03-17 19:50:07,097] Step: 617 | lr: 0.7943 | Time: 13.99s |TRAIN loss  0.0325 | TRAIN Acc:  99.63% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:50:21,051] Gradient total norm was 0.7370645999908447. Clipping to 0.25.
[2023-03-17 19:50:21,054] Step: 618 | lr: 0.7942 | Time: 13.94s |TRAIN loss  0.0318 | TRAIN Acc:  99.62% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:50:35,026] Gradient total norm was 0.544933557510376. Clipping to 0.25.
[2023-03-17 19:50:35,029] Step: 619 | lr: 0.7942 | Time: 13.96s |TRAIN loss  0.0289 | TRAIN Acc:  99.80% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:50:48,967] Gradient total norm was 0.8081252574920654. Clipping to 0.25.
[2023-03-17 19:50:48,971] Step: 620 | lr: 0.7941 | Time: 13.93s |TRAIN loss  0.0318 | TRAIN Acc:  99.60% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:51:02,949] Gradient total norm was 0.9441203474998474. Clipping to 0.25.
[2023-03-17 19:51:02,952] Step: 621 | lr: 0.7940 | Time: 13.97s |TRAIN loss  0.0374 | TRAIN Acc:  99.28% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:51:16,946] Gradient total norm was 0.8395431637763977. Clipping to 0.25.
[2023-03-17 19:51:16,949] Step: 622 | lr: 0.7940 | Time: 13.98s |TRAIN loss  0.0366 | TRAIN Acc:  99.34% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:51:30,850] Gradient total norm was 0.6603332161903381. Clipping to 0.25.
[2023-03-17 19:51:30,853] Step: 623 | lr: 0.7939 | Time: 13.89s |TRAIN loss  0.0428 | TRAIN Acc:  99.21% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:51:44,806] Gradient total norm was 0.5079787373542786. Clipping to 0.25.
[2023-03-17 19:51:44,809] Step: 624 | lr: 0.7939 | Time: 13.94s |TRAIN loss  0.0381 | TRAIN Acc:  99.35% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:51:58,755] Gradient total norm was 0.535721480846405. Clipping to 0.25.
[2023-03-17 19:51:58,758] Step: 625 | lr: 0.7938 | Time: 13.94s |TRAIN loss  0.0391 | TRAIN Acc:  99.46% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:52:12,696] Gradient total norm was 0.5843843817710876. Clipping to 0.25.
[2023-03-17 19:52:12,699] Step: 626 | lr: 0.7938 | Time: 13.93s |TRAIN loss  0.0345 | TRAIN Acc:  99.42% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:52:26,590] Gradient total norm was 1.0565364360809326. Clipping to 0.25.
[2023-03-17 19:52:26,593] Step: 627 | lr: 0.7937 | Time: 13.88s |TRAIN loss  0.0345 | TRAIN Acc:  99.59% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:52:40,541] Gradient total norm was 2.3004446029663086. Clipping to 0.25.
[2023-03-17 19:52:40,544] Step: 628 | lr: 0.7937 | Time: 13.94s |TRAIN loss  0.0574 | TRAIN Acc:  98.59% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:52:54,481] Gradient total norm was 0.8033513426780701. Clipping to 0.25.
[2023-03-17 19:52:54,485] Step: 629 | lr: 0.7936 | Time: 13.93s |TRAIN loss  0.0429 | TRAIN Acc:  99.32% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:53:08,422] Gradient total norm was 1.1434069871902466. Clipping to 0.25.
[2023-03-17 19:53:08,425] Step: 630 | lr: 0.7935 | Time: 13.93s |TRAIN loss  0.0441 | TRAIN Acc:  99.38% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:53:22,400] Gradient total norm was 1.8973106145858765. Clipping to 0.25.
[2023-03-17 19:53:22,403] Step: 631 | lr: 0.7935 | Time: 13.96s |TRAIN loss  0.0578 | TRAIN Acc:  98.94% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:53:36,355] Gradient total norm was 0.7836836576461792. Clipping to 0.25.
[2023-03-17 19:53:36,358] Step: 632 | lr: 0.7934 | Time: 13.94s |TRAIN loss  0.0438 | TRAIN Acc:  99.49% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:53:50,373] Gradient total norm was 1.0804260969161987. Clipping to 0.25.
[2023-03-17 19:53:50,376] Step: 633 | lr: 0.7934 | Time: 14.00s |TRAIN loss  0.0464 | TRAIN Acc:  99.36% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:54:04,348] Gradient total norm was 0.7050861716270447. Clipping to 0.25.
[2023-03-17 19:54:04,352] Step: 634 | lr: 0.7933 | Time: 13.96s |TRAIN loss  0.0448 | TRAIN Acc:  99.49% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:54:18,292] Gradient total norm was 0.6597393155097961. Clipping to 0.25.
[2023-03-17 19:54:18,295] Step: 635 | lr: 0.7933 | Time: 13.93s |TRAIN loss  0.0403 | TRAIN Acc:  99.66% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:54:32,230] Gradient total norm was 0.8932790756225586. Clipping to 0.25.
[2023-03-17 19:54:32,233] Step: 636 | lr: 0.7932 | Time: 13.92s |TRAIN loss  0.0374 | TRAIN Acc:  99.74% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:54:46,187] Gradient total norm was 1.0876554250717163. Clipping to 0.25.
[2023-03-17 19:54:46,191] Step: 637 | lr: 0.7931 | Time: 13.94s |TRAIN loss  0.0372 | TRAIN Acc:  99.72% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:55:00,119] Gradient total norm was 1.5734598636627197. Clipping to 0.25.
[2023-03-17 19:55:00,122] Step: 638 | lr: 0.7931 | Time: 13.92s |TRAIN loss  0.0385 | TRAIN Acc:  99.54% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:55:14,056] Gradient total norm was 1.2065703868865967. Clipping to 0.25.
[2023-03-17 19:55:14,060] Step: 639 | lr: 0.7930 | Time: 13.92s |TRAIN loss  0.0463 | TRAIN Acc:  99.10% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:55:28,036] Gradient total norm was 0.6769916415214539. Clipping to 0.25.
[2023-03-17 19:55:28,039] Step: 640 | lr: 0.7930 | Time: 13.97s |TRAIN loss  0.0384 | TRAIN Acc:  99.55% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:55:41,975] Gradient total norm was 0.7954108119010925. Clipping to 0.25.
[2023-03-17 19:55:41,978] Step: 641 | lr: 0.7929 | Time: 13.93s |TRAIN loss  0.0397 | TRAIN Acc:  99.54% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:55:55,938] Gradient total norm was 0.6810541749000549. Clipping to 0.25.
[2023-03-17 19:55:55,942] Step: 642 | lr: 0.7929 | Time: 13.95s |TRAIN loss  0.0356 | TRAIN Acc:  99.76% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:56:09,848] Gradient total norm was 1.2476105690002441. Clipping to 0.25.
[2023-03-17 19:56:09,851] Step: 643 | lr: 0.7928 | Time: 13.90s |TRAIN loss  0.0368 | TRAIN Acc:  99.68% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:56:23,884] Gradient total norm was 0.9979824423789978. Clipping to 0.25.
[2023-03-17 19:56:23,887] Step: 644 | lr: 0.7927 | Time: 14.02s |TRAIN loss  0.0426 | TRAIN Acc:  99.39% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:56:37,794] Gradient total norm was 0.5213626623153687. Clipping to 0.25.
[2023-03-17 19:56:37,797] Step: 645 | lr: 0.7927 | Time: 13.90s |TRAIN loss  0.0338 | TRAIN Acc:  99.84% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:56:51,762] Gradient total norm was 0.8216144442558289. Clipping to 0.25.
[2023-03-17 19:56:51,765] Step: 646 | lr: 0.7926 | Time: 13.95s |TRAIN loss  0.0350 | TRAIN Acc:  99.77% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:57:05,685] Gradient total norm was 0.77486252784729. Clipping to 0.25.
[2023-03-17 19:57:05,688] Step: 647 | lr: 0.7926 | Time: 13.91s |TRAIN loss  0.0314 | TRAIN Acc:  99.80% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:57:19,628] Gradient total norm was 0.9468505382537842. Clipping to 0.25.
[2023-03-17 19:57:19,631] Step: 648 | lr: 0.7925 | Time: 13.93s |TRAIN loss  0.0337 | TRAIN Acc:  99.70% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:57:33,558] Gradient total norm was 1.0147143602371216. Clipping to 0.25.
[2023-03-17 19:57:33,561] Step: 649 | lr: 0.7924 | Time: 13.92s |TRAIN loss  0.0345 | TRAIN Acc:  99.50% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:57:47,484] Gradient total norm was 0.6208850741386414. Clipping to 0.25.
[2023-03-17 19:57:47,488] Step: 650 | lr: 0.7924 | Time: 13.91s |TRAIN loss  0.0338 | TRAIN Acc:  99.64% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:58:01,469] Gradient total norm was 0.8211643099784851. Clipping to 0.25.
[2023-03-17 19:58:01,473] Step: 651 | lr: 0.7923 | Time: 13.97s |TRAIN loss  0.0386 | TRAIN Acc:  99.15% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:58:15,368] Gradient total norm was 0.48387208580970764. Clipping to 0.25.
[2023-03-17 19:58:15,371] Step: 652 | lr: 0.7923 | Time: 13.89s |TRAIN loss  0.0345 | TRAIN Acc:  99.52% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:58:29,271] Gradient total norm was 0.6898893117904663. Clipping to 0.25.
[2023-03-17 19:58:29,275] Step: 653 | lr: 0.7922 | Time: 13.89s |TRAIN loss  0.0351 | TRAIN Acc:  99.51% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:58:43,205] Gradient total norm was 0.7166887521743774. Clipping to 0.25.
[2023-03-17 19:58:43,209] Step: 654 | lr: 0.7921 | Time: 13.92s |TRAIN loss  0.0319 | TRAIN Acc:  99.81% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:58:57,113] Gradient total norm was 1.5849183797836304. Clipping to 0.25.
[2023-03-17 19:58:57,116] Step: 655 | lr: 0.7921 | Time: 13.89s |TRAIN loss  0.0382 | TRAIN Acc:  99.45% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:59:11,012] Gradient total norm was 0.8360052108764648. Clipping to 0.25.
[2023-03-17 19:59:11,015] Step: 656 | lr: 0.7920 | Time: 13.89s |TRAIN loss  0.0315 | TRAIN Acc:  99.80% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:59:25,004] Gradient total norm was 0.9503569602966309. Clipping to 0.25.
[2023-03-17 19:59:25,007] Step: 657 | lr: 0.7919 | Time: 13.98s |TRAIN loss  0.0359 | TRAIN Acc:  99.45% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:59:38,901] Gradient total norm was 0.6509684920310974. Clipping to 0.25.
[2023-03-17 19:59:38,904] Step: 658 | lr: 0.7919 | Time: 13.88s |TRAIN loss  0.0301 | TRAIN Acc:  99.79% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 19:59:52,790] Gradient total norm was 0.7325459718704224. Clipping to 0.25.
[2023-03-17 19:59:52,794] Step: 659 | lr: 0.7918 | Time: 13.88s |TRAIN loss  0.0302 | TRAIN Acc:  99.74% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:00:06,729] Gradient total norm was 1.4384723901748657. Clipping to 0.25.
[2023-03-17 20:00:06,733] Step: 660 | lr: 0.7918 | Time: 13.93s |TRAIN loss  0.0335 | TRAIN Acc:  99.56% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:00:20,606] Gradient total norm was 0.751436710357666. Clipping to 0.25.
[2023-03-17 20:00:20,610] Step: 661 | lr: 0.7917 | Time: 13.86s |TRAIN loss  0.0312 | TRAIN Acc:  99.69% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:00:34,540] Gradient total norm was 0.925672173500061. Clipping to 0.25.
[2023-03-17 20:00:34,543] Step: 662 | lr: 0.7916 | Time: 13.92s |TRAIN loss  0.0329 | TRAIN Acc:  99.68% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:00:48,428] Gradient total norm was 0.541785478591919. Clipping to 0.25.
[2023-03-17 20:00:48,431] Step: 663 | lr: 0.7916 | Time: 13.87s |TRAIN loss  0.0299 | TRAIN Acc:  99.70% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:01:02,343] Gradient total norm was 0.6838195323944092. Clipping to 0.25.
[2023-03-17 20:01:02,346] Step: 664 | lr: 0.7915 | Time: 13.90s |TRAIN loss  0.0269 | TRAIN Acc:  99.87% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:01:16,214] Gradient total norm was 0.8518680334091187. Clipping to 0.25.
[2023-03-17 20:01:16,217] Step: 665 | lr: 0.7914 | Time: 13.86s |TRAIN loss  0.0266 | TRAIN Acc:  99.86% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:01:30,150] Gradient total norm was 1.0795923471450806. Clipping to 0.25.
[2023-03-17 20:01:30,153] Step: 666 | lr: 0.7914 | Time: 13.92s |TRAIN loss  0.0252 | TRAIN Acc:  99.81% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:01:43,987] Gradient total norm was 1.2036330699920654. Clipping to 0.25.
[2023-03-17 20:01:43,990] Step: 667 | lr: 0.7913 | Time: 13.82s |TRAIN loss  0.0278 | TRAIN Acc:  99.68% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:01:57,864] Gradient total norm was 0.9243630170822144. Clipping to 0.25.
[2023-03-17 20:01:57,867] Step: 668 | lr: 0.7912 | Time: 13.86s |TRAIN loss  0.0320 | TRAIN Acc:  99.44% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:02:11,825] Gradient total norm was 0.7620051503181458. Clipping to 0.25.
[2023-03-17 20:02:11,828] Step: 669 | lr: 0.7912 | Time: 13.95s |TRAIN loss  0.0306 | TRAIN Acc:  99.57% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:02:25,738] Gradient total norm was 0.5039993524551392. Clipping to 0.25.
[2023-03-17 20:02:25,742] Step: 670 | lr: 0.7911 | Time: 13.90s |TRAIN loss  0.0307 | TRAIN Acc:  99.46% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:02:39,658] Gradient total norm was 0.8017281293869019. Clipping to 0.25.
[2023-03-17 20:02:39,661] Step: 671 | lr: 0.7910 | Time: 13.91s |TRAIN loss  0.0273 | TRAIN Acc:  99.83% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:02:53,583] Gradient total norm was 1.7177361249923706. Clipping to 0.25.
[2023-03-17 20:02:53,586] Step: 672 | lr: 0.7910 | Time: 13.91s |TRAIN loss  0.0333 | TRAIN Acc:  99.49% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:03:07,541] Gradient total norm was 1.8708707094192505. Clipping to 0.25.
[2023-03-17 20:03:07,544] Step: 673 | lr: 0.7909 | Time: 13.94s |TRAIN loss  0.0456 | TRAIN Acc:  99.09% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:03:21,457] Gradient total norm was 0.9079064130783081. Clipping to 0.25.
[2023-03-17 20:03:21,460] Step: 674 | lr: 0.7908 | Time: 13.90s |TRAIN loss  0.0438 | TRAIN Acc:  99.25% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:03:35,409] Gradient total norm was 0.7668365836143494. Clipping to 0.25.
[2023-03-17 20:03:35,412] Step: 675 | lr: 0.7908 | Time: 13.94s |TRAIN loss  0.0465 | TRAIN Acc:  99.27% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:03:49,322] Gradient total norm was 0.6112441420555115. Clipping to 0.25.
[2023-03-17 20:03:49,325] Step: 676 | lr: 0.7907 | Time: 13.90s |TRAIN loss  0.0428 | TRAIN Acc:  99.45% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:04:03,183] Gradient total norm was 1.2916516065597534. Clipping to 0.25.
[2023-03-17 20:04:03,187] Step: 677 | lr: 0.7906 | Time: 13.85s |TRAIN loss  0.0386 | TRAIN Acc:  99.53% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:04:17,160] Gradient total norm was 1.985479712486267. Clipping to 0.25.
[2023-03-17 20:04:17,163] Step: 678 | lr: 0.7906 | Time: 13.96s |TRAIN loss  0.0469 | TRAIN Acc:  99.11% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:04:31,075] Gradient total norm was 0.8117871284484863. Clipping to 0.25.
[2023-03-17 20:04:31,078] Step: 679 | lr: 0.7905 | Time: 13.90s |TRAIN loss  0.0415 | TRAIN Acc:  99.45% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:04:44,961] Gradient total norm was 1.5863405466079712. Clipping to 0.25.
[2023-03-17 20:04:44,964] Step: 680 | lr: 0.7904 | Time: 13.87s |TRAIN loss  0.0419 | TRAIN Acc:  99.49% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:04:58,871] Gradient total norm was 1.0408382415771484. Clipping to 0.25.
[2023-03-17 20:04:58,874] Step: 681 | lr: 0.7904 | Time: 13.90s |TRAIN loss  0.0480 | TRAIN Acc:  99.39% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:05:12,787] Gradient total norm was 1.0150749683380127. Clipping to 0.25.
[2023-03-17 20:05:12,790] Step: 682 | lr: 0.7903 | Time: 13.90s |TRAIN loss  0.0405 | TRAIN Acc:  99.70% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:05:26,684] Gradient total norm was 1.0607136487960815. Clipping to 0.25.
[2023-03-17 20:05:26,687] Step: 683 | lr: 0.7902 | Time: 13.88s |TRAIN loss  0.0457 | TRAIN Acc:  99.54% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:05:40,629] Gradient total norm was 0.7937655448913574. Clipping to 0.25.
[2023-03-17 20:05:40,633] Step: 684 | lr: 0.7902 | Time: 13.93s |TRAIN loss  0.0382 | TRAIN Acc:  99.76% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:05:54,493] Gradient total norm was 0.7784261107444763. Clipping to 0.25.
[2023-03-17 20:05:54,496] Step: 685 | lr: 0.7901 | Time: 13.85s |TRAIN loss  0.0393 | TRAIN Acc:  99.76% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:06:08,393] Gradient total norm was 0.6522597074508667. Clipping to 0.25.
[2023-03-17 20:06:08,396] Step: 686 | lr: 0.7900 | Time: 13.89s |TRAIN loss  0.0338 | TRAIN Acc:  99.82% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:06:22,275] Gradient total norm was 0.6887254118919373. Clipping to 0.25.
[2023-03-17 20:06:22,278] Step: 687 | lr: 0.7900 | Time: 13.87s |TRAIN loss  0.0338 | TRAIN Acc:  99.84% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:06:36,175] Gradient total norm was 0.8352245092391968. Clipping to 0.25.
[2023-03-17 20:06:36,178] Step: 688 | lr: 0.7899 | Time: 13.89s |TRAIN loss  0.0296 | TRAIN Acc:  99.85% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:06:50,147] Gradient total norm was 0.7138195037841797. Clipping to 0.25.
[2023-03-17 20:06:50,150] Step: 689 | lr: 0.7898 | Time: 13.96s |TRAIN loss  0.0302 | TRAIN Acc:  99.82% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:07:04,084] Gradient total norm was 0.7043771743774414. Clipping to 0.25.
[2023-03-17 20:07:04,088] Step: 690 | lr: 0.7897 | Time: 13.92s |TRAIN loss  0.0266 | TRAIN Acc:  99.84% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:07:18,149] Gradient total norm was 1.5976557731628418. Clipping to 0.25.
[2023-03-17 20:07:18,152] Step: 691 | lr: 0.7897 | Time: 14.05s |TRAIN loss  0.0337 | TRAIN Acc:  99.50% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:07:32,084] Gradient total norm was 1.7262803316116333. Clipping to 0.25.
[2023-03-17 20:07:32,088] Step: 692 | lr: 0.7896 | Time: 13.92s |TRAIN loss  0.0405 | TRAIN Acc:  99.16% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:07:46,059] Gradient total norm was 1.2586742639541626. Clipping to 0.25.
[2023-03-17 20:07:46,062] Step: 693 | lr: 0.7895 | Time: 13.96s |TRAIN loss  0.0435 | TRAIN Acc:  99.06% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:08:00,008] Gradient total norm was 0.595375657081604. Clipping to 0.25.
[2023-03-17 20:08:00,011] Step: 694 | lr: 0.7895 | Time: 13.94s |TRAIN loss  0.0399 | TRAIN Acc:  99.53% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:08:14,018] Gradient total norm was 0.698996365070343. Clipping to 0.25.
[2023-03-17 20:08:14,021] Step: 695 | lr: 0.7894 | Time: 14.00s |TRAIN loss  0.0384 | TRAIN Acc:  99.39% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:08:28,018] Gradient total norm was 0.8108639121055603. Clipping to 0.25.
[2023-03-17 20:08:28,021] Step: 696 | lr: 0.7893 | Time: 13.99s |TRAIN loss  0.0324 | TRAIN Acc:  99.75% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:08:42,002] Gradient total norm was 0.9466227293014526. Clipping to 0.25.
[2023-03-17 20:08:42,005] Step: 697 | lr: 0.7892 | Time: 13.97s |TRAIN loss  0.0320 | TRAIN Acc:  99.67% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:08:56,052] Gradient total norm was 0.5028218030929565. Clipping to 0.25.
[2023-03-17 20:08:56,056] Step: 698 | lr: 0.7892 | Time: 14.04s |TRAIN loss  0.0290 | TRAIN Acc:  99.83% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:09:10,056] Gradient total norm was 0.9283782839775085. Clipping to 0.25.
[2023-03-17 20:09:10,060] Step: 699 | lr: 0.7891 | Time: 13.99s |TRAIN loss  0.0297 | TRAIN Acc:  99.67% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:09:24,025] Gradient total norm was 0.5458531379699707. Clipping to 0.25.
[2023-03-17 20:09:24,028] Step: 700 | lr: 0.7890 | Time: 13.95s |TRAIN loss  0.0272 | TRAIN Acc:  99.77% |VAL loss  0.3467 | VAL Acc:  89.04% |
[2023-03-17 20:09:38,005] Gradient total norm was 0.7794957160949707. Clipping to 0.25.
[2023-03-17 20:09:43,326] Step: 701 | lr: 0.7889 | Time: 13.97s |TRAIN loss  0.0265 | TRAIN Acc:  99.80% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:09:57,316] Gradient total norm was 0.8707050681114197. Clipping to 0.25.
[2023-03-17 20:09:57,319] Step: 702 | lr: 0.7889 | Time: 13.98s |TRAIN loss  0.0252 | TRAIN Acc:  99.87% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:10:11,293] Gradient total norm was 1.2011810541152954. Clipping to 0.25.
[2023-03-17 20:10:11,296] Step: 703 | lr: 0.7888 | Time: 13.96s |TRAIN loss  0.0277 | TRAIN Acc:  99.74% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:10:25,329] Gradient total norm was 0.9537053108215332. Clipping to 0.25.
[2023-03-17 20:10:25,332] Step: 704 | lr: 0.7887 | Time: 14.02s |TRAIN loss  0.0288 | TRAIN Acc:  99.68% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:10:39,357] Gradient total norm was 0.6794105172157288. Clipping to 0.25.
[2023-03-17 20:10:39,361] Step: 705 | lr: 0.7887 | Time: 14.01s |TRAIN loss  0.0284 | TRAIN Acc:  99.72% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:10:53,377] Gradient total norm was 0.7753458023071289. Clipping to 0.25.
[2023-03-17 20:10:53,381] Step: 706 | lr: 0.7886 | Time: 14.01s |TRAIN loss  0.0302 | TRAIN Acc:  99.72% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:11:07,454] Gradient total norm was 1.2352979183197021. Clipping to 0.25.
[2023-03-17 20:11:07,458] Step: 707 | lr: 0.7885 | Time: 14.06s |TRAIN loss  0.0290 | TRAIN Acc:  99.80% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:11:21,583] Gradient total norm was 1.3742700815200806. Clipping to 0.25.
[2023-03-17 20:11:21,587] Step: 708 | lr: 0.7884 | Time: 14.12s |TRAIN loss  0.0371 | TRAIN Acc:  99.47% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:11:35,630] Gradient total norm was 0.7275109887123108. Clipping to 0.25.
[2023-03-17 20:11:35,633] Step: 709 | lr: 0.7884 | Time: 14.03s |TRAIN loss  0.0321 | TRAIN Acc:  99.83% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:11:49,648] Gradient total norm was 1.2424907684326172. Clipping to 0.25.
[2023-03-17 20:11:49,651] Step: 710 | lr: 0.7883 | Time: 14.00s |TRAIN loss  0.0324 | TRAIN Acc:  99.69% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:12:03,722] Gradient total norm was 1.2732170820236206. Clipping to 0.25.
[2023-03-17 20:12:03,725] Step: 711 | lr: 0.7882 | Time: 14.06s |TRAIN loss  0.0397 | TRAIN Acc:  99.44% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:12:17,767] Gradient total norm was 0.7258188724517822. Clipping to 0.25.
[2023-03-17 20:12:17,771] Step: 712 | lr: 0.7881 | Time: 14.03s |TRAIN loss  0.0342 | TRAIN Acc:  99.82% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:12:31,813] Gradient total norm was 0.8062846660614014. Clipping to 0.25.
[2023-03-17 20:12:31,816] Step: 713 | lr: 0.7881 | Time: 14.03s |TRAIN loss  0.0348 | TRAIN Acc:  99.78% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:12:45,898] Gradient total norm was 1.0804417133331299. Clipping to 0.25.
[2023-03-17 20:12:45,902] Step: 714 | lr: 0.7880 | Time: 14.07s |TRAIN loss  0.0363 | TRAIN Acc:  99.70% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:12:59,975] Gradient total norm was 0.7579495906829834. Clipping to 0.25.
[2023-03-17 20:12:59,979] Step: 715 | lr: 0.7879 | Time: 14.06s |TRAIN loss  0.0313 | TRAIN Acc:  99.79% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:13:14,011] Gradient total norm was 0.8107557892799377. Clipping to 0.25.
[2023-03-17 20:13:14,014] Step: 716 | lr: 0.7878 | Time: 14.02s |TRAIN loss  0.0335 | TRAIN Acc:  99.77% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:13:28,039] Gradient total norm was 1.1122223138809204. Clipping to 0.25.
[2023-03-17 20:13:28,042] Step: 717 | lr: 0.7877 | Time: 14.01s |TRAIN loss  0.0304 | TRAIN Acc:  99.70% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:13:42,067] Gradient total norm was 1.0074892044067383. Clipping to 0.25.
[2023-03-17 20:13:42,071] Step: 718 | lr: 0.7877 | Time: 14.01s |TRAIN loss  0.0362 | TRAIN Acc:  99.38% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:13:56,149] Gradient total norm was 0.6876800060272217. Clipping to 0.25.
[2023-03-17 20:13:56,152] Step: 719 | lr: 0.7876 | Time: 14.07s |TRAIN loss  0.0307 | TRAIN Acc:  99.71% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:14:10,247] Gradient total norm was 0.5626242160797119. Clipping to 0.25.
[2023-03-17 20:14:10,250] Step: 720 | lr: 0.7875 | Time: 14.08s |TRAIN loss  0.0271 | TRAIN Acc:  99.76% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:14:24,267] Gradient total norm was 0.621609628200531. Clipping to 0.25.
[2023-03-17 20:14:24,270] Step: 721 | lr: 0.7874 | Time: 14.01s |TRAIN loss  0.0254 | TRAIN Acc:  99.86% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:14:38,301] Gradient total norm was 0.8104841709136963. Clipping to 0.25.
[2023-03-17 20:14:38,305] Step: 722 | lr: 0.7874 | Time: 14.02s |TRAIN loss  0.0224 | TRAIN Acc:  99.89% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:14:52,332] Gradient total norm was 0.6964735984802246. Clipping to 0.25.
[2023-03-17 20:14:52,336] Step: 723 | lr: 0.7873 | Time: 14.02s |TRAIN loss  0.0213 | TRAIN Acc:  99.90% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:15:06,390] Gradient total norm was 0.8006396889686584. Clipping to 0.25.
[2023-03-17 20:15:06,394] Step: 724 | lr: 0.7872 | Time: 14.04s |TRAIN loss  0.0222 | TRAIN Acc:  99.81% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:15:20,443] Gradient total norm was 0.6211152672767639. Clipping to 0.25.
[2023-03-17 20:15:20,446] Step: 725 | lr: 0.7871 | Time: 14.04s |TRAIN loss  0.0212 | TRAIN Acc:  99.85% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:15:34,485] Gradient total norm was 0.6570327281951904. Clipping to 0.25.
[2023-03-17 20:15:34,488] Step: 726 | lr: 0.7870 | Time: 14.03s |TRAIN loss  0.0221 | TRAIN Acc:  99.91% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:15:48,509] Gradient total norm was 0.9363685846328735. Clipping to 0.25.
[2023-03-17 20:15:48,512] Step: 727 | lr: 0.7870 | Time: 14.01s |TRAIN loss  0.0237 | TRAIN Acc:  99.79% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:16:02,567] Gradient total norm was 0.6295721530914307. Clipping to 0.25.
[2023-03-17 20:16:02,570] Step: 728 | lr: 0.7869 | Time: 14.04s |TRAIN loss  0.0249 | TRAIN Acc:  99.84% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:16:16,637] Gradient total norm was 0.8427103757858276. Clipping to 0.25.
[2023-03-17 20:16:16,640] Step: 729 | lr: 0.7868 | Time: 14.06s |TRAIN loss  0.0245 | TRAIN Acc:  99.72% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:16:30,696] Gradient total norm was 0.5782510638237. Clipping to 0.25.
[2023-03-17 20:16:30,699] Step: 730 | lr: 0.7867 | Time: 14.04s |TRAIN loss  0.0227 | TRAIN Acc:  99.82% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:16:44,692] Gradient total norm was 0.9587013721466064. Clipping to 0.25.
[2023-03-17 20:16:44,695] Step: 731 | lr: 0.7866 | Time: 13.98s |TRAIN loss  0.0262 | TRAIN Acc:  99.62% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:16:58,767] Gradient total norm was 0.9414682388305664. Clipping to 0.25.
[2023-03-17 20:16:58,771] Step: 732 | lr: 0.7866 | Time: 14.06s |TRAIN loss  0.0249 | TRAIN Acc:  99.66% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:17:12,757] Gradient total norm was 1.131049633026123. Clipping to 0.25.
[2023-03-17 20:17:12,761] Step: 733 | lr: 0.7865 | Time: 13.98s |TRAIN loss  0.0410 | TRAIN Acc:  99.12% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:17:26,755] Gradient total norm was 0.6245813965797424. Clipping to 0.25.
[2023-03-17 20:17:26,758] Step: 734 | lr: 0.7864 | Time: 13.98s |TRAIN loss  0.0273 | TRAIN Acc:  99.76% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:17:40,799] Gradient total norm was 1.3657108545303345. Clipping to 0.25.
[2023-03-17 20:17:40,802] Step: 735 | lr: 0.7863 | Time: 14.03s |TRAIN loss  0.0338 | TRAIN Acc:  99.46% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:17:54,843] Gradient total norm was 1.6952015161514282. Clipping to 0.25.
[2023-03-17 20:17:54,847] Step: 736 | lr: 0.7862 | Time: 14.03s |TRAIN loss  0.0395 | TRAIN Acc:  99.42% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:18:08,886] Gradient total norm was 1.2867687940597534. Clipping to 0.25.
[2023-03-17 20:18:08,890] Step: 737 | lr: 0.7862 | Time: 14.03s |TRAIN loss  0.0450 | TRAIN Acc:  99.28% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:18:22,905] Gradient total norm was 0.7411026358604431. Clipping to 0.25.
[2023-03-17 20:18:22,909] Step: 738 | lr: 0.7861 | Time: 14.01s |TRAIN loss  0.0400 | TRAIN Acc:  99.60% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:18:36,866] Gradient total norm was 0.6927710175514221. Clipping to 0.25.
[2023-03-17 20:18:36,870] Step: 739 | lr: 0.7860 | Time: 13.95s |TRAIN loss  0.0348 | TRAIN Acc:  99.73% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:18:50,896] Gradient total norm was 0.8873381614685059. Clipping to 0.25.
[2023-03-17 20:18:50,899] Step: 740 | lr: 0.7859 | Time: 14.02s |TRAIN loss  0.0328 | TRAIN Acc:  99.69% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:19:04,901] Gradient total norm was 0.7494685649871826. Clipping to 0.25.
[2023-03-17 20:19:04,905] Step: 741 | lr: 0.7858 | Time: 13.99s |TRAIN loss  0.0296 | TRAIN Acc:  99.73% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:19:18,894] Gradient total norm was 0.7498041391372681. Clipping to 0.25.
[2023-03-17 20:19:18,897] Step: 742 | lr: 0.7857 | Time: 13.98s |TRAIN loss  0.0293 | TRAIN Acc:  99.69% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:19:32,969] Gradient total norm was 0.9085354208946228. Clipping to 0.25.
[2023-03-17 20:19:32,972] Step: 743 | lr: 0.7857 | Time: 14.06s |TRAIN loss  0.0291 | TRAIN Acc:  99.65% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:19:46,992] Gradient total norm was 1.349480390548706. Clipping to 0.25.
[2023-03-17 20:19:46,996] Step: 744 | lr: 0.7856 | Time: 14.01s |TRAIN loss  0.0352 | TRAIN Acc:  99.27% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:20:01,155] Gradient total norm was 0.6633707284927368. Clipping to 0.25.
[2023-03-17 20:20:01,158] Step: 745 | lr: 0.7855 | Time: 14.15s |TRAIN loss  0.0327 | TRAIN Acc:  99.51% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:20:15,185] Gradient total norm was 0.6440752148628235. Clipping to 0.25.
[2023-03-17 20:20:15,188] Step: 746 | lr: 0.7854 | Time: 14.02s |TRAIN loss  0.0353 | TRAIN Acc:  99.45% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:20:29,240] Gradient total norm was 0.4918264150619507. Clipping to 0.25.
[2023-03-17 20:20:29,243] Step: 747 | lr: 0.7853 | Time: 14.04s |TRAIN loss  0.0294 | TRAIN Acc:  99.72% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:20:43,277] Gradient total norm was 0.6021570563316345. Clipping to 0.25.
[2023-03-17 20:20:43,280] Step: 748 | lr: 0.7852 | Time: 14.02s |TRAIN loss  0.0259 | TRAIN Acc:  99.88% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:20:57,380] Gradient total norm was 0.7805054187774658. Clipping to 0.25.
[2023-03-17 20:20:57,384] Step: 749 | lr: 0.7852 | Time: 14.09s |TRAIN loss  0.0228 | TRAIN Acc:  99.86% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:21:11,493] Gradient total norm was 1.2179230451583862. Clipping to 0.25.
[2023-03-17 20:21:11,496] Step: 750 | lr: 0.7851 | Time: 14.10s |TRAIN loss  0.0241 | TRAIN Acc:  99.80% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:21:25,538] Gradient total norm was 0.8195501565933228. Clipping to 0.25.
[2023-03-17 20:21:25,542] Step: 751 | lr: 0.7850 | Time: 14.03s |TRAIN loss  0.0225 | TRAIN Acc:  99.85% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:21:39,567] Gradient total norm was 0.9340700507164001. Clipping to 0.25.
[2023-03-17 20:21:39,571] Step: 752 | lr: 0.7849 | Time: 14.02s |TRAIN loss  0.0222 | TRAIN Acc:  99.85% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:21:53,562] Gradient total norm was 0.854992687702179. Clipping to 0.25.
[2023-03-17 20:21:53,566] Step: 753 | lr: 0.7848 | Time: 13.98s |TRAIN loss  0.0219 | TRAIN Acc:  99.87% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:22:07,639] Gradient total norm was 1.1125099658966064. Clipping to 0.25.
[2023-03-17 20:22:07,643] Step: 754 | lr: 0.7847 | Time: 14.06s |TRAIN loss  0.0238 | TRAIN Acc:  99.81% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:22:21,703] Gradient total norm was 0.8748689889907837. Clipping to 0.25.
[2023-03-17 20:22:21,707] Step: 755 | lr: 0.7846 | Time: 14.05s |TRAIN loss  0.0224 | TRAIN Acc:  99.89% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:22:35,733] Gradient total norm was 1.0981205701828003. Clipping to 0.25.
[2023-03-17 20:22:35,736] Step: 756 | lr: 0.7846 | Time: 14.02s |TRAIN loss  0.0271 | TRAIN Acc:  99.71% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:22:49,804] Gradient total norm was 1.024823784828186. Clipping to 0.25.
[2023-03-17 20:22:49,807] Step: 757 | lr: 0.7845 | Time: 14.06s |TRAIN loss  0.0272 | TRAIN Acc:  99.64% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:23:03,797] Gradient total norm was 0.8036147952079773. Clipping to 0.25.
[2023-03-17 20:23:03,800] Step: 758 | lr: 0.7844 | Time: 13.98s |TRAIN loss  0.0292 | TRAIN Acc:  99.70% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:23:17,926] Gradient total norm was 0.8797667622566223. Clipping to 0.25.
[2023-03-17 20:23:17,929] Step: 759 | lr: 0.7843 | Time: 14.12s |TRAIN loss  0.0308 | TRAIN Acc:  99.65% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:23:32,031] Gradient total norm was 1.3027517795562744. Clipping to 0.25.
[2023-03-17 20:23:32,034] Step: 760 | lr: 0.7842 | Time: 14.09s |TRAIN loss  0.0309 | TRAIN Acc:  99.70% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:23:46,123] Gradient total norm was 1.1403248310089111. Clipping to 0.25.
[2023-03-17 20:23:46,126] Step: 761 | lr: 0.7841 | Time: 14.08s |TRAIN loss  0.0354 | TRAIN Acc:  99.58% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:24:00,219] Gradient total norm was 0.6364223957061768. Clipping to 0.25.
[2023-03-17 20:24:00,222] Step: 762 | lr: 0.7840 | Time: 14.08s |TRAIN loss  0.0308 | TRAIN Acc:  99.80% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:24:14,261] Gradient total norm was 0.8393535614013672. Clipping to 0.25.
[2023-03-17 20:24:14,264] Step: 763 | lr: 0.7839 | Time: 14.03s |TRAIN loss  0.0315 | TRAIN Acc:  99.77% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:24:28,356] Gradient total norm was 0.8076711893081665. Clipping to 0.25.
[2023-03-17 20:24:28,359] Step: 764 | lr: 0.7839 | Time: 14.08s |TRAIN loss  0.0286 | TRAIN Acc:  99.89% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:24:42,377] Gradient total norm was 1.17659330368042. Clipping to 0.25.
[2023-03-17 20:24:42,380] Step: 765 | lr: 0.7838 | Time: 14.01s |TRAIN loss  0.0277 | TRAIN Acc:  99.83% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:24:56,424] Gradient total norm was 1.6040693521499634. Clipping to 0.25.
[2023-03-17 20:24:56,427] Step: 766 | lr: 0.7837 | Time: 14.03s |TRAIN loss  0.0309 | TRAIN Acc:  99.73% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:25:10,487] Gradient total norm was 1.2445876598358154. Clipping to 0.25.
[2023-03-17 20:25:10,490] Step: 767 | lr: 0.7836 | Time: 14.05s |TRAIN loss  0.0349 | TRAIN Acc:  99.52% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:25:24,507] Gradient total norm was 1.1247460842132568. Clipping to 0.25.
[2023-03-17 20:25:24,511] Step: 768 | lr: 0.7835 | Time: 14.01s |TRAIN loss  0.0331 | TRAIN Acc:  99.68% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:25:38,587] Gradient total norm was 0.7648868560791016. Clipping to 0.25.
[2023-03-17 20:25:38,591] Step: 769 | lr: 0.7834 | Time: 14.07s |TRAIN loss  0.0368 | TRAIN Acc:  99.48% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:25:52,636] Gradient total norm was 0.6196410059928894. Clipping to 0.25.
[2023-03-17 20:25:52,639] Step: 770 | lr: 0.7833 | Time: 14.04s |TRAIN loss  0.0296 | TRAIN Acc:  99.84% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:26:06,711] Gradient total norm was 0.6330071091651917. Clipping to 0.25.
[2023-03-17 20:26:06,721] Step: 771 | lr: 0.7832 | Time: 14.06s |TRAIN loss  0.0252 | TRAIN Acc:  99.88% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:26:20,793] Gradient total norm was 0.7639226317405701. Clipping to 0.25.
[2023-03-17 20:26:20,797] Step: 772 | lr: 0.7831 | Time: 14.06s |TRAIN loss  0.0255 | TRAIN Acc:  99.90% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:26:34,848] Gradient total norm was 0.9847081899642944. Clipping to 0.25.
[2023-03-17 20:26:34,851] Step: 773 | lr: 0.7830 | Time: 14.04s |TRAIN loss  0.0218 | TRAIN Acc:  99.89% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:26:48,978] Gradient total norm was 0.8223446607589722. Clipping to 0.25.
[2023-03-17 20:26:48,981] Step: 774 | lr: 0.7830 | Time: 14.12s |TRAIN loss  0.0234 | TRAIN Acc:  99.81% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:27:03,020] Gradient total norm was 1.1618967056274414. Clipping to 0.25.
[2023-03-17 20:27:03,023] Step: 775 | lr: 0.7829 | Time: 14.03s |TRAIN loss  0.0218 | TRAIN Acc:  99.83% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:27:17,141] Gradient total norm was 0.8472071290016174. Clipping to 0.25.
[2023-03-17 20:27:17,144] Step: 776 | lr: 0.7828 | Time: 14.11s |TRAIN loss  0.0223 | TRAIN Acc:  99.86% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:27:31,233] Gradient total norm was 0.810534656047821. Clipping to 0.25.
[2023-03-17 20:27:31,236] Step: 777 | lr: 0.7827 | Time: 14.08s |TRAIN loss  0.0208 | TRAIN Acc:  99.90% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:27:45,320] Gradient total norm was 0.589370846748352. Clipping to 0.25.
[2023-03-17 20:27:45,324] Step: 778 | lr: 0.7826 | Time: 14.07s |TRAIN loss  0.0190 | TRAIN Acc:  99.92% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:27:59,446] Gradient total norm was 0.6740206480026245. Clipping to 0.25.
[2023-03-17 20:27:59,449] Step: 779 | lr: 0.7825 | Time: 14.11s |TRAIN loss  0.0181 | TRAIN Acc:  99.93% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:28:13,533] Gradient total norm was 1.2916805744171143. Clipping to 0.25.
[2023-03-17 20:28:13,536] Step: 780 | lr: 0.7824 | Time: 14.07s |TRAIN loss  0.0199 | TRAIN Acc:  99.84% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:28:27,660] Gradient total norm was 0.8935717940330505. Clipping to 0.25.
[2023-03-17 20:28:27,664] Step: 781 | lr: 0.7823 | Time: 14.11s |TRAIN loss  0.0223 | TRAIN Acc:  99.73% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:28:41,813] Gradient total norm was 1.0342669486999512. Clipping to 0.25.
[2023-03-17 20:28:41,817] Step: 782 | lr: 0.7822 | Time: 14.14s |TRAIN loss  0.0254 | TRAIN Acc:  99.60% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:28:55,894] Gradient total norm was 0.7111388444900513. Clipping to 0.25.
[2023-03-17 20:28:55,897] Step: 783 | lr: 0.7821 | Time: 14.07s |TRAIN loss  0.0284 | TRAIN Acc:  99.51% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:29:09,986] Gradient total norm was 0.5595795512199402. Clipping to 0.25.
[2023-03-17 20:29:09,989] Step: 784 | lr: 0.7820 | Time: 14.08s |TRAIN loss  0.0232 | TRAIN Acc:  99.76% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:29:24,058] Gradient total norm was 0.752030074596405. Clipping to 0.25.
[2023-03-17 20:29:24,061] Step: 785 | lr: 0.7819 | Time: 14.06s |TRAIN loss  0.0238 | TRAIN Acc:  99.87% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:29:38,115] Gradient total norm was 1.2397783994674683. Clipping to 0.25.
[2023-03-17 20:29:38,118] Step: 786 | lr: 0.7819 | Time: 14.04s |TRAIN loss  0.0253 | TRAIN Acc:  99.66% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:29:52,188] Gradient total norm was 0.7229570746421814. Clipping to 0.25.
[2023-03-17 20:29:52,192] Step: 787 | lr: 0.7818 | Time: 14.06s |TRAIN loss  0.0273 | TRAIN Acc:  99.76% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:30:06,200] Gradient total norm was 1.059087872505188. Clipping to 0.25.
[2023-03-17 20:30:06,203] Step: 788 | lr: 0.7817 | Time: 14.00s |TRAIN loss  0.0247 | TRAIN Acc:  99.82% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:30:20,285] Gradient total norm was 1.0259355306625366. Clipping to 0.25.
[2023-03-17 20:30:20,288] Step: 789 | lr: 0.7816 | Time: 14.07s |TRAIN loss  0.0284 | TRAIN Acc:  99.73% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:30:34,358] Gradient total norm was 1.559898853302002. Clipping to 0.25.
[2023-03-17 20:30:34,361] Step: 790 | lr: 0.7815 | Time: 14.06s |TRAIN loss  0.0370 | TRAIN Acc:  99.25% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:30:48,426] Gradient total norm was 0.5731585025787354. Clipping to 0.25.
[2023-03-17 20:30:48,430] Step: 791 | lr: 0.7814 | Time: 14.05s |TRAIN loss  0.0302 | TRAIN Acc:  99.70% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:31:02,480] Gradient total norm was 0.6779136657714844. Clipping to 0.25.
[2023-03-17 20:31:02,483] Step: 792 | lr: 0.7813 | Time: 14.04s |TRAIN loss  0.0343 | TRAIN Acc:  99.49% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:31:16,625] Gradient total norm was 0.6226786375045776. Clipping to 0.25.
[2023-03-17 20:31:16,628] Step: 793 | lr: 0.7812 | Time: 14.13s |TRAIN loss  0.0339 | TRAIN Acc:  99.59% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:31:30,747] Gradient total norm was 0.7325185537338257. Clipping to 0.25.
[2023-03-17 20:31:30,750] Step: 794 | lr: 0.7811 | Time: 14.11s |TRAIN loss  0.0321 | TRAIN Acc:  99.51% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:31:44,808] Gradient total norm was 0.4832552671432495. Clipping to 0.25.
[2023-03-17 20:31:44,811] Step: 795 | lr: 0.7810 | Time: 14.05s |TRAIN loss  0.0345 | TRAIN Acc:  99.79% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:31:58,877] Gradient total norm was 0.759609043598175. Clipping to 0.25.
[2023-03-17 20:31:58,881] Step: 796 | lr: 0.7809 | Time: 14.06s |TRAIN loss  0.0259 | TRAIN Acc:  99.83% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:32:12,904] Gradient total norm was 0.8150033354759216. Clipping to 0.25.
[2023-03-17 20:32:12,908] Step: 797 | lr: 0.7808 | Time: 14.01s |TRAIN loss  0.0271 | TRAIN Acc:  99.89% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:32:26,862] Gradient total norm was 1.063445806503296. Clipping to 0.25.
[2023-03-17 20:32:26,866] Step: 798 | lr: 0.7807 | Time: 13.94s |TRAIN loss  0.0228 | TRAIN Acc:  99.89% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:32:40,812] Gradient total norm was 0.6987510919570923. Clipping to 0.25.
[2023-03-17 20:32:40,815] Step: 799 | lr: 0.7806 | Time: 13.94s |TRAIN loss  0.0218 | TRAIN Acc:  99.92% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:32:54,873] Gradient total norm was 1.1689831018447876. Clipping to 0.25.
[2023-03-17 20:32:54,877] Step: 800 | lr: 0.7805 | Time: 14.05s |TRAIN loss  0.0201 | TRAIN Acc:  99.86% |VAL loss  0.3258 | VAL Acc:  90.17% |
[2023-03-17 20:33:08,967] Gradient total norm was 1.155369520187378. Clipping to 0.25.
[2023-03-17 20:33:13,898] Step: 801 | lr: 0.7804 | Time: 14.08s |TRAIN loss  0.0222 | TRAIN Acc:  99.78% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:33:27,904] Gradient total norm was 1.1236848831176758. Clipping to 0.25.
[2023-03-17 20:33:27,908] Step: 802 | lr: 0.7803 | Time: 14.00s |TRAIN loss  0.0276 | TRAIN Acc:  99.59% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:33:41,899] Gradient total norm was 0.5756925940513611. Clipping to 0.25.
[2023-03-17 20:33:41,903] Step: 803 | lr: 0.7802 | Time: 13.98s |TRAIN loss  0.0250 | TRAIN Acc:  99.83% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:33:55,897] Gradient total norm was 1.2141156196594238. Clipping to 0.25.
[2023-03-17 20:33:55,901] Step: 804 | lr: 0.7801 | Time: 13.98s |TRAIN loss  0.0256 | TRAIN Acc:  99.75% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:34:09,912] Gradient total norm was 0.9666882157325745. Clipping to 0.25.
[2023-03-17 20:34:09,916] Step: 805 | lr: 0.7800 | Time: 14.00s |TRAIN loss  0.0318 | TRAIN Acc:  99.47% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:34:23,951] Gradient total norm was 0.7859047651290894. Clipping to 0.25.
[2023-03-17 20:34:23,955] Step: 806 | lr: 0.7799 | Time: 14.02s |TRAIN loss  0.0285 | TRAIN Acc:  99.84% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:34:37,952] Gradient total norm was 1.1217150688171387. Clipping to 0.25.
[2023-03-17 20:34:37,956] Step: 807 | lr: 0.7798 | Time: 13.99s |TRAIN loss  0.0317 | TRAIN Acc:  99.51% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:34:51,955] Gradient total norm was 1.4962055683135986. Clipping to 0.25.
[2023-03-17 20:34:51,958] Step: 808 | lr: 0.7797 | Time: 13.99s |TRAIN loss  0.0349 | TRAIN Acc:  99.53% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:35:05,982] Gradient total norm was 1.2461493015289307. Clipping to 0.25.
[2023-03-17 20:35:05,985] Step: 809 | lr: 0.7796 | Time: 14.01s |TRAIN loss  0.0364 | TRAIN Acc:  99.50% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:35:19,983] Gradient total norm was 0.9877994656562805. Clipping to 0.25.
[2023-03-17 20:35:19,986] Step: 810 | lr: 0.7795 | Time: 13.99s |TRAIN loss  0.0382 | TRAIN Acc:  99.62% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:35:33,993] Gradient total norm was 1.0279560089111328. Clipping to 0.25.
[2023-03-17 20:35:33,997] Step: 811 | lr: 0.7794 | Time: 14.00s |TRAIN loss  0.0427 | TRAIN Acc:  99.35% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:35:48,042] Gradient total norm was 1.4980530738830566. Clipping to 0.25.
[2023-03-17 20:35:48,045] Step: 812 | lr: 0.7793 | Time: 14.04s |TRAIN loss  0.0406 | TRAIN Acc:  99.58% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:36:02,116] Gradient total norm was 3.516200304031372. Clipping to 0.25.
[2023-03-17 20:36:02,119] Step: 813 | lr: 0.7792 | Time: 14.06s |TRAIN loss  0.0822 | TRAIN Acc:  97.96% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:36:16,225] Gradient total norm was 0.6961889863014221. Clipping to 0.25.
[2023-03-17 20:36:16,228] Step: 814 | lr: 0.7791 | Time: 14.10s |TRAIN loss  0.0457 | TRAIN Acc:  99.64% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:36:30,272] Gradient total norm was 1.058640718460083. Clipping to 0.25.
[2023-03-17 20:36:30,275] Step: 815 | lr: 0.7790 | Time: 14.03s |TRAIN loss  0.0459 | TRAIN Acc:  99.67% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:36:44,340] Gradient total norm was 0.765593409538269. Clipping to 0.25.
[2023-03-17 20:36:44,343] Step: 816 | lr: 0.7789 | Time: 14.05s |TRAIN loss  0.0423 | TRAIN Acc:  99.84% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:36:58,411] Gradient total norm was 1.1786112785339355. Clipping to 0.25.
[2023-03-17 20:36:58,415] Step: 817 | lr: 0.7788 | Time: 14.06s |TRAIN loss  0.0392 | TRAIN Acc:  99.76% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:37:12,451] Gradient total norm was 0.5916094779968262. Clipping to 0.25.
[2023-03-17 20:37:12,455] Step: 818 | lr: 0.7787 | Time: 14.03s |TRAIN loss  0.0341 | TRAIN Acc:  99.89% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:37:26,386] Gradient total norm was 0.6934278607368469. Clipping to 0.25.
[2023-03-17 20:37:26,390] Step: 819 | lr: 0.7786 | Time: 13.92s |TRAIN loss  0.0289 | TRAIN Acc:  99.88% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:37:40,405] Gradient total norm was 1.0540885925292969. Clipping to 0.25.
[2023-03-17 20:37:40,408] Step: 820 | lr: 0.7785 | Time: 14.00s |TRAIN loss  0.0297 | TRAIN Acc:  99.84% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:37:54,483] Gradient total norm was 1.0632951259613037. Clipping to 0.25.
[2023-03-17 20:37:54,486] Step: 821 | lr: 0.7784 | Time: 14.07s |TRAIN loss  0.0278 | TRAIN Acc:  99.78% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:38:08,546] Gradient total norm was 0.8314023613929749. Clipping to 0.25.
[2023-03-17 20:38:08,549] Step: 822 | lr: 0.7783 | Time: 14.05s |TRAIN loss  0.0263 | TRAIN Acc:  99.85% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:38:22,588] Gradient total norm was 1.1090623140335083. Clipping to 0.25.
[2023-03-17 20:38:22,591] Step: 823 | lr: 0.7782 | Time: 14.03s |TRAIN loss  0.0288 | TRAIN Acc:  99.78% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:38:36,578] Gradient total norm was 1.2907907962799072. Clipping to 0.25.
[2023-03-17 20:38:36,582] Step: 824 | lr: 0.7781 | Time: 13.98s |TRAIN loss  0.0300 | TRAIN Acc:  99.76% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:38:50,664] Gradient total norm was 1.6601195335388184. Clipping to 0.25.
[2023-03-17 20:38:50,667] Step: 825 | lr: 0.7780 | Time: 14.07s |TRAIN loss  0.0334 | TRAIN Acc:  99.68% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:39:04,727] Gradient total norm was 1.020501971244812. Clipping to 0.25.
[2023-03-17 20:39:04,730] Step: 826 | lr: 0.7779 | Time: 14.05s |TRAIN loss  0.0382 | TRAIN Acc:  99.51% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:39:18,784] Gradient total norm was 0.8576653003692627. Clipping to 0.25.
[2023-03-17 20:39:18,787] Step: 827 | lr: 0.7778 | Time: 14.04s |TRAIN loss  0.0347 | TRAIN Acc:  99.74% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:39:32,828] Gradient total norm was 0.7210482954978943. Clipping to 0.25.
[2023-03-17 20:39:32,831] Step: 828 | lr: 0.7777 | Time: 14.03s |TRAIN loss  0.0332 | TRAIN Acc:  99.76% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:39:46,946] Gradient total norm was 0.9077308177947998. Clipping to 0.25.
[2023-03-17 20:39:46,949] Step: 829 | lr: 0.7776 | Time: 14.10s |TRAIN loss  0.0307 | TRAIN Acc:  99.90% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:40:00,990] Gradient total norm was 1.2216826677322388. Clipping to 0.25.
[2023-03-17 20:40:00,994] Step: 830 | lr: 0.7775 | Time: 14.03s |TRAIN loss  0.0322 | TRAIN Acc:  99.73% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:40:14,974] Gradient total norm was 0.8527754545211792. Clipping to 0.25.
[2023-03-17 20:40:14,978] Step: 831 | lr: 0.7774 | Time: 13.97s |TRAIN loss  0.0304 | TRAIN Acc:  99.80% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:40:29,026] Gradient total norm was 1.2341572046279907. Clipping to 0.25.
[2023-03-17 20:40:29,030] Step: 832 | lr: 0.7773 | Time: 14.04s |TRAIN loss  0.0282 | TRAIN Acc:  99.80% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:40:43,099] Gradient total norm was 0.6938563585281372. Clipping to 0.25.
[2023-03-17 20:40:43,103] Step: 833 | lr: 0.7772 | Time: 14.06s |TRAIN loss  0.0303 | TRAIN Acc:  99.70% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:40:57,153] Gradient total norm was 0.7174017429351807. Clipping to 0.25.
[2023-03-17 20:40:57,156] Step: 834 | lr: 0.7771 | Time: 14.04s |TRAIN loss  0.0280 | TRAIN Acc:  99.92% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:41:11,258] Gradient total norm was 0.7481417059898376. Clipping to 0.25.
[2023-03-17 20:41:11,261] Step: 835 | lr: 0.7770 | Time: 14.09s |TRAIN loss  0.0256 | TRAIN Acc:  99.85% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:41:25,340] Gradient total norm was 1.054533839225769. Clipping to 0.25.
[2023-03-17 20:41:25,343] Step: 836 | lr: 0.7769 | Time: 14.07s |TRAIN loss  0.0297 | TRAIN Acc:  99.81% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:41:39,429] Gradient total norm was 0.8320037126541138. Clipping to 0.25.
[2023-03-17 20:41:39,432] Step: 837 | lr: 0.7768 | Time: 14.08s |TRAIN loss  0.0282 | TRAIN Acc:  99.69% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:41:53,455] Gradient total norm was 0.8603410124778748. Clipping to 0.25.
[2023-03-17 20:41:53,459] Step: 838 | lr: 0.7767 | Time: 14.01s |TRAIN loss  0.0306 | TRAIN Acc:  99.61% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:42:07,505] Gradient total norm was 0.6366244554519653. Clipping to 0.25.
[2023-03-17 20:42:07,508] Step: 839 | lr: 0.7766 | Time: 14.04s |TRAIN loss  0.0314 | TRAIN Acc:  99.63% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:42:21,613] Gradient total norm was 0.6015546321868896. Clipping to 0.25.
[2023-03-17 20:42:21,616] Step: 840 | lr: 0.7765 | Time: 14.09s |TRAIN loss  0.0283 | TRAIN Acc:  99.73% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:42:35,662] Gradient total norm was 0.6507041454315186. Clipping to 0.25.
[2023-03-17 20:42:35,665] Step: 841 | lr: 0.7764 | Time: 14.04s |TRAIN loss  0.0275 | TRAIN Acc:  99.89% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:42:49,706] Gradient total norm was 2.5085315704345703. Clipping to 0.25.
[2023-03-17 20:42:49,709] Step: 842 | lr: 0.7762 | Time: 14.03s |TRAIN loss  0.0310 | TRAIN Acc:  99.59% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:43:03,756] Gradient total norm was 0.8701702952384949. Clipping to 0.25.
[2023-03-17 20:43:03,759] Step: 843 | lr: 0.7761 | Time: 14.04s |TRAIN loss  0.0295 | TRAIN Acc:  99.74% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:43:17,812] Gradient total norm was 0.8985827565193176. Clipping to 0.25.
[2023-03-17 20:43:17,815] Step: 844 | lr: 0.7760 | Time: 14.04s |TRAIN loss  0.0277 | TRAIN Acc:  99.83% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:43:31,905] Gradient total norm was 0.8299204707145691. Clipping to 0.25.
[2023-03-17 20:43:31,909] Step: 845 | lr: 0.7759 | Time: 14.08s |TRAIN loss  0.0273 | TRAIN Acc:  99.80% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:43:46,051] Gradient total norm was 0.6893583536148071. Clipping to 0.25.
[2023-03-17 20:43:46,055] Step: 846 | lr: 0.7758 | Time: 14.13s |TRAIN loss  0.0253 | TRAIN Acc:  99.88% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:44:00,174] Gradient total norm was 0.9946367740631104. Clipping to 0.25.
[2023-03-17 20:44:00,177] Step: 847 | lr: 0.7757 | Time: 14.11s |TRAIN loss  0.0221 | TRAIN Acc:  99.89% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:44:14,213] Gradient total norm was 1.1196304559707642. Clipping to 0.25.
[2023-03-17 20:44:14,216] Step: 848 | lr: 0.7756 | Time: 14.03s |TRAIN loss  0.0239 | TRAIN Acc:  99.88% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:44:28,256] Gradient total norm was 1.474041223526001. Clipping to 0.25.
[2023-03-17 20:44:28,259] Step: 849 | lr: 0.7755 | Time: 14.03s |TRAIN loss  0.0241 | TRAIN Acc:  99.78% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:44:42,332] Gradient total norm was 0.8537009954452515. Clipping to 0.25.
[2023-03-17 20:44:42,336] Step: 850 | lr: 0.7754 | Time: 14.06s |TRAIN loss  0.0227 | TRAIN Acc:  99.91% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:44:56,383] Gradient total norm was 0.7333192825317383. Clipping to 0.25.
[2023-03-17 20:44:56,387] Step: 851 | lr: 0.7753 | Time: 14.04s |TRAIN loss  0.0190 | TRAIN Acc:  99.92% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:45:10,434] Gradient total norm was 0.8184034824371338. Clipping to 0.25.
[2023-03-17 20:45:10,438] Step: 852 | lr: 0.7752 | Time: 14.04s |TRAIN loss  0.0195 | TRAIN Acc:  99.90% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:45:24,556] Gradient total norm was 1.9729869365692139. Clipping to 0.25.
[2023-03-17 20:45:24,559] Step: 853 | lr: 0.7751 | Time: 14.11s |TRAIN loss  0.0345 | TRAIN Acc:  99.31% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:45:38,632] Gradient total norm was 0.96355140209198. Clipping to 0.25.
[2023-03-17 20:45:38,635] Step: 854 | lr: 0.7749 | Time: 14.06s |TRAIN loss  0.0295 | TRAIN Acc:  99.55% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:45:52,711] Gradient total norm was 1.0973398685455322. Clipping to 0.25.
[2023-03-17 20:45:52,714] Step: 855 | lr: 0.7748 | Time: 14.07s |TRAIN loss  0.0459 | TRAIN Acc:  98.89% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:46:06,763] Gradient total norm was 0.5994428992271423. Clipping to 0.25.
[2023-03-17 20:46:06,766] Step: 856 | lr: 0.7747 | Time: 14.04s |TRAIN loss  0.0367 | TRAIN Acc:  99.60% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:46:20,856] Gradient total norm was 0.6793298125267029. Clipping to 0.25.
[2023-03-17 20:46:20,859] Step: 857 | lr: 0.7746 | Time: 14.08s |TRAIN loss  0.0280 | TRAIN Acc:  99.86% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:46:34,906] Gradient total norm was 1.076033115386963. Clipping to 0.25.
[2023-03-17 20:46:34,909] Step: 858 | lr: 0.7745 | Time: 14.04s |TRAIN loss  0.0288 | TRAIN Acc:  99.74% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:46:49,075] Gradient total norm was 1.485726237297058. Clipping to 0.25.
[2023-03-17 20:46:49,079] Step: 859 | lr: 0.7744 | Time: 14.16s |TRAIN loss  0.0291 | TRAIN Acc:  99.62% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:47:03,356] Gradient total norm was 1.2213282585144043. Clipping to 0.25.
[2023-03-17 20:47:03,359] Step: 860 | lr: 0.7743 | Time: 14.26s |TRAIN loss  0.0325 | TRAIN Acc:  99.55% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:47:17,510] Gradient total norm was 1.0533738136291504. Clipping to 0.25.
[2023-03-17 20:47:17,513] Step: 861 | lr: 0.7742 | Time: 14.14s |TRAIN loss  0.0300 | TRAIN Acc:  99.68% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:47:31,721] Gradient total norm was 3.132338523864746. Clipping to 0.25.
[2023-03-17 20:47:31,724] Step: 862 | lr: 0.7741 | Time: 14.20s |TRAIN loss  0.0757 | TRAIN Acc:  97.83% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:47:45,954] Gradient total norm was 0.510925829410553. Clipping to 0.25.
[2023-03-17 20:47:45,957] Step: 863 | lr: 0.7740 | Time: 14.22s |TRAIN loss  0.0340 | TRAIN Acc:  99.80% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:48:00,203] Gradient total norm was 0.8130536079406738. Clipping to 0.25.
[2023-03-17 20:48:00,207] Step: 864 | lr: 0.7738 | Time: 14.24s |TRAIN loss  0.0305 | TRAIN Acc:  99.86% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:48:14,334] Gradient total norm was 1.0221563577651978. Clipping to 0.25.
[2023-03-17 20:48:14,338] Step: 865 | lr: 0.7737 | Time: 14.12s |TRAIN loss  0.0345 | TRAIN Acc:  99.75% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:48:28,533] Gradient total norm was 2.0354340076446533. Clipping to 0.25.
[2023-03-17 20:48:28,536] Step: 866 | lr: 0.7736 | Time: 14.18s |TRAIN loss  0.0411 | TRAIN Acc:  99.32% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:48:42,705] Gradient total norm was 0.7587659358978271. Clipping to 0.25.
[2023-03-17 20:48:42,709] Step: 867 | lr: 0.7735 | Time: 14.16s |TRAIN loss  0.0364 | TRAIN Acc:  99.70% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:48:56,752] Gradient total norm was 0.8100603818893433. Clipping to 0.25.
[2023-03-17 20:48:56,755] Step: 868 | lr: 0.7734 | Time: 14.03s |TRAIN loss  0.0350 | TRAIN Acc:  99.71% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:49:10,990] Gradient total norm was 0.6592445969581604. Clipping to 0.25.
[2023-03-17 20:49:10,994] Step: 869 | lr: 0.7733 | Time: 14.22s |TRAIN loss  0.0357 | TRAIN Acc:  99.81% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:49:25,154] Gradient total norm was 0.5623683929443359. Clipping to 0.25.
[2023-03-17 20:49:25,157] Step: 870 | lr: 0.7732 | Time: 14.15s |TRAIN loss  0.0307 | TRAIN Acc:  99.82% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:49:39,178] Gradient total norm was 0.8458338379859924. Clipping to 0.25.
[2023-03-17 20:49:39,182] Step: 871 | lr: 0.7731 | Time: 14.01s |TRAIN loss  0.0295 | TRAIN Acc:  99.90% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:49:53,741] Gradient total norm was 2.4982573986053467. Clipping to 0.25.
[2023-03-17 20:49:53,744] Step: 872 | lr: 0.7729 | Time: 14.55s |TRAIN loss  0.0379 | TRAIN Acc:  99.32% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:50:08,092] Gradient total norm was 0.939521849155426. Clipping to 0.25.
[2023-03-17 20:50:08,095] Step: 873 | lr: 0.7728 | Time: 14.34s |TRAIN loss  0.0373 | TRAIN Acc:  99.42% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:50:23,071] Gradient total norm was 0.7639701962471008. Clipping to 0.25.
[2023-03-17 20:50:23,074] Step: 874 | lr: 0.7727 | Time: 14.97s |TRAIN loss  0.0351 | TRAIN Acc:  99.61% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:50:37,238] Gradient total norm was 0.9410348534584045. Clipping to 0.25.
[2023-03-17 20:50:37,241] Step: 875 | lr: 0.7726 | Time: 14.15s |TRAIN loss  0.0305 | TRAIN Acc:  99.77% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:50:51,649] Gradient total norm was 1.3837298154830933. Clipping to 0.25.
[2023-03-17 20:50:51,653] Step: 876 | lr: 0.7725 | Time: 14.40s |TRAIN loss  0.0315 | TRAIN Acc:  99.71% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:51:05,821] Gradient total norm was 1.012886881828308. Clipping to 0.25.
[2023-03-17 20:51:05,825] Step: 877 | lr: 0.7724 | Time: 14.16s |TRAIN loss  0.0301 | TRAIN Acc:  99.77% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:51:20,021] Gradient total norm was 0.8162286877632141. Clipping to 0.25.
[2023-03-17 20:51:20,024] Step: 878 | lr: 0.7723 | Time: 14.19s |TRAIN loss  0.0318 | TRAIN Acc:  99.78% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:51:34,198] Gradient total norm was 0.6879220604896545. Clipping to 0.25.
[2023-03-17 20:51:34,202] Step: 879 | lr: 0.7721 | Time: 14.16s |TRAIN loss  0.0281 | TRAIN Acc:  99.87% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:51:48,336] Gradient total norm was 0.6610422730445862. Clipping to 0.25.
[2023-03-17 20:51:48,340] Step: 880 | lr: 0.7720 | Time: 14.12s |TRAIN loss  0.0254 | TRAIN Acc:  99.89% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:52:02,625] Gradient total norm was 0.7231387495994568. Clipping to 0.25.
[2023-03-17 20:52:02,628] Step: 881 | lr: 0.7719 | Time: 14.27s |TRAIN loss  0.0264 | TRAIN Acc:  99.88% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:52:16,781] Gradient total norm was 0.6992771625518799. Clipping to 0.25.
[2023-03-17 20:52:16,784] Step: 882 | lr: 0.7718 | Time: 14.14s |TRAIN loss  0.0222 | TRAIN Acc:  99.93% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:52:30,891] Gradient total norm was 0.6692761182785034. Clipping to 0.25.
[2023-03-17 20:52:30,895] Step: 883 | lr: 0.7717 | Time: 14.10s |TRAIN loss  0.0221 | TRAIN Acc:  99.93% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:52:44,904] Gradient total norm was 0.7546117901802063. Clipping to 0.25.
[2023-03-17 20:52:44,908] Step: 884 | lr: 0.7716 | Time: 14.00s |TRAIN loss  0.0215 | TRAIN Acc:  99.84% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:52:58,945] Gradient total norm was 0.6087344884872437. Clipping to 0.25.
[2023-03-17 20:52:58,949] Step: 885 | lr: 0.7714 | Time: 14.03s |TRAIN loss  0.0196 | TRAIN Acc:  99.88% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:53:12,943] Gradient total norm was 0.7015113234519958. Clipping to 0.25.
[2023-03-17 20:53:12,947] Step: 886 | lr: 0.7713 | Time: 13.98s |TRAIN loss  0.0227 | TRAIN Acc:  99.79% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:53:26,935] Gradient total norm was 0.526273787021637. Clipping to 0.25.
[2023-03-17 20:53:26,940] Step: 887 | lr: 0.7712 | Time: 13.98s |TRAIN loss  0.0182 | TRAIN Acc:  99.93% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:53:40,923] Gradient total norm was 0.6243524551391602. Clipping to 0.25.
[2023-03-17 20:53:40,926] Step: 888 | lr: 0.7711 | Time: 13.97s |TRAIN loss  0.0191 | TRAIN Acc:  99.95% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:53:54,863] Gradient total norm was 0.8289108872413635. Clipping to 0.25.
[2023-03-17 20:53:54,867] Step: 889 | lr: 0.7710 | Time: 13.93s |TRAIN loss  0.0172 | TRAIN Acc:  99.94% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:54:08,869] Gradient total norm was 0.8524789214134216. Clipping to 0.25.
[2023-03-17 20:54:08,872] Step: 890 | lr: 0.7709 | Time: 13.99s |TRAIN loss  0.0171 | TRAIN Acc:  99.90% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:54:22,914] Gradient total norm was 1.0552709102630615. Clipping to 0.25.
[2023-03-17 20:54:22,917] Step: 891 | lr: 0.7707 | Time: 14.03s |TRAIN loss  0.0199 | TRAIN Acc:  99.75% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:54:36,899] Gradient total norm was 1.0547356605529785. Clipping to 0.25.
[2023-03-17 20:54:36,902] Step: 892 | lr: 0.7706 | Time: 13.97s |TRAIN loss  0.0219 | TRAIN Acc:  99.59% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:54:50,805] Gradient total norm was 0.7005466818809509. Clipping to 0.25.
[2023-03-17 20:54:50,808] Step: 893 | lr: 0.7705 | Time: 13.89s |TRAIN loss  0.0319 | TRAIN Acc:  99.32% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:55:04,759] Gradient total norm was 0.6691396832466125. Clipping to 0.25.
[2023-03-17 20:55:04,763] Step: 894 | lr: 0.7704 | Time: 13.94s |TRAIN loss  0.0212 | TRAIN Acc:  99.80% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:55:18,707] Gradient total norm was 1.5376783609390259. Clipping to 0.25.
[2023-03-17 20:55:18,710] Step: 895 | lr: 0.7703 | Time: 13.93s |TRAIN loss  0.0283 | TRAIN Acc:  99.57% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:55:32,664] Gradient total norm was 0.7662965655326843. Clipping to 0.25.
[2023-03-17 20:55:32,668] Step: 896 | lr: 0.7702 | Time: 13.94s |TRAIN loss  0.0250 | TRAIN Acc:  99.72% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:55:46,608] Gradient total norm was 0.8574501872062683. Clipping to 0.25.
[2023-03-17 20:55:46,612] Step: 897 | lr: 0.7700 | Time: 13.93s |TRAIN loss  0.0248 | TRAIN Acc:  99.80% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:56:00,611] Gradient total norm was 0.9225108027458191. Clipping to 0.25.
[2023-03-17 20:56:00,615] Step: 898 | lr: 0.7699 | Time: 13.99s |TRAIN loss  0.0259 | TRAIN Acc:  99.76% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:56:14,625] Gradient total norm was 0.6458659768104553. Clipping to 0.25.
[2023-03-17 20:56:14,628] Step: 899 | lr: 0.7698 | Time: 14.00s |TRAIN loss  0.0219 | TRAIN Acc:  99.85% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:56:28,562] Gradient total norm was 0.7696914076805115. Clipping to 0.25.
[2023-03-17 20:56:28,565] Step: 900 | lr: 0.7697 | Time: 13.92s |TRAIN loss  0.0212 | TRAIN Acc:  99.84% |VAL loss  0.4072 | VAL Acc:  87.39% |
[2023-03-17 20:56:42,514] Gradient total norm was 1.5114552974700928. Clipping to 0.25.
[2023-03-17 20:56:47,794] Step: 901 | lr: 0.7696 | Time: 13.94s |TRAIN loss  0.0267 | TRAIN Acc:  99.58% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 20:57:01,703] Gradient total norm was 0.7306666970252991. Clipping to 0.25.
[2023-03-17 20:57:01,707] Step: 902 | lr: 0.7694 | Time: 13.90s |TRAIN loss  0.0259 | TRAIN Acc:  99.67% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 20:57:15,652] Gradient total norm was 0.9089644551277161. Clipping to 0.25.
[2023-03-17 20:57:15,656] Step: 903 | lr: 0.7693 | Time: 13.94s |TRAIN loss  0.0288 | TRAIN Acc:  99.53% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 20:57:29,597] Gradient total norm was 1.4208436012268066. Clipping to 0.25.
[2023-03-17 20:57:29,601] Step: 904 | lr: 0.7692 | Time: 13.93s |TRAIN loss  0.0314 | TRAIN Acc:  99.60% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 20:57:43,553] Gradient total norm was 1.7553247213363647. Clipping to 0.25.
[2023-03-17 20:57:43,557] Step: 905 | lr: 0.7691 | Time: 13.94s |TRAIN loss  0.0383 | TRAIN Acc:  99.25% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 20:57:57,645] Gradient total norm was 1.2847578525543213. Clipping to 0.25.
[2023-03-17 20:57:57,648] Step: 906 | lr: 0.7689 | Time: 14.08s |TRAIN loss  0.0481 | TRAIN Acc:  98.92% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 20:58:11,634] Gradient total norm was 0.7246557474136353. Clipping to 0.25.
[2023-03-17 20:58:11,639] Step: 907 | lr: 0.7688 | Time: 13.97s |TRAIN loss  0.0368 | TRAIN Acc:  99.59% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 20:58:25,614] Gradient total norm was 0.7259906530380249. Clipping to 0.25.
[2023-03-17 20:58:25,618] Step: 908 | lr: 0.7687 | Time: 13.96s |TRAIN loss  0.0357 | TRAIN Acc:  99.61% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 20:58:39,510] Gradient total norm was 0.9191445708274841. Clipping to 0.25.
[2023-03-17 20:58:39,514] Step: 909 | lr: 0.7686 | Time: 13.88s |TRAIN loss  0.0325 | TRAIN Acc:  99.83% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 20:58:53,452] Gradient total norm was 0.6472536325454712. Clipping to 0.25.
[2023-03-17 20:58:53,455] Step: 910 | lr: 0.7685 | Time: 13.93s |TRAIN loss  0.0285 | TRAIN Acc:  99.86% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 20:59:07,507] Gradient total norm was 0.6713147759437561. Clipping to 0.25.
[2023-03-17 20:59:07,510] Step: 911 | lr: 0.7683 | Time: 14.04s |TRAIN loss  0.0260 | TRAIN Acc:  99.91% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 20:59:21,451] Gradient total norm was 0.5661589503288269. Clipping to 0.25.
[2023-03-17 20:59:21,454] Step: 912 | lr: 0.7682 | Time: 13.93s |TRAIN loss  0.0245 | TRAIN Acc:  99.91% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 20:59:35,370] Gradient total norm was 0.7216414213180542. Clipping to 0.25.
[2023-03-17 20:59:35,373] Step: 913 | lr: 0.7681 | Time: 13.91s |TRAIN loss  0.0220 | TRAIN Acc:  99.88% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 20:59:49,302] Gradient total norm was 0.745107889175415. Clipping to 0.25.
[2023-03-17 20:59:49,306] Step: 914 | lr: 0.7680 | Time: 13.92s |TRAIN loss  0.0223 | TRAIN Acc:  99.85% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:00:03,243] Gradient total norm was 1.444091558456421. Clipping to 0.25.
[2023-03-17 21:00:03,246] Step: 915 | lr: 0.7678 | Time: 13.93s |TRAIN loss  0.0226 | TRAIN Acc:  99.85% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:00:17,227] Gradient total norm was 1.280009150505066. Clipping to 0.25.
[2023-03-17 21:00:17,230] Step: 916 | lr: 0.7677 | Time: 13.97s |TRAIN loss  0.0313 | TRAIN Acc:  99.51% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:00:31,178] Gradient total norm was 0.7850512862205505. Clipping to 0.25.
[2023-03-17 21:00:31,183] Step: 917 | lr: 0.7676 | Time: 13.94s |TRAIN loss  0.0270 | TRAIN Acc:  99.80% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:00:45,178] Gradient total norm was 0.9771024584770203. Clipping to 0.25.
[2023-03-17 21:00:45,181] Step: 918 | lr: 0.7675 | Time: 13.98s |TRAIN loss  0.0271 | TRAIN Acc:  99.67% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:00:59,146] Gradient total norm was 0.8333994746208191. Clipping to 0.25.
[2023-03-17 21:00:59,149] Step: 919 | lr: 0.7674 | Time: 13.95s |TRAIN loss  0.0289 | TRAIN Acc:  99.82% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:01:13,103] Gradient total norm was 1.5480496883392334. Clipping to 0.25.
[2023-03-17 21:01:13,106] Step: 920 | lr: 0.7672 | Time: 13.94s |TRAIN loss  0.0309 | TRAIN Acc:  99.69% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:01:27,087] Gradient total norm was 1.4962072372436523. Clipping to 0.25.
[2023-03-17 21:01:27,091] Step: 921 | lr: 0.7671 | Time: 13.97s |TRAIN loss  0.0334 | TRAIN Acc:  99.68% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:01:41,085] Gradient total norm was 0.9771959781646729. Clipping to 0.25.
[2023-03-17 21:01:41,089] Step: 922 | lr: 0.7670 | Time: 13.98s |TRAIN loss  0.0302 | TRAIN Acc:  99.77% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:01:55,040] Gradient total norm was 1.7321815490722656. Clipping to 0.25.
[2023-03-17 21:01:55,043] Step: 923 | lr: 0.7669 | Time: 13.94s |TRAIN loss  0.0359 | TRAIN Acc:  99.54% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:02:09,015] Gradient total norm was 1.184713363647461. Clipping to 0.25.
[2023-03-17 21:02:09,018] Step: 924 | lr: 0.7667 | Time: 13.96s |TRAIN loss  0.0333 | TRAIN Acc:  99.66% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:02:22,989] Gradient total norm was 1.3750938177108765. Clipping to 0.25.
[2023-03-17 21:02:22,993] Step: 925 | lr: 0.7666 | Time: 13.96s |TRAIN loss  0.0393 | TRAIN Acc:  99.32% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:02:36,980] Gradient total norm was 0.7866907715797424. Clipping to 0.25.
[2023-03-17 21:02:36,983] Step: 926 | lr: 0.7665 | Time: 13.98s |TRAIN loss  0.0394 | TRAIN Acc:  99.59% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:02:50,974] Gradient total norm was 0.929702639579773. Clipping to 0.25.
[2023-03-17 21:02:50,978] Step: 927 | lr: 0.7663 | Time: 13.98s |TRAIN loss  0.0416 | TRAIN Acc:  99.32% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:03:05,048] Gradient total norm was 0.45899805426597595. Clipping to 0.25.
[2023-03-17 21:03:05,051] Step: 928 | lr: 0.7662 | Time: 14.06s |TRAIN loss  0.0380 | TRAIN Acc:  99.82% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:03:19,044] Gradient total norm was 0.66871577501297. Clipping to 0.25.
[2023-03-17 21:03:19,047] Step: 929 | lr: 0.7661 | Time: 13.98s |TRAIN loss  0.0304 | TRAIN Acc:  99.85% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:03:33,046] Gradient total norm was 0.6778066754341125. Clipping to 0.25.
[2023-03-17 21:03:33,049] Step: 930 | lr: 0.7660 | Time: 13.99s |TRAIN loss  0.0297 | TRAIN Acc:  99.91% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:03:47,087] Gradient total norm was 1.6213457584381104. Clipping to 0.25.
[2023-03-17 21:03:47,091] Step: 931 | lr: 0.7658 | Time: 14.03s |TRAIN loss  0.0280 | TRAIN Acc:  99.79% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:04:01,051] Gradient total norm was 1.1263487339019775. Clipping to 0.25.
[2023-03-17 21:04:01,054] Step: 932 | lr: 0.7657 | Time: 13.95s |TRAIN loss  0.0314 | TRAIN Acc:  99.64% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:04:15,143] Gradient total norm was 0.7162598967552185. Clipping to 0.25.
[2023-03-17 21:04:15,146] Step: 933 | lr: 0.7656 | Time: 14.08s |TRAIN loss  0.0247 | TRAIN Acc:  99.90% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:04:29,249] Gradient total norm was 0.9013507962226868. Clipping to 0.25.
[2023-03-17 21:04:29,253] Step: 934 | lr: 0.7655 | Time: 14.09s |TRAIN loss  0.0250 | TRAIN Acc:  99.79% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:04:43,320] Gradient total norm was 1.1507190465927124. Clipping to 0.25.
[2023-03-17 21:04:43,324] Step: 935 | lr: 0.7653 | Time: 14.06s |TRAIN loss  0.0260 | TRAIN Acc:  99.86% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:04:57,363] Gradient total norm was 0.6797589063644409. Clipping to 0.25.
[2023-03-17 21:04:57,366] Step: 936 | lr: 0.7652 | Time: 14.03s |TRAIN loss  0.0236 | TRAIN Acc:  99.93% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:05:11,353] Gradient total norm was 0.9405344128608704. Clipping to 0.25.
[2023-03-17 21:05:11,356] Step: 937 | lr: 0.7651 | Time: 13.98s |TRAIN loss  0.0234 | TRAIN Acc:  99.88% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:05:25,402] Gradient total norm was 1.3091468811035156. Clipping to 0.25.
[2023-03-17 21:05:25,406] Step: 938 | lr: 0.7649 | Time: 14.04s |TRAIN loss  0.0294 | TRAIN Acc:  99.64% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:05:39,426] Gradient total norm was 0.7788253426551819. Clipping to 0.25.
[2023-03-17 21:05:39,429] Step: 939 | lr: 0.7648 | Time: 14.01s |TRAIN loss  0.0265 | TRAIN Acc:  99.83% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:05:53,501] Gradient total norm was 0.7957022190093994. Clipping to 0.25.
[2023-03-17 21:05:53,504] Step: 940 | lr: 0.7647 | Time: 14.06s |TRAIN loss  0.0261 | TRAIN Acc:  99.71% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:06:07,511] Gradient total norm was 0.9644501805305481. Clipping to 0.25.
[2023-03-17 21:06:07,515] Step: 941 | lr: 0.7646 | Time: 14.00s |TRAIN loss  0.0248 | TRAIN Acc:  99.75% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:06:21,584] Gradient total norm was 0.5318102240562439. Clipping to 0.25.
[2023-03-17 21:06:21,587] Step: 942 | lr: 0.7644 | Time: 14.06s |TRAIN loss  0.0238 | TRAIN Acc:  99.79% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:06:35,700] Gradient total norm was 0.7597086429595947. Clipping to 0.25.
[2023-03-17 21:06:35,703] Step: 943 | lr: 0.7643 | Time: 14.10s |TRAIN loss  0.0207 | TRAIN Acc:  99.94% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:06:49,779] Gradient total norm was 0.661230206489563. Clipping to 0.25.
[2023-03-17 21:06:49,783] Step: 944 | lr: 0.7642 | Time: 14.07s |TRAIN loss  0.0209 | TRAIN Acc:  99.93% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:07:03,892] Gradient total norm was 0.9267810583114624. Clipping to 0.25.
[2023-03-17 21:07:03,896] Step: 945 | lr: 0.7640 | Time: 14.10s |TRAIN loss  0.0184 | TRAIN Acc:  99.93% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:07:17,930] Gradient total norm was 0.8544026613235474. Clipping to 0.25.
[2023-03-17 21:07:17,934] Step: 946 | lr: 0.7639 | Time: 14.02s |TRAIN loss  0.0204 | TRAIN Acc:  99.91% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:07:31,972] Gradient total norm was 1.1283153295516968. Clipping to 0.25.
[2023-03-17 21:07:31,976] Step: 947 | lr: 0.7638 | Time: 14.03s |TRAIN loss  0.0199 | TRAIN Acc:  99.80% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:07:46,096] Gradient total norm was 0.9205043315887451. Clipping to 0.25.
[2023-03-17 21:07:46,099] Step: 948 | lr: 0.7637 | Time: 14.11s |TRAIN loss  0.0228 | TRAIN Acc:  99.68% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:08:00,128] Gradient total norm was 0.9071864485740662. Clipping to 0.25.
[2023-03-17 21:08:00,131] Step: 949 | lr: 0.7635 | Time: 14.02s |TRAIN loss  0.0277 | TRAIN Acc:  99.57% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:08:14,251] Gradient total norm was 0.6341395378112793. Clipping to 0.25.
[2023-03-17 21:08:14,254] Step: 950 | lr: 0.7634 | Time: 14.11s |TRAIN loss  0.0271 | TRAIN Acc:  99.74% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:08:28,312] Gradient total norm was 0.7838912606239319. Clipping to 0.25.
[2023-03-17 21:08:28,315] Step: 951 | lr: 0.7633 | Time: 14.05s |TRAIN loss  0.0261 | TRAIN Acc:  99.87% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:08:42,417] Gradient total norm was 0.87063068151474. Clipping to 0.25.
[2023-03-17 21:08:42,420] Step: 952 | lr: 0.7631 | Time: 14.09s |TRAIN loss  0.0245 | TRAIN Acc:  99.94% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:08:56,411] Gradient total norm was 0.8555538058280945. Clipping to 0.25.
[2023-03-17 21:08:56,414] Step: 953 | lr: 0.7630 | Time: 13.98s |TRAIN loss  0.0234 | TRAIN Acc:  99.90% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:09:10,407] Gradient total norm was 1.183263897895813. Clipping to 0.25.
[2023-03-17 21:09:10,411] Step: 954 | lr: 0.7629 | Time: 13.98s |TRAIN loss  0.0241 | TRAIN Acc:  99.86% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:09:24,449] Gradient total norm was 0.7786458134651184. Clipping to 0.25.
[2023-03-17 21:09:24,452] Step: 955 | lr: 0.7627 | Time: 14.03s |TRAIN loss  0.0232 | TRAIN Acc:  99.82% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:09:38,469] Gradient total norm was 0.7532963752746582. Clipping to 0.25.
[2023-03-17 21:09:38,472] Step: 956 | lr: 0.7626 | Time: 14.01s |TRAIN loss  0.0216 | TRAIN Acc:  99.88% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:09:52,516] Gradient total norm was 0.7192554473876953. Clipping to 0.25.
[2023-03-17 21:09:52,520] Step: 957 | lr: 0.7625 | Time: 14.03s |TRAIN loss  0.0254 | TRAIN Acc:  99.67% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:10:06,616] Gradient total norm was 0.5980082154273987. Clipping to 0.25.
[2023-03-17 21:10:06,620] Step: 958 | lr: 0.7623 | Time: 14.09s |TRAIN loss  0.0207 | TRAIN Acc:  99.92% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:10:20,634] Gradient total norm was 0.5280103087425232. Clipping to 0.25.
[2023-03-17 21:10:20,638] Step: 959 | lr: 0.7622 | Time: 14.00s |TRAIN loss  0.0211 | TRAIN Acc:  99.91% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:10:34,584] Gradient total norm was 0.9080753326416016. Clipping to 0.25.
[2023-03-17 21:10:34,587] Step: 960 | lr: 0.7621 | Time: 13.94s |TRAIN loss  0.0172 | TRAIN Acc:  99.94% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:10:48,542] Gradient total norm was 0.9618750214576721. Clipping to 0.25.
[2023-03-17 21:10:48,545] Step: 961 | lr: 0.7619 | Time: 13.94s |TRAIN loss  0.0208 | TRAIN Acc:  99.88% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:11:02,493] Gradient total norm was 1.7969099283218384. Clipping to 0.25.
[2023-03-17 21:11:02,496] Step: 962 | lr: 0.7618 | Time: 13.94s |TRAIN loss  0.0253 | TRAIN Acc:  99.52% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:11:16,499] Gradient total norm was 1.819896936416626. Clipping to 0.25.
[2023-03-17 21:11:16,502] Step: 963 | lr: 0.7617 | Time: 13.99s |TRAIN loss  0.0392 | TRAIN Acc:  98.99% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:11:30,434] Gradient total norm was 0.8795047998428345. Clipping to 0.25.
[2023-03-17 21:11:30,438] Step: 964 | lr: 0.7615 | Time: 13.92s |TRAIN loss  0.0328 | TRAIN Acc:  99.43% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:11:44,308] Gradient total norm was 0.6274536848068237. Clipping to 0.25.
[2023-03-17 21:11:44,311] Step: 965 | lr: 0.7614 | Time: 13.86s |TRAIN loss  0.0327 | TRAIN Acc:  99.68% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:11:58,208] Gradient total norm was 0.7103103995323181. Clipping to 0.25.
[2023-03-17 21:11:58,212] Step: 966 | lr: 0.7613 | Time: 13.89s |TRAIN loss  0.0305 | TRAIN Acc:  99.45% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:12:12,143] Gradient total norm was 1.8672648668289185. Clipping to 0.25.
[2023-03-17 21:12:12,147] Step: 967 | lr: 0.7611 | Time: 13.92s |TRAIN loss  0.0296 | TRAIN Acc:  99.54% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:12:26,035] Gradient total norm was 0.909296989440918. Clipping to 0.25.
[2023-03-17 21:12:26,038] Step: 968 | lr: 0.7610 | Time: 13.88s |TRAIN loss  0.0335 | TRAIN Acc:  99.50% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:12:39,899] Gradient total norm was 0.8038439154624939. Clipping to 0.25.
[2023-03-17 21:12:39,903] Step: 969 | lr: 0.7609 | Time: 13.85s |TRAIN loss  0.0285 | TRAIN Acc:  99.88% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:12:53,770] Gradient total norm was 0.9359648823738098. Clipping to 0.25.
[2023-03-17 21:12:53,773] Step: 970 | lr: 0.7607 | Time: 13.86s |TRAIN loss  0.0340 | TRAIN Acc:  99.53% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:13:07,582] Gradient total norm was 2.09913969039917. Clipping to 0.25.
[2023-03-17 21:13:07,586] Step: 971 | lr: 0.7606 | Time: 13.80s |TRAIN loss  0.0370 | TRAIN Acc:  99.35% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:13:21,449] Gradient total norm was 0.9971588253974915. Clipping to 0.25.
[2023-03-17 21:13:21,453] Step: 972 | lr: 0.7604 | Time: 13.85s |TRAIN loss  0.0361 | TRAIN Acc:  99.48% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:13:35,312] Gradient total norm was 0.7586719989776611. Clipping to 0.25.
[2023-03-17 21:13:35,315] Step: 973 | lr: 0.7603 | Time: 13.85s |TRAIN loss  0.0397 | TRAIN Acc:  99.47% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:13:49,149] Gradient total norm was 0.5445277094841003. Clipping to 0.25.
[2023-03-17 21:13:49,152] Step: 974 | lr: 0.7602 | Time: 13.82s |TRAIN loss  0.0350 | TRAIN Acc:  99.56% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:14:03,061] Gradient total norm was 0.502258837223053. Clipping to 0.25.
[2023-03-17 21:14:03,064] Step: 975 | lr: 0.7600 | Time: 13.90s |TRAIN loss  0.0280 | TRAIN Acc:  99.79% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:14:16,926] Gradient total norm was 0.572278618812561. Clipping to 0.25.
[2023-03-17 21:14:16,929] Step: 976 | lr: 0.7599 | Time: 13.85s |TRAIN loss  0.0239 | TRAIN Acc:  99.83% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:14:30,819] Gradient total norm was 0.6192895770072937. Clipping to 0.25.
[2023-03-17 21:14:30,822] Step: 977 | lr: 0.7598 | Time: 13.88s |TRAIN loss  0.0228 | TRAIN Acc:  99.81% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:14:44,657] Gradient total norm was 0.6540553569793701. Clipping to 0.25.
[2023-03-17 21:14:44,661] Step: 978 | lr: 0.7596 | Time: 13.83s |TRAIN loss  0.0199 | TRAIN Acc:  99.92% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:14:58,560] Gradient total norm was 1.1979069709777832. Clipping to 0.25.
[2023-03-17 21:14:58,563] Step: 979 | lr: 0.7595 | Time: 13.89s |TRAIN loss  0.0199 | TRAIN Acc:  99.87% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:15:12,543] Gradient total norm was 2.0309526920318604. Clipping to 0.25.
[2023-03-17 21:15:12,547] Step: 980 | lr: 0.7593 | Time: 13.97s |TRAIN loss  0.0252 | TRAIN Acc:  99.54% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:15:26,383] Gradient total norm was 0.9761831164360046. Clipping to 0.25.
[2023-03-17 21:15:26,387] Step: 981 | lr: 0.7592 | Time: 13.83s |TRAIN loss  0.0257 | TRAIN Acc:  99.71% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:15:40,239] Gradient total norm was 0.9535683989524841. Clipping to 0.25.
[2023-03-17 21:15:40,243] Step: 982 | lr: 0.7591 | Time: 13.84s |TRAIN loss  0.0236 | TRAIN Acc:  99.79% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:15:54,105] Gradient total norm was 1.0056201219558716. Clipping to 0.25.
[2023-03-17 21:15:54,109] Step: 983 | lr: 0.7589 | Time: 13.85s |TRAIN loss  0.0267 | TRAIN Acc:  99.84% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:16:07,963] Gradient total norm was 2.4058854579925537. Clipping to 0.25.
[2023-03-17 21:16:07,966] Step: 984 | lr: 0.7588 | Time: 13.84s |TRAIN loss  0.0339 | TRAIN Acc:  99.53% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:16:21,867] Gradient total norm was 0.6506842970848083. Clipping to 0.25.
[2023-03-17 21:16:21,870] Step: 985 | lr: 0.7587 | Time: 13.89s |TRAIN loss  0.0322 | TRAIN Acc:  99.65% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:16:35,776] Gradient total norm was 0.6692723035812378. Clipping to 0.25.
[2023-03-17 21:16:35,779] Step: 986 | lr: 0.7585 | Time: 13.90s |TRAIN loss  0.0261 | TRAIN Acc:  99.91% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:16:49,736] Gradient total norm was 0.808979868888855. Clipping to 0.25.
[2023-03-17 21:16:49,740] Step: 987 | lr: 0.7584 | Time: 13.95s |TRAIN loss  0.0289 | TRAIN Acc:  99.86% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:17:03,612] Gradient total norm was 1.1454769372940063. Clipping to 0.25.
[2023-03-17 21:17:03,615] Step: 988 | lr: 0.7582 | Time: 13.86s |TRAIN loss  0.0264 | TRAIN Acc:  99.82% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:17:17,535] Gradient total norm was 0.7880193591117859. Clipping to 0.25.
[2023-03-17 21:17:17,538] Step: 989 | lr: 0.7581 | Time: 13.91s |TRAIN loss  0.0236 | TRAIN Acc:  99.86% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:17:31,473] Gradient total norm was 0.9542279839515686. Clipping to 0.25.
[2023-03-17 21:17:31,476] Step: 990 | lr: 0.7580 | Time: 13.92s |TRAIN loss  0.0278 | TRAIN Acc:  99.76% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:17:45,409] Gradient total norm was 0.6611312627792358. Clipping to 0.25.
[2023-03-17 21:17:45,413] Step: 991 | lr: 0.7578 | Time: 13.92s |TRAIN loss  0.0235 | TRAIN Acc:  99.88% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:17:59,407] Gradient total norm was 0.6695426106452942. Clipping to 0.25.
[2023-03-17 21:17:59,410] Step: 992 | lr: 0.7577 | Time: 13.98s |TRAIN loss  0.0228 | TRAIN Acc:  99.91% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:18:13,311] Gradient total norm was 0.8609997630119324. Clipping to 0.25.
[2023-03-17 21:18:13,314] Step: 993 | lr: 0.7575 | Time: 13.89s |TRAIN loss  0.0218 | TRAIN Acc:  99.88% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:18:27,217] Gradient total norm was 1.3059803247451782. Clipping to 0.25.
[2023-03-17 21:18:27,221] Step: 994 | lr: 0.7574 | Time: 13.89s |TRAIN loss  0.0255 | TRAIN Acc:  99.75% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:18:41,185] Gradient total norm was 1.4404895305633545. Clipping to 0.25.
[2023-03-17 21:18:41,188] Step: 995 | lr: 0.7573 | Time: 13.95s |TRAIN loss  0.0301 | TRAIN Acc:  99.48% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:18:55,104] Gradient total norm was 0.8629581928253174. Clipping to 0.25.
[2023-03-17 21:18:55,107] Step: 996 | lr: 0.7571 | Time: 13.91s |TRAIN loss  0.0344 | TRAIN Acc:  99.31% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:19:09,155] Gradient total norm was 0.6432682275772095. Clipping to 0.25.
[2023-03-17 21:19:09,159] Step: 997 | lr: 0.7570 | Time: 14.04s |TRAIN loss  0.0285 | TRAIN Acc:  99.79% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:19:23,043] Gradient total norm was 1.2989696264266968. Clipping to 0.25.
[2023-03-17 21:19:23,046] Step: 998 | lr: 0.7568 | Time: 13.87s |TRAIN loss  0.0264 | TRAIN Acc:  99.84% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:19:36,895] Gradient total norm was 1.6414536237716675. Clipping to 0.25.
[2023-03-17 21:19:36,898] Step: 999 | lr: 0.7567 | Time: 13.84s |TRAIN loss  0.0340 | TRAIN Acc:  99.48% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:19:50,867] Gradient total norm was 0.6180174946784973. Clipping to 0.25.
[2023-03-17 21:19:50,870] Step: 1000| lr: 0.7565 | Time: 13.96s |TRAIN loss  0.0278 | TRAIN Acc:  99.90% |VAL loss  0.2898 | VAL Acc:  90.62% |
[2023-03-17 21:20:04,768] Gradient total norm was 0.6155230402946472. Clipping to 0.25.
[2023-03-17 21:20:10,113] Step: 1001| lr: 0.7564 | Time: 13.89s |TRAIN loss  0.0247 | TRAIN Acc:  99.87% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:20:23,986] Gradient total norm was 1.1806696653366089. Clipping to 0.25.
[2023-03-17 21:20:23,989] Step: 1002| lr: 0.7563 | Time: 13.86s |TRAIN loss  0.0236 | TRAIN Acc:  99.83% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:20:37,904] Gradient total norm was 0.8081755638122559. Clipping to 0.25.
[2023-03-17 21:20:37,908] Step: 1003| lr: 0.7561 | Time: 13.90s |TRAIN loss  0.0245 | TRAIN Acc:  99.80% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:20:51,870] Gradient total norm was 0.7941624522209167. Clipping to 0.25.
[2023-03-17 21:20:51,873] Step: 1004| lr: 0.7560 | Time: 13.95s |TRAIN loss  0.0233 | TRAIN Acc:  99.83% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:21:05,824] Gradient total norm was 0.620880126953125. Clipping to 0.25.
[2023-03-17 21:21:05,828] Step: 1005| lr: 0.7558 | Time: 13.94s |TRAIN loss  0.0245 | TRAIN Acc:  99.72% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:21:19,778] Gradient total norm was 0.6086174845695496. Clipping to 0.25.
[2023-03-17 21:21:19,781] Step: 1006| lr: 0.7557 | Time: 13.94s |TRAIN loss  0.0229 | TRAIN Acc:  99.91% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:21:33,744] Gradient total norm was 0.8592102527618408. Clipping to 0.25.
[2023-03-17 21:21:33,747] Step: 1007| lr: 0.7555 | Time: 13.95s |TRAIN loss  0.0216 | TRAIN Acc:  99.87% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:21:47,703] Gradient total norm was 1.0142797231674194. Clipping to 0.25.
[2023-03-17 21:21:47,707] Step: 1008| lr: 0.7554 | Time: 13.95s |TRAIN loss  0.0209 | TRAIN Acc:  99.84% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:22:01,605] Gradient total norm was 0.7630393505096436. Clipping to 0.25.
[2023-03-17 21:22:01,609] Step: 1009| lr: 0.7553 | Time: 13.89s |TRAIN loss  0.0221 | TRAIN Acc:  99.79% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:22:15,630] Gradient total norm was 0.7023041248321533. Clipping to 0.25.
[2023-03-17 21:22:15,633] Step: 1010| lr: 0.7551 | Time: 14.01s |TRAIN loss  0.0207 | TRAIN Acc:  99.79% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:22:29,470] Gradient total norm was 0.6264119148254395. Clipping to 0.25.
[2023-03-17 21:22:29,474] Step: 1011| lr: 0.7550 | Time: 13.83s |TRAIN loss  0.0206 | TRAIN Acc:  99.84% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:22:43,386] Gradient total norm was 0.7549518346786499. Clipping to 0.25.
[2023-03-17 21:22:43,389] Step: 1012| lr: 0.7548 | Time: 13.90s |TRAIN loss  0.0189 | TRAIN Acc:  99.92% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:22:57,399] Gradient total norm was 1.4964746236801147. Clipping to 0.25.
[2023-03-17 21:22:57,402] Step: 1013| lr: 0.7547 | Time: 14.00s |TRAIN loss  0.0247 | TRAIN Acc:  99.70% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:23:11,364] Gradient total norm was 1.1968355178833008. Clipping to 0.25.
[2023-03-17 21:23:11,368] Step: 1014| lr: 0.7545 | Time: 13.95s |TRAIN loss  0.0249 | TRAIN Acc:  99.61% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:23:25,383] Gradient total norm was 0.8490311503410339. Clipping to 0.25.
[2023-03-17 21:23:25,386] Step: 1015| lr: 0.7544 | Time: 14.00s |TRAIN loss  0.0278 | TRAIN Acc:  99.66% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:23:39,315] Gradient total norm was 0.6938486695289612. Clipping to 0.25.
[2023-03-17 21:23:39,318] Step: 1016| lr: 0.7542 | Time: 13.92s |TRAIN loss  0.0249 | TRAIN Acc:  99.72% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:23:53,255] Gradient total norm was 0.7417812347412109. Clipping to 0.25.
[2023-03-17 21:23:53,258] Step: 1017| lr: 0.7541 | Time: 13.93s |TRAIN loss  0.0294 | TRAIN Acc:  99.70% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:24:07,220] Gradient total norm was 0.5648688673973083. Clipping to 0.25.
[2023-03-17 21:24:07,223] Step: 1018| lr: 0.7539 | Time: 13.95s |TRAIN loss  0.0256 | TRAIN Acc:  99.80% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:24:21,262] Gradient total norm was 0.47656434774398804. Clipping to 0.25.
[2023-03-17 21:24:21,266] Step: 1019| lr: 0.7538 | Time: 14.03s |TRAIN loss  0.0243 | TRAIN Acc:  99.94% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:24:35,181] Gradient total norm was 0.6274086236953735. Clipping to 0.25.
[2023-03-17 21:24:35,184] Step: 1020| lr: 0.7537 | Time: 13.90s |TRAIN loss  0.0184 | TRAIN Acc:  99.93% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:24:49,161] Gradient total norm was 0.6671756505966187. Clipping to 0.25.
[2023-03-17 21:24:49,165] Step: 1021| lr: 0.7535 | Time: 13.97s |TRAIN loss  0.0196 | TRAIN Acc:  99.94% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:25:03,085] Gradient total norm was 1.2483017444610596. Clipping to 0.25.
[2023-03-17 21:25:03,088] Step: 1022| lr: 0.7534 | Time: 13.91s |TRAIN loss  0.0172 | TRAIN Acc:  99.89% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:25:17,021] Gradient total norm was 1.6383317708969116. Clipping to 0.25.
[2023-03-17 21:25:17,025] Step: 1023| lr: 0.7532 | Time: 13.92s |TRAIN loss  0.0218 | TRAIN Acc:  99.68% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:25:31,015] Gradient total norm was 1.5089051723480225. Clipping to 0.25.
[2023-03-17 21:25:31,019] Step: 1024| lr: 0.7531 | Time: 13.98s |TRAIN loss  0.0291 | TRAIN Acc:  99.50% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:25:44,940] Gradient total norm was 0.723855197429657. Clipping to 0.25.
[2023-03-17 21:25:44,943] Step: 1025| lr: 0.7529 | Time: 13.91s |TRAIN loss  0.0234 | TRAIN Acc:  99.80% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:25:58,922] Gradient total norm was 1.3672113418579102. Clipping to 0.25.
[2023-03-17 21:25:58,926] Step: 1026| lr: 0.7528 | Time: 13.97s |TRAIN loss  0.0261 | TRAIN Acc:  99.72% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:26:12,867] Gradient total norm was 1.2515685558319092. Clipping to 0.25.
[2023-03-17 21:26:12,871] Step: 1027| lr: 0.7526 | Time: 13.93s |TRAIN loss  0.0295 | TRAIN Acc:  99.61% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:26:26,803] Gradient total norm was 0.7832992672920227. Clipping to 0.25.
[2023-03-17 21:26:26,807] Step: 1028| lr: 0.7525 | Time: 13.92s |TRAIN loss  0.0292 | TRAIN Acc:  99.72% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:26:40,780] Gradient total norm was 1.9257463216781616. Clipping to 0.25.
[2023-03-17 21:26:40,784] Step: 1029| lr: 0.7523 | Time: 13.96s |TRAIN loss  0.0449 | TRAIN Acc:  98.89% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:26:54,620] Gradient total norm was 0.5280377864837646. Clipping to 0.25.
[2023-03-17 21:26:54,623] Step: 1030| lr: 0.7522 | Time: 13.83s |TRAIN loss  0.0325 | TRAIN Acc:  99.66% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:27:08,618] Gradient total norm was 0.7894221544265747. Clipping to 0.25.
[2023-03-17 21:27:08,621] Step: 1031| lr: 0.7520 | Time: 13.98s |TRAIN loss  0.0330 | TRAIN Acc:  99.66% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:27:22,521] Gradient total norm was 0.83454829454422. Clipping to 0.25.
[2023-03-17 21:27:22,525] Step: 1032| lr: 0.7519 | Time: 13.89s |TRAIN loss  0.0274 | TRAIN Acc:  99.85% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:27:36,429] Gradient total norm was 0.9024877548217773. Clipping to 0.25.
[2023-03-17 21:27:36,432] Step: 1033| lr: 0.7517 | Time: 13.89s |TRAIN loss  0.0261 | TRAIN Acc:  99.88% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:27:50,352] Gradient total norm was 0.6959735155105591. Clipping to 0.25.
[2023-03-17 21:27:50,356] Step: 1034| lr: 0.7516 | Time: 13.91s |TRAIN loss  0.0251 | TRAIN Acc:  99.83% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:28:04,321] Gradient total norm was 0.7583123445510864. Clipping to 0.25.
[2023-03-17 21:28:04,324] Step: 1035| lr: 0.7514 | Time: 13.96s |TRAIN loss  0.0294 | TRAIN Acc:  99.64% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:28:18,364] Gradient total norm was 0.8190872669219971. Clipping to 0.25.
[2023-03-17 21:28:18,367] Step: 1036| lr: 0.7513 | Time: 14.03s |TRAIN loss  0.0275 | TRAIN Acc:  99.69% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:28:32,305] Gradient total norm was 0.7771947383880615. Clipping to 0.25.
[2023-03-17 21:28:32,309] Step: 1037| lr: 0.7511 | Time: 13.93s |TRAIN loss  0.0318 | TRAIN Acc:  99.51% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:28:46,217] Gradient total norm was 0.5542632341384888. Clipping to 0.25.
[2023-03-17 21:28:46,220] Step: 1038| lr: 0.7510 | Time: 13.90s |TRAIN loss  0.0265 | TRAIN Acc:  99.81% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:29:00,141] Gradient total norm was 1.0062733888626099. Clipping to 0.25.
[2023-03-17 21:29:00,144] Step: 1039| lr: 0.7508 | Time: 13.91s |TRAIN loss  0.0285 | TRAIN Acc:  99.76% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:29:14,052] Gradient total norm was 0.8485962152481079. Clipping to 0.25.
[2023-03-17 21:29:14,055] Step: 1040| lr: 0.7507 | Time: 13.90s |TRAIN loss  0.0257 | TRAIN Acc:  99.80% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:29:28,041] Gradient total norm was 0.798096776008606. Clipping to 0.25.
[2023-03-17 21:29:28,044] Step: 1041| lr: 0.7505 | Time: 13.98s |TRAIN loss  0.0242 | TRAIN Acc:  99.81% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:29:42,004] Gradient total norm was 0.9300193786621094. Clipping to 0.25.
[2023-03-17 21:29:42,008] Step: 1042| lr: 0.7504 | Time: 13.95s |TRAIN loss  0.0246 | TRAIN Acc:  99.79% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:29:55,915] Gradient total norm was 0.7218474745750427. Clipping to 0.25.
[2023-03-17 21:29:55,919] Step: 1043| lr: 0.7502 | Time: 13.90s |TRAIN loss  0.0225 | TRAIN Acc:  99.83% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:30:09,884] Gradient total norm was 0.5769153237342834. Clipping to 0.25.
[2023-03-17 21:30:09,888] Step: 1044| lr: 0.7501 | Time: 13.96s |TRAIN loss  0.0203 | TRAIN Acc:  99.88% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:30:23,803] Gradient total norm was 0.5336857438087463. Clipping to 0.25.
[2023-03-17 21:30:23,807] Step: 1045| lr: 0.7499 | Time: 13.91s |TRAIN loss  0.0195 | TRAIN Acc:  99.88% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:30:37,869] Gradient total norm was 0.6919606328010559. Clipping to 0.25.
[2023-03-17 21:30:37,872] Step: 1046| lr: 0.7498 | Time: 14.05s |TRAIN loss  0.0185 | TRAIN Acc:  99.89% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:30:51,813] Gradient total norm was 0.7126107215881348. Clipping to 0.25.
[2023-03-17 21:30:51,817] Step: 1047| lr: 0.7496 | Time: 13.93s |TRAIN loss  0.0173 | TRAIN Acc:  99.90% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:31:07,483] Gradient total norm was 1.9632717370986938. Clipping to 0.25.
[2023-03-17 21:31:07,486] Step: 1048| lr: 0.7495 | Time: 15.66s |TRAIN loss  0.0285 | TRAIN Acc:  99.41% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:31:24,023] Gradient total norm was 0.5974946022033691. Clipping to 0.25.
[2023-03-17 21:31:24,026] Step: 1049| lr: 0.7493 | Time: 16.53s |TRAIN loss  0.0208 | TRAIN Acc:  99.83% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:31:37,900] Gradient total norm was 0.798136830329895. Clipping to 0.25.
[2023-03-17 21:31:37,903] Step: 1050| lr: 0.7492 | Time: 13.86s |TRAIN loss  0.0213 | TRAIN Acc:  99.84% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:31:51,895] Gradient total norm was 0.6823989748954773. Clipping to 0.25.
[2023-03-17 21:31:51,899] Step: 1051| lr: 0.7490 | Time: 13.98s |TRAIN loss  0.0211 | TRAIN Acc:  99.91% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:32:05,777] Gradient total norm was 1.7379727363586426. Clipping to 0.25.
[2023-03-17 21:32:05,781] Step: 1052| lr: 0.7488 | Time: 13.87s |TRAIN loss  0.0275 | TRAIN Acc:  99.54% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:32:19,753] Gradient total norm was 0.6048001050949097. Clipping to 0.25.
[2023-03-17 21:32:19,756] Step: 1053| lr: 0.7487 | Time: 13.96s |TRAIN loss  0.0226 | TRAIN Acc:  99.87% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:32:33,753] Gradient total norm was 0.7710469961166382. Clipping to 0.25.
[2023-03-17 21:32:33,756] Step: 1054| lr: 0.7485 | Time: 13.99s |TRAIN loss  0.0246 | TRAIN Acc:  99.68% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:32:47,682] Gradient total norm was 0.5240976214408875. Clipping to 0.25.
[2023-03-17 21:32:47,685] Step: 1055| lr: 0.7484 | Time: 13.92s |TRAIN loss  0.0236 | TRAIN Acc:  99.90% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:33:01,590] Gradient total norm was 0.5496004223823547. Clipping to 0.25.
[2023-03-17 21:33:01,593] Step: 1056| lr: 0.7482 | Time: 13.89s |TRAIN loss  0.0220 | TRAIN Acc:  99.90% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:33:15,490] Gradient total norm was 0.8885793089866638. Clipping to 0.25.
[2023-03-17 21:33:15,493] Step: 1057| lr: 0.7481 | Time: 13.89s |TRAIN loss  0.0185 | TRAIN Acc:  99.94% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:33:29,414] Gradient total norm was 0.6424950957298279. Clipping to 0.25.
[2023-03-17 21:33:29,417] Step: 1058| lr: 0.7479 | Time: 13.91s |TRAIN loss  0.0215 | TRAIN Acc:  99.89% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:33:43,343] Gradient total norm was 0.7577510476112366. Clipping to 0.25.
[2023-03-17 21:33:43,347] Step: 1059| lr: 0.7478 | Time: 13.92s |TRAIN loss  0.0160 | TRAIN Acc:  99.96% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:33:57,262] Gradient total norm was 0.836693525314331. Clipping to 0.25.
[2023-03-17 21:33:57,265] Step: 1060| lr: 0.7476 | Time: 13.90s |TRAIN loss  0.0184 | TRAIN Acc:  99.81% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:34:11,262] Gradient total norm was 1.2554147243499756. Clipping to 0.25.
[2023-03-17 21:34:11,265] Step: 1061| lr: 0.7475 | Time: 13.99s |TRAIN loss  0.0264 | TRAIN Acc:  99.44% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:34:25,222] Gradient total norm was 0.49867483973503113. Clipping to 0.25.
[2023-03-17 21:34:25,226] Step: 1062| lr: 0.7473 | Time: 13.95s |TRAIN loss  0.0189 | TRAIN Acc:  99.83% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:34:39,212] Gradient total norm was 0.7474067211151123. Clipping to 0.25.
[2023-03-17 21:34:39,215] Step: 1063| lr: 0.7471 | Time: 13.98s |TRAIN loss  0.0226 | TRAIN Acc:  99.78% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:34:53,145] Gradient total norm was 0.8106400370597839. Clipping to 0.25.
[2023-03-17 21:34:53,149] Step: 1064| lr: 0.7470 | Time: 13.92s |TRAIN loss  0.0167 | TRAIN Acc:  99.92% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:35:07,053] Gradient total norm was 1.3415769338607788. Clipping to 0.25.
[2023-03-17 21:35:07,056] Step: 1065| lr: 0.7468 | Time: 13.89s |TRAIN loss  0.0204 | TRAIN Acc:  99.79% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:35:21,043] Gradient total norm was 0.6813486218452454. Clipping to 0.25.
[2023-03-17 21:35:21,046] Step: 1066| lr: 0.7467 | Time: 13.98s |TRAIN loss  0.0198 | TRAIN Acc:  99.88% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:35:35,004] Gradient total norm was 0.627884030342102. Clipping to 0.25.
[2023-03-17 21:35:35,007] Step: 1067| lr: 0.7465 | Time: 13.95s |TRAIN loss  0.0171 | TRAIN Acc:  99.91% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:35:49,054] Gradient total norm was 0.6365430951118469. Clipping to 0.25.
[2023-03-17 21:35:49,057] Step: 1068| lr: 0.7464 | Time: 14.04s |TRAIN loss  0.0175 | TRAIN Acc:  99.91% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:36:03,059] Gradient total norm was 0.6177724599838257. Clipping to 0.25.
[2023-03-17 21:36:03,063] Step: 1069| lr: 0.7462 | Time: 13.99s |TRAIN loss  0.0170 | TRAIN Acc:  99.83% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:36:17,040] Gradient total norm was 0.4086354374885559. Clipping to 0.25.
[2023-03-17 21:36:17,043] Step: 1070| lr: 0.7460 | Time: 13.97s |TRAIN loss  0.0152 | TRAIN Acc:  99.95% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:36:31,036] Gradient total norm was 0.4461148977279663. Clipping to 0.25.
[2023-03-17 21:36:31,039] Step: 1071| lr: 0.7459 | Time: 13.98s |TRAIN loss  0.0137 | TRAIN Acc:  99.93% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:36:45,011] Gradient total norm was 0.6823283433914185. Clipping to 0.25.
[2023-03-17 21:36:45,014] Step: 1072| lr: 0.7457 | Time: 13.96s |TRAIN loss  0.0129 | TRAIN Acc:  99.96% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:36:59,013] Gradient total norm was 0.8155330419540405. Clipping to 0.25.
[2023-03-17 21:36:59,016] Step: 1073| lr: 0.7456 | Time: 13.99s |TRAIN loss  0.0147 | TRAIN Acc:  99.91% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:37:13,033] Gradient total norm was 1.280121088027954. Clipping to 0.25.
[2023-03-17 21:37:13,036] Step: 1074| lr: 0.7454 | Time: 14.01s |TRAIN loss  0.0142 | TRAIN Acc:  99.88% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:37:26,949] Gradient total norm was 0.7990187406539917. Clipping to 0.25.
[2023-03-17 21:37:26,952] Step: 1075| lr: 0.7453 | Time: 13.90s |TRAIN loss  0.0170 | TRAIN Acc:  99.82% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:37:40,952] Gradient total norm was 0.9566806554794312. Clipping to 0.25.
[2023-03-17 21:37:40,955] Step: 1076| lr: 0.7451 | Time: 13.99s |TRAIN loss  0.0204 | TRAIN Acc:  99.67% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:37:54,859] Gradient total norm was 0.5236008167266846. Clipping to 0.25.
[2023-03-17 21:37:54,862] Step: 1077| lr: 0.7449 | Time: 13.89s |TRAIN loss  0.0192 | TRAIN Acc:  99.87% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:38:08,859] Gradient total norm was 0.6581993103027344. Clipping to 0.25.
[2023-03-17 21:38:08,862] Step: 1078| lr: 0.7448 | Time: 13.99s |TRAIN loss  0.0192 | TRAIN Acc:  99.92% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:38:22,822] Gradient total norm was 1.0501272678375244. Clipping to 0.25.
[2023-03-17 21:38:22,825] Step: 1079| lr: 0.7446 | Time: 13.95s |TRAIN loss  0.0187 | TRAIN Acc:  99.86% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:38:36,804] Gradient total norm was 0.9988404512405396. Clipping to 0.25.
[2023-03-17 21:38:36,807] Step: 1080| lr: 0.7445 | Time: 13.97s |TRAIN loss  0.0188 | TRAIN Acc:  99.86% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:38:50,763] Gradient total norm was 0.7149295210838318. Clipping to 0.25.
[2023-03-17 21:38:50,767] Step: 1081| lr: 0.7443 | Time: 13.95s |TRAIN loss  0.0192 | TRAIN Acc:  99.90% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:39:04,714] Gradient total norm was 0.7692654728889465. Clipping to 0.25.
[2023-03-17 21:39:04,718] Step: 1082| lr: 0.7441 | Time: 13.94s |TRAIN loss  0.0168 | TRAIN Acc:  99.93% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:39:18,711] Gradient total norm was 0.7671125531196594. Clipping to 0.25.
[2023-03-17 21:39:18,714] Step: 1083| lr: 0.7440 | Time: 13.98s |TRAIN loss  0.0175 | TRAIN Acc:  99.93% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:39:32,644] Gradient total norm was 1.2415142059326172. Clipping to 0.25.
[2023-03-17 21:39:32,647] Step: 1084| lr: 0.7438 | Time: 13.92s |TRAIN loss  0.0170 | TRAIN Acc:  99.90% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:39:46,644] Gradient total norm was 1.846746802330017. Clipping to 0.25.
[2023-03-17 21:39:46,648] Step: 1085| lr: 0.7437 | Time: 13.99s |TRAIN loss  0.0240 | TRAIN Acc:  99.58% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:40:00,641] Gradient total norm was 2.2947568893432617. Clipping to 0.25.
[2023-03-17 21:40:00,644] Step: 1086| lr: 0.7435 | Time: 13.98s |TRAIN loss  0.0316 | TRAIN Acc:  99.32% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:40:14,517] Gradient total norm was 1.0076372623443604. Clipping to 0.25.
[2023-03-17 21:40:14,520] Step: 1087| lr: 0.7433 | Time: 13.86s |TRAIN loss  0.0337 | TRAIN Acc:  99.47% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:40:28,489] Gradient total norm was 1.0021367073059082. Clipping to 0.25.
[2023-03-17 21:40:28,492] Step: 1088| lr: 0.7432 | Time: 13.96s |TRAIN loss  0.0302 | TRAIN Acc:  99.65% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:40:42,508] Gradient total norm was 1.520678997039795. Clipping to 0.25.
[2023-03-17 21:40:42,512] Step: 1089| lr: 0.7430 | Time: 14.01s |TRAIN loss  0.0349 | TRAIN Acc:  99.55% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:40:56,591] Gradient total norm was 1.0937618017196655. Clipping to 0.25.
[2023-03-17 21:40:56,595] Step: 1090| lr: 0.7428 | Time: 14.07s |TRAIN loss  0.0353 | TRAIN Acc:  99.57% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:41:10,522] Gradient total norm was 1.0945703983306885. Clipping to 0.25.
[2023-03-17 21:41:10,526] Step: 1091| lr: 0.7427 | Time: 13.92s |TRAIN loss  0.0322 | TRAIN Acc:  99.75% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:41:24,431] Gradient total norm was 1.9755547046661377. Clipping to 0.25.
[2023-03-17 21:41:24,434] Step: 1092| lr: 0.7425 | Time: 13.90s |TRAIN loss  0.0470 | TRAIN Acc:  98.97% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:41:38,434] Gradient total norm was 0.781281590461731. Clipping to 0.25.
[2023-03-17 21:41:38,437] Step: 1093| lr: 0.7424 | Time: 13.99s |TRAIN loss  0.0410 | TRAIN Acc:  99.48% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:41:52,401] Gradient total norm was 0.6749054193496704. Clipping to 0.25.
[2023-03-17 21:41:52,404] Step: 1094| lr: 0.7422 | Time: 13.95s |TRAIN loss  0.0369 | TRAIN Acc:  99.57% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:42:06,396] Gradient total norm was 0.638139545917511. Clipping to 0.25.
[2023-03-17 21:42:06,400] Step: 1095| lr: 0.7420 | Time: 13.98s |TRAIN loss  0.0354 | TRAIN Acc:  99.68% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:42:20,317] Gradient total norm was 0.708249032497406. Clipping to 0.25.
[2023-03-17 21:42:20,320] Step: 1096| lr: 0.7419 | Time: 13.91s |TRAIN loss  0.0256 | TRAIN Acc:  99.88% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:42:34,296] Gradient total norm was 0.6670128703117371. Clipping to 0.25.
[2023-03-17 21:42:34,299] Step: 1097| lr: 0.7417 | Time: 13.97s |TRAIN loss  0.0256 | TRAIN Acc:  99.92% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:42:48,310] Gradient total norm was 0.7313459515571594. Clipping to 0.25.
[2023-03-17 21:42:48,314] Step: 1098| lr: 0.7415 | Time: 14.00s |TRAIN loss  0.0206 | TRAIN Acc:  99.95% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:43:02,281] Gradient total norm was 0.6201311349868774. Clipping to 0.25.
[2023-03-17 21:43:02,285] Step: 1099| lr: 0.7414 | Time: 13.96s |TRAIN loss  0.0209 | TRAIN Acc:  99.94% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:43:16,235] Gradient total norm was 1.295231580734253. Clipping to 0.25.
[2023-03-17 21:43:16,238] Step: 1100| lr: 0.7412 | Time: 13.94s |TRAIN loss  0.0187 | TRAIN Acc:  99.88% |VAL loss  0.2779 | VAL Acc:  91.20% |
[2023-03-17 21:43:30,162] Gradient total norm was 1.4420065879821777. Clipping to 0.25.
[2023-03-17 21:43:35,654] Step: 1101| lr: 0.7411 | Time: 13.91s |TRAIN loss  0.0227 | TRAIN Acc:  99.71% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:43:49,615] Gradient total norm was 1.0750387907028198. Clipping to 0.25.
[2023-03-17 21:43:49,619] Step: 1102| lr: 0.7409 | Time: 13.95s |TRAIN loss  0.0282 | TRAIN Acc:  99.59% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:44:03,578] Gradient total norm was 0.7353314757347107. Clipping to 0.25.
[2023-03-17 21:44:03,581] Step: 1103| lr: 0.7407 | Time: 13.95s |TRAIN loss  0.0264 | TRAIN Acc:  99.80% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:44:17,528] Gradient total norm was 0.6312381029129028. Clipping to 0.25.
[2023-03-17 21:44:17,531] Step: 1104| lr: 0.7406 | Time: 13.94s |TRAIN loss  0.0260 | TRAIN Acc:  99.73% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:44:31,496] Gradient total norm was 0.48867008090019226. Clipping to 0.25.
[2023-03-17 21:44:31,499] Step: 1105| lr: 0.7404 | Time: 13.95s |TRAIN loss  0.0233 | TRAIN Acc:  99.88% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:44:45,443] Gradient total norm was 0.5402153730392456. Clipping to 0.25.
[2023-03-17 21:44:45,446] Step: 1106| lr: 0.7402 | Time: 13.93s |TRAIN loss  0.0222 | TRAIN Acc:  99.87% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:44:59,398] Gradient total norm was 0.4879293143749237. Clipping to 0.25.
[2023-03-17 21:44:59,401] Step: 1107| lr: 0.7401 | Time: 13.94s |TRAIN loss  0.0188 | TRAIN Acc:  99.94% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:45:13,330] Gradient total norm was 0.6970773935317993. Clipping to 0.25.
[2023-03-17 21:45:13,333] Step: 1108| lr: 0.7399 | Time: 13.92s |TRAIN loss  0.0178 | TRAIN Acc:  99.92% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:45:27,311] Gradient total norm was 1.3910131454467773. Clipping to 0.25.
[2023-03-17 21:45:27,314] Step: 1109| lr: 0.7397 | Time: 13.97s |TRAIN loss  0.0186 | TRAIN Acc:  99.82% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:45:41,259] Gradient total norm was 0.8308397531509399. Clipping to 0.25.
[2023-03-17 21:45:41,262] Step: 1110| lr: 0.7396 | Time: 13.93s |TRAIN loss  0.0235 | TRAIN Acc:  99.64% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:45:55,246] Gradient total norm was 0.5993911623954773. Clipping to 0.25.
[2023-03-17 21:45:55,249] Step: 1111| lr: 0.7394 | Time: 13.97s |TRAIN loss  0.0173 | TRAIN Acc:  99.92% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:46:09,185] Gradient total norm was 0.5838348865509033. Clipping to 0.25.
[2023-03-17 21:46:09,189] Step: 1112| lr: 0.7392 | Time: 13.93s |TRAIN loss  0.0185 | TRAIN Acc:  99.88% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:46:23,088] Gradient total norm was 0.5956975817680359. Clipping to 0.25.
[2023-03-17 21:46:23,091] Step: 1113| lr: 0.7391 | Time: 13.89s |TRAIN loss  0.0171 | TRAIN Acc:  99.91% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:46:37,114] Gradient total norm was 1.25932776927948. Clipping to 0.25.
[2023-03-17 21:46:37,117] Step: 1114| lr: 0.7389 | Time: 14.01s |TRAIN loss  0.0200 | TRAIN Acc:  99.74% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:46:51,084] Gradient total norm was 0.7519703507423401. Clipping to 0.25.
[2023-03-17 21:46:51,087] Step: 1115| lr: 0.7387 | Time: 13.96s |TRAIN loss  0.0201 | TRAIN Acc:  99.83% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:47:05,004] Gradient total norm was 0.7637399435043335. Clipping to 0.25.
[2023-03-17 21:47:05,007] Step: 1116| lr: 0.7386 | Time: 13.91s |TRAIN loss  0.0192 | TRAIN Acc:  99.83% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:47:18,930] Gradient total norm was 0.8164899945259094. Clipping to 0.25.
[2023-03-17 21:47:18,934] Step: 1117| lr: 0.7384 | Time: 13.91s |TRAIN loss  0.0203 | TRAIN Acc:  99.89% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:47:32,850] Gradient total norm was 0.6335499882698059. Clipping to 0.25.
[2023-03-17 21:47:32,853] Step: 1118| lr: 0.7382 | Time: 13.91s |TRAIN loss  0.0203 | TRAIN Acc:  99.79% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:47:46,805] Gradient total norm was 0.5095047950744629. Clipping to 0.25.
[2023-03-17 21:47:46,808] Step: 1119| lr: 0.7381 | Time: 13.94s |TRAIN loss  0.0189 | TRAIN Acc:  99.93% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:48:00,724] Gradient total norm was 0.6785545349121094. Clipping to 0.25.
[2023-03-17 21:48:00,727] Step: 1120| lr: 0.7379 | Time: 13.91s |TRAIN loss  0.0183 | TRAIN Acc:  99.88% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:48:14,701] Gradient total norm was 0.8353970646858215. Clipping to 0.25.
[2023-03-17 21:48:14,704] Step: 1121| lr: 0.7377 | Time: 13.96s |TRAIN loss  0.0184 | TRAIN Acc:  99.88% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:48:28,723] Gradient total norm was 0.975178062915802. Clipping to 0.25.
[2023-03-17 21:48:28,726] Step: 1122| lr: 0.7376 | Time: 14.01s |TRAIN loss  0.0199 | TRAIN Acc:  99.81% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:48:42,764] Gradient total norm was 0.5515093803405762. Clipping to 0.25.
[2023-03-17 21:48:42,767] Step: 1123| lr: 0.7374 | Time: 14.03s |TRAIN loss  0.0182 | TRAIN Acc:  99.90% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:48:56,671] Gradient total norm was 0.7705503702163696. Clipping to 0.25.
[2023-03-17 21:48:56,674] Step: 1124| lr: 0.7372 | Time: 13.89s |TRAIN loss  0.0164 | TRAIN Acc:  99.93% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:49:10,607] Gradient total norm was 0.8641217350959778. Clipping to 0.25.
[2023-03-17 21:49:10,610] Step: 1125| lr: 0.7371 | Time: 13.92s |TRAIN loss  0.0200 | TRAIN Acc:  99.85% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:49:24,580] Gradient total norm was 1.2361201047897339. Clipping to 0.25.
[2023-03-17 21:49:24,583] Step: 1126| lr: 0.7369 | Time: 13.96s |TRAIN loss  0.0185 | TRAIN Acc:  99.82% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:49:38,615] Gradient total norm was 0.5998778939247131. Clipping to 0.25.
[2023-03-17 21:49:38,619] Step: 1127| lr: 0.7367 | Time: 14.02s |TRAIN loss  0.0177 | TRAIN Acc:  99.90% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:49:52,640] Gradient total norm was 1.1330492496490479. Clipping to 0.25.
[2023-03-17 21:49:52,644] Step: 1128| lr: 0.7365 | Time: 14.01s |TRAIN loss  0.0195 | TRAIN Acc:  99.86% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:50:06,550] Gradient total norm was 0.9367634057998657. Clipping to 0.25.
[2023-03-17 21:50:06,553] Step: 1129| lr: 0.7364 | Time: 13.90s |TRAIN loss  0.0189 | TRAIN Acc:  99.89% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:50:20,529] Gradient total norm was 1.0242867469787598. Clipping to 0.25.
[2023-03-17 21:50:20,533] Step: 1130| lr: 0.7362 | Time: 13.97s |TRAIN loss  0.0199 | TRAIN Acc:  99.80% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:50:34,491] Gradient total norm was 0.889498233795166. Clipping to 0.25.
[2023-03-17 21:50:34,494] Step: 1131| lr: 0.7360 | Time: 13.95s |TRAIN loss  0.0218 | TRAIN Acc:  99.83% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:50:48,440] Gradient total norm was 0.8235262632369995. Clipping to 0.25.
[2023-03-17 21:50:48,444] Step: 1132| lr: 0.7359 | Time: 13.94s |TRAIN loss  0.0226 | TRAIN Acc:  99.65% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:51:02,411] Gradient total norm was 2.963505268096924. Clipping to 0.25.
[2023-03-17 21:51:02,414] Step: 1133| lr: 0.7357 | Time: 13.96s |TRAIN loss  0.0313 | TRAIN Acc:  99.38% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:51:16,396] Gradient total norm was 0.9266961216926575. Clipping to 0.25.
[2023-03-17 21:51:16,399] Step: 1134| lr: 0.7355 | Time: 13.97s |TRAIN loss  0.0299 | TRAIN Acc:  99.59% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:51:30,407] Gradient total norm was 0.9548439979553223. Clipping to 0.25.
[2023-03-17 21:51:30,411] Step: 1135| lr: 0.7354 | Time: 14.00s |TRAIN loss  0.0333 | TRAIN Acc:  99.43% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:51:44,406] Gradient total norm was 0.5782646536827087. Clipping to 0.25.
[2023-03-17 21:51:44,410] Step: 1136| lr: 0.7352 | Time: 13.99s |TRAIN loss  0.0310 | TRAIN Acc:  99.69% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:51:58,387] Gradient total norm was 0.7772533893585205. Clipping to 0.25.
[2023-03-17 21:51:58,391] Step: 1137| lr: 0.7350 | Time: 13.97s |TRAIN loss  0.0287 | TRAIN Acc:  99.81% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:52:12,300] Gradient total norm was 1.1985410451889038. Clipping to 0.25.
[2023-03-17 21:52:12,304] Step: 1138| lr: 0.7348 | Time: 13.90s |TRAIN loss  0.0244 | TRAIN Acc:  99.86% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:52:26,311] Gradient total norm was 1.9408519268035889. Clipping to 0.25.
[2023-03-17 21:52:26,315] Step: 1139| lr: 0.7347 | Time: 14.00s |TRAIN loss  0.0303 | TRAIN Acc:  99.54% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:52:40,206] Gradient total norm was 0.7381705045700073. Clipping to 0.25.
[2023-03-17 21:52:40,209] Step: 1140| lr: 0.7345 | Time: 13.88s |TRAIN loss  0.0267 | TRAIN Acc:  99.78% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:52:54,211] Gradient total norm was 0.8236389756202698. Clipping to 0.25.
[2023-03-17 21:52:54,215] Step: 1141| lr: 0.7343 | Time: 13.99s |TRAIN loss  0.0266 | TRAIN Acc:  99.72% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:53:08,264] Gradient total norm was 0.4705665409564972. Clipping to 0.25.
[2023-03-17 21:53:08,267] Step: 1142| lr: 0.7342 | Time: 14.04s |TRAIN loss  0.0244 | TRAIN Acc:  99.89% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:53:22,187] Gradient total norm was 0.5211428999900818. Clipping to 0.25.
[2023-03-17 21:53:22,190] Step: 1143| lr: 0.7340 | Time: 13.91s |TRAIN loss  0.0247 | TRAIN Acc:  99.85% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:53:36,116] Gradient total norm was 0.667620837688446. Clipping to 0.25.
[2023-03-17 21:53:36,119] Step: 1144| lr: 0.7338 | Time: 13.92s |TRAIN loss  0.0207 | TRAIN Acc:  99.89% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:53:50,063] Gradient total norm was 0.6973268389701843. Clipping to 0.25.
[2023-03-17 21:53:50,067] Step: 1145| lr: 0.7336 | Time: 13.93s |TRAIN loss  0.0249 | TRAIN Acc:  99.84% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:54:03,967] Gradient total norm was 0.558190107345581. Clipping to 0.25.
[2023-03-17 21:54:03,970] Step: 1146| lr: 0.7335 | Time: 13.89s |TRAIN loss  0.0183 | TRAIN Acc:  99.96% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:54:17,988] Gradient total norm was 0.699890673160553. Clipping to 0.25.
[2023-03-17 21:54:17,992] Step: 1147| lr: 0.7333 | Time: 14.01s |TRAIN loss  0.0186 | TRAIN Acc:  99.93% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:54:31,961] Gradient total norm was 1.2819244861602783. Clipping to 0.25.
[2023-03-17 21:54:31,964] Step: 1148| lr: 0.7331 | Time: 13.96s |TRAIN loss  0.0178 | TRAIN Acc:  99.83% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:54:45,910] Gradient total norm was 0.4186205565929413. Clipping to 0.25.
[2023-03-17 21:54:45,913] Step: 1149| lr: 0.7329 | Time: 13.93s |TRAIN loss  0.0159 | TRAIN Acc:  99.94% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:54:59,837] Gradient total norm was 0.8973698616027832. Clipping to 0.25.
[2023-03-17 21:54:59,840] Step: 1150| lr: 0.7328 | Time: 13.91s |TRAIN loss  0.0160 | TRAIN Acc:  99.91% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:55:13,839] Gradient total norm was 0.7877001762390137. Clipping to 0.25.
[2023-03-17 21:55:13,842] Step: 1151| lr: 0.7326 | Time: 13.99s |TRAIN loss  0.0173 | TRAIN Acc:  99.87% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:55:27,752] Gradient total norm was 0.4550904631614685. Clipping to 0.25.
[2023-03-17 21:55:27,755] Step: 1152| lr: 0.7324 | Time: 13.90s |TRAIN loss  0.0148 | TRAIN Acc:  99.95% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:55:41,772] Gradient total norm was 0.6022033095359802. Clipping to 0.25.
[2023-03-17 21:55:41,775] Step: 1153| lr: 0.7322 | Time: 14.01s |TRAIN loss  0.0152 | TRAIN Acc:  99.96% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:55:55,808] Gradient total norm was 0.49133482575416565. Clipping to 0.25.
[2023-03-17 21:55:55,812] Step: 1154| lr: 0.7321 | Time: 14.02s |TRAIN loss  0.0137 | TRAIN Acc:  99.96% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:56:09,743] Gradient total norm was 0.7691515684127808. Clipping to 0.25.
[2023-03-17 21:56:09,747] Step: 1155| lr: 0.7319 | Time: 13.92s |TRAIN loss  0.0136 | TRAIN Acc:  99.95% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:56:23,685] Gradient total norm was 1.9830766916275024. Clipping to 0.25.
[2023-03-17 21:56:23,689] Step: 1156| lr: 0.7317 | Time: 13.93s |TRAIN loss  0.0204 | TRAIN Acc:  99.66% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:56:37,623] Gradient total norm was 1.877813458442688. Clipping to 0.25.
[2023-03-17 21:56:37,626] Step: 1157| lr: 0.7315 | Time: 13.92s |TRAIN loss  0.0274 | TRAIN Acc:  99.37% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:56:51,563] Gradient total norm was 1.3951374292373657. Clipping to 0.25.
[2023-03-17 21:56:51,566] Step: 1158| lr: 0.7314 | Time: 13.93s |TRAIN loss  0.0274 | TRAIN Acc:  99.38% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:57:05,587] Gradient total norm was 0.8816311955451965. Clipping to 0.25.
[2023-03-17 21:57:05,591] Step: 1159| lr: 0.7312 | Time: 14.01s |TRAIN loss  0.0371 | TRAIN Acc:  99.13% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:57:19,608] Gradient total norm was 0.6725382208824158. Clipping to 0.25.
[2023-03-17 21:57:19,612] Step: 1160| lr: 0.7310 | Time: 14.01s |TRAIN loss  0.0357 | TRAIN Acc:  99.39% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:57:33,593] Gradient total norm was 0.5582128167152405. Clipping to 0.25.
[2023-03-17 21:57:33,597] Step: 1161| lr: 0.7308 | Time: 13.97s |TRAIN loss  0.0244 | TRAIN Acc:  99.78% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:57:47,591] Gradient total norm was 0.8768056631088257. Clipping to 0.25.
[2023-03-17 21:57:47,594] Step: 1162| lr: 0.7307 | Time: 13.98s |TRAIN loss  0.0229 | TRAIN Acc:  99.79% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:58:01,583] Gradient total norm was 0.6078084111213684. Clipping to 0.25.
[2023-03-17 21:58:01,586] Step: 1163| lr: 0.7305 | Time: 13.98s |TRAIN loss  0.0203 | TRAIN Acc:  99.86% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:58:15,552] Gradient total norm was 0.5926147699356079. Clipping to 0.25.
[2023-03-17 21:58:15,555] Step: 1164| lr: 0.7303 | Time: 13.96s |TRAIN loss  0.0208 | TRAIN Acc:  99.85% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:58:29,513] Gradient total norm was 0.5688002109527588. Clipping to 0.25.
[2023-03-17 21:58:29,517] Step: 1165| lr: 0.7301 | Time: 13.95s |TRAIN loss  0.0184 | TRAIN Acc:  99.91% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:58:43,516] Gradient total norm was 0.5718054175376892. Clipping to 0.25.
[2023-03-17 21:58:43,519] Step: 1166| lr: 0.7299 | Time: 13.99s |TRAIN loss  0.0171 | TRAIN Acc:  99.94% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:58:57,515] Gradient total norm was 0.8963544368743896. Clipping to 0.25.
[2023-03-17 21:58:57,519] Step: 1167| lr: 0.7298 | Time: 13.99s |TRAIN loss  0.0207 | TRAIN Acc:  99.75% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:59:11,450] Gradient total norm was 0.624064564704895. Clipping to 0.25.
[2023-03-17 21:59:11,453] Step: 1168| lr: 0.7296 | Time: 13.92s |TRAIN loss  0.0183 | TRAIN Acc:  99.85% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:59:25,388] Gradient total norm was 1.2472890615463257. Clipping to 0.25.
[2023-03-17 21:59:25,392] Step: 1169| lr: 0.7294 | Time: 13.93s |TRAIN loss  0.0241 | TRAIN Acc:  99.62% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:59:39,330] Gradient total norm was 0.5223004817962646. Clipping to 0.25.
[2023-03-17 21:59:39,333] Step: 1170| lr: 0.7292 | Time: 13.93s |TRAIN loss  0.0220 | TRAIN Acc:  99.70% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 21:59:53,272] Gradient total norm was 0.6337877511978149. Clipping to 0.25.
[2023-03-17 21:59:53,275] Step: 1171| lr: 0.7291 | Time: 13.93s |TRAIN loss  0.0206 | TRAIN Acc:  99.83% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:00:07,287] Gradient total norm was 0.5086445808410645. Clipping to 0.25.
[2023-03-17 22:00:07,291] Step: 1172| lr: 0.7289 | Time: 14.00s |TRAIN loss  0.0222 | TRAIN Acc:  99.71% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:00:21,214] Gradient total norm was 0.48239216208457947. Clipping to 0.25.
[2023-03-17 22:00:21,217] Step: 1173| lr: 0.7287 | Time: 13.91s |TRAIN loss  0.0177 | TRAIN Acc:  99.94% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:00:35,244] Gradient total norm was 0.7796310782432556. Clipping to 0.25.
[2023-03-17 22:00:35,247] Step: 1174| lr: 0.7285 | Time: 14.02s |TRAIN loss  0.0188 | TRAIN Acc:  99.87% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:00:49,185] Gradient total norm was 0.8739973902702332. Clipping to 0.25.
[2023-03-17 22:00:49,189] Step: 1175| lr: 0.7283 | Time: 13.93s |TRAIN loss  0.0191 | TRAIN Acc:  99.84% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:01:03,141] Gradient total norm was 0.6272190809249878. Clipping to 0.25.
[2023-03-17 22:01:03,145] Step: 1176| lr: 0.7282 | Time: 13.94s |TRAIN loss  0.0172 | TRAIN Acc:  99.86% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:01:17,061] Gradient total norm was 0.6246374845504761. Clipping to 0.25.
[2023-03-17 22:01:17,065] Step: 1177| lr: 0.7280 | Time: 13.91s |TRAIN loss  0.0175 | TRAIN Acc:  99.89% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:01:31,020] Gradient total norm was 0.5696781277656555. Clipping to 0.25.
[2023-03-17 22:01:31,023] Step: 1178| lr: 0.7278 | Time: 13.94s |TRAIN loss  0.0158 | TRAIN Acc:  99.94% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:01:45,023] Gradient total norm was 0.9384762644767761. Clipping to 0.25.
[2023-03-17 22:01:45,026] Step: 1179| lr: 0.7276 | Time: 13.99s |TRAIN loss  0.0159 | TRAIN Acc:  99.92% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:01:58,867] Gradient total norm was 1.0195927619934082. Clipping to 0.25.
[2023-03-17 22:01:58,870] Step: 1180| lr: 0.7274 | Time: 13.83s |TRAIN loss  0.0176 | TRAIN Acc:  99.88% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:02:12,856] Gradient total norm was 1.6919350624084473. Clipping to 0.25.
[2023-03-17 22:02:12,860] Step: 1181| lr: 0.7273 | Time: 13.98s |TRAIN loss  0.0199 | TRAIN Acc:  99.77% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:02:26,797] Gradient total norm was 0.9879711270332336. Clipping to 0.25.
[2023-03-17 22:02:26,800] Step: 1182| lr: 0.7271 | Time: 13.93s |TRAIN loss  0.0205 | TRAIN Acc:  99.83% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:02:40,742] Gradient total norm was 0.8217484951019287. Clipping to 0.25.
[2023-03-17 22:02:40,746] Step: 1183| lr: 0.7269 | Time: 13.93s |TRAIN loss  0.0196 | TRAIN Acc:  99.86% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:02:54,738] Gradient total norm was 0.7586386203765869. Clipping to 0.25.
[2023-03-17 22:02:54,741] Step: 1184| lr: 0.7267 | Time: 13.98s |TRAIN loss  0.0223 | TRAIN Acc:  99.84% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:03:08,725] Gradient total norm was 0.6926816701889038. Clipping to 0.25.
[2023-03-17 22:03:08,728] Step: 1185| lr: 0.7265 | Time: 13.97s |TRAIN loss  0.0231 | TRAIN Acc:  99.79% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:03:22,680] Gradient total norm was 0.5377582907676697. Clipping to 0.25.
[2023-03-17 22:03:22,683] Step: 1186| lr: 0.7264 | Time: 13.94s |TRAIN loss  0.0219 | TRAIN Acc:  99.83% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:03:36,635] Gradient total norm was 0.6531736850738525. Clipping to 0.25.
[2023-03-17 22:03:36,638] Step: 1187| lr: 0.7262 | Time: 13.94s |TRAIN loss  0.0215 | TRAIN Acc:  99.79% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:03:50,497] Gradient total norm was 0.42678403854370117. Clipping to 0.25.
[2023-03-17 22:03:50,500] Step: 1188| lr: 0.7260 | Time: 13.85s |TRAIN loss  0.0215 | TRAIN Acc:  99.90% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:04:04,482] Gradient total norm was 0.398964524269104. Clipping to 0.25.
[2023-03-17 22:04:04,485] Step: 1189| lr: 0.7258 | Time: 13.97s |TRAIN loss  0.0162 | TRAIN Acc:  99.93% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:04:18,469] Gradient total norm was 0.4165520668029785. Clipping to 0.25.
[2023-03-17 22:04:18,472] Step: 1190| lr: 0.7256 | Time: 13.97s |TRAIN loss  0.0142 | TRAIN Acc:  99.95% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:04:32,450] Gradient total norm was 0.6062965393066406. Clipping to 0.25.
[2023-03-17 22:04:32,453] Step: 1191| lr: 0.7254 | Time: 13.97s |TRAIN loss  0.0129 | TRAIN Acc:  99.94% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:04:46,376] Gradient total norm was 1.5478514432907104. Clipping to 0.25.
[2023-03-17 22:04:46,380] Step: 1192| lr: 0.7253 | Time: 13.91s |TRAIN loss  0.0164 | TRAIN Acc:  99.80% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:05:00,312] Gradient total norm was 0.8200629949569702. Clipping to 0.25.
[2023-03-17 22:05:00,315] Step: 1193| lr: 0.7251 | Time: 13.92s |TRAIN loss  0.0154 | TRAIN Acc:  99.80% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:05:14,262] Gradient total norm was 0.9142868518829346. Clipping to 0.25.
[2023-03-17 22:05:14,265] Step: 1194| lr: 0.7249 | Time: 13.94s |TRAIN loss  0.0192 | TRAIN Acc:  99.72% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:05:28,116] Gradient total norm was 0.6469710469245911. Clipping to 0.25.
[2023-03-17 22:05:28,119] Step: 1195| lr: 0.7247 | Time: 13.84s |TRAIN loss  0.0191 | TRAIN Acc:  99.71% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:05:42,109] Gradient total norm was 2.7362639904022217. Clipping to 0.25.
[2023-03-17 22:05:42,113] Step: 1196| lr: 0.7245 | Time: 13.98s |TRAIN loss  0.0317 | TRAIN Acc:  99.27% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:05:56,136] Gradient total norm was 0.8703616857528687. Clipping to 0.25.
[2023-03-17 22:05:56,139] Step: 1197| lr: 0.7243 | Time: 14.01s |TRAIN loss  0.0312 | TRAIN Acc:  99.61% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:06:10,147] Gradient total norm was 0.5975037217140198. Clipping to 0.25.
[2023-03-17 22:06:10,150] Step: 1198| lr: 0.7242 | Time: 14.00s |TRAIN loss  0.0240 | TRAIN Acc:  99.76% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:06:24,146] Gradient total norm was 0.5293151140213013. Clipping to 0.25.
[2023-03-17 22:06:24,149] Step: 1199| lr: 0.7240 | Time: 13.99s |TRAIN loss  0.0218 | TRAIN Acc:  99.80% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:06:38,062] Gradient total norm was 0.3684869408607483. Clipping to 0.25.
[2023-03-17 22:06:38,066] Step: 1200| lr: 0.7238 | Time: 13.90s |TRAIN loss  0.0182 | TRAIN Acc:  99.87% |VAL loss  0.3576 | VAL Acc:  89.08% |
[2023-03-17 22:06:52,069] Gradient total norm was 0.6293290853500366. Clipping to 0.25.
[2023-03-17 22:06:57,487] Step: 1201| lr: 0.7236 | Time: 13.99s |TRAIN loss  0.0166 | TRAIN Acc:  99.86% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:07:11,396] Gradient total norm was 0.5242544412612915. Clipping to 0.25.
[2023-03-17 22:07:11,399] Step: 1202| lr: 0.7234 | Time: 13.90s |TRAIN loss  0.0158 | TRAIN Acc:  99.89% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:07:25,377] Gradient total norm was 1.6726759672164917. Clipping to 0.25.
[2023-03-17 22:07:25,380] Step: 1203| lr: 0.7232 | Time: 13.97s |TRAIN loss  0.0189 | TRAIN Acc:  99.72% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:07:39,290] Gradient total norm was 0.7690510153770447. Clipping to 0.25.
[2023-03-17 22:07:39,294] Step: 1204| lr: 0.7231 | Time: 13.90s |TRAIN loss  0.0186 | TRAIN Acc:  99.82% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:07:53,258] Gradient total norm was 0.7074797749519348. Clipping to 0.25.
[2023-03-17 22:07:53,261] Step: 1205| lr: 0.7229 | Time: 13.95s |TRAIN loss  0.0193 | TRAIN Acc:  99.86% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:08:07,270] Gradient total norm was 0.6105988025665283. Clipping to 0.25.
[2023-03-17 22:08:07,273] Step: 1206| lr: 0.7227 | Time: 14.00s |TRAIN loss  0.0190 | TRAIN Acc:  99.84% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:08:21,265] Gradient total norm was 0.550971508026123. Clipping to 0.25.
[2023-03-17 22:08:21,269] Step: 1207| lr: 0.7225 | Time: 13.98s |TRAIN loss  0.0165 | TRAIN Acc:  99.94% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:08:35,244] Gradient total norm was 0.5727477073669434. Clipping to 0.25.
[2023-03-17 22:08:35,248] Step: 1208| lr: 0.7223 | Time: 13.97s |TRAIN loss  0.0157 | TRAIN Acc:  99.96% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:08:49,257] Gradient total norm was 0.6561040282249451. Clipping to 0.25.
[2023-03-17 22:08:49,260] Step: 1209| lr: 0.7221 | Time: 14.00s |TRAIN loss  0.0133 | TRAIN Acc:  99.96% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:09:03,228] Gradient total norm was 0.8178127408027649. Clipping to 0.25.
[2023-03-17 22:09:03,231] Step: 1210| lr: 0.7219 | Time: 13.96s |TRAIN loss  0.0137 | TRAIN Acc:  99.94% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:09:17,228] Gradient total norm was 1.6426442861557007. Clipping to 0.25.
[2023-03-17 22:09:17,231] Step: 1211| lr: 0.7218 | Time: 13.99s |TRAIN loss  0.0237 | TRAIN Acc:  99.53% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:09:31,165] Gradient total norm was 0.8465160131454468. Clipping to 0.25.
[2023-03-17 22:09:31,169] Step: 1212| lr: 0.7216 | Time: 13.92s |TRAIN loss  0.0187 | TRAIN Acc:  99.87% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:09:45,155] Gradient total norm was 0.9688392877578735. Clipping to 0.25.
[2023-03-17 22:09:45,158] Step: 1213| lr: 0.7214 | Time: 13.98s |TRAIN loss  0.0211 | TRAIN Acc:  99.76% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:09:59,117] Gradient total norm was 0.5378832817077637. Clipping to 0.25.
[2023-03-17 22:09:59,121] Step: 1214| lr: 0.7212 | Time: 13.95s |TRAIN loss  0.0195 | TRAIN Acc:  99.93% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:10:13,041] Gradient total norm was 0.941928505897522. Clipping to 0.25.
[2023-03-17 22:10:13,044] Step: 1215| lr: 0.7210 | Time: 13.91s |TRAIN loss  0.0167 | TRAIN Acc:  99.93% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:10:26,961] Gradient total norm was 1.0729103088378906. Clipping to 0.25.
[2023-03-17 22:10:26,964] Step: 1216| lr: 0.7208 | Time: 13.91s |TRAIN loss  0.0195 | TRAIN Acc:  99.84% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:10:40,888] Gradient total norm was 0.8636671304702759. Clipping to 0.25.
[2023-03-17 22:10:40,891] Step: 1217| lr: 0.7206 | Time: 13.91s |TRAIN loss  0.0165 | TRAIN Acc:  99.89% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:10:54,819] Gradient total norm was 0.5860850811004639. Clipping to 0.25.
[2023-03-17 22:10:54,822] Step: 1218| lr: 0.7204 | Time: 13.92s |TRAIN loss  0.0177 | TRAIN Acc:  99.89% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:11:08,729] Gradient total norm was 0.646919846534729. Clipping to 0.25.
[2023-03-17 22:11:08,732] Step: 1219| lr: 0.7203 | Time: 13.90s |TRAIN loss  0.0173 | TRAIN Acc:  99.88% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:11:22,698] Gradient total norm was 0.5287231206893921. Clipping to 0.25.
[2023-03-17 22:11:22,701] Step: 1220| lr: 0.7201 | Time: 13.96s |TRAIN loss  0.0174 | TRAIN Acc:  99.86% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:11:36,665] Gradient total norm was 0.6360646486282349. Clipping to 0.25.
[2023-03-17 22:11:36,668] Step: 1221| lr: 0.7199 | Time: 13.95s |TRAIN loss  0.0196 | TRAIN Acc:  99.82% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:11:50,607] Gradient total norm was 0.6228638291358948. Clipping to 0.25.
[2023-03-17 22:11:50,610] Step: 1222| lr: 0.7197 | Time: 13.93s |TRAIN loss  0.0195 | TRAIN Acc:  99.87% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:12:04,598] Gradient total norm was 2.0110180377960205. Clipping to 0.25.
[2023-03-17 22:12:04,601] Step: 1223| lr: 0.7195 | Time: 13.98s |TRAIN loss  0.0218 | TRAIN Acc:  99.68% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:12:18,522] Gradient total norm was 1.9600201845169067. Clipping to 0.25.
[2023-03-17 22:12:18,525] Step: 1224| lr: 0.7193 | Time: 13.91s |TRAIN loss  0.0375 | TRAIN Acc:  99.09% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:12:32,489] Gradient total norm was 0.8865246176719666. Clipping to 0.25.
[2023-03-17 22:12:32,493] Step: 1225| lr: 0.7191 | Time: 13.95s |TRAIN loss  0.0306 | TRAIN Acc:  99.59% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:12:46,427] Gradient total norm was 0.7105676531791687. Clipping to 0.25.
[2023-03-17 22:12:46,430] Step: 1226| lr: 0.7189 | Time: 13.92s |TRAIN loss  0.0338 | TRAIN Acc:  99.63% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:13:00,380] Gradient total norm was 0.5940616726875305. Clipping to 0.25.
[2023-03-17 22:13:00,383] Step: 1227| lr: 0.7187 | Time: 13.94s |TRAIN loss  0.0272 | TRAIN Acc:  99.79% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:13:14,445] Gradient total norm was 0.8938968777656555. Clipping to 0.25.
[2023-03-17 22:13:14,448] Step: 1228| lr: 0.7185 | Time: 14.05s |TRAIN loss  0.0218 | TRAIN Acc:  99.91% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:13:28,393] Gradient total norm was 1.81831693649292. Clipping to 0.25.
[2023-03-17 22:13:28,396] Step: 1229| lr: 0.7184 | Time: 13.93s |TRAIN loss  0.0347 | TRAIN Acc:  99.34% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:13:42,350] Gradient total norm was 1.039156198501587. Clipping to 0.25.
[2023-03-17 22:13:42,354] Step: 1230| lr: 0.7182 | Time: 13.94s |TRAIN loss  0.0297 | TRAIN Acc:  99.67% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:13:56,265] Gradient total norm was 1.7181814908981323. Clipping to 0.25.
[2023-03-17 22:13:56,268] Step: 1231| lr: 0.7180 | Time: 13.90s |TRAIN loss  0.0280 | TRAIN Acc:  99.63% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:14:10,194] Gradient total norm was 1.6811699867248535. Clipping to 0.25.
[2023-03-17 22:14:10,197] Step: 1232| lr: 0.7178 | Time: 13.92s |TRAIN loss  0.0386 | TRAIN Acc:  99.22% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:14:24,187] Gradient total norm was 0.7401708364486694. Clipping to 0.25.
[2023-03-17 22:14:24,190] Step: 1233| lr: 0.7176 | Time: 13.98s |TRAIN loss  0.0341 | TRAIN Acc:  99.66% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:14:38,159] Gradient total norm was 0.7079101204872131. Clipping to 0.25.
[2023-03-17 22:14:38,163] Step: 1234| lr: 0.7174 | Time: 13.96s |TRAIN loss  0.0331 | TRAIN Acc:  99.75% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:14:52,214] Gradient total norm was 0.5902305245399475. Clipping to 0.25.
[2023-03-17 22:14:52,217] Step: 1235| lr: 0.7172 | Time: 14.04s |TRAIN loss  0.0298 | TRAIN Acc:  99.83% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:15:06,188] Gradient total norm was 0.6153988838195801. Clipping to 0.25.
[2023-03-17 22:15:06,191] Step: 1236| lr: 0.7170 | Time: 13.96s |TRAIN loss  0.0228 | TRAIN Acc:  99.93% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:15:20,143] Gradient total norm was 0.8346078991889954. Clipping to 0.25.
[2023-03-17 22:15:20,147] Step: 1237| lr: 0.7168 | Time: 13.94s |TRAIN loss  0.0223 | TRAIN Acc:  99.89% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:15:34,070] Gradient total norm was 0.9136989116668701. Clipping to 0.25.
[2023-03-17 22:15:34,074] Step: 1238| lr: 0.7166 | Time: 13.91s |TRAIN loss  0.0216 | TRAIN Acc:  99.73% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:15:48,009] Gradient total norm was 0.7136879563331604. Clipping to 0.25.
[2023-03-17 22:15:48,012] Step: 1239| lr: 0.7164 | Time: 13.93s |TRAIN loss  0.0217 | TRAIN Acc:  99.74% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:16:01,866] Gradient total norm was 0.5024026036262512. Clipping to 0.25.
[2023-03-17 22:16:01,870] Step: 1240| lr: 0.7163 | Time: 13.84s |TRAIN loss  0.0219 | TRAIN Acc:  99.67% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:16:15,822] Gradient total norm was 0.4518934488296509. Clipping to 0.25.
[2023-03-17 22:16:15,825] Step: 1241| lr: 0.7161 | Time: 13.94s |TRAIN loss  0.0180 | TRAIN Acc:  99.94% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:16:29,751] Gradient total norm was 0.5819617509841919. Clipping to 0.25.
[2023-03-17 22:16:29,754] Step: 1242| lr: 0.7159 | Time: 13.92s |TRAIN loss  0.0184 | TRAIN Acc:  99.90% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:16:43,781] Gradient total norm was 1.5052403211593628. Clipping to 0.25.
[2023-03-17 22:16:43,784] Step: 1243| lr: 0.7157 | Time: 14.02s |TRAIN loss  0.0199 | TRAIN Acc:  99.75% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:16:57,681] Gradient total norm was 0.7534457445144653. Clipping to 0.25.
[2023-03-17 22:16:57,685] Step: 1244| lr: 0.7155 | Time: 13.89s |TRAIN loss  0.0212 | TRAIN Acc:  99.75% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:17:11,669] Gradient total norm was 0.6069725155830383. Clipping to 0.25.
[2023-03-17 22:17:11,673] Step: 1245| lr: 0.7153 | Time: 13.97s |TRAIN loss  0.0206 | TRAIN Acc:  99.84% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:17:25,586] Gradient total norm was 0.5242342948913574. Clipping to 0.25.
[2023-03-17 22:17:25,589] Step: 1246| lr: 0.7151 | Time: 13.90s |TRAIN loss  0.0180 | TRAIN Acc:  99.91% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:17:39,539] Gradient total norm was 0.611864447593689. Clipping to 0.25.
[2023-03-17 22:17:39,542] Step: 1247| lr: 0.7149 | Time: 13.94s |TRAIN loss  0.0171 | TRAIN Acc:  99.94% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:17:53,505] Gradient total norm was 0.7188106179237366. Clipping to 0.25.
[2023-03-17 22:17:53,508] Step: 1248| lr: 0.7147 | Time: 13.95s |TRAIN loss  0.0141 | TRAIN Acc:  99.96% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:18:07,460] Gradient total norm was 0.6028943061828613. Clipping to 0.25.
[2023-03-17 22:18:07,463] Step: 1249| lr: 0.7145 | Time: 13.94s |TRAIN loss  0.0150 | TRAIN Acc:  99.94% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:18:21,443] Gradient total norm was 0.7190406918525696. Clipping to 0.25.
[2023-03-17 22:18:21,446] Step: 1250| lr: 0.7143 | Time: 13.97s |TRAIN loss  0.0143 | TRAIN Acc:  99.94% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:18:35,450] Gradient total norm was 1.125274419784546. Clipping to 0.25.
[2023-03-17 22:18:35,454] Step: 1251| lr: 0.7141 | Time: 13.99s |TRAIN loss  0.0153 | TRAIN Acc:  99.85% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:18:49,357] Gradient total norm was 1.8066834211349487. Clipping to 0.25.
[2023-03-17 22:18:49,360] Step: 1252| lr: 0.7139 | Time: 13.89s |TRAIN loss  0.0236 | TRAIN Acc:  99.54% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:19:03,353] Gradient total norm was 0.6573438048362732. Clipping to 0.25.
[2023-03-17 22:19:03,356] Step: 1253| lr: 0.7137 | Time: 13.98s |TRAIN loss  0.0197 | TRAIN Acc:  99.87% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:19:17,360] Gradient total norm was 1.0590170621871948. Clipping to 0.25.
[2023-03-17 22:19:17,363] Step: 1254| lr: 0.7135 | Time: 13.99s |TRAIN loss  0.0181 | TRAIN Acc:  99.91% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:19:31,249] Gradient total norm was 0.9148674607276917. Clipping to 0.25.
[2023-03-17 22:19:31,253] Step: 1255| lr: 0.7133 | Time: 13.88s |TRAIN loss  0.0211 | TRAIN Acc:  99.88% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:19:45,251] Gradient total norm was 1.2060234546661377. Clipping to 0.25.
[2023-03-17 22:19:45,255] Step: 1256| lr: 0.7132 | Time: 13.99s |TRAIN loss  0.0220 | TRAIN Acc:  99.80% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:19:59,170] Gradient total norm was 0.5435623526573181. Clipping to 0.25.
[2023-03-17 22:19:59,173] Step: 1257| lr: 0.7130 | Time: 13.90s |TRAIN loss  0.0217 | TRAIN Acc:  99.86% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:20:13,102] Gradient total norm was 0.6315702199935913. Clipping to 0.25.
[2023-03-17 22:20:13,105] Step: 1258| lr: 0.7128 | Time: 13.92s |TRAIN loss  0.0186 | TRAIN Acc:  99.91% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:20:27,038] Gradient total norm was 0.40779224038124084. Clipping to 0.25.
[2023-03-17 22:20:27,042] Step: 1259| lr: 0.7126 | Time: 13.92s |TRAIN loss  0.0191 | TRAIN Acc:  99.83% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:20:40,955] Gradient total norm was 0.565234899520874. Clipping to 0.25.
[2023-03-17 22:20:40,958] Step: 1260| lr: 0.7124 | Time: 13.90s |TRAIN loss  0.0172 | TRAIN Acc:  99.92% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:20:54,851] Gradient total norm was 0.4947296977043152. Clipping to 0.25.
[2023-03-17 22:20:54,854] Step: 1261| lr: 0.7122 | Time: 13.88s |TRAIN loss  0.0170 | TRAIN Acc:  99.93% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:21:08,778] Gradient total norm was 0.7084691524505615. Clipping to 0.25.
[2023-03-17 22:21:08,781] Step: 1262| lr: 0.7120 | Time: 13.91s |TRAIN loss  0.0149 | TRAIN Acc:  99.91% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:21:22,744] Gradient total norm was 0.838893711566925. Clipping to 0.25.
[2023-03-17 22:21:22,747] Step: 1263| lr: 0.7118 | Time: 13.95s |TRAIN loss  0.0197 | TRAIN Acc:  99.71% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:21:36,700] Gradient total norm was 0.607523500919342. Clipping to 0.25.
[2023-03-17 22:21:36,704] Step: 1264| lr: 0.7116 | Time: 13.94s |TRAIN loss  0.0176 | TRAIN Acc:  99.81% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:21:50,620] Gradient total norm was 0.6117066740989685. Clipping to 0.25.
[2023-03-17 22:21:50,623] Step: 1265| lr: 0.7114 | Time: 13.91s |TRAIN loss  0.0195 | TRAIN Acc:  99.78% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:22:04,576] Gradient total norm was 0.3515625298023224. Clipping to 0.25.
[2023-03-17 22:22:04,579] Step: 1266| lr: 0.7112 | Time: 13.94s |TRAIN loss  0.0158 | TRAIN Acc:  99.92% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:22:18,559] Gradient total norm was 0.4226963520050049. Clipping to 0.25.
[2023-03-17 22:22:18,563] Step: 1267| lr: 0.7110 | Time: 13.97s |TRAIN loss  0.0136 | TRAIN Acc:  99.93% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:22:32,583] Gradient total norm was 0.41051149368286133. Clipping to 0.25.
[2023-03-17 22:22:32,586] Step: 1268| lr: 0.7108 | Time: 14.01s |TRAIN loss  0.0124 | TRAIN Acc:  99.95% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:22:46,493] Gradient total norm was 0.685921311378479. Clipping to 0.25.
[2023-03-17 22:22:46,496] Step: 1269| lr: 0.7106 | Time: 13.90s |TRAIN loss  0.0116 | TRAIN Acc:  99.95% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:23:00,418] Gradient total norm was 2.247544527053833. Clipping to 0.25.
[2023-03-17 22:23:00,421] Step: 1270| lr: 0.7104 | Time: 13.91s |TRAIN loss  0.0281 | TRAIN Acc:  99.29% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:23:14,428] Gradient total norm was 0.6259603500366211. Clipping to 0.25.
[2023-03-17 22:23:14,432] Step: 1271| lr: 0.7102 | Time: 14.00s |TRAIN loss  0.0174 | TRAIN Acc:  99.90% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:23:28,386] Gradient total norm was 0.744581937789917. Clipping to 0.25.
[2023-03-17 22:23:28,390] Step: 1272| lr: 0.7100 | Time: 13.94s |TRAIN loss  0.0153 | TRAIN Acc:  99.87% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:23:42,363] Gradient total norm was 0.5433785915374756. Clipping to 0.25.
[2023-03-17 22:23:42,367] Step: 1273| lr: 0.7098 | Time: 13.96s |TRAIN loss  0.0158 | TRAIN Acc:  99.92% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:23:56,298] Gradient total norm was 0.5514217019081116. Clipping to 0.25.
[2023-03-17 22:23:56,302] Step: 1274| lr: 0.7096 | Time: 13.92s |TRAIN loss  0.0153 | TRAIN Acc:  99.91% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:24:10,257] Gradient total norm was 0.8501195311546326. Clipping to 0.25.
[2023-03-17 22:24:10,260] Step: 1275| lr: 0.7094 | Time: 13.94s |TRAIN loss  0.0157 | TRAIN Acc:  99.89% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:24:24,243] Gradient total norm was 1.612816333770752. Clipping to 0.25.
[2023-03-17 22:24:24,246] Step: 1276| lr: 0.7092 | Time: 13.97s |TRAIN loss  0.0256 | TRAIN Acc:  99.54% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:24:38,188] Gradient total norm was 0.6878728866577148. Clipping to 0.25.
[2023-03-17 22:24:38,191] Step: 1277| lr: 0.7090 | Time: 13.93s |TRAIN loss  0.0216 | TRAIN Acc:  99.79% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:24:52,110] Gradient total norm was 0.5679112672805786. Clipping to 0.25.
[2023-03-17 22:24:52,113] Step: 1278| lr: 0.7088 | Time: 13.91s |TRAIN loss  0.0192 | TRAIN Acc:  99.82% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:25:06,015] Gradient total norm was 0.5569944977760315. Clipping to 0.25.
[2023-03-17 22:25:06,018] Step: 1279| lr: 0.7086 | Time: 13.89s |TRAIN loss  0.0182 | TRAIN Acc:  99.90% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:25:20,035] Gradient total norm was 1.7401138544082642. Clipping to 0.25.
[2023-03-17 22:25:20,038] Step: 1280| lr: 0.7084 | Time: 14.01s |TRAIN loss  0.0239 | TRAIN Acc:  99.61% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:25:33,952] Gradient total norm was 1.4021412134170532. Clipping to 0.25.
[2023-03-17 22:25:33,955] Step: 1281| lr: 0.7082 | Time: 13.90s |TRAIN loss  0.0251 | TRAIN Acc:  99.49% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:25:48,002] Gradient total norm was 1.172203779220581. Clipping to 0.25.
[2023-03-17 22:25:48,005] Step: 1282| lr: 0.7080 | Time: 14.04s |TRAIN loss  0.0320 | TRAIN Acc:  99.27% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:26:01,884] Gradient total norm was 0.5309289693832397. Clipping to 0.25.
[2023-03-17 22:26:01,887] Step: 1283| lr: 0.7078 | Time: 13.87s |TRAIN loss  0.0310 | TRAIN Acc:  99.65% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:26:15,781] Gradient total norm was 0.4642680883407593. Clipping to 0.25.
[2023-03-17 22:26:15,785] Step: 1284| lr: 0.7076 | Time: 13.88s |TRAIN loss  0.0231 | TRAIN Acc:  99.73% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:26:29,844] Gradient total norm was 0.3884817361831665. Clipping to 0.25.
[2023-03-17 22:26:29,847] Step: 1285| lr: 0.7074 | Time: 14.05s |TRAIN loss  0.0214 | TRAIN Acc:  99.86% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:26:43,745] Gradient total norm was 0.4263659715652466. Clipping to 0.25.
[2023-03-17 22:26:43,749] Step: 1286| lr: 0.7072 | Time: 13.89s |TRAIN loss  0.0170 | TRAIN Acc:  99.91% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:26:57,714] Gradient total norm was 0.7771947979927063. Clipping to 0.25.
[2023-03-17 22:26:57,718] Step: 1287| lr: 0.7070 | Time: 13.96s |TRAIN loss  0.0162 | TRAIN Acc:  99.94% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:27:11,621] Gradient total norm was 1.5023332834243774. Clipping to 0.25.
[2023-03-17 22:27:11,624] Step: 1288| lr: 0.7068 | Time: 13.89s |TRAIN loss  0.0180 | TRAIN Acc:  99.83% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:27:25,525] Gradient total norm was 0.928530752658844. Clipping to 0.25.
[2023-03-17 22:27:25,529] Step: 1289| lr: 0.7066 | Time: 13.89s |TRAIN loss  0.0154 | TRAIN Acc:  99.91% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:27:39,487] Gradient total norm was 1.6805634498596191. Clipping to 0.25.
[2023-03-17 22:27:39,491] Step: 1290| lr: 0.7064 | Time: 13.95s |TRAIN loss  0.0199 | TRAIN Acc:  99.70% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:27:53,409] Gradient total norm was 0.9882358908653259. Clipping to 0.25.
[2023-03-17 22:27:53,413] Step: 1291| lr: 0.7062 | Time: 13.91s |TRAIN loss  0.0238 | TRAIN Acc:  99.67% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:28:07,431] Gradient total norm was 0.630005419254303. Clipping to 0.25.
[2023-03-17 22:28:07,434] Step: 1292| lr: 0.7060 | Time: 14.01s |TRAIN loss  0.0191 | TRAIN Acc:  99.93% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:28:21,353] Gradient total norm was 0.7961571216583252. Clipping to 0.25.
[2023-03-17 22:28:21,357] Step: 1293| lr: 0.7058 | Time: 13.91s |TRAIN loss  0.0226 | TRAIN Acc:  99.85% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:28:35,292] Gradient total norm was 0.8386228680610657. Clipping to 0.25.
[2023-03-17 22:28:35,295] Step: 1294| lr: 0.7056 | Time: 13.92s |TRAIN loss  0.0189 | TRAIN Acc:  99.91% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:28:49,407] Gradient total norm was 1.15091073513031. Clipping to 0.25.
[2023-03-17 22:28:49,410] Step: 1295| lr: 0.7054 | Time: 14.10s |TRAIN loss  0.0224 | TRAIN Acc:  99.86% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:29:03,280] Gradient total norm was 1.3044321537017822. Clipping to 0.25.
[2023-03-17 22:29:03,283] Step: 1296| lr: 0.7052 | Time: 13.86s |TRAIN loss  0.0257 | TRAIN Acc:  99.67% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:29:17,221] Gradient total norm was 0.6276274919509888. Clipping to 0.25.
[2023-03-17 22:29:17,224] Step: 1297| lr: 0.7050 | Time: 13.93s |TRAIN loss  0.0192 | TRAIN Acc:  99.92% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:29:31,175] Gradient total norm was 0.6881638765335083. Clipping to 0.25.
[2023-03-17 22:29:31,179] Step: 1298| lr: 0.7048 | Time: 13.94s |TRAIN loss  0.0214 | TRAIN Acc:  99.83% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:29:45,109] Gradient total norm was 0.5733761191368103. Clipping to 0.25.
[2023-03-17 22:29:45,112] Step: 1299| lr: 0.7046 | Time: 13.92s |TRAIN loss  0.0206 | TRAIN Acc:  99.91% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:29:59,104] Gradient total norm was 0.4683057963848114. Clipping to 0.25.
[2023-03-17 22:29:59,108] Step: 1300| lr: 0.7044 | Time: 13.98s |TRAIN loss  0.0163 | TRAIN Acc:  99.94% |VAL loss  0.3587 | VAL Acc:  88.74% |
[2023-03-17 22:30:13,000] Gradient total norm was 0.48960134387016296. Clipping to 0.25.
[2023-03-17 22:30:18,444] Step: 1301| lr: 0.7042 | Time: 13.88s |TRAIN loss  0.0164 | TRAIN Acc:  99.97% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:30:32,407] Gradient total norm was 0.7307512164115906. Clipping to 0.25.
[2023-03-17 22:30:32,410] Step: 1302| lr: 0.7040 | Time: 13.95s |TRAIN loss  0.0124 | TRAIN Acc:  99.96% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:30:46,337] Gradient total norm was 0.45444077253341675. Clipping to 0.25.
[2023-03-17 22:30:46,341] Step: 1303| lr: 0.7038 | Time: 13.92s |TRAIN loss  0.0138 | TRAIN Acc:  99.97% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:31:00,337] Gradient total norm was 0.9365603923797607. Clipping to 0.25.
[2023-03-17 22:31:00,340] Step: 1304| lr: 0.7035 | Time: 13.99s |TRAIN loss  0.0122 | TRAIN Acc:  99.91% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:31:14,245] Gradient total norm was 0.9691673517227173. Clipping to 0.25.
[2023-03-17 22:31:14,249] Step: 1305| lr: 0.7033 | Time: 13.90s |TRAIN loss  0.0143 | TRAIN Acc:  99.85% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:31:28,188] Gradient total norm was 0.608349621295929. Clipping to 0.25.
[2023-03-17 22:31:28,191] Step: 1306| lr: 0.7031 | Time: 13.93s |TRAIN loss  0.0149 | TRAIN Acc:  99.86% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:31:42,142] Gradient total norm was 0.5545802116394043. Clipping to 0.25.
[2023-03-17 22:31:42,146] Step: 1307| lr: 0.7029 | Time: 13.94s |TRAIN loss  0.0153 | TRAIN Acc:  99.89% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:31:59,951] Gradient total norm was 0.3768286108970642. Clipping to 0.25.
[2023-03-17 22:31:59,954] Step: 1308| lr: 0.7027 | Time: 17.79s |TRAIN loss  0.0144 | TRAIN Acc:  99.94% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:32:13,887] Gradient total norm was 0.32957983016967773. Clipping to 0.25.
[2023-03-17 22:32:13,890] Step: 1309| lr: 0.7025 | Time: 13.92s |TRAIN loss  0.0138 | TRAIN Acc:  99.95% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:32:27,827] Gradient total norm was 0.41867828369140625. Clipping to 0.25.
[2023-03-17 22:32:27,831] Step: 1310| lr: 0.7023 | Time: 13.93s |TRAIN loss  0.0111 | TRAIN Acc:  99.95% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:32:41,794] Gradient total norm was 0.3159894645214081. Clipping to 0.25.
[2023-03-17 22:32:41,798] Step: 1311| lr: 0.7021 | Time: 13.95s |TRAIN loss  0.0114 | TRAIN Acc:  99.97% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:32:55,735] Gradient total norm was 0.4086054563522339. Clipping to 0.25.
[2023-03-17 22:32:55,739] Step: 1312| lr: 0.7019 | Time: 13.93s |TRAIN loss  0.0092 | TRAIN Acc:  99.96% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:33:09,695] Gradient total norm was 0.40646135807037354. Clipping to 0.25.
[2023-03-17 22:33:09,698] Step: 1313| lr: 0.7017 | Time: 13.95s |TRAIN loss  0.0090 | TRAIN Acc:  99.97% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:33:23,684] Gradient total norm was 1.3187464475631714. Clipping to 0.25.
[2023-03-17 22:33:23,687] Step: 1314| lr: 0.7015 | Time: 13.98s |TRAIN loss  0.0123 | TRAIN Acc:  99.82% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:33:37,647] Gradient total norm was 0.6495062112808228. Clipping to 0.25.
[2023-03-17 22:33:37,650] Step: 1315| lr: 0.7013 | Time: 13.95s |TRAIN loss  0.0140 | TRAIN Acc:  99.75% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:33:51,616] Gradient total norm was 0.6618248224258423. Clipping to 0.25.
[2023-03-17 22:33:51,620] Step: 1316| lr: 0.7011 | Time: 13.96s |TRAIN loss  0.0141 | TRAIN Acc:  99.88% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:34:05,546] Gradient total norm was 0.6595882773399353. Clipping to 0.25.
[2023-03-17 22:34:05,550] Step: 1317| lr: 0.7009 | Time: 13.92s |TRAIN loss  0.0167 | TRAIN Acc:  99.68% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:34:19,436] Gradient total norm was 0.3980020582675934. Clipping to 0.25.
[2023-03-17 22:34:19,439] Step: 1318| lr: 0.7007 | Time: 13.88s |TRAIN loss  0.0137 | TRAIN Acc:  99.96% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:34:33,381] Gradient total norm was 0.607816219329834. Clipping to 0.25.
[2023-03-17 22:34:33,385] Step: 1319| lr: 0.7005 | Time: 13.93s |TRAIN loss  0.0131 | TRAIN Acc:  99.94% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:34:47,310] Gradient total norm was 1.0818716287612915. Clipping to 0.25.
[2023-03-17 22:34:47,313] Step: 1320| lr: 0.7003 | Time: 13.91s |TRAIN loss  0.0138 | TRAIN Acc:  99.89% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:35:01,304] Gradient total norm was 1.4703446626663208. Clipping to 0.25.
[2023-03-17 22:35:01,307] Step: 1321| lr: 0.7000 | Time: 13.98s |TRAIN loss  0.0241 | TRAIN Acc:  99.47% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:35:15,204] Gradient total norm was 0.48127758502960205. Clipping to 0.25.
[2023-03-17 22:35:15,207] Step: 1322| lr: 0.6998 | Time: 13.89s |TRAIN loss  0.0170 | TRAIN Acc:  99.92% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:35:29,102] Gradient total norm was 0.47604626417160034. Clipping to 0.25.
[2023-03-17 22:35:29,105] Step: 1323| lr: 0.6996 | Time: 13.88s |TRAIN loss  0.0154 | TRAIN Acc:  99.90% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:35:43,104] Gradient total norm was 0.5525315403938293. Clipping to 0.25.
[2023-03-17 22:35:43,108] Step: 1324| lr: 0.6994 | Time: 13.99s |TRAIN loss  0.0148 | TRAIN Acc:  99.94% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:35:57,026] Gradient total norm was 0.5279661417007446. Clipping to 0.25.
[2023-03-17 22:35:57,030] Step: 1325| lr: 0.6992 | Time: 13.91s |TRAIN loss  0.0144 | TRAIN Acc:  99.93% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:36:10,998] Gradient total norm was 0.863179087638855. Clipping to 0.25.
[2023-03-17 22:36:11,001] Step: 1326| lr: 0.6990 | Time: 13.96s |TRAIN loss  0.0134 | TRAIN Acc:  99.93% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:36:24,989] Gradient total norm was 0.788289487361908. Clipping to 0.25.
[2023-03-17 22:36:24,992] Step: 1327| lr: 0.6988 | Time: 13.98s |TRAIN loss  0.0145 | TRAIN Acc:  99.91% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:36:38,912] Gradient total norm was 0.6166830062866211. Clipping to 0.25.
[2023-03-17 22:36:38,916] Step: 1328| lr: 0.6986 | Time: 13.91s |TRAIN loss  0.0152 | TRAIN Acc:  99.86% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:36:52,904] Gradient total norm was 0.6977858543395996. Clipping to 0.25.
[2023-03-17 22:36:52,908] Step: 1329| lr: 0.6984 | Time: 13.98s |TRAIN loss  0.0138 | TRAIN Acc:  99.94% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:37:06,843] Gradient total norm was 0.7256560325622559. Clipping to 0.25.
[2023-03-17 22:37:06,846] Step: 1330| lr: 0.6982 | Time: 13.92s |TRAIN loss  0.0170 | TRAIN Acc:  99.89% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:37:20,779] Gradient total norm was 1.2634789943695068. Clipping to 0.25.
[2023-03-17 22:37:20,782] Step: 1331| lr: 0.6980 | Time: 13.92s |TRAIN loss  0.0176 | TRAIN Acc:  99.81% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:37:34,772] Gradient total norm was 0.592799961566925. Clipping to 0.25.
[2023-03-17 22:37:34,776] Step: 1332| lr: 0.6977 | Time: 13.98s |TRAIN loss  0.0161 | TRAIN Acc:  99.93% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:37:48,672] Gradient total norm was 0.5703810453414917. Clipping to 0.25.
[2023-03-17 22:37:48,676] Step: 1333| lr: 0.6975 | Time: 13.89s |TRAIN loss  0.0156 | TRAIN Acc:  99.94% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:38:02,724] Gradient total norm was 0.5597116351127625. Clipping to 0.25.
[2023-03-17 22:38:02,727] Step: 1334| lr: 0.6973 | Time: 14.04s |TRAIN loss  0.0151 | TRAIN Acc:  99.90% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:38:16,668] Gradient total norm was 0.5233199000358582. Clipping to 0.25.
[2023-03-17 22:38:16,671] Step: 1335| lr: 0.6971 | Time: 13.93s |TRAIN loss  0.0152 | TRAIN Acc:  99.93% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:38:30,689] Gradient total norm was 0.4195433259010315. Clipping to 0.25.
[2023-03-17 22:38:30,693] Step: 1336| lr: 0.6969 | Time: 14.01s |TRAIN loss  0.0134 | TRAIN Acc:  99.95% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:38:44,696] Gradient total norm was 0.46688687801361084. Clipping to 0.25.
[2023-03-17 22:38:44,699] Step: 1337| lr: 0.6967 | Time: 13.99s |TRAIN loss  0.0112 | TRAIN Acc:  99.97% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:38:58,641] Gradient total norm was 0.7446836829185486. Clipping to 0.25.
[2023-03-17 22:38:58,644] Step: 1338| lr: 0.6965 | Time: 13.93s |TRAIN loss  0.0112 | TRAIN Acc:  99.95% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:39:12,620] Gradient total norm was 1.01694917678833. Clipping to 0.25.
[2023-03-17 22:39:12,623] Step: 1339| lr: 0.6963 | Time: 13.97s |TRAIN loss  0.0130 | TRAIN Acc:  99.89% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:39:26,570] Gradient total norm was 0.7345778346061707. Clipping to 0.25.
[2023-03-17 22:39:26,573] Step: 1340| lr: 0.6961 | Time: 13.93s |TRAIN loss  0.0111 | TRAIN Acc:  99.92% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:39:40,473] Gradient total norm was 0.7500984072685242. Clipping to 0.25.
[2023-03-17 22:39:40,476] Step: 1341| lr: 0.6959 | Time: 13.89s |TRAIN loss  0.0150 | TRAIN Acc:  99.83% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:39:54,454] Gradient total norm was 0.5273573398590088. Clipping to 0.25.
[2023-03-17 22:39:54,458] Step: 1342| lr: 0.6956 | Time: 13.97s |TRAIN loss  0.0126 | TRAIN Acc:  99.93% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:40:08,387] Gradient total norm was 0.49135321378707886. Clipping to 0.25.
[2023-03-17 22:40:08,390] Step: 1343| lr: 0.6954 | Time: 13.92s |TRAIN loss  0.0129 | TRAIN Acc:  99.94% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:40:22,307] Gradient total norm was 0.5748351216316223. Clipping to 0.25.
[2023-03-17 22:40:22,310] Step: 1344| lr: 0.6952 | Time: 13.91s |TRAIN loss  0.0120 | TRAIN Acc:  99.92% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:40:36,186] Gradient total norm was 1.13590407371521. Clipping to 0.25.
[2023-03-17 22:40:36,190] Step: 1345| lr: 0.6950 | Time: 13.87s |TRAIN loss  0.0144 | TRAIN Acc:  99.85% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:40:50,121] Gradient total norm was 1.0692167282104492. Clipping to 0.25.
[2023-03-17 22:40:50,124] Step: 1346| lr: 0.6948 | Time: 13.92s |TRAIN loss  0.0264 | TRAIN Acc:  99.49% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:41:04,116] Gradient total norm was 0.6751211881637573. Clipping to 0.25.
[2023-03-17 22:41:04,119] Step: 1347| lr: 0.6946 | Time: 13.98s |TRAIN loss  0.0171 | TRAIN Acc:  99.84% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:41:18,123] Gradient total norm was 1.6229054927825928. Clipping to 0.25.
[2023-03-17 22:41:18,126] Step: 1348| lr: 0.6944 | Time: 13.99s |TRAIN loss  0.0252 | TRAIN Acc:  99.51% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:41:32,033] Gradient total norm was 1.919684886932373. Clipping to 0.25.
[2023-03-17 22:41:32,036] Step: 1349| lr: 0.6942 | Time: 13.90s |TRAIN loss  0.0332 | TRAIN Acc:  99.44% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:41:45,948] Gradient total norm was 1.391802191734314. Clipping to 0.25.
[2023-03-17 22:41:45,952] Step: 1350| lr: 0.6939 | Time: 13.90s |TRAIN loss  0.0353 | TRAIN Acc:  99.48% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:41:59,937] Gradient total norm was 1.6973563432693481. Clipping to 0.25.
[2023-03-17 22:41:59,940] Step: 1351| lr: 0.6937 | Time: 13.98s |TRAIN loss  0.0411 | TRAIN Acc:  99.42% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:42:13,875] Gradient total norm was 0.7764772772789001. Clipping to 0.25.
[2023-03-17 22:42:13,879] Step: 1352| lr: 0.6935 | Time: 13.92s |TRAIN loss  0.0396 | TRAIN Acc:  99.58% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:42:27,762] Gradient total norm was 0.8904141783714294. Clipping to 0.25.
[2023-03-17 22:42:27,765] Step: 1353| lr: 0.6933 | Time: 13.87s |TRAIN loss  0.0317 | TRAIN Acc:  99.74% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:42:41,726] Gradient total norm was 0.9437427520751953. Clipping to 0.25.
[2023-03-17 22:42:41,729] Step: 1354| lr: 0.6931 | Time: 13.95s |TRAIN loss  0.0314 | TRAIN Acc:  99.73% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:42:55,680] Gradient total norm was 0.6938685178756714. Clipping to 0.25.
[2023-03-17 22:42:55,684] Step: 1355| lr: 0.6929 | Time: 13.94s |TRAIN loss  0.0278 | TRAIN Acc:  99.73% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:43:09,680] Gradient total norm was 1.6846823692321777. Clipping to 0.25.
[2023-03-17 22:43:09,684] Step: 1356| lr: 0.6927 | Time: 13.99s |TRAIN loss  0.0314 | TRAIN Acc:  99.48% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:43:23,652] Gradient total norm was 1.2534421682357788. Clipping to 0.25.
[2023-03-17 22:43:23,655] Step: 1357| lr: 0.6924 | Time: 13.96s |TRAIN loss  0.0387 | TRAIN Acc:  99.25% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:43:37,649] Gradient total norm was 0.6298666596412659. Clipping to 0.25.
[2023-03-17 22:43:37,653] Step: 1358| lr: 0.6922 | Time: 13.98s |TRAIN loss  0.0332 | TRAIN Acc:  99.62% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:43:51,576] Gradient total norm was 0.3749729096889496. Clipping to 0.25.
[2023-03-17 22:43:51,579] Step: 1359| lr: 0.6920 | Time: 13.91s |TRAIN loss  0.0286 | TRAIN Acc:  99.78% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:44:05,543] Gradient total norm was 0.4487242102622986. Clipping to 0.25.
[2023-03-17 22:44:05,547] Step: 1360| lr: 0.6918 | Time: 13.95s |TRAIN loss  0.0281 | TRAIN Acc:  99.70% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:44:19,531] Gradient total norm was 0.370951771736145. Clipping to 0.25.
[2023-03-17 22:44:19,535] Step: 1361| lr: 0.6916 | Time: 13.97s |TRAIN loss  0.0220 | TRAIN Acc:  99.82% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:44:33,507] Gradient total norm was 0.34436026215553284. Clipping to 0.25.
[2023-03-17 22:44:33,511] Step: 1362| lr: 0.6914 | Time: 13.96s |TRAIN loss  0.0182 | TRAIN Acc:  99.91% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:44:47,499] Gradient total norm was 0.42426323890686035. Clipping to 0.25.
[2023-03-17 22:44:47,502] Step: 1363| lr: 0.6912 | Time: 13.98s |TRAIN loss  0.0156 | TRAIN Acc:  99.94% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:45:01,522] Gradient total norm was 0.7129783034324646. Clipping to 0.25.
[2023-03-17 22:45:01,525] Step: 1364| lr: 0.6909 | Time: 14.01s |TRAIN loss  0.0132 | TRAIN Acc:  99.96% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:45:15,416] Gradient total norm was 0.7490009665489197. Clipping to 0.25.
[2023-03-17 22:45:15,419] Step: 1365| lr: 0.6907 | Time: 13.88s |TRAIN loss  0.0134 | TRAIN Acc:  99.92% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:45:29,470] Gradient total norm was 0.8328975439071655. Clipping to 0.25.
[2023-03-17 22:45:29,473] Step: 1366| lr: 0.6905 | Time: 14.04s |TRAIN loss  0.0141 | TRAIN Acc:  99.89% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:45:43,344] Gradient total norm was 0.5078539252281189. Clipping to 0.25.
[2023-03-17 22:45:43,348] Step: 1367| lr: 0.6903 | Time: 13.86s |TRAIN loss  0.0114 | TRAIN Acc:  99.96% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:45:57,264] Gradient total norm was 0.5493878126144409. Clipping to 0.25.
[2023-03-17 22:45:57,267] Step: 1368| lr: 0.6901 | Time: 13.91s |TRAIN loss  0.0115 | TRAIN Acc:  99.96% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:46:11,131] Gradient total norm was 0.5546656847000122. Clipping to 0.25.
[2023-03-17 22:46:11,134] Step: 1369| lr: 0.6899 | Time: 13.85s |TRAIN loss  0.0110 | TRAIN Acc:  99.95% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:46:25,193] Gradient total norm was 0.6982512474060059. Clipping to 0.25.
[2023-03-17 22:46:25,196] Step: 1370| lr: 0.6896 | Time: 14.05s |TRAIN loss  0.0117 | TRAIN Acc:  99.93% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:46:39,142] Gradient total norm was 1.3551154136657715. Clipping to 0.25.
[2023-03-17 22:46:39,146] Step: 1371| lr: 0.6894 | Time: 13.94s |TRAIN loss  0.0155 | TRAIN Acc:  99.77% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:46:53,154] Gradient total norm was 1.1738516092300415. Clipping to 0.25.
[2023-03-17 22:46:53,157] Step: 1372| lr: 0.6892 | Time: 14.00s |TRAIN loss  0.0234 | TRAIN Acc:  99.54% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:47:07,108] Gradient total norm was 0.6137022376060486. Clipping to 0.25.
[2023-03-17 22:47:07,112] Step: 1373| lr: 0.6890 | Time: 13.94s |TRAIN loss  0.0182 | TRAIN Acc:  99.83% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:47:21,057] Gradient total norm was 0.48334380984306335. Clipping to 0.25.
[2023-03-17 22:47:21,060] Step: 1374| lr: 0.6888 | Time: 13.94s |TRAIN loss  0.0223 | TRAIN Acc:  99.83% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:47:34,975] Gradient total norm was 0.5005844831466675. Clipping to 0.25.
[2023-03-17 22:47:34,978] Step: 1375| lr: 0.6886 | Time: 13.90s |TRAIN loss  0.0170 | TRAIN Acc:  99.89% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:47:48,906] Gradient total norm was 0.6221328973770142. Clipping to 0.25.
[2023-03-17 22:47:48,910] Step: 1376| lr: 0.6883 | Time: 13.92s |TRAIN loss  0.0196 | TRAIN Acc:  99.89% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:48:02,848] Gradient total norm was 0.5752973556518555. Clipping to 0.25.
[2023-03-17 22:48:02,851] Step: 1377| lr: 0.6881 | Time: 13.93s |TRAIN loss  0.0153 | TRAIN Acc:  99.93% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:48:16,843] Gradient total norm was 0.9491285085678101. Clipping to 0.25.
[2023-03-17 22:48:16,846] Step: 1378| lr: 0.6879 | Time: 13.98s |TRAIN loss  0.0158 | TRAIN Acc:  99.90% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:48:30,806] Gradient total norm was 2.6043996810913086. Clipping to 0.25.
[2023-03-17 22:48:30,809] Step: 1379| lr: 0.6877 | Time: 13.95s |TRAIN loss  0.0307 | TRAIN Acc:  99.23% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:48:44,794] Gradient total norm was 0.551637589931488. Clipping to 0.25.
[2023-03-17 22:48:44,797] Step: 1380| lr: 0.6875 | Time: 13.98s |TRAIN loss  0.0199 | TRAIN Acc:  99.80% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:48:58,749] Gradient total norm was 0.45393049716949463. Clipping to 0.25.
[2023-03-17 22:48:58,752] Step: 1381| lr: 0.6873 | Time: 13.94s |TRAIN loss  0.0141 | TRAIN Acc:  99.92% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:49:12,676] Gradient total norm was 0.44809791445732117. Clipping to 0.25.
[2023-03-17 22:49:12,680] Step: 1382| lr: 0.6870 | Time: 13.91s |TRAIN loss  0.0144 | TRAIN Acc:  99.92% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:49:26,661] Gradient total norm was 0.4100419580936432. Clipping to 0.25.
[2023-03-17 22:49:26,664] Step: 1383| lr: 0.6868 | Time: 13.97s |TRAIN loss  0.0119 | TRAIN Acc:  99.94% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:49:40,549] Gradient total norm was 0.5950520634651184. Clipping to 0.25.
[2023-03-17 22:49:40,552] Step: 1384| lr: 0.6866 | Time: 13.88s |TRAIN loss  0.0114 | TRAIN Acc:  99.95% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:49:54,501] Gradient total norm was 0.6427915096282959. Clipping to 0.25.
[2023-03-17 22:49:54,504] Step: 1385| lr: 0.6864 | Time: 13.94s |TRAIN loss  0.0127 | TRAIN Acc:  99.92% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:50:08,515] Gradient total norm was 0.7564615607261658. Clipping to 0.25.
[2023-03-17 22:50:08,518] Step: 1386| lr: 0.6862 | Time: 14.00s |TRAIN loss  0.0126 | TRAIN Acc:  99.91% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:50:22,453] Gradient total norm was 0.7447810769081116. Clipping to 0.25.
[2023-03-17 22:50:22,456] Step: 1387| lr: 0.6859 | Time: 13.92s |TRAIN loss  0.0177 | TRAIN Acc:  99.74% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:50:36,413] Gradient total norm was 0.3774891793727875. Clipping to 0.25.
[2023-03-17 22:50:36,417] Step: 1388| lr: 0.6857 | Time: 13.95s |TRAIN loss  0.0126 | TRAIN Acc:  99.96% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:50:50,397] Gradient total norm was 0.8291317820549011. Clipping to 0.25.
[2023-03-17 22:50:50,401] Step: 1389| lr: 0.6855 | Time: 13.97s |TRAIN loss  0.0127 | TRAIN Acc:  99.94% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:51:04,302] Gradient total norm was 0.6098490357398987. Clipping to 0.25.
[2023-03-17 22:51:04,306] Step: 1390| lr: 0.6853 | Time: 13.89s |TRAIN loss  0.0140 | TRAIN Acc:  99.93% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:51:18,247] Gradient total norm was 0.6782698631286621. Clipping to 0.25.
[2023-03-17 22:51:18,250] Step: 1391| lr: 0.6851 | Time: 13.93s |TRAIN loss  0.0141 | TRAIN Acc:  99.84% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:51:32,222] Gradient total norm was 0.7093003988265991. Clipping to 0.25.
[2023-03-17 22:51:32,225] Step: 1392| lr: 0.6848 | Time: 13.96s |TRAIN loss  0.0176 | TRAIN Acc:  99.80% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:51:46,205] Gradient total norm was 0.4151657223701477. Clipping to 0.25.
[2023-03-17 22:51:46,208] Step: 1393| lr: 0.6846 | Time: 13.97s |TRAIN loss  0.0161 | TRAIN Acc:  99.75% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:52:00,253] Gradient total norm was 0.49781855940818787. Clipping to 0.25.
[2023-03-17 22:52:00,256] Step: 1394| lr: 0.6844 | Time: 14.03s |TRAIN loss  0.0135 | TRAIN Acc:  99.94% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:52:14,234] Gradient total norm was 0.4966470003128052. Clipping to 0.25.
[2023-03-17 22:52:14,237] Step: 1395| lr: 0.6842 | Time: 13.97s |TRAIN loss  0.0160 | TRAIN Acc:  99.84% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:52:28,175] Gradient total norm was 0.4031115472316742. Clipping to 0.25.
[2023-03-17 22:52:28,178] Step: 1396| lr: 0.6840 | Time: 13.93s |TRAIN loss  0.0119 | TRAIN Acc:  99.93% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:52:42,105] Gradient total norm was 0.4214644134044647. Clipping to 0.25.
[2023-03-17 22:52:42,108] Step: 1397| lr: 0.6837 | Time: 13.92s |TRAIN loss  0.0117 | TRAIN Acc:  99.94% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:52:56,091] Gradient total norm was 0.9802818298339844. Clipping to 0.25.
[2023-03-17 22:52:56,095] Step: 1398| lr: 0.6835 | Time: 13.97s |TRAIN loss  0.0122 | TRAIN Acc:  99.89% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:53:10,027] Gradient total norm was 1.1893136501312256. Clipping to 0.25.
[2023-03-17 22:53:10,031] Step: 1399| lr: 0.6833 | Time: 13.92s |TRAIN loss  0.0158 | TRAIN Acc:  99.74% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:53:24,036] Gradient total norm was 0.8320162892341614. Clipping to 0.25.
[2023-03-17 22:53:24,039] Step: 1400| lr: 0.6831 | Time: 14.00s |TRAIN loss  0.0174 | TRAIN Acc:  99.80% |VAL loss  0.3962 | VAL Acc:  88.16% |
[2023-03-17 22:53:37,975] Gradient total norm was 0.6339425444602966. Clipping to 0.25.
[2023-03-17 22:53:43,410] Step: 1401| lr: 0.6828 | Time: 13.93s |TRAIN loss  0.0161 | TRAIN Acc:  99.89% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:53:57,295] Gradient total norm was 0.8506956100463867. Clipping to 0.25.
[2023-03-17 22:53:57,298] Step: 1402| lr: 0.6826 | Time: 13.87s |TRAIN loss  0.0162 | TRAIN Acc:  99.87% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:54:11,188] Gradient total norm was 1.6900655031204224. Clipping to 0.25.
[2023-03-17 22:54:11,192] Step: 1403| lr: 0.6824 | Time: 13.88s |TRAIN loss  0.0295 | TRAIN Acc:  99.31% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:54:25,162] Gradient total norm was 0.4703114330768585. Clipping to 0.25.
[2023-03-17 22:54:25,165] Step: 1404| lr: 0.6822 | Time: 13.96s |TRAIN loss  0.0204 | TRAIN Acc:  99.88% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:54:39,061] Gradient total norm was 0.47783443331718445. Clipping to 0.25.
[2023-03-17 22:54:39,064] Step: 1405| lr: 0.6820 | Time: 13.89s |TRAIN loss  0.0175 | TRAIN Acc:  99.86% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:54:52,950] Gradient total norm was 0.4316372871398926. Clipping to 0.25.
[2023-03-17 22:54:52,953] Step: 1406| lr: 0.6817 | Time: 13.88s |TRAIN loss  0.0158 | TRAIN Acc:  99.93% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:55:06,894] Gradient total norm was 0.3735772371292114. Clipping to 0.25.
[2023-03-17 22:55:06,897] Step: 1407| lr: 0.6815 | Time: 13.93s |TRAIN loss  0.0134 | TRAIN Acc:  99.94% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:55:20,736] Gradient total norm was 0.5577089786529541. Clipping to 0.25.
[2023-03-17 22:55:20,740] Step: 1408| lr: 0.6813 | Time: 13.83s |TRAIN loss  0.0127 | TRAIN Acc:  99.94% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:55:34,693] Gradient total norm was 0.8554791212081909. Clipping to 0.25.
[2023-03-17 22:55:34,696] Step: 1409| lr: 0.6811 | Time: 13.94s |TRAIN loss  0.0132 | TRAIN Acc:  99.91% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:55:48,609] Gradient total norm was 0.8973091244697571. Clipping to 0.25.
[2023-03-17 22:55:48,613] Step: 1410| lr: 0.6808 | Time: 13.90s |TRAIN loss  0.0137 | TRAIN Acc:  99.89% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:56:02,449] Gradient total norm was 0.5966024398803711. Clipping to 0.25.
[2023-03-17 22:56:02,453] Step: 1411| lr: 0.6806 | Time: 13.83s |TRAIN loss  0.0126 | TRAIN Acc:  99.93% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:56:16,451] Gradient total norm was 0.6185548305511475. Clipping to 0.25.
[2023-03-17 22:56:16,454] Step: 1412| lr: 0.6804 | Time: 13.99s |TRAIN loss  0.0127 | TRAIN Acc:  99.91% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:56:30,417] Gradient total norm was 0.4447154104709625. Clipping to 0.25.
[2023-03-17 22:56:30,421] Step: 1413| lr: 0.6802 | Time: 13.95s |TRAIN loss  0.0112 | TRAIN Acc:  99.96% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:56:44,326] Gradient total norm was 0.511418879032135. Clipping to 0.25.
[2023-03-17 22:56:44,330] Step: 1414| lr: 0.6799 | Time: 13.90s |TRAIN loss  0.0105 | TRAIN Acc:  99.97% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:56:58,294] Gradient total norm was 1.1507529020309448. Clipping to 0.25.
[2023-03-17 22:56:58,297] Step: 1415| lr: 0.6797 | Time: 13.95s |TRAIN loss  0.0128 | TRAIN Acc:  99.87% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:57:12,192] Gradient total norm was 1.0835886001586914. Clipping to 0.25.
[2023-03-17 22:57:12,195] Step: 1416| lr: 0.6795 | Time: 13.88s |TRAIN loss  0.0166 | TRAIN Acc:  99.74% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:57:26,145] Gradient total norm was 0.5627805590629578. Clipping to 0.25.
[2023-03-17 22:57:26,149] Step: 1417| lr: 0.6793 | Time: 13.94s |TRAIN loss  0.0158 | TRAIN Acc:  99.87% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:57:40,120] Gradient total norm was 0.5777941942214966. Clipping to 0.25.
[2023-03-17 22:57:40,123] Step: 1418| lr: 0.6790 | Time: 13.96s |TRAIN loss  0.0142 | TRAIN Acc:  99.92% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:57:54,067] Gradient total norm was 0.6064116358757019. Clipping to 0.25.
[2023-03-17 22:57:54,070] Step: 1419| lr: 0.6788 | Time: 13.93s |TRAIN loss  0.0141 | TRAIN Acc:  99.96% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:58:08,124] Gradient total norm was 0.7280910611152649. Clipping to 0.25.
[2023-03-17 22:58:08,127] Step: 1420| lr: 0.6786 | Time: 14.04s |TRAIN loss  0.0141 | TRAIN Acc:  99.92% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:58:22,033] Gradient total norm was 0.648997962474823. Clipping to 0.25.
[2023-03-17 22:58:22,036] Step: 1421| lr: 0.6784 | Time: 13.90s |TRAIN loss  0.0134 | TRAIN Acc:  99.95% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:58:35,960] Gradient total norm was 0.7026269435882568. Clipping to 0.25.
[2023-03-17 22:58:35,963] Step: 1422| lr: 0.6781 | Time: 13.91s |TRAIN loss  0.0138 | TRAIN Acc:  99.93% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:58:49,960] Gradient total norm was 0.9889965057373047. Clipping to 0.25.
[2023-03-17 22:58:49,964] Step: 1423| lr: 0.6779 | Time: 13.99s |TRAIN loss  0.0173 | TRAIN Acc:  99.83% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:59:03,938] Gradient total norm was 0.723065197467804. Clipping to 0.25.
[2023-03-17 22:59:03,942] Step: 1424| lr: 0.6777 | Time: 13.96s |TRAIN loss  0.0166 | TRAIN Acc:  99.92% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:59:17,945] Gradient total norm was 0.6966671943664551. Clipping to 0.25.
[2023-03-17 22:59:17,949] Step: 1425| lr: 0.6775 | Time: 13.99s |TRAIN loss  0.0162 | TRAIN Acc:  99.92% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:59:31,832] Gradient total norm was 0.9535265564918518. Clipping to 0.25.
[2023-03-17 22:59:31,835] Step: 1426| lr: 0.6772 | Time: 13.87s |TRAIN loss  0.0166 | TRAIN Acc:  99.88% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:59:45,805] Gradient total norm was 0.765933096408844. Clipping to 0.25.
[2023-03-17 22:59:45,808] Step: 1427| lr: 0.6770 | Time: 13.96s |TRAIN loss  0.0151 | TRAIN Acc:  99.92% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 22:59:59,762] Gradient total norm was 0.9924678802490234. Clipping to 0.25.
[2023-03-17 22:59:59,766] Step: 1428| lr: 0.6768 | Time: 13.94s |TRAIN loss  0.0200 | TRAIN Acc:  99.76% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:00:13,718] Gradient total norm was 0.43683457374572754. Clipping to 0.25.
[2023-03-17 23:00:13,722] Step: 1429| lr: 0.6766 | Time: 13.94s |TRAIN loss  0.0170 | TRAIN Acc:  99.91% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:00:27,687] Gradient total norm was 0.4915507733821869. Clipping to 0.25.
[2023-03-17 23:00:27,690] Step: 1430| lr: 0.6763 | Time: 13.96s |TRAIN loss  0.0168 | TRAIN Acc:  99.88% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:00:41,650] Gradient total norm was 0.5146497488021851. Clipping to 0.25.
[2023-03-17 23:00:41,654] Step: 1431| lr: 0.6761 | Time: 13.95s |TRAIN loss  0.0156 | TRAIN Acc:  99.92% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:00:55,591] Gradient total norm was 0.6496292352676392. Clipping to 0.25.
[2023-03-17 23:00:55,594] Step: 1432| lr: 0.6759 | Time: 13.93s |TRAIN loss  0.0171 | TRAIN Acc:  99.82% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:01:09,492] Gradient total norm was 0.5473551154136658. Clipping to 0.25.
[2023-03-17 23:01:09,496] Step: 1433| lr: 0.6756 | Time: 13.89s |TRAIN loss  0.0176 | TRAIN Acc:  99.79% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:01:23,437] Gradient total norm was 0.4135879576206207. Clipping to 0.25.
[2023-03-17 23:01:23,440] Step: 1434| lr: 0.6754 | Time: 13.93s |TRAIN loss  0.0191 | TRAIN Acc:  99.90% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:01:37,462] Gradient total norm was 0.5491559505462646. Clipping to 0.25.
[2023-03-17 23:01:37,466] Step: 1435| lr: 0.6752 | Time: 14.01s |TRAIN loss  0.0164 | TRAIN Acc:  99.81% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:01:51,462] Gradient total norm was 0.29987117648124695. Clipping to 0.25.
[2023-03-17 23:01:51,465] Step: 1436| lr: 0.6750 | Time: 13.99s |TRAIN loss  0.0152 | TRAIN Acc:  99.97% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:02:05,399] Gradient total norm was 0.4347202777862549. Clipping to 0.25.
[2023-03-17 23:02:05,402] Step: 1437| lr: 0.6747 | Time: 13.92s |TRAIN loss  0.0101 | TRAIN Acc:  99.97% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:02:19,324] Gradient total norm was 0.42593470215797424. Clipping to 0.25.
[2023-03-17 23:02:19,328] Step: 1438| lr: 0.6745 | Time: 13.91s |TRAIN loss  0.0115 | TRAIN Acc:  99.97% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:02:33,329] Gradient total norm was 0.4904993176460266. Clipping to 0.25.
[2023-03-17 23:02:33,333] Step: 1439| lr: 0.6743 | Time: 13.99s |TRAIN loss  0.0083 | TRAIN Acc:  99.97% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:02:47,244] Gradient total norm was 0.5993760228157043. Clipping to 0.25.
[2023-03-17 23:02:47,247] Step: 1440| lr: 0.6740 | Time: 13.90s |TRAIN loss  0.0085 | TRAIN Acc:  99.97% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:03:01,173] Gradient total norm was 0.8005815744400024. Clipping to 0.25.
[2023-03-17 23:03:01,177] Step: 1441| lr: 0.6738 | Time: 13.92s |TRAIN loss  0.0115 | TRAIN Acc:  99.84% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:03:15,189] Gradient total norm was 0.4699252247810364. Clipping to 0.25.
[2023-03-17 23:03:15,192] Step: 1442| lr: 0.6736 | Time: 14.00s |TRAIN loss  0.0093 | TRAIN Acc:  99.95% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:03:29,195] Gradient total norm was 0.5362218022346497. Clipping to 0.25.
[2023-03-17 23:03:29,198] Step: 1443| lr: 0.6734 | Time: 13.99s |TRAIN loss  0.0108 | TRAIN Acc:  99.92% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:03:43,158] Gradient total norm was 0.7551490068435669. Clipping to 0.25.
[2023-03-17 23:03:43,161] Step: 1444| lr: 0.6731 | Time: 13.95s |TRAIN loss  0.0111 | TRAIN Acc:  99.93% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:03:57,145] Gradient total norm was 0.42398345470428467. Clipping to 0.25.
[2023-03-17 23:03:57,148] Step: 1445| lr: 0.6729 | Time: 13.97s |TRAIN loss  0.0119 | TRAIN Acc:  99.92% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:04:11,026] Gradient total norm was 0.5189790725708008. Clipping to 0.25.
[2023-03-17 23:04:11,030] Step: 1446| lr: 0.6727 | Time: 13.87s |TRAIN loss  0.0105 | TRAIN Acc:  99.96% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:04:25,060] Gradient total norm was 0.6171326041221619. Clipping to 0.25.
[2023-03-17 23:04:25,063] Step: 1447| lr: 0.6724 | Time: 14.02s |TRAIN loss  0.0119 | TRAIN Acc:  99.94% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:04:39,016] Gradient total norm was 0.8112481236457825. Clipping to 0.25.
[2023-03-17 23:04:39,019] Step: 1448| lr: 0.6722 | Time: 13.94s |TRAIN loss  0.0159 | TRAIN Acc:  99.69% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:04:52,969] Gradient total norm was 0.36968621611595154. Clipping to 0.25.
[2023-03-17 23:04:52,972] Step: 1449| lr: 0.6720 | Time: 13.94s |TRAIN loss  0.0128 | TRAIN Acc:  99.95% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:05:06,898] Gradient total norm was 0.5190961956977844. Clipping to 0.25.
[2023-03-17 23:05:06,901] Step: 1450| lr: 0.6718 | Time: 13.92s |TRAIN loss  0.0122 | TRAIN Acc:  99.91% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:05:20,800] Gradient total norm was 1.1067310571670532. Clipping to 0.25.
[2023-03-17 23:05:20,803] Step: 1451| lr: 0.6715 | Time: 13.89s |TRAIN loss  0.0139 | TRAIN Acc:  99.91% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:05:34,770] Gradient total norm was 0.8056130409240723. Clipping to 0.25.
[2023-03-17 23:05:34,773] Step: 1452| lr: 0.6713 | Time: 13.96s |TRAIN loss  0.0153 | TRAIN Acc:  99.81% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:05:48,693] Gradient total norm was 0.5100610256195068. Clipping to 0.25.
[2023-03-17 23:05:48,696] Step: 1453| lr: 0.6711 | Time: 13.91s |TRAIN loss  0.0137 | TRAIN Acc:  99.95% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:06:02,676] Gradient total norm was 0.5715509653091431. Clipping to 0.25.
[2023-03-17 23:06:02,679] Step: 1454| lr: 0.6708 | Time: 13.97s |TRAIN loss  0.0141 | TRAIN Acc:  99.90% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:06:16,625] Gradient total norm was 0.4060226380825043. Clipping to 0.25.
[2023-03-17 23:06:16,628] Step: 1455| lr: 0.6706 | Time: 13.94s |TRAIN loss  0.0124 | TRAIN Acc:  99.97% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:06:30,595] Gradient total norm was 0.6962623000144958. Clipping to 0.25.
[2023-03-17 23:06:30,598] Step: 1456| lr: 0.6704 | Time: 13.96s |TRAIN loss  0.0124 | TRAIN Acc:  99.94% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:06:44,558] Gradient total norm was 0.45930299162864685. Clipping to 0.25.
[2023-03-17 23:06:44,561] Step: 1457| lr: 0.6701 | Time: 13.95s |TRAIN loss  0.0125 | TRAIN Acc:  99.93% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:06:58,497] Gradient total norm was 0.34813830256462097. Clipping to 0.25.
[2023-03-17 23:06:58,501] Step: 1458| lr: 0.6699 | Time: 13.93s |TRAIN loss  0.0110 | TRAIN Acc:  99.96% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:07:12,489] Gradient total norm was 0.40741708874702454. Clipping to 0.25.
[2023-03-17 23:07:12,493] Step: 1459| lr: 0.6697 | Time: 13.98s |TRAIN loss  0.0109 | TRAIN Acc:  99.97% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:07:26,380] Gradient total norm was 0.4017927348613739. Clipping to 0.25.
[2023-03-17 23:07:26,383] Step: 1460| lr: 0.6694 | Time: 13.88s |TRAIN loss  0.0093 | TRAIN Acc:  99.97% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:07:40,248] Gradient total norm was 0.5348373055458069. Clipping to 0.25.
[2023-03-17 23:07:40,251] Step: 1461| lr: 0.6692 | Time: 13.85s |TRAIN loss  0.0095 | TRAIN Acc:  99.97% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:07:54,340] Gradient total norm was 0.7759285569190979. Clipping to 0.25.
[2023-03-17 23:07:54,343] Step: 1462| lr: 0.6690 | Time: 14.08s |TRAIN loss  0.0117 | TRAIN Acc:  99.88% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:08:08,237] Gradient total norm was 1.2002891302108765. Clipping to 0.25.
[2023-03-17 23:08:08,240] Step: 1463| lr: 0.6687 | Time: 13.88s |TRAIN loss  0.0132 | TRAIN Acc:  99.79% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:08:22,262] Gradient total norm was 1.5556073188781738. Clipping to 0.25.
[2023-03-17 23:08:22,265] Step: 1464| lr: 0.6685 | Time: 14.01s |TRAIN loss  0.0240 | TRAIN Acc:  99.43% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:08:36,213] Gradient total norm was 1.1483006477355957. Clipping to 0.25.
[2023-03-17 23:08:36,216] Step: 1465| lr: 0.6683 | Time: 13.94s |TRAIN loss  0.0316 | TRAIN Acc:  99.16% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:08:50,138] Gradient total norm was 0.5653350353240967. Clipping to 0.25.
[2023-03-17 23:08:50,142] Step: 1466| lr: 0.6680 | Time: 13.91s |TRAIN loss  0.0270 | TRAIN Acc:  99.59% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:09:04,018] Gradient total norm was 0.5961635112762451. Clipping to 0.25.
[2023-03-17 23:09:04,021] Step: 1467| lr: 0.6678 | Time: 13.87s |TRAIN loss  0.0242 | TRAIN Acc:  99.66% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:09:17,953] Gradient total norm was 0.744378387928009. Clipping to 0.25.
[2023-03-17 23:09:17,956] Step: 1468| lr: 0.6676 | Time: 13.92s |TRAIN loss  0.0211 | TRAIN Acc:  99.79% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:09:31,923] Gradient total norm was 1.3421971797943115. Clipping to 0.25.
[2023-03-17 23:09:31,927] Step: 1469| lr: 0.6673 | Time: 13.96s |TRAIN loss  0.0210 | TRAIN Acc:  99.67% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:09:45,843] Gradient total norm was 0.6065059304237366. Clipping to 0.25.
[2023-03-17 23:09:45,846] Step: 1470| lr: 0.6671 | Time: 13.91s |TRAIN loss  0.0189 | TRAIN Acc:  99.87% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:09:59,783] Gradient total norm was 0.6257706880569458. Clipping to 0.25.
[2023-03-17 23:09:59,786] Step: 1471| lr: 0.6669 | Time: 13.93s |TRAIN loss  0.0177 | TRAIN Acc:  99.88% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:10:13,780] Gradient total norm was 0.8318175077438354. Clipping to 0.25.
[2023-03-17 23:10:13,783] Step: 1472| lr: 0.6666 | Time: 13.98s |TRAIN loss  0.0167 | TRAIN Acc:  99.90% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:10:27,818] Gradient total norm was 1.7974843978881836. Clipping to 0.25.
[2023-03-17 23:10:27,821] Step: 1473| lr: 0.6664 | Time: 14.02s |TRAIN loss  0.0319 | TRAIN Acc:  99.39% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:10:41,764] Gradient total norm was 0.5885378122329712. Clipping to 0.25.
[2023-03-17 23:10:41,767] Step: 1474| lr: 0.6662 | Time: 13.93s |TRAIN loss  0.0215 | TRAIN Acc:  99.82% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:10:55,717] Gradient total norm was 0.5942590236663818. Clipping to 0.25.
[2023-03-17 23:10:55,720] Step: 1475| lr: 0.6659 | Time: 13.94s |TRAIN loss  0.0220 | TRAIN Acc:  99.82% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:11:09,610] Gradient total norm was 0.6741542220115662. Clipping to 0.25.
[2023-03-17 23:11:09,613] Step: 1476| lr: 0.6657 | Time: 13.88s |TRAIN loss  0.0238 | TRAIN Acc:  99.71% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:11:23,616] Gradient total norm was 0.46748408675193787. Clipping to 0.25.
[2023-03-17 23:11:23,619] Step: 1477| lr: 0.6655 | Time: 13.99s |TRAIN loss  0.0212 | TRAIN Acc:  99.82% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:11:37,492] Gradient total norm was 1.216652274131775. Clipping to 0.25.
[2023-03-17 23:11:37,496] Step: 1478| lr: 0.6652 | Time: 13.86s |TRAIN loss  0.0202 | TRAIN Acc:  99.77% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:11:51,431] Gradient total norm was 0.5399689674377441. Clipping to 0.25.
[2023-03-17 23:11:51,434] Step: 1479| lr: 0.6650 | Time: 13.93s |TRAIN loss  0.0253 | TRAIN Acc:  99.64% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:12:05,387] Gradient total norm was 0.6810613870620728. Clipping to 0.25.
[2023-03-17 23:12:05,390] Step: 1480| lr: 0.6648 | Time: 13.94s |TRAIN loss  0.0194 | TRAIN Acc:  99.79% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:12:19,316] Gradient total norm was 0.5030450224876404. Clipping to 0.25.
[2023-03-17 23:12:19,320] Step: 1481| lr: 0.6645 | Time: 13.92s |TRAIN loss  0.0233 | TRAIN Acc:  99.60% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:12:33,287] Gradient total norm was 0.4907115697860718. Clipping to 0.25.
[2023-03-17 23:12:33,290] Step: 1482| lr: 0.6643 | Time: 13.96s |TRAIN loss  0.0216 | TRAIN Acc:  99.86% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:12:47,275] Gradient total norm was 0.4263879358768463. Clipping to 0.25.
[2023-03-17 23:12:47,278] Step: 1483| lr: 0.6641 | Time: 13.97s |TRAIN loss  0.0193 | TRAIN Acc:  99.81% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:13:01,240] Gradient total norm was 0.968601644039154. Clipping to 0.25.
[2023-03-17 23:13:01,243] Step: 1484| lr: 0.6638 | Time: 13.95s |TRAIN loss  0.0180 | TRAIN Acc:  99.83% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:13:15,142] Gradient total norm was 0.7321500182151794. Clipping to 0.25.
[2023-03-17 23:13:15,146] Step: 1485| lr: 0.6636 | Time: 13.89s |TRAIN loss  0.0181 | TRAIN Acc:  99.86% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:13:29,062] Gradient total norm was 0.5068929195404053. Clipping to 0.25.
[2023-03-17 23:13:29,066] Step: 1486| lr: 0.6633 | Time: 13.91s |TRAIN loss  0.0159 | TRAIN Acc:  99.87% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:13:43,020] Gradient total norm was 0.41470369696617126. Clipping to 0.25.
[2023-03-17 23:13:43,024] Step: 1487| lr: 0.6631 | Time: 13.94s |TRAIN loss  0.0140 | TRAIN Acc:  99.90% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:13:56,925] Gradient total norm was 0.3562837541103363. Clipping to 0.25.
[2023-03-17 23:13:56,928] Step: 1488| lr: 0.6629 | Time: 13.89s |TRAIN loss  0.0128 | TRAIN Acc:  99.91% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:14:10,867] Gradient total norm was 0.568825900554657. Clipping to 0.25.
[2023-03-17 23:14:10,871] Step: 1489| lr: 0.6626 | Time: 13.93s |TRAIN loss  0.0118 | TRAIN Acc:  99.94% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:14:24,807] Gradient total norm was 0.3812813460826874. Clipping to 0.25.
[2023-03-17 23:14:24,810] Step: 1490| lr: 0.6624 | Time: 13.93s |TRAIN loss  0.0114 | TRAIN Acc:  99.95% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:14:38,777] Gradient total norm was 0.4313522279262543. Clipping to 0.25.
[2023-03-17 23:14:38,780] Step: 1491| lr: 0.6622 | Time: 13.96s |TRAIN loss  0.0097 | TRAIN Acc:  99.96% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:14:52,704] Gradient total norm was 0.7481560111045837. Clipping to 0.25.
[2023-03-17 23:14:52,708] Step: 1492| lr: 0.6619 | Time: 13.91s |TRAIN loss  0.0106 | TRAIN Acc:  99.95% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:15:06,612] Gradient total norm was 1.4424705505371094. Clipping to 0.25.
[2023-03-17 23:15:06,615] Step: 1493| lr: 0.6617 | Time: 13.89s |TRAIN loss  0.0158 | TRAIN Acc:  99.69% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:15:20,571] Gradient total norm was 0.6409497261047363. Clipping to 0.25.
[2023-03-17 23:15:20,574] Step: 1494| lr: 0.6614 | Time: 13.95s |TRAIN loss  0.0129 | TRAIN Acc:  99.94% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:15:34,594] Gradient total norm was 0.5631971955299377. Clipping to 0.25.
[2023-03-17 23:15:34,598] Step: 1495| lr: 0.6612 | Time: 14.01s |TRAIN loss  0.0142 | TRAIN Acc:  99.91% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:15:48,583] Gradient total norm was 0.6414688229560852. Clipping to 0.25.
[2023-03-17 23:15:48,586] Step: 1496| lr: 0.6610 | Time: 13.98s |TRAIN loss  0.0133 | TRAIN Acc:  99.88% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:16:02,536] Gradient total norm was 0.422545462846756. Clipping to 0.25.
[2023-03-17 23:16:02,539] Step: 1497| lr: 0.6607 | Time: 13.94s |TRAIN loss  0.0142 | TRAIN Acc:  99.93% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:16:16,457] Gradient total norm was 0.47096002101898193. Clipping to 0.25.
[2023-03-17 23:16:16,460] Step: 1498| lr: 0.6605 | Time: 13.91s |TRAIN loss  0.0146 | TRAIN Acc:  99.91% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:16:30,482] Gradient total norm was 0.5363197922706604. Clipping to 0.25.
[2023-03-17 23:16:30,485] Step: 1499| lr: 0.6603 | Time: 14.01s |TRAIN loss  0.0154 | TRAIN Acc:  99.85% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:16:44,424] Gradient total norm was 0.44902732968330383. Clipping to 0.25.
[2023-03-17 23:16:44,427] Step: 1500| lr: 0.6600 | Time: 13.93s |TRAIN loss  0.0149 | TRAIN Acc:  99.89% |VAL loss  0.3195 | VAL Acc:  90.26% |
[2023-03-17 23:16:58,487] Gradient total norm was 0.3791459798812866. Clipping to 0.25.
[2023-03-17 23:17:03,885] Step: 1501| lr: 0.6598 | Time: 14.05s |TRAIN loss  0.0138 | TRAIN Acc:  99.96% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:17:17,850] Gradient total norm was 0.32170572876930237. Clipping to 0.25.
[2023-03-17 23:17:17,853] Step: 1502| lr: 0.6595 | Time: 13.95s |TRAIN loss  0.0105 | TRAIN Acc:  99.97% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:17:31,811] Gradient total norm was 0.35330843925476074. Clipping to 0.25.
[2023-03-17 23:17:31,815] Step: 1503| lr: 0.6593 | Time: 13.95s |TRAIN loss  0.0101 | TRAIN Acc:  99.96% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:17:45,781] Gradient total norm was 0.3920719623565674. Clipping to 0.25.
[2023-03-17 23:17:45,785] Step: 1504| lr: 0.6591 | Time: 13.96s |TRAIN loss  0.0083 | TRAIN Acc:  99.97% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:17:59,711] Gradient total norm was 0.3120799958705902. Clipping to 0.25.
[2023-03-17 23:17:59,714] Step: 1505| lr: 0.6588 | Time: 13.92s |TRAIN loss  0.0086 | TRAIN Acc:  99.97% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:18:13,688] Gradient total norm was 0.36652010679244995. Clipping to 0.25.
[2023-03-17 23:18:13,691] Step: 1506| lr: 0.6586 | Time: 13.96s |TRAIN loss  0.0071 | TRAIN Acc:  99.98% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:18:27,618] Gradient total norm was 0.2757881283760071. Clipping to 0.25.
[2023-03-17 23:18:27,621] Step: 1507| lr: 0.6583 | Time: 13.92s |TRAIN loss  0.0070 | TRAIN Acc:  99.98% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:18:41,617] Gradient total norm was 0.46490466594696045. Clipping to 0.25.
[2023-03-17 23:18:41,628] Step: 1508| lr: 0.6581 | Time: 13.99s |TRAIN loss  0.0058 | TRAIN Acc:  99.98% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:18:55,576] Gradient total norm was 0.4896012842655182. Clipping to 0.25.
[2023-03-17 23:18:55,579] Step: 1509| lr: 0.6579 | Time: 13.93s |TRAIN loss  0.0066 | TRAIN Acc:  99.98% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:19:09,490] Gradient total norm was 2.0868425369262695. Clipping to 0.25.
[2023-03-17 23:19:09,493] Step: 1510| lr: 0.6576 | Time: 13.90s |TRAIN loss  0.0126 | TRAIN Acc:  99.71% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:19:23,416] Gradient total norm was 0.7882364392280579. Clipping to 0.25.
[2023-03-17 23:19:23,419] Step: 1511| lr: 0.6574 | Time: 13.91s |TRAIN loss  0.0125 | TRAIN Acc:  99.78% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:19:37,332] Gradient total norm was 0.6725943088531494. Clipping to 0.25.
[2023-03-17 23:19:37,336] Step: 1512| lr: 0.6571 | Time: 13.90s |TRAIN loss  0.0129 | TRAIN Acc:  99.82% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:19:51,391] Gradient total norm was 0.4776873290538788. Clipping to 0.25.
[2023-03-17 23:19:51,395] Step: 1513| lr: 0.6569 | Time: 14.05s |TRAIN loss  0.0140 | TRAIN Acc:  99.85% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:20:05,376] Gradient total norm was 0.36864233016967773. Clipping to 0.25.
[2023-03-17 23:20:05,380] Step: 1514| lr: 0.6567 | Time: 13.97s |TRAIN loss  0.0102 | TRAIN Acc:  99.98% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:20:19,300] Gradient total norm was 0.4473598003387451. Clipping to 0.25.
[2023-03-17 23:20:19,303] Step: 1515| lr: 0.6564 | Time: 13.91s |TRAIN loss  0.0092 | TRAIN Acc:  99.98% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:20:33,377] Gradient total norm was 0.486432820558548. Clipping to 0.25.
[2023-03-17 23:20:33,380] Step: 1516| lr: 0.6562 | Time: 14.06s |TRAIN loss  0.0085 | TRAIN Acc:  99.97% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:20:47,422] Gradient total norm was 0.6731067895889282. Clipping to 0.25.
[2023-03-17 23:20:47,425] Step: 1517| lr: 0.6559 | Time: 14.03s |TRAIN loss  0.0091 | TRAIN Acc:  99.96% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:21:01,415] Gradient total norm was 1.1170709133148193. Clipping to 0.25.
[2023-03-17 23:21:01,418] Step: 1518| lr: 0.6557 | Time: 13.98s |TRAIN loss  0.0101 | TRAIN Acc:  99.88% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:21:15,400] Gradient total norm was 1.683251976966858. Clipping to 0.25.
[2023-03-17 23:21:15,403] Step: 1519| lr: 0.6555 | Time: 13.97s |TRAIN loss  0.0210 | TRAIN Acc:  99.42% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:21:29,331] Gradient total norm was 0.8314381837844849. Clipping to 0.25.
[2023-03-17 23:21:29,334] Step: 1520| lr: 0.6552 | Time: 13.92s |TRAIN loss  0.0173 | TRAIN Acc:  99.74% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:21:43,313] Gradient total norm was 0.5623032450675964. Clipping to 0.25.
[2023-03-17 23:21:43,316] Step: 1521| lr: 0.6550 | Time: 13.97s |TRAIN loss  0.0191 | TRAIN Acc:  99.79% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:21:57,260] Gradient total norm was 0.495263010263443. Clipping to 0.25.
[2023-03-17 23:21:57,264] Step: 1522| lr: 0.6547 | Time: 13.93s |TRAIN loss  0.0181 | TRAIN Acc:  99.79% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:22:11,276] Gradient total norm was 0.4138539135456085. Clipping to 0.25.
[2023-03-17 23:22:11,279] Step: 1523| lr: 0.6545 | Time: 14.00s |TRAIN loss  0.0181 | TRAIN Acc:  99.87% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:22:25,293] Gradient total norm was 0.3782539367675781. Clipping to 0.25.
[2023-03-17 23:22:25,297] Step: 1524| lr: 0.6542 | Time: 14.00s |TRAIN loss  0.0129 | TRAIN Acc:  99.95% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:22:39,218] Gradient total norm was 0.6126536130905151. Clipping to 0.25.
[2023-03-17 23:22:39,222] Step: 1525| lr: 0.6540 | Time: 13.91s |TRAIN loss  0.0129 | TRAIN Acc:  99.93% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:22:53,422] Gradient total norm was 1.1968255043029785. Clipping to 0.25.
[2023-03-17 23:22:53,425] Step: 1526| lr: 0.6538 | Time: 14.19s |TRAIN loss  0.0178 | TRAIN Acc:  99.67% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:23:07,417] Gradient total norm was 0.43276146054267883. Clipping to 0.25.
[2023-03-17 23:23:07,420] Step: 1527| lr: 0.6535 | Time: 13.98s |TRAIN loss  0.0133 | TRAIN Acc:  99.91% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:23:21,337] Gradient total norm was 0.46210482716560364. Clipping to 0.25.
[2023-03-17 23:23:21,340] Step: 1528| lr: 0.6533 | Time: 13.91s |TRAIN loss  0.0127 | TRAIN Acc:  99.90% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:23:35,264] Gradient total norm was 0.43530383706092834. Clipping to 0.25.
[2023-03-17 23:23:35,268] Step: 1529| lr: 0.6530 | Time: 13.91s |TRAIN loss  0.0118 | TRAIN Acc:  99.96% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:23:49,214] Gradient total norm was 0.8614718914031982. Clipping to 0.25.
[2023-03-17 23:23:49,218] Step: 1530| lr: 0.6528 | Time: 13.94s |TRAIN loss  0.0151 | TRAIN Acc:  99.84% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:24:03,243] Gradient total norm was 1.047528624534607. Clipping to 0.25.
[2023-03-17 23:24:03,247] Step: 1531| lr: 0.6525 | Time: 14.02s |TRAIN loss  0.0172 | TRAIN Acc:  99.73% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:24:17,166] Gradient total norm was 0.5559336543083191. Clipping to 0.25.
[2023-03-17 23:24:17,169] Step: 1532| lr: 0.6523 | Time: 13.91s |TRAIN loss  0.0168 | TRAIN Acc:  99.79% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:24:31,122] Gradient total norm was 0.4476066827774048. Clipping to 0.25.
[2023-03-17 23:24:31,126] Step: 1533| lr: 0.6521 | Time: 13.94s |TRAIN loss  0.0162 | TRAIN Acc:  99.86% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:24:45,115] Gradient total norm was 0.3099217712879181. Clipping to 0.25.
[2023-03-17 23:24:45,119] Step: 1534| lr: 0.6518 | Time: 13.98s |TRAIN loss  0.0132 | TRAIN Acc:  99.96% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:24:59,115] Gradient total norm was 0.3408229351043701. Clipping to 0.25.
[2023-03-17 23:24:59,118] Step: 1535| lr: 0.6516 | Time: 13.99s |TRAIN loss  0.0104 | TRAIN Acc:  99.98% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:25:13,088] Gradient total norm was 0.43174615502357483. Clipping to 0.25.
[2023-03-17 23:25:13,091] Step: 1536| lr: 0.6513 | Time: 13.96s |TRAIN loss  0.0100 | TRAIN Acc:  99.97% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:25:26,971] Gradient total norm was 0.4837442934513092. Clipping to 0.25.
[2023-03-17 23:25:26,975] Step: 1537| lr: 0.6511 | Time: 13.87s |TRAIN loss  0.0084 | TRAIN Acc:  99.98% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:25:40,949] Gradient total norm was 0.4173445701599121. Clipping to 0.25.
[2023-03-17 23:25:40,952] Step: 1538| lr: 0.6508 | Time: 13.96s |TRAIN loss  0.0088 | TRAIN Acc:  99.98% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:25:54,941] Gradient total norm was 1.1088474988937378. Clipping to 0.25.
[2023-03-17 23:25:54,945] Step: 1539| lr: 0.6506 | Time: 13.98s |TRAIN loss  0.0100 | TRAIN Acc:  99.88% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:26:08,915] Gradient total norm was 0.7036228179931641. Clipping to 0.25.
[2023-03-17 23:26:08,918] Step: 1540| lr: 0.6503 | Time: 13.96s |TRAIN loss  0.0141 | TRAIN Acc:  99.72% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:26:22,860] Gradient total norm was 0.35678574442863464. Clipping to 0.25.
[2023-03-17 23:26:22,863] Step: 1541| lr: 0.6501 | Time: 13.93s |TRAIN loss  0.0110 | TRAIN Acc:  99.95% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:26:36,833] Gradient total norm was 0.5016930103302002. Clipping to 0.25.
[2023-03-17 23:26:36,837] Step: 1542| lr: 0.6499 | Time: 13.96s |TRAIN loss  0.0115 | TRAIN Acc:  99.87% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:26:50,830] Gradient total norm was 0.34778109192848206. Clipping to 0.25.
[2023-03-17 23:26:50,833] Step: 1543| lr: 0.6496 | Time: 13.98s |TRAIN loss  0.0112 | TRAIN Acc:  99.93% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:27:04,727] Gradient total norm was 0.43242016434669495. Clipping to 0.25.
[2023-03-17 23:27:04,731] Step: 1544| lr: 0.6494 | Time: 13.88s |TRAIN loss  0.0100 | TRAIN Acc:  99.97% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:27:18,661] Gradient total norm was 0.36916840076446533. Clipping to 0.25.
[2023-03-17 23:27:18,665] Step: 1545| lr: 0.6491 | Time: 13.92s |TRAIN loss  0.0095 | TRAIN Acc:  99.95% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:27:32,688] Gradient total norm was 0.3264831602573395. Clipping to 0.25.
[2023-03-17 23:27:32,691] Step: 1546| lr: 0.6489 | Time: 14.01s |TRAIN loss  0.0082 | TRAIN Acc:  99.98% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:27:46,682] Gradient total norm was 0.4325517416000366. Clipping to 0.25.
[2023-03-17 23:27:46,686] Step: 1547| lr: 0.6486 | Time: 13.98s |TRAIN loss  0.0077 | TRAIN Acc:  99.98% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:28:00,576] Gradient total norm was 1.053382396697998. Clipping to 0.25.
[2023-03-17 23:28:00,579] Step: 1548| lr: 0.6484 | Time: 13.88s |TRAIN loss  0.0096 | TRAIN Acc:  99.91% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:28:14,524] Gradient total norm was 0.8122761249542236. Clipping to 0.25.
[2023-03-17 23:28:14,528] Step: 1549| lr: 0.6481 | Time: 13.94s |TRAIN loss  0.0105 | TRAIN Acc:  99.89% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:28:28,545] Gradient total norm was 0.7413890361785889. Clipping to 0.25.
[2023-03-17 23:28:28,549] Step: 1550| lr: 0.6479 | Time: 14.01s |TRAIN loss  0.0116 | TRAIN Acc:  99.90% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:28:42,515] Gradient total norm was 0.6447815895080566. Clipping to 0.25.
[2023-03-17 23:28:42,518] Step: 1551| lr: 0.6476 | Time: 13.96s |TRAIN loss  0.0142 | TRAIN Acc:  99.86% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:28:56,413] Gradient total norm was 0.4211328625679016. Clipping to 0.25.
[2023-03-17 23:28:56,417] Step: 1552| lr: 0.6474 | Time: 13.88s |TRAIN loss  0.0129 | TRAIN Acc:  99.85% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:29:10,367] Gradient total norm was 0.4642515778541565. Clipping to 0.25.
[2023-03-17 23:29:10,370] Step: 1553| lr: 0.6471 | Time: 13.94s |TRAIN loss  0.0132 | TRAIN Acc:  99.96% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:29:24,321] Gradient total norm was 0.4388025403022766. Clipping to 0.25.
[2023-03-17 23:29:24,325] Step: 1554| lr: 0.6469 | Time: 13.94s |TRAIN loss  0.0119 | TRAIN Acc:  99.88% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:29:38,330] Gradient total norm was 0.4020529091358185. Clipping to 0.25.
[2023-03-17 23:29:38,334] Step: 1555| lr: 0.6466 | Time: 14.00s |TRAIN loss  0.0099 | TRAIN Acc:  99.98% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:29:52,212] Gradient total norm was 0.8929557204246521. Clipping to 0.25.
[2023-03-17 23:29:52,215] Step: 1556| lr: 0.6464 | Time: 13.87s |TRAIN loss  0.0111 | TRAIN Acc:  99.93% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:30:06,197] Gradient total norm was 0.7434218525886536. Clipping to 0.25.
[2023-03-17 23:30:06,201] Step: 1557| lr: 0.6462 | Time: 13.97s |TRAIN loss  0.0121 | TRAIN Acc:  99.90% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:30:20,127] Gradient total norm was 0.6473797559738159. Clipping to 0.25.
[2023-03-17 23:30:20,130] Step: 1558| lr: 0.6459 | Time: 13.92s |TRAIN loss  0.0132 | TRAIN Acc:  99.90% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:30:34,037] Gradient total norm was 0.4369972050189972. Clipping to 0.25.
[2023-03-17 23:30:34,040] Step: 1559| lr: 0.6457 | Time: 13.90s |TRAIN loss  0.0126 | TRAIN Acc:  99.92% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:30:48,068] Gradient total norm was 0.37636798620224. Clipping to 0.25.
[2023-03-17 23:30:48,071] Step: 1560| lr: 0.6454 | Time: 14.02s |TRAIN loss  0.0119 | TRAIN Acc:  99.97% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:31:02,007] Gradient total norm was 0.3317653238773346. Clipping to 0.25.
[2023-03-17 23:31:02,010] Step: 1561| lr: 0.6452 | Time: 13.93s |TRAIN loss  0.0099 | TRAIN Acc:  99.96% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:31:15,939] Gradient total norm was 0.3550606369972229. Clipping to 0.25.
[2023-03-17 23:31:15,943] Step: 1562| lr: 0.6449 | Time: 13.92s |TRAIN loss  0.0094 | TRAIN Acc:  99.99% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:31:29,928] Gradient total norm was 0.4973517656326294. Clipping to 0.25.
[2023-03-17 23:31:29,932] Step: 1563| lr: 0.6447 | Time: 13.98s |TRAIN loss  0.0079 | TRAIN Acc:  99.98% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:31:43,817] Gradient total norm was 0.9040572643280029. Clipping to 0.25.
[2023-03-17 23:31:43,821] Step: 1564| lr: 0.6444 | Time: 13.88s |TRAIN loss  0.0090 | TRAIN Acc:  99.96% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:31:57,778] Gradient total norm was 1.7351386547088623. Clipping to 0.25.
[2023-03-17 23:31:57,781] Step: 1565| lr: 0.6442 | Time: 13.95s |TRAIN loss  0.0204 | TRAIN Acc:  99.48% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:32:11,743] Gradient total norm was 0.4978207051753998. Clipping to 0.25.
[2023-03-17 23:32:11,747] Step: 1566| lr: 0.6439 | Time: 13.95s |TRAIN loss  0.0108 | TRAIN Acc:  99.97% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:32:25,693] Gradient total norm was 0.630695641040802. Clipping to 0.25.
[2023-03-17 23:32:25,696] Step: 1567| lr: 0.6437 | Time: 13.94s |TRAIN loss  0.0126 | TRAIN Acc:  99.88% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:32:39,703] Gradient total norm was 0.47177591919898987. Clipping to 0.25.
[2023-03-17 23:32:39,706] Step: 1568| lr: 0.6434 | Time: 14.00s |TRAIN loss  0.0125 | TRAIN Acc:  99.91% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:32:53,624] Gradient total norm was 0.3774678707122803. Clipping to 0.25.
[2023-03-17 23:32:53,628] Step: 1569| lr: 0.6432 | Time: 13.91s |TRAIN loss  0.0120 | TRAIN Acc:  99.92% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:33:07,608] Gradient total norm was 0.30932825803756714. Clipping to 0.25.
[2023-03-17 23:33:07,612] Step: 1570| lr: 0.6429 | Time: 13.97s |TRAIN loss  0.0093 | TRAIN Acc:  99.98% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:33:21,500] Gradient total norm was 0.37229835987091064. Clipping to 0.25.
[2023-03-17 23:33:21,503] Step: 1571| lr: 0.6427 | Time: 13.88s |TRAIN loss  0.0086 | TRAIN Acc:  99.97% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:33:35,489] Gradient total norm was 0.4574616849422455. Clipping to 0.25.
[2023-03-17 23:33:35,493] Step: 1572| lr: 0.6424 | Time: 13.98s |TRAIN loss  0.0077 | TRAIN Acc:  99.97% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:33:49,422] Gradient total norm was 0.6444137096405029. Clipping to 0.25.
[2023-03-17 23:33:49,426] Step: 1573| lr: 0.6422 | Time: 13.92s |TRAIN loss  0.0084 | TRAIN Acc:  99.95% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:34:03,323] Gradient total norm was 0.8686455488204956. Clipping to 0.25.
[2023-03-17 23:34:03,326] Step: 1574| lr: 0.6419 | Time: 13.89s |TRAIN loss  0.0104 | TRAIN Acc:  99.89% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:34:17,297] Gradient total norm was 0.3860339820384979. Clipping to 0.25.
[2023-03-17 23:34:17,301] Step: 1575| lr: 0.6417 | Time: 13.96s |TRAIN loss  0.0093 | TRAIN Acc:  99.97% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:34:31,222] Gradient total norm was 0.328453004360199. Clipping to 0.25.
[2023-03-17 23:34:31,225] Step: 1576| lr: 0.6414 | Time: 13.91s |TRAIN loss  0.0081 | TRAIN Acc:  99.98% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:34:45,156] Gradient total norm was 0.34882432222366333. Clipping to 0.25.
[2023-03-17 23:34:45,160] Step: 1577| lr: 0.6412 | Time: 13.92s |TRAIN loss  0.0079 | TRAIN Acc:  99.98% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:34:59,079] Gradient total norm was 0.33986803889274597. Clipping to 0.25.
[2023-03-17 23:34:59,083] Step: 1578| lr: 0.6409 | Time: 13.91s |TRAIN loss  0.0069 | TRAIN Acc:  99.99% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:35:13,033] Gradient total norm was 1.7338811159133911. Clipping to 0.25.
[2023-03-17 23:35:13,037] Step: 1579| lr: 0.6407 | Time: 13.94s |TRAIN loss  0.0149 | TRAIN Acc:  99.68% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:35:26,956] Gradient total norm was 1.0036594867706299. Clipping to 0.25.
[2023-03-17 23:35:26,959] Step: 1580| lr: 0.6404 | Time: 13.91s |TRAIN loss  0.0147 | TRAIN Acc:  99.74% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:35:40,845] Gradient total norm was 0.7895488739013672. Clipping to 0.25.
[2023-03-17 23:35:40,848] Step: 1581| lr: 0.6402 | Time: 13.88s |TRAIN loss  0.0213 | TRAIN Acc:  99.50% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:35:54,912] Gradient total norm was 0.42837291955947876. Clipping to 0.25.
[2023-03-17 23:35:54,915] Step: 1582| lr: 0.6399 | Time: 14.05s |TRAIN loss  0.0140 | TRAIN Acc:  99.84% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:36:08,826] Gradient total norm was 0.4119463860988617. Clipping to 0.25.
[2023-03-17 23:36:08,829] Step: 1583| lr: 0.6397 | Time: 13.90s |TRAIN loss  0.0129 | TRAIN Acc:  99.90% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:36:22,768] Gradient total norm was 0.28739628195762634. Clipping to 0.25.
[2023-03-17 23:36:22,772] Step: 1584| lr: 0.6394 | Time: 13.93s |TRAIN loss  0.0100 | TRAIN Acc:  99.94% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:36:36,778] Gradient total norm was 0.31217294931411743. Clipping to 0.25.
[2023-03-17 23:36:36,781] Step: 1585| lr: 0.6392 | Time: 14.00s |TRAIN loss  0.0088 | TRAIN Acc:  99.98% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:36:50,709] Gradient total norm was 0.5537550449371338. Clipping to 0.25.
[2023-03-17 23:36:50,713] Step: 1586| lr: 0.6389 | Time: 13.92s |TRAIN loss  0.0077 | TRAIN Acc:  99.98% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:37:04,646] Gradient total norm was 1.7732759714126587. Clipping to 0.25.
[2023-03-17 23:37:04,650] Step: 1587| lr: 0.6387 | Time: 13.92s |TRAIN loss  0.0132 | TRAIN Acc:  99.77% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:37:18,702] Gradient total norm was 1.155615210533142. Clipping to 0.25.
[2023-03-17 23:37:18,705] Step: 1588| lr: 0.6384 | Time: 14.04s |TRAIN loss  0.0146 | TRAIN Acc:  99.78% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:37:32,608] Gradient total norm was 0.7162131667137146. Clipping to 0.25.
[2023-03-17 23:37:32,612] Step: 1589| lr: 0.6382 | Time: 13.89s |TRAIN loss  0.0139 | TRAIN Acc:  99.86% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:37:46,638] Gradient total norm was 0.9148203134536743. Clipping to 0.25.
[2023-03-17 23:37:46,642] Step: 1590| lr: 0.6379 | Time: 14.02s |TRAIN loss  0.0163 | TRAIN Acc:  99.74% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:38:00,563] Gradient total norm was 0.39636552333831787. Clipping to 0.25.
[2023-03-17 23:38:00,566] Step: 1591| lr: 0.6376 | Time: 13.91s |TRAIN loss  0.0135 | TRAIN Acc:  99.94% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:38:14,561] Gradient total norm was 0.366289347410202. Clipping to 0.25.
[2023-03-17 23:38:14,565] Step: 1592| lr: 0.6374 | Time: 13.99s |TRAIN loss  0.0113 | TRAIN Acc:  99.96% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:38:28,464] Gradient total norm was 0.5367287993431091. Clipping to 0.25.
[2023-03-17 23:38:28,468] Step: 1593| lr: 0.6371 | Time: 13.89s |TRAIN loss  0.0115 | TRAIN Acc:  99.96% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:38:42,412] Gradient total norm was 0.6145980954170227. Clipping to 0.25.
[2023-03-17 23:38:42,415] Step: 1594| lr: 0.6369 | Time: 13.93s |TRAIN loss  0.0104 | TRAIN Acc:  99.96% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:38:56,434] Gradient total norm was 1.5018506050109863. Clipping to 0.25.
[2023-03-17 23:38:56,437] Step: 1595| lr: 0.6366 | Time: 14.01s |TRAIN loss  0.0182 | TRAIN Acc:  99.63% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:39:10,382] Gradient total norm was 0.5599007606506348. Clipping to 0.25.
[2023-03-17 23:39:10,385] Step: 1596| lr: 0.6364 | Time: 13.94s |TRAIN loss  0.0139 | TRAIN Acc:  99.89% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:39:24,282] Gradient total norm was 0.5334903597831726. Clipping to 0.25.
[2023-03-17 23:39:24,285] Step: 1597| lr: 0.6361 | Time: 13.89s |TRAIN loss  0.0138 | TRAIN Acc:  99.88% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:39:38,147] Gradient total norm was 0.4070177972316742. Clipping to 0.25.
[2023-03-17 23:39:38,151] Step: 1598| lr: 0.6359 | Time: 13.85s |TRAIN loss  0.0142 | TRAIN Acc:  99.90% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:39:52,071] Gradient total norm was 0.5694267749786377. Clipping to 0.25.
[2023-03-17 23:39:52,074] Step: 1599| lr: 0.6356 | Time: 13.91s |TRAIN loss  0.0140 | TRAIN Acc:  99.95% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:40:05,995] Gradient total norm was 0.6356719136238098. Clipping to 0.25.
[2023-03-17 23:40:05,999] Step: 1600| lr: 0.6354 | Time: 13.91s |TRAIN loss  0.0128 | TRAIN Acc:  99.95% |VAL loss  0.2506 | VAL Acc:  92.69% |
[2023-03-17 23:40:19,931] Gradient total norm was 0.6091272234916687. Clipping to 0.25.
[2023-03-17 23:40:25,326] Step: 1601| lr: 0.6351 | Time: 13.92s |TRAIN loss  0.0128 | TRAIN Acc:  99.94% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:40:39,282] Gradient total norm was 0.5772531032562256. Clipping to 0.25.
[2023-03-17 23:40:39,285] Step: 1602| lr: 0.6349 | Time: 13.94s |TRAIN loss  0.0114 | TRAIN Acc:  99.96% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:40:53,265] Gradient total norm was 0.35580340027809143. Clipping to 0.25.
[2023-03-17 23:40:53,268] Step: 1603| lr: 0.6346 | Time: 13.97s |TRAIN loss  0.0103 | TRAIN Acc:  99.98% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:41:07,239] Gradient total norm was 0.33822470903396606. Clipping to 0.25.
[2023-03-17 23:41:07,243] Step: 1604| lr: 0.6344 | Time: 13.96s |TRAIN loss  0.0094 | TRAIN Acc:  99.99% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:41:21,234] Gradient total norm was 0.27952563762664795. Clipping to 0.25.
[2023-03-17 23:41:21,237] Step: 1605| lr: 0.6341 | Time: 13.98s |TRAIN loss  0.0083 | TRAIN Acc:  99.99% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:41:35,161] Gradient total norm was 0.3350070118904114. Clipping to 0.25.
[2023-03-17 23:41:35,164] Step: 1606| lr: 0.6338 | Time: 13.91s |TRAIN loss  0.0074 | TRAIN Acc:  99.99% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:41:49,141] Gradient total norm was 0.36105042695999146. Clipping to 0.25.
[2023-03-17 23:41:49,144] Step: 1607| lr: 0.6336 | Time: 13.97s |TRAIN loss  0.0074 | TRAIN Acc:  99.99% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:42:03,062] Gradient total norm was 0.6243777275085449. Clipping to 0.25.
[2023-03-17 23:42:03,065] Step: 1608| lr: 0.6333 | Time: 13.91s |TRAIN loss  0.0076 | TRAIN Acc:  99.96% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:42:17,060] Gradient total norm was 0.814170241355896. Clipping to 0.25.
[2023-03-17 23:42:17,063] Step: 1609| lr: 0.6331 | Time: 13.98s |TRAIN loss  0.0097 | TRAIN Acc:  99.91% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:42:30,943] Gradient total norm was 1.141771674156189. Clipping to 0.25.
[2023-03-17 23:42:30,946] Step: 1610| lr: 0.6328 | Time: 13.87s |TRAIN loss  0.0117 | TRAIN Acc:  99.85% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:42:44,968] Gradient total norm was 0.6711391806602478. Clipping to 0.25.
[2023-03-17 23:42:44,971] Step: 1611| lr: 0.6326 | Time: 14.01s |TRAIN loss  0.0124 | TRAIN Acc:  99.89% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:42:58,944] Gradient total norm was 0.682095468044281. Clipping to 0.25.
[2023-03-17 23:42:58,948] Step: 1612| lr: 0.6323 | Time: 13.96s |TRAIN loss  0.0128 | TRAIN Acc:  99.93% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:43:12,872] Gradient total norm was 0.5690199732780457. Clipping to 0.25.
[2023-03-17 23:43:12,875] Step: 1613| lr: 0.6321 | Time: 13.91s |TRAIN loss  0.0150 | TRAIN Acc:  99.95% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:43:26,854] Gradient total norm was 0.48940780758857727. Clipping to 0.25.
[2023-03-17 23:43:26,858] Step: 1614| lr: 0.6318 | Time: 13.97s |TRAIN loss  0.0111 | TRAIN Acc:  99.98% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:43:40,807] Gradient total norm was 0.48646852374076843. Clipping to 0.25.
[2023-03-17 23:43:40,810] Step: 1615| lr: 0.6315 | Time: 13.94s |TRAIN loss  0.0114 | TRAIN Acc:  99.97% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:43:54,819] Gradient total norm was 0.6740199327468872. Clipping to 0.25.
[2023-03-17 23:43:54,823] Step: 1616| lr: 0.6313 | Time: 14.00s |TRAIN loss  0.0095 | TRAIN Acc:  99.96% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:44:08,750] Gradient total norm was 0.5478460788726807. Clipping to 0.25.
[2023-03-17 23:44:08,753] Step: 1617| lr: 0.6310 | Time: 13.92s |TRAIN loss  0.0107 | TRAIN Acc:  99.93% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:44:22,706] Gradient total norm was 0.5086097121238708. Clipping to 0.25.
[2023-03-17 23:44:22,709] Step: 1618| lr: 0.6308 | Time: 13.94s |TRAIN loss  0.0103 | TRAIN Acc:  99.97% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:44:36,694] Gradient total norm was 0.5179699063301086. Clipping to 0.25.
[2023-03-17 23:44:36,697] Step: 1619| lr: 0.6305 | Time: 13.98s |TRAIN loss  0.0106 | TRAIN Acc:  99.95% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:44:50,625] Gradient total norm was 0.5616888999938965. Clipping to 0.25.
[2023-03-17 23:44:50,629] Step: 1620| lr: 0.6303 | Time: 13.92s |TRAIN loss  0.0102 | TRAIN Acc:  99.94% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:45:04,507] Gradient total norm was 0.8184666037559509. Clipping to 0.25.
[2023-03-17 23:45:04,511] Step: 1621| lr: 0.6300 | Time: 13.87s |TRAIN loss  0.0115 | TRAIN Acc:  99.93% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:45:18,596] Gradient total norm was 0.8516806364059448. Clipping to 0.25.
[2023-03-17 23:45:18,599] Step: 1622| lr: 0.6297 | Time: 14.08s |TRAIN loss  0.0150 | TRAIN Acc:  99.80% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:45:32,527] Gradient total norm was 0.6192139983177185. Clipping to 0.25.
[2023-03-17 23:45:32,531] Step: 1623| lr: 0.6295 | Time: 13.92s |TRAIN loss  0.0166 | TRAIN Acc:  99.87% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:45:46,502] Gradient total norm was 0.6244083642959595. Clipping to 0.25.
[2023-03-17 23:45:46,505] Step: 1624| lr: 0.6292 | Time: 13.96s |TRAIN loss  0.0151 | TRAIN Acc:  99.90% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:46:00,389] Gradient total norm was 0.36820653080940247. Clipping to 0.25.
[2023-03-17 23:46:00,392] Step: 1625| lr: 0.6290 | Time: 13.87s |TRAIN loss  0.0143 | TRAIN Acc:  99.94% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:46:14,350] Gradient total norm was 0.3059155344963074. Clipping to 0.25.
[2023-03-17 23:46:14,354] Step: 1626| lr: 0.6287 | Time: 13.95s |TRAIN loss  0.0114 | TRAIN Acc:  99.98% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:46:28,317] Gradient total norm was 0.3444094657897949. Clipping to 0.25.
[2023-03-17 23:46:28,320] Step: 1627| lr: 0.6285 | Time: 13.95s |TRAIN loss  0.0091 | TRAIN Acc:  99.98% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:46:42,233] Gradient total norm was 0.5076466798782349. Clipping to 0.25.
[2023-03-17 23:46:42,236] Step: 1628| lr: 0.6282 | Time: 13.90s |TRAIN loss  0.0093 | TRAIN Acc:  99.95% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:46:56,230] Gradient total norm was 0.3481086194515228. Clipping to 0.25.
[2023-03-17 23:46:56,233] Step: 1629| lr: 0.6279 | Time: 13.98s |TRAIN loss  0.0087 | TRAIN Acc:  99.97% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:47:10,132] Gradient total norm was 0.447870671749115. Clipping to 0.25.
[2023-03-17 23:47:10,136] Step: 1630| lr: 0.6277 | Time: 13.89s |TRAIN loss  0.0082 | TRAIN Acc:  99.98% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:47:24,106] Gradient total norm was 0.3030998110771179. Clipping to 0.25.
[2023-03-17 23:47:24,110] Step: 1631| lr: 0.6274 | Time: 13.96s |TRAIN loss  0.0075 | TRAIN Acc:  99.98% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:47:38,110] Gradient total norm was 0.5170830488204956. Clipping to 0.25.
[2023-03-17 23:47:38,113] Step: 1632| lr: 0.6272 | Time: 13.99s |TRAIN loss  0.0068 | TRAIN Acc:  99.99% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:47:52,011] Gradient total norm was 0.5304550528526306. Clipping to 0.25.
[2023-03-17 23:47:52,014] Step: 1633| lr: 0.6269 | Time: 13.89s |TRAIN loss  0.0072 | TRAIN Acc:  99.98% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:48:05,956] Gradient total norm was 0.5246389508247375. Clipping to 0.25.
[2023-03-17 23:48:05,959] Step: 1634| lr: 0.6266 | Time: 13.93s |TRAIN loss  0.0076 | TRAIN Acc:  99.97% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:48:19,885] Gradient total norm was 0.7899782657623291. Clipping to 0.25.
[2023-03-17 23:48:19,888] Step: 1635| lr: 0.6264 | Time: 13.92s |TRAIN loss  0.0090 | TRAIN Acc:  99.93% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:48:33,870] Gradient total norm was 0.3621624708175659. Clipping to 0.25.
[2023-03-17 23:48:33,873] Step: 1636| lr: 0.6261 | Time: 13.97s |TRAIN loss  0.0079 | TRAIN Acc:  99.96% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:48:47,888] Gradient total norm was 0.8871064782142639. Clipping to 0.25.
[2023-03-17 23:48:47,891] Step: 1637| lr: 0.6259 | Time: 14.00s |TRAIN loss  0.0106 | TRAIN Acc:  99.92% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:49:01,835] Gradient total norm was 0.34573858976364136. Clipping to 0.25.
[2023-03-17 23:49:01,838] Step: 1638| lr: 0.6256 | Time: 13.93s |TRAIN loss  0.0102 | TRAIN Acc:  99.88% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:49:15,891] Gradient total norm was 0.3868825137615204. Clipping to 0.25.
[2023-03-17 23:49:15,894] Step: 1639| lr: 0.6254 | Time: 14.04s |TRAIN loss  0.0097 | TRAIN Acc:  99.96% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:49:29,811] Gradient total norm was 0.41675135493278503. Clipping to 0.25.
[2023-03-17 23:49:29,815] Step: 1640| lr: 0.6251 | Time: 13.91s |TRAIN loss  0.0095 | TRAIN Acc:  99.95% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:49:43,785] Gradient total norm was 0.49330100417137146. Clipping to 0.25.
[2023-03-17 23:49:43,788] Step: 1641| lr: 0.6248 | Time: 13.96s |TRAIN loss  0.0106 | TRAIN Acc:  99.93% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:49:57,767] Gradient total norm was 0.5648618936538696. Clipping to 0.25.
[2023-03-17 23:49:57,770] Step: 1642| lr: 0.6246 | Time: 13.97s |TRAIN loss  0.0121 | TRAIN Acc:  99.85% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:50:11,737] Gradient total norm was 0.5026570558547974. Clipping to 0.25.
[2023-03-17 23:50:11,740] Step: 1643| lr: 0.6243 | Time: 13.96s |TRAIN loss  0.0110 | TRAIN Acc:  99.89% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:50:25,782] Gradient total norm was 0.3544870913028717. Clipping to 0.25.
[2023-03-17 23:50:25,786] Step: 1644| lr: 0.6241 | Time: 14.03s |TRAIN loss  0.0112 | TRAIN Acc:  99.94% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:50:39,708] Gradient total norm was 0.28842979669570923. Clipping to 0.25.
[2023-03-17 23:50:39,711] Step: 1645| lr: 0.6238 | Time: 13.91s |TRAIN loss  0.0090 | TRAIN Acc:  99.97% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:50:53,661] Gradient total norm was 0.26159438490867615. Clipping to 0.25.
[2023-03-17 23:50:53,665] Step: 1646| lr: 0.6235 | Time: 13.94s |TRAIN loss  0.0077 | TRAIN Acc:  99.98% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:51:07,616] Gradient total norm was 0.5935115814208984. Clipping to 0.25.
[2023-03-17 23:51:07,619] Step: 1647| lr: 0.6233 | Time: 13.94s |TRAIN loss  0.0070 | TRAIN Acc:  99.98% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:51:21,559] Gradient total norm was 2.4228615760803223. Clipping to 0.25.
[2023-03-17 23:51:21,562] Step: 1648| lr: 0.6230 | Time: 13.93s |TRAIN loss  0.0162 | TRAIN Acc:  99.64% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:51:35,597] Gradient total norm was 0.7640076279640198. Clipping to 0.25.
[2023-03-17 23:51:35,600] Step: 1649| lr: 0.6228 | Time: 14.02s |TRAIN loss  0.0126 | TRAIN Acc:  99.86% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:51:49,446] Gradient total norm was 0.5602095127105713. Clipping to 0.25.
[2023-03-17 23:51:49,450] Step: 1650| lr: 0.6225 | Time: 13.84s |TRAIN loss  0.0093 | TRAIN Acc:  99.94% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:52:03,359] Gradient total norm was 0.8423285484313965. Clipping to 0.25.
[2023-03-17 23:52:03,362] Step: 1651| lr: 0.6222 | Time: 13.90s |TRAIN loss  0.0130 | TRAIN Acc:  99.89% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:52:17,291] Gradient total norm was 1.4513391256332397. Clipping to 0.25.
[2023-03-17 23:52:17,294] Step: 1652| lr: 0.6220 | Time: 13.92s |TRAIN loss  0.0200 | TRAIN Acc:  99.59% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:52:31,233] Gradient total norm was 0.5178213119506836. Clipping to 0.25.
[2023-03-17 23:52:31,236] Step: 1653| lr: 0.6217 | Time: 13.93s |TRAIN loss  0.0159 | TRAIN Acc:  99.85% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:52:45,212] Gradient total norm was 0.43857088685035706. Clipping to 0.25.
[2023-03-17 23:52:45,216] Step: 1654| lr: 0.6214 | Time: 13.97s |TRAIN loss  0.0159 | TRAIN Acc:  99.86% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:52:59,130] Gradient total norm was 0.35654735565185547. Clipping to 0.25.
[2023-03-17 23:52:59,133] Step: 1655| lr: 0.6212 | Time: 13.90s |TRAIN loss  0.0131 | TRAIN Acc:  99.91% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:53:13,156] Gradient total norm was 0.3876749277114868. Clipping to 0.25.
[2023-03-17 23:53:13,159] Step: 1656| lr: 0.6209 | Time: 14.01s |TRAIN loss  0.0107 | TRAIN Acc:  99.97% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:53:27,220] Gradient total norm was 0.5691992044448853. Clipping to 0.25.
[2023-03-17 23:53:27,224] Step: 1657| lr: 0.6207 | Time: 14.05s |TRAIN loss  0.0098 | TRAIN Acc:  99.95% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:53:41,132] Gradient total norm was 2.1364846229553223. Clipping to 0.25.
[2023-03-17 23:53:41,135] Step: 1658| lr: 0.6204 | Time: 13.90s |TRAIN loss  0.0252 | TRAIN Acc:  99.32% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:53:55,069] Gradient total norm was 0.7034475803375244. Clipping to 0.25.
[2023-03-17 23:53:55,072] Step: 1659| lr: 0.6201 | Time: 13.92s |TRAIN loss  0.0150 | TRAIN Acc:  99.84% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:54:09,066] Gradient total norm was 0.5005828142166138. Clipping to 0.25.
[2023-03-17 23:54:09,069] Step: 1660| lr: 0.6199 | Time: 13.98s |TRAIN loss  0.0153 | TRAIN Acc:  99.84% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:54:22,962] Gradient total norm was 0.6573758125305176. Clipping to 0.25.
[2023-03-17 23:54:22,966] Step: 1661| lr: 0.6196 | Time: 13.88s |TRAIN loss  0.0207 | TRAIN Acc:  99.58% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:54:36,907] Gradient total norm was 0.34864598512649536. Clipping to 0.25.
[2023-03-17 23:54:36,910] Step: 1662| lr: 0.6193 | Time: 13.93s |TRAIN loss  0.0170 | TRAIN Acc:  99.85% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:54:50,774] Gradient total norm was 0.32151615619659424. Clipping to 0.25.
[2023-03-17 23:54:50,777] Step: 1663| lr: 0.6191 | Time: 13.85s |TRAIN loss  0.0135 | TRAIN Acc:  99.88% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:55:04,754] Gradient total norm was 0.3439454734325409. Clipping to 0.25.
[2023-03-17 23:55:04,757] Step: 1664| lr: 0.6188 | Time: 13.97s |TRAIN loss  0.0117 | TRAIN Acc:  99.93% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:55:18,793] Gradient total norm was 0.3027001917362213. Clipping to 0.25.
[2023-03-17 23:55:18,796] Step: 1665| lr: 0.6186 | Time: 14.03s |TRAIN loss  0.0095 | TRAIN Acc:  99.96% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:55:32,723] Gradient total norm was 0.3194897174835205. Clipping to 0.25.
[2023-03-17 23:55:32,727] Step: 1666| lr: 0.6183 | Time: 13.92s |TRAIN loss  0.0081 | TRAIN Acc:  99.98% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:55:46,621] Gradient total norm was 0.40049049258232117. Clipping to 0.25.
[2023-03-17 23:55:46,624] Step: 1667| lr: 0.6180 | Time: 13.88s |TRAIN loss  0.0070 | TRAIN Acc:  99.99% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:56:00,537] Gradient total norm was 1.2277635335922241. Clipping to 0.25.
[2023-03-17 23:56:00,540] Step: 1668| lr: 0.6178 | Time: 13.90s |TRAIN loss  0.0088 | TRAIN Acc:  99.90% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:56:14,515] Gradient total norm was 1.0071648359298706. Clipping to 0.25.
[2023-03-17 23:56:14,518] Step: 1669| lr: 0.6175 | Time: 13.96s |TRAIN loss  0.0118 | TRAIN Acc:  99.84% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:56:28,439] Gradient total norm was 0.9092753529548645. Clipping to 0.25.
[2023-03-17 23:56:28,443] Step: 1670| lr: 0.6172 | Time: 13.91s |TRAIN loss  0.0134 | TRAIN Acc:  99.83% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:56:42,372] Gradient total norm was 0.7425951957702637. Clipping to 0.25.
[2023-03-17 23:56:42,375] Step: 1671| lr: 0.6170 | Time: 13.92s |TRAIN loss  0.0198 | TRAIN Acc:  99.66% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:56:56,369] Gradient total norm was 0.43586015701293945. Clipping to 0.25.
[2023-03-17 23:56:56,372] Step: 1672| lr: 0.6167 | Time: 13.98s |TRAIN loss  0.0126 | TRAIN Acc:  99.94% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:57:10,318] Gradient total norm was 0.5673250555992126. Clipping to 0.25.
[2023-03-17 23:57:10,321] Step: 1673| lr: 0.6164 | Time: 13.94s |TRAIN loss  0.0141 | TRAIN Acc:  99.98% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:57:24,218] Gradient total norm was 0.8510741591453552. Clipping to 0.25.
[2023-03-17 23:57:24,221] Step: 1674| lr: 0.6162 | Time: 13.89s |TRAIN loss  0.0111 | TRAIN Acc:  99.95% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:57:38,215] Gradient total norm was 0.5604180097579956. Clipping to 0.25.
[2023-03-17 23:57:38,219] Step: 1675| lr: 0.6159 | Time: 13.98s |TRAIN loss  0.0116 | TRAIN Acc:  99.97% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:57:52,165] Gradient total norm was 0.8310204744338989. Clipping to 0.25.
[2023-03-17 23:57:52,169] Step: 1676| lr: 0.6157 | Time: 13.94s |TRAIN loss  0.0116 | TRAIN Acc:  99.91% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:58:06,131] Gradient total norm was 0.4942519962787628. Clipping to 0.25.
[2023-03-17 23:58:06,134] Step: 1677| lr: 0.6154 | Time: 13.95s |TRAIN loss  0.0115 | TRAIN Acc:  99.95% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:58:20,082] Gradient total norm was 0.43493467569351196. Clipping to 0.25.
[2023-03-17 23:58:20,086] Step: 1678| lr: 0.6151 | Time: 13.94s |TRAIN loss  0.0110 | TRAIN Acc:  99.98% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:58:33,980] Gradient total norm was 0.4510228931903839. Clipping to 0.25.
[2023-03-17 23:58:33,983] Step: 1679| lr: 0.6149 | Time: 13.88s |TRAIN loss  0.0096 | TRAIN Acc:  99.98% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:58:47,855] Gradient total norm was 0.3702033460140228. Clipping to 0.25.
[2023-03-17 23:58:47,859] Step: 1680| lr: 0.6146 | Time: 13.86s |TRAIN loss  0.0090 | TRAIN Acc:  99.98% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:59:01,811] Gradient total norm was 0.5768014192581177. Clipping to 0.25.
[2023-03-17 23:59:01,814] Step: 1681| lr: 0.6143 | Time: 13.94s |TRAIN loss  0.0087 | TRAIN Acc:  99.97% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:59:15,728] Gradient total norm was 0.574282705783844. Clipping to 0.25.
[2023-03-17 23:59:15,731] Step: 1682| lr: 0.6141 | Time: 13.90s |TRAIN loss  0.0096 | TRAIN Acc:  99.95% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:59:30,417] Gradient total norm was 0.35713258385658264. Clipping to 0.25.
[2023-03-17 23:59:30,420] Step: 1683| lr: 0.6138 | Time: 14.67s |TRAIN loss  0.0089 | TRAIN Acc:  99.98% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:59:45,241] Gradient total norm was 0.6405079960823059. Clipping to 0.25.
[2023-03-17 23:59:45,245] Step: 1684| lr: 0.6135 | Time: 14.81s |TRAIN loss  0.0100 | TRAIN Acc:  99.91% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-17 23:59:59,471] Gradient total norm was 0.3520025908946991. Clipping to 0.25.
[2023-03-17 23:59:59,474] Step: 1685| lr: 0.6133 | Time: 14.22s |TRAIN loss  0.0094 | TRAIN Acc:  99.96% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-18 00:00:14,194] Gradient total norm was 0.2920152246952057. Clipping to 0.25.
[2023-03-18 00:00:14,198] Step: 1686| lr: 0.6130 | Time: 14.71s |TRAIN loss  0.0079 | TRAIN Acc:  99.99% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-18 00:00:28,823] Gradient total norm was 1.5839636325836182. Clipping to 0.25.
[2023-03-18 00:00:28,826] Step: 1687| lr: 0.6127 | Time: 14.61s |TRAIN loss  0.0128 | TRAIN Acc:  99.77% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-18 00:00:44,216] Gradient total norm was 0.6596825122833252. Clipping to 0.25.
[2023-03-18 00:00:44,220] Step: 1688| lr: 0.6125 | Time: 15.38s |TRAIN loss  0.0155 | TRAIN Acc:  99.72% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-18 00:00:58,955] Gradient total norm was 0.34353700280189514. Clipping to 0.25.
[2023-03-18 00:00:58,958] Step: 1689| lr: 0.6122 | Time: 14.72s |TRAIN loss  0.0110 | TRAIN Acc:  99.97% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-18 00:01:13,924] Gradient total norm was 0.39661723375320435. Clipping to 0.25.
[2023-03-18 00:01:13,928] Step: 1690| lr: 0.6119 | Time: 14.96s |TRAIN loss  0.0113 | TRAIN Acc:  99.88% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-18 00:01:28,697] Gradient total norm was 0.45618751645088196. Clipping to 0.25.
[2023-03-18 00:01:28,701] Step: 1691| lr: 0.6117 | Time: 14.76s |TRAIN loss  0.0105 | TRAIN Acc:  99.99% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-18 00:01:43,044] Gradient total norm was 0.43928536772727966. Clipping to 0.25.
[2023-03-18 00:01:43,048] Step: 1692| lr: 0.6114 | Time: 14.33s |TRAIN loss  0.0103 | TRAIN Acc:  99.93% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-18 00:01:58,380] Gradient total norm was 0.5447763800621033. Clipping to 0.25.
[2023-03-18 00:01:58,384] Step: 1693| lr: 0.6111 | Time: 15.32s |TRAIN loss  0.0099 | TRAIN Acc:  99.92% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-18 00:02:13,321] Gradient total norm was 0.44477227330207825. Clipping to 0.25.
[2023-03-18 00:02:13,324] Step: 1694| lr: 0.6109 | Time: 14.93s |TRAIN loss  0.0112 | TRAIN Acc:  99.88% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-18 00:02:28,636] Gradient total norm was 0.30962085723876953. Clipping to 0.25.
[2023-03-18 00:02:28,639] Step: 1695| lr: 0.6106 | Time: 15.30s |TRAIN loss  0.0092 | TRAIN Acc:  99.96% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-18 00:02:42,973] Gradient total norm was 0.36916297674179077. Clipping to 0.25.
[2023-03-18 00:02:42,977] Step: 1696| lr: 0.6103 | Time: 14.32s |TRAIN loss  0.0082 | TRAIN Acc:  99.98% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-18 00:02:57,355] Gradient total norm was 0.3392719626426697. Clipping to 0.25.
[2023-03-18 00:02:57,358] Step: 1697| lr: 0.6101 | Time: 14.37s |TRAIN loss  0.0083 | TRAIN Acc:  99.98% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-18 00:03:11,296] Gradient total norm was 0.4154103994369507. Clipping to 0.25.
[2023-03-18 00:03:11,299] Step: 1698| lr: 0.6098 | Time: 13.93s |TRAIN loss  0.0076 | TRAIN Acc:  99.97% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-18 00:03:25,171] Gradient total norm was 0.5616350769996643. Clipping to 0.25.
[2023-03-18 00:03:25,174] Step: 1699| lr: 0.6095 | Time: 13.86s |TRAIN loss  0.0079 | TRAIN Acc:  99.97% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-18 00:03:38,994] Gradient total norm was 0.5598030686378479. Clipping to 0.25.
[2023-03-18 00:03:38,998] Step: 1700| lr: 0.6093 | Time: 13.81s |TRAIN loss  0.0090 | TRAIN Acc:  99.95% |VAL loss  0.5189 | VAL Acc:  85.07% |
[2023-03-18 00:03:52,810] Gradient total norm was 0.7731563448905945. Clipping to 0.25.
[2023-03-18 00:03:58,312] Step: 1701| lr: 0.6090 | Time: 13.80s |TRAIN loss  0.0097 | TRAIN Acc:  99.91% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:04:12,206] Gradient total norm was 0.455598920583725. Clipping to 0.25.
[2023-03-18 00:04:12,209] Step: 1702| lr: 0.6087 | Time: 13.88s |TRAIN loss  0.0103 | TRAIN Acc:  99.96% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:04:26,062] Gradient total norm was 0.38659754395484924. Clipping to 0.25.
[2023-03-18 00:04:26,065] Step: 1703| lr: 0.6085 | Time: 13.84s |TRAIN loss  0.0092 | TRAIN Acc:  99.97% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:04:39,959] Gradient total norm was 0.340291827917099. Clipping to 0.25.
[2023-03-18 00:04:39,962] Step: 1704| lr: 0.6082 | Time: 13.88s |TRAIN loss  0.0081 | TRAIN Acc:  99.98% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:04:53,883] Gradient total norm was 0.36986207962036133. Clipping to 0.25.
[2023-03-18 00:04:53,887] Step: 1705| lr: 0.6079 | Time: 13.91s |TRAIN loss  0.0073 | TRAIN Acc:  99.99% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:05:07,747] Gradient total norm was 0.798431396484375. Clipping to 0.25.
[2023-03-18 00:05:07,751] Step: 1706| lr: 0.6077 | Time: 13.85s |TRAIN loss  0.0089 | TRAIN Acc:  99.90% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:05:21,705] Gradient total norm was 0.9699623584747314. Clipping to 0.25.
[2023-03-18 00:05:21,708] Step: 1707| lr: 0.6074 | Time: 13.94s |TRAIN loss  0.0119 | TRAIN Acc:  99.86% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:05:35,585] Gradient total norm was 0.6046427488327026. Clipping to 0.25.
[2023-03-18 00:05:35,589] Step: 1708| lr: 0.6071 | Time: 13.87s |TRAIN loss  0.0109 | TRAIN Acc:  99.91% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:05:49,480] Gradient total norm was 0.49613654613494873. Clipping to 0.25.
[2023-03-18 00:05:49,484] Step: 1709| lr: 0.6069 | Time: 13.88s |TRAIN loss  0.0138 | TRAIN Acc:  99.92% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:06:03,457] Gradient total norm was 0.4202808141708374. Clipping to 0.25.
[2023-03-18 00:06:03,461] Step: 1710| lr: 0.6066 | Time: 13.96s |TRAIN loss  0.0117 | TRAIN Acc:  99.94% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:06:17,352] Gradient total norm was 0.3133346140384674. Clipping to 0.25.
[2023-03-18 00:06:17,355] Step: 1711| lr: 0.6063 | Time: 13.88s |TRAIN loss  0.0110 | TRAIN Acc:  99.97% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:06:31,282] Gradient total norm was 0.27310577034950256. Clipping to 0.25.
[2023-03-18 00:06:31,285] Step: 1712| lr: 0.6060 | Time: 13.92s |TRAIN loss  0.0090 | TRAIN Acc:  99.98% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:06:45,191] Gradient total norm was 0.33238935470581055. Clipping to 0.25.
[2023-03-18 00:06:45,194] Step: 1713| lr: 0.6058 | Time: 13.90s |TRAIN loss  0.0080 | TRAIN Acc:  99.99% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:06:59,147] Gradient total norm was 0.26804912090301514. Clipping to 0.25.
[2023-03-18 00:06:59,150] Step: 1714| lr: 0.6055 | Time: 13.94s |TRAIN loss  0.0066 | TRAIN Acc:  99.99% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:07:13,042] Gradient total norm was 0.27692896127700806. Clipping to 0.25.
[2023-03-18 00:07:13,045] Step: 1715| lr: 0.6052 | Time: 13.88s |TRAIN loss  0.0060 | TRAIN Acc:  99.98% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:07:26,976] Gradient total norm was 0.3810960054397583. Clipping to 0.25.
[2023-03-18 00:07:26,980] Step: 1716| lr: 0.6050 | Time: 13.92s |TRAIN loss  0.0055 | TRAIN Acc:  99.99% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:07:41,000] Gradient total norm was 0.8974018692970276. Clipping to 0.25.
[2023-03-18 00:07:41,004] Step: 1717| lr: 0.6047 | Time: 14.01s |TRAIN loss  0.0086 | TRAIN Acc:  99.87% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:07:54,916] Gradient total norm was 0.6567364931106567. Clipping to 0.25.
[2023-03-18 00:07:54,919] Step: 1718| lr: 0.6044 | Time: 13.90s |TRAIN loss  0.0094 | TRAIN Acc:  99.89% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:08:08,901] Gradient total norm was 0.5991105437278748. Clipping to 0.25.
[2023-03-18 00:08:08,904] Step: 1719| lr: 0.6042 | Time: 13.97s |TRAIN loss  0.0111 | TRAIN Acc:  99.82% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:08:22,796] Gradient total norm was 0.5842623710632324. Clipping to 0.25.
[2023-03-18 00:08:22,800] Step: 1720| lr: 0.6039 | Time: 13.88s |TRAIN loss  0.0128 | TRAIN Acc:  99.76% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:08:36,749] Gradient total norm was 0.3280046582221985. Clipping to 0.25.
[2023-03-18 00:08:36,753] Step: 1721| lr: 0.6036 | Time: 13.94s |TRAIN loss  0.0110 | TRAIN Acc:  99.91% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:08:50,777] Gradient total norm was 0.3331092894077301. Clipping to 0.25.
[2023-03-18 00:08:50,780] Step: 1722| lr: 0.6033 | Time: 14.01s |TRAIN loss  0.0093 | TRAIN Acc:  99.95% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:09:04,724] Step: 1723| lr: 0.6031 | Time: 13.93s |TRAIN loss  0.0073 | TRAIN Acc:  99.99% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:09:18,656] Gradient total norm was 0.4590113162994385. Clipping to 0.25.
[2023-03-18 00:09:18,659] Step: 1724| lr: 0.6028 | Time: 13.92s |TRAIN loss  0.0059 | TRAIN Acc:  99.99% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:09:32,593] Gradient total norm was 0.8634095788002014. Clipping to 0.25.
[2023-03-18 00:09:32,596] Step: 1725| lr: 0.6025 | Time: 13.92s |TRAIN loss  0.0082 | TRAIN Acc:  99.91% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:09:46,494] Gradient total norm was 2.1522104740142822. Clipping to 0.25.
[2023-03-18 00:09:46,497] Step: 1726| lr: 0.6023 | Time: 13.89s |TRAIN loss  0.0161 | TRAIN Acc:  99.60% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:10:00,542] Gradient total norm was 0.7697880864143372. Clipping to 0.25.
[2023-03-18 00:10:00,546] Step: 1727| lr: 0.6020 | Time: 14.04s |TRAIN loss  0.0148 | TRAIN Acc:  99.76% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:10:14,463] Gradient total norm was 0.6057186126708984. Clipping to 0.25.
[2023-03-18 00:10:14,467] Step: 1728| lr: 0.6017 | Time: 13.91s |TRAIN loss  0.0140 | TRAIN Acc:  99.83% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:10:28,364] Gradient total norm was 0.4906948506832123. Clipping to 0.25.
[2023-03-18 00:10:28,367] Step: 1729| lr: 0.6014 | Time: 13.89s |TRAIN loss  0.0149 | TRAIN Acc:  99.85% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:10:42,397] Gradient total norm was 0.3414689898490906. Clipping to 0.25.
[2023-03-18 00:10:42,400] Step: 1730| lr: 0.6012 | Time: 14.02s |TRAIN loss  0.0114 | TRAIN Acc:  99.95% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:10:56,384] Gradient total norm was 0.3439408838748932. Clipping to 0.25.
[2023-03-18 00:10:56,388] Step: 1731| lr: 0.6009 | Time: 13.97s |TRAIN loss  0.0088 | TRAIN Acc:  99.98% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:11:10,334] Gradient total norm was 0.2909819483757019. Clipping to 0.25.
[2023-03-18 00:11:10,337] Step: 1732| lr: 0.6006 | Time: 13.94s |TRAIN loss  0.0075 | TRAIN Acc:  99.99% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:11:24,268] Gradient total norm was 0.30866479873657227. Clipping to 0.25.
[2023-03-18 00:11:24,271] Step: 1733| lr: 0.6004 | Time: 13.92s |TRAIN loss  0.0065 | TRAIN Acc:  99.99% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:11:38,238] Gradient total norm was 0.7087737321853638. Clipping to 0.25.
[2023-03-18 00:11:38,242] Step: 1734| lr: 0.6001 | Time: 13.96s |TRAIN loss  0.0076 | TRAIN Acc:  99.96% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:11:52,170] Gradient total norm was 2.178860664367676. Clipping to 0.25.
[2023-03-18 00:11:52,173] Step: 1735| lr: 0.5998 | Time: 13.92s |TRAIN loss  0.0228 | TRAIN Acc:  99.28% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:12:06,118] Gradient total norm was 0.6503214836120605. Clipping to 0.25.
[2023-03-18 00:12:06,121] Step: 1736| lr: 0.5995 | Time: 13.93s |TRAIN loss  0.0124 | TRAIN Acc:  99.93% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:12:20,078] Gradient total norm was 0.6532055735588074. Clipping to 0.25.
[2023-03-18 00:12:20,082] Step: 1737| lr: 0.5993 | Time: 13.95s |TRAIN loss  0.0092 | TRAIN Acc:  99.98% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:12:34,040] Gradient total norm was 0.4920438230037689. Clipping to 0.25.
[2023-03-18 00:12:34,043] Step: 1738| lr: 0.5990 | Time: 13.95s |TRAIN loss  0.0107 | TRAIN Acc:  99.98% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:12:47,995] Gradient total norm was 0.5162332057952881. Clipping to 0.25.
[2023-03-18 00:12:47,999] Step: 1739| lr: 0.5987 | Time: 13.94s |TRAIN loss  0.0098 | TRAIN Acc:  99.97% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:13:01,953] Gradient total norm was 0.2833176255226135. Clipping to 0.25.
[2023-03-18 00:13:01,956] Step: 1740| lr: 0.5985 | Time: 13.94s |TRAIN loss  0.0087 | TRAIN Acc:  99.99% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:13:15,887] Gradient total norm was 0.258851557970047. Clipping to 0.25.
[2023-03-18 00:13:15,890] Step: 1741| lr: 0.5982 | Time: 13.92s |TRAIN loss  0.0074 | TRAIN Acc:  99.99% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:13:29,827] Step: 1742| lr: 0.5979 | Time: 13.93s |TRAIN loss  0.0066 | TRAIN Acc:  99.99% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:13:43,783] Gradient total norm was 0.26070520281791687. Clipping to 0.25.
[2023-03-18 00:13:43,787] Step: 1743| lr: 0.5976 | Time: 13.95s |TRAIN loss  0.0060 | TRAIN Acc: 100.00% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:13:57,813] Gradient total norm was 0.304229736328125. Clipping to 0.25.
[2023-03-18 00:13:57,816] Step: 1744| lr: 0.5974 | Time: 14.02s |TRAIN loss  0.0054 | TRAIN Acc:  99.99% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:14:11,794] Gradient total norm was 0.5149633884429932. Clipping to 0.25.
[2023-03-18 00:14:11,797] Step: 1745| lr: 0.5971 | Time: 13.97s |TRAIN loss  0.0063 | TRAIN Acc:  99.98% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:14:25,742] Gradient total norm was 0.819239616394043. Clipping to 0.25.
[2023-03-18 00:14:25,745] Step: 1746| lr: 0.5968 | Time: 13.93s |TRAIN loss  0.0066 | TRAIN Acc:  99.97% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:14:39,779] Gradient total norm was 0.6532976031303406. Clipping to 0.25.
[2023-03-18 00:14:39,782] Step: 1747| lr: 0.5965 | Time: 14.02s |TRAIN loss  0.0071 | TRAIN Acc:  99.95% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:14:53,743] Gradient total norm was 0.6201893091201782. Clipping to 0.25.
[2023-03-18 00:14:53,747] Step: 1748| lr: 0.5963 | Time: 13.95s |TRAIN loss  0.0076 | TRAIN Acc:  99.95% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:15:07,713] Gradient total norm was 0.48695626854896545. Clipping to 0.25.
[2023-03-18 00:15:07,716] Step: 1749| lr: 0.5960 | Time: 13.96s |TRAIN loss  0.0084 | TRAIN Acc:  99.97% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:15:21,690] Gradient total norm was 0.3729817271232605. Clipping to 0.25.
[2023-03-18 00:15:21,693] Step: 1750| lr: 0.5957 | Time: 13.96s |TRAIN loss  0.0069 | TRAIN Acc:  99.99% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:15:35,690] Gradient total norm was 0.42110180854797363. Clipping to 0.25.
[2023-03-18 00:15:35,693] Step: 1751| lr: 0.5954 | Time: 13.99s |TRAIN loss  0.0078 | TRAIN Acc:  99.99% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:15:49,674] Gradient total norm was 0.4714556038379669. Clipping to 0.25.
[2023-03-18 00:15:49,677] Step: 1752| lr: 0.5952 | Time: 13.97s |TRAIN loss  0.0069 | TRAIN Acc:  99.98% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:16:03,622] Gradient total norm was 0.4775836169719696. Clipping to 0.25.
[2023-03-18 00:16:03,625] Step: 1753| lr: 0.5949 | Time: 13.93s |TRAIN loss  0.0075 | TRAIN Acc:  99.98% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:16:17,594] Gradient total norm was 0.4733995199203491. Clipping to 0.25.
[2023-03-18 00:16:17,598] Step: 1754| lr: 0.5946 | Time: 13.96s |TRAIN loss  0.0076 | TRAIN Acc:  99.97% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:16:31,506] Gradient total norm was 0.5025455951690674. Clipping to 0.25.
[2023-03-18 00:16:31,509] Step: 1755| lr: 0.5944 | Time: 13.90s |TRAIN loss  0.0076 | TRAIN Acc:  99.98% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:16:45,488] Gradient total norm was 0.46852463483810425. Clipping to 0.25.
[2023-03-18 00:16:45,491] Step: 1756| lr: 0.5941 | Time: 13.97s |TRAIN loss  0.0079 | TRAIN Acc:  99.98% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:16:59,420] Gradient total norm was 0.5602290630340576. Clipping to 0.25.
[2023-03-18 00:16:59,423] Step: 1757| lr: 0.5938 | Time: 13.92s |TRAIN loss  0.0087 | TRAIN Acc:  99.95% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:17:13,349] Gradient total norm was 0.49920082092285156. Clipping to 0.25.
[2023-03-18 00:17:13,352] Step: 1758| lr: 0.5935 | Time: 13.92s |TRAIN loss  0.0099 | TRAIN Acc:  99.91% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:17:27,368] Gradient total norm was 0.4249840974807739. Clipping to 0.25.
[2023-03-18 00:17:27,371] Step: 1759| lr: 0.5933 | Time: 14.01s |TRAIN loss  0.0110 | TRAIN Acc:  99.91% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:17:41,350] Gradient total norm was 0.3726072311401367. Clipping to 0.25.
[2023-03-18 00:17:41,353] Step: 1760| lr: 0.5930 | Time: 13.97s |TRAIN loss  0.0101 | TRAIN Acc:  99.94% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:17:55,363] Gradient total norm was 0.3395307660102844. Clipping to 0.25.
[2023-03-18 00:17:55,366] Step: 1761| lr: 0.5927 | Time: 14.00s |TRAIN loss  0.0094 | TRAIN Acc:  99.98% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:18:09,254] Step: 1762| lr: 0.5924 | Time: 13.88s |TRAIN loss  0.0072 | TRAIN Acc:  99.99% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:18:23,274] Step: 1763| lr: 0.5922 | Time: 14.01s |TRAIN loss  0.0062 | TRAIN Acc: 100.00% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:18:37,276] Step: 1764| lr: 0.5919 | Time: 13.99s |TRAIN loss  0.0048 | TRAIN Acc: 100.00% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:18:51,209] Step: 1765| lr: 0.5916 | Time: 13.92s |TRAIN loss  0.0044 | TRAIN Acc: 100.00% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:19:05,155] Gradient total norm was 0.9728201627731323. Clipping to 0.25.
[2023-03-18 00:19:05,158] Step: 1766| lr: 0.5913 | Time: 13.93s |TRAIN loss  0.0074 | TRAIN Acc:  99.88% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:19:19,051] Gradient total norm was 0.5252864360809326. Clipping to 0.25.
[2023-03-18 00:19:19,054] Step: 1767| lr: 0.5910 | Time: 13.88s |TRAIN loss  0.0074 | TRAIN Acc:  99.92% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:19:32,952] Gradient total norm was 0.622619092464447. Clipping to 0.25.
[2023-03-18 00:19:32,955] Step: 1768| lr: 0.5908 | Time: 13.88s |TRAIN loss  0.0083 | TRAIN Acc:  99.91% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:19:46,950] Gradient total norm was 0.5566600561141968. Clipping to 0.25.
[2023-03-18 00:19:46,955] Step: 1769| lr: 0.5905 | Time: 13.98s |TRAIN loss  0.0092 | TRAIN Acc:  99.93% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:20:00,913] Gradient total norm was 0.5705428123474121. Clipping to 0.25.
[2023-03-18 00:20:00,917] Step: 1770| lr: 0.5902 | Time: 13.95s |TRAIN loss  0.0101 | TRAIN Acc:  99.89% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:20:14,866] Gradient total norm was 0.42183801531791687. Clipping to 0.25.
[2023-03-18 00:20:14,870] Step: 1771| lr: 0.5899 | Time: 13.94s |TRAIN loss  0.0119 | TRAIN Acc:  99.93% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:20:28,833] Gradient total norm was 0.4340926706790924. Clipping to 0.25.
[2023-03-18 00:20:28,837] Step: 1772| lr: 0.5897 | Time: 13.95s |TRAIN loss  0.0108 | TRAIN Acc:  99.90% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:20:42,765] Gradient total norm was 0.5021726489067078. Clipping to 0.25.
[2023-03-18 00:20:42,768] Step: 1773| lr: 0.5894 | Time: 13.92s |TRAIN loss  0.0112 | TRAIN Acc:  99.91% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:20:56,719] Gradient total norm was 0.3423873484134674. Clipping to 0.25.
[2023-03-18 00:20:56,722] Step: 1774| lr: 0.5891 | Time: 13.94s |TRAIN loss  0.0115 | TRAIN Acc:  99.96% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:21:10,649] Gradient total norm was 0.26271623373031616. Clipping to 0.25.
[2023-03-18 00:21:10,652] Step: 1775| lr: 0.5888 | Time: 13.92s |TRAIN loss  0.0077 | TRAIN Acc:  99.99% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:21:24,581] Gradient total norm was 0.5669524669647217. Clipping to 0.25.
[2023-03-18 00:21:24,585] Step: 1776| lr: 0.5886 | Time: 13.92s |TRAIN loss  0.0074 | TRAIN Acc:  99.95% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:21:38,552] Gradient total norm was 1.9570059776306152. Clipping to 0.25.
[2023-03-18 00:21:38,556] Step: 1777| lr: 0.5883 | Time: 13.96s |TRAIN loss  0.0227 | TRAIN Acc:  99.29% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:21:52,492] Gradient total norm was 0.48721176385879517. Clipping to 0.25.
[2023-03-18 00:21:52,497] Step: 1778| lr: 0.5880 | Time: 13.92s |TRAIN loss  0.0117 | TRAIN Acc:  99.83% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:22:06,467] Gradient total norm was 0.453338623046875. Clipping to 0.25.
[2023-03-18 00:22:06,471] Step: 1779| lr: 0.5877 | Time: 13.96s |TRAIN loss  0.0091 | TRAIN Acc:  99.98% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:22:20,401] Gradient total norm was 0.3275202214717865. Clipping to 0.25.
[2023-03-18 00:22:20,405] Step: 1780| lr: 0.5874 | Time: 13.92s |TRAIN loss  0.0101 | TRAIN Acc:  99.86% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:22:34,416] Gradient total norm was 0.37206390500068665. Clipping to 0.25.
[2023-03-18 00:22:34,419] Step: 1781| lr: 0.5872 | Time: 14.00s |TRAIN loss  0.0083 | TRAIN Acc:  99.97% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:22:48,298] Gradient total norm was 0.40736764669418335. Clipping to 0.25.
[2023-03-18 00:22:48,301] Step: 1782| lr: 0.5869 | Time: 13.87s |TRAIN loss  0.0085 | TRAIN Acc:  99.95% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:23:02,236] Gradient total norm was 1.0010615587234497. Clipping to 0.25.
[2023-03-18 00:23:02,239] Step: 1783| lr: 0.5866 | Time: 13.92s |TRAIN loss  0.0105 | TRAIN Acc:  99.87% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:23:16,214] Gradient total norm was 1.5563287734985352. Clipping to 0.25.
[2023-03-18 00:23:16,218] Step: 1784| lr: 0.5863 | Time: 13.96s |TRAIN loss  0.0141 | TRAIN Acc:  99.77% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:23:30,161] Gradient total norm was 0.6452784538269043. Clipping to 0.25.
[2023-03-18 00:23:30,165] Step: 1785| lr: 0.5861 | Time: 13.93s |TRAIN loss  0.0151 | TRAIN Acc:  99.84% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:23:44,094] Gradient total norm was 0.6157242655754089. Clipping to 0.25.
[2023-03-18 00:23:44,097] Step: 1786| lr: 0.5858 | Time: 13.92s |TRAIN loss  0.0117 | TRAIN Acc:  99.95% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:23:58,062] Gradient total norm was 0.7581690549850464. Clipping to 0.25.
[2023-03-18 00:23:58,066] Step: 1787| lr: 0.5855 | Time: 13.95s |TRAIN loss  0.0147 | TRAIN Acc:  99.90% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:24:12,097] Gradient total norm was 0.9105176329612732. Clipping to 0.25.
[2023-03-18 00:24:12,100] Step: 1788| lr: 0.5852 | Time: 14.02s |TRAIN loss  0.0151 | TRAIN Acc:  99.90% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:24:26,063] Gradient total norm was 0.5716364979743958. Clipping to 0.25.
[2023-03-18 00:24:26,066] Step: 1789| lr: 0.5849 | Time: 13.95s |TRAIN loss  0.0146 | TRAIN Acc:  99.91% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:24:40,015] Gradient total norm was 0.5987233519554138. Clipping to 0.25.
[2023-03-18 00:24:40,019] Step: 1790| lr: 0.5847 | Time: 13.94s |TRAIN loss  0.0149 | TRAIN Acc:  99.92% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:24:54,041] Gradient total norm was 0.45959991216659546. Clipping to 0.25.
[2023-03-18 00:24:54,044] Step: 1791| lr: 0.5844 | Time: 14.01s |TRAIN loss  0.0133 | TRAIN Acc:  99.95% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:25:08,016] Gradient total norm was 0.36233675479888916. Clipping to 0.25.
[2023-03-18 00:25:08,019] Step: 1792| lr: 0.5841 | Time: 13.96s |TRAIN loss  0.0112 | TRAIN Acc:  99.99% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:25:21,975] Gradient total norm was 0.32270318269729614. Clipping to 0.25.
[2023-03-18 00:25:21,978] Step: 1793| lr: 0.5838 | Time: 13.95s |TRAIN loss  0.0087 | TRAIN Acc:  99.99% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:25:35,946] Gradient total norm was 0.3367786407470703. Clipping to 0.25.
[2023-03-18 00:25:35,950] Step: 1794| lr: 0.5836 | Time: 13.96s |TRAIN loss  0.0083 | TRAIN Acc:  99.99% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:25:49,891] Gradient total norm was 0.7766749858856201. Clipping to 0.25.
[2023-03-18 00:25:49,894] Step: 1795| lr: 0.5833 | Time: 13.93s |TRAIN loss  0.0083 | TRAIN Acc:  99.94% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:26:03,888] Gradient total norm was 0.5077036619186401. Clipping to 0.25.
[2023-03-18 00:26:03,892] Step: 1796| lr: 0.5830 | Time: 13.98s |TRAIN loss  0.0086 | TRAIN Acc:  99.96% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:26:17,832] Gradient total norm was 0.49070948362350464. Clipping to 0.25.
[2023-03-18 00:26:17,835] Step: 1797| lr: 0.5827 | Time: 13.93s |TRAIN loss  0.0089 | TRAIN Acc:  99.96% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:26:31,828] Gradient total norm was 0.39884528517723083. Clipping to 0.25.
[2023-03-18 00:26:31,832] Step: 1798| lr: 0.5824 | Time: 13.98s |TRAIN loss  0.0102 | TRAIN Acc:  99.93% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:26:45,785] Gradient total norm was 0.2850758731365204. Clipping to 0.25.
[2023-03-18 00:26:45,789] Step: 1799| lr: 0.5822 | Time: 13.94s |TRAIN loss  0.0083 | TRAIN Acc:  99.98% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:26:59,718] Gradient total norm was 0.25904470682144165. Clipping to 0.25.
[2023-03-18 00:26:59,722] Step: 1800| lr: 0.5819 | Time: 13.92s |TRAIN loss  0.0077 | TRAIN Acc:  99.99% |VAL loss  0.3567 | VAL Acc:  89.29% |
[2023-03-18 00:27:13,747] Gradient total norm was 0.4413542151451111. Clipping to 0.25.
[2023-03-18 00:27:19,142] Step: 1801| lr: 0.5816 | Time: 14.01s |TRAIN loss  0.0064 | TRAIN Acc:  99.98% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:27:33,089] Gradient total norm was 0.5168181657791138. Clipping to 0.25.
[2023-03-18 00:27:33,093] Step: 1802| lr: 0.5813 | Time: 13.94s |TRAIN loss  0.0085 | TRAIN Acc:  99.90% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:27:47,045] Gradient total norm was 0.6787076592445374. Clipping to 0.25.
[2023-03-18 00:27:47,048] Step: 1803| lr: 0.5810 | Time: 13.94s |TRAIN loss  0.0094 | TRAIN Acc:  99.94% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:28:00,995] Gradient total norm was 0.6627291440963745. Clipping to 0.25.
[2023-03-18 00:28:00,998] Step: 1804| lr: 0.5808 | Time: 13.94s |TRAIN loss  0.0112 | TRAIN Acc:  99.83% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:28:14,960] Gradient total norm was 0.3666004538536072. Clipping to 0.25.
[2023-03-18 00:28:14,963] Step: 1805| lr: 0.5805 | Time: 13.95s |TRAIN loss  0.0102 | TRAIN Acc:  99.97% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:28:28,913] Gradient total norm was 0.3584900200366974. Clipping to 0.25.
[2023-03-18 00:28:28,917] Step: 1806| lr: 0.5802 | Time: 13.94s |TRAIN loss  0.0095 | TRAIN Acc:  99.97% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:28:42,853] Gradient total norm was 0.4096900522708893. Clipping to 0.25.
[2023-03-18 00:28:42,856] Step: 1807| lr: 0.5799 | Time: 13.93s |TRAIN loss  0.0085 | TRAIN Acc:  99.98% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:28:56,884] Gradient total norm was 0.4899265468120575. Clipping to 0.25.
[2023-03-18 00:28:56,888] Step: 1808| lr: 0.5796 | Time: 14.02s |TRAIN loss  0.0079 | TRAIN Acc:  99.98% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:29:10,900] Gradient total norm was 0.3270031213760376. Clipping to 0.25.
[2023-03-18 00:29:10,904] Step: 1809| lr: 0.5794 | Time: 14.00s |TRAIN loss  0.0074 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:29:24,884] Gradient total norm was 0.3701939880847931. Clipping to 0.25.
[2023-03-18 00:29:24,888] Step: 1810| lr: 0.5791 | Time: 13.97s |TRAIN loss  0.0073 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:29:38,806] Gradient total norm was 0.27639830112457275. Clipping to 0.25.
[2023-03-18 00:29:38,809] Step: 1811| lr: 0.5788 | Time: 13.91s |TRAIN loss  0.0066 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:29:52,740] Gradient total norm was 0.3250941336154938. Clipping to 0.25.
[2023-03-18 00:29:52,743] Step: 1812| lr: 0.5785 | Time: 13.92s |TRAIN loss  0.0060 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:30:06,713] Gradient total norm was 0.5857751965522766. Clipping to 0.25.
[2023-03-18 00:30:06,717] Step: 1813| lr: 0.5782 | Time: 13.96s |TRAIN loss  0.0073 | TRAIN Acc:  99.93% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:30:20,719] Gradient total norm was 0.4130728244781494. Clipping to 0.25.
[2023-03-18 00:30:20,723] Step: 1814| lr: 0.5779 | Time: 13.99s |TRAIN loss  0.0077 | TRAIN Acc:  99.98% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:30:34,687] Gradient total norm was 0.3484218716621399. Clipping to 0.25.
[2023-03-18 00:30:34,690] Step: 1815| lr: 0.5777 | Time: 13.95s |TRAIN loss  0.0071 | TRAIN Acc:  99.98% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:30:48,571] Gradient total norm was 0.32479554414749146. Clipping to 0.25.
[2023-03-18 00:30:48,575] Step: 1816| lr: 0.5774 | Time: 13.87s |TRAIN loss  0.0074 | TRAIN Acc: 100.00% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:31:02,523] Gradient total norm was 0.30243057012557983. Clipping to 0.25.
[2023-03-18 00:31:02,527] Step: 1817| lr: 0.5771 | Time: 13.94s |TRAIN loss  0.0058 | TRAIN Acc: 100.00% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:31:16,459] Gradient total norm was 0.6279747486114502. Clipping to 0.25.
[2023-03-18 00:31:16,462] Step: 1818| lr: 0.5768 | Time: 13.92s |TRAIN loss  0.0071 | TRAIN Acc:  99.97% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:31:30,399] Gradient total norm was 3.3179819583892822. Clipping to 0.25.
[2023-03-18 00:31:30,402] Step: 1819| lr: 0.5765 | Time: 13.93s |TRAIN loss  0.0297 | TRAIN Acc:  99.16% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:31:44,426] Gradient total norm was 0.4999530613422394. Clipping to 0.25.
[2023-03-18 00:31:44,430] Step: 1820| lr: 0.5763 | Time: 14.01s |TRAIN loss  0.0100 | TRAIN Acc:  99.95% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:31:58,389] Gradient total norm was 0.6611739993095398. Clipping to 0.25.
[2023-03-18 00:31:58,392] Step: 1821| lr: 0.5760 | Time: 13.95s |TRAIN loss  0.0113 | TRAIN Acc:  99.87% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:32:12,431] Gradient total norm was 0.8110972046852112. Clipping to 0.25.
[2023-03-18 00:32:12,434] Step: 1822| lr: 0.5757 | Time: 14.03s |TRAIN loss  0.0221 | TRAIN Acc:  99.53% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:32:26,424] Gradient total norm was 0.45609158277511597. Clipping to 0.25.
[2023-03-18 00:32:26,428] Step: 1823| lr: 0.5754 | Time: 13.98s |TRAIN loss  0.0168 | TRAIN Acc:  99.69% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:32:40,393] Gradient total norm was 0.46139290928840637. Clipping to 0.25.
[2023-03-18 00:32:40,396] Step: 1824| lr: 0.5751 | Time: 13.96s |TRAIN loss  0.0172 | TRAIN Acc:  99.85% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:32:54,423] Gradient total norm was 0.5657832622528076. Clipping to 0.25.
[2023-03-18 00:32:54,426] Step: 1825| lr: 0.5748 | Time: 14.02s |TRAIN loss  0.0140 | TRAIN Acc:  99.90% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:33:08,385] Gradient total norm was 1.061691403388977. Clipping to 0.25.
[2023-03-18 00:33:08,389] Step: 1826| lr: 0.5746 | Time: 13.95s |TRAIN loss  0.0159 | TRAIN Acc:  99.77% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:33:22,298] Gradient total norm was 0.467271625995636. Clipping to 0.25.
[2023-03-18 00:33:22,301] Step: 1827| lr: 0.5743 | Time: 13.90s |TRAIN loss  0.0129 | TRAIN Acc:  99.93% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:33:36,254] Gradient total norm was 0.45912379026412964. Clipping to 0.25.
[2023-03-18 00:33:36,257] Step: 1828| lr: 0.5740 | Time: 13.94s |TRAIN loss  0.0121 | TRAIN Acc:  99.94% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:33:50,208] Gradient total norm was 0.3710612952709198. Clipping to 0.25.
[2023-03-18 00:33:50,211] Step: 1829| lr: 0.5737 | Time: 13.94s |TRAIN loss  0.0125 | TRAIN Acc:  99.93% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:34:04,164] Step: 1830| lr: 0.5734 | Time: 13.94s |TRAIN loss  0.0099 | TRAIN Acc:  99.98% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:34:18,226] Step: 1831| lr: 0.5731 | Time: 14.05s |TRAIN loss  0.0081 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:34:32,194] Step: 1832| lr: 0.5729 | Time: 13.96s |TRAIN loss  0.0062 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:34:46,126] Step: 1833| lr: 0.5726 | Time: 13.92s |TRAIN loss  0.0053 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:35:00,074] Step: 1834| lr: 0.5723 | Time: 13.94s |TRAIN loss  0.0048 | TRAIN Acc: 100.00% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:35:13,964] Step: 1835| lr: 0.5720 | Time: 13.88s |TRAIN loss  0.0042 | TRAIN Acc: 100.00% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:35:27,870] Step: 1836| lr: 0.5717 | Time: 13.90s |TRAIN loss  0.0038 | TRAIN Acc: 100.00% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:35:41,796] Step: 1837| lr: 0.5714 | Time: 13.92s |TRAIN loss  0.0036 | TRAIN Acc: 100.00% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:35:55,687] Step: 1838| lr: 0.5712 | Time: 13.88s |TRAIN loss  0.0032 | TRAIN Acc: 100.00% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:36:09,603] Step: 1839| lr: 0.5709 | Time: 13.91s |TRAIN loss  0.0030 | TRAIN Acc: 100.00% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:36:23,634] Step: 1840| lr: 0.5706 | Time: 14.02s |TRAIN loss  0.0029 | TRAIN Acc: 100.00% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:36:37,629] Step: 1841| lr: 0.5703 | Time: 13.99s |TRAIN loss  0.0027 | TRAIN Acc: 100.00% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:36:51,634] Step: 1842| lr: 0.5700 | Time: 14.00s |TRAIN loss  0.0027 | TRAIN Acc: 100.00% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:37:05,570] Step: 1843| lr: 0.5697 | Time: 13.93s |TRAIN loss  0.0027 | TRAIN Acc: 100.00% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:37:19,625] Step: 1844| lr: 0.5695 | Time: 14.05s |TRAIN loss  0.0027 | TRAIN Acc: 100.00% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:37:33,580] Gradient total norm was 0.30314862728118896. Clipping to 0.25.
[2023-03-18 00:37:33,583] Step: 1845| lr: 0.5692 | Time: 13.94s |TRAIN loss  0.0030 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:37:47,514] Gradient total norm was 1.6856439113616943. Clipping to 0.25.
[2023-03-18 00:37:47,517] Step: 1846| lr: 0.5689 | Time: 13.92s |TRAIN loss  0.0078 | TRAIN Acc:  99.84% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:38:01,496] Gradient total norm was 1.313164472579956. Clipping to 0.25.
[2023-03-18 00:38:01,499] Step: 1847| lr: 0.5686 | Time: 13.97s |TRAIN loss  0.0087 | TRAIN Acc:  99.85% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:38:15,417] Gradient total norm was 0.7999524474143982. Clipping to 0.25.
[2023-03-18 00:38:15,420] Step: 1848| lr: 0.5683 | Time: 13.91s |TRAIN loss  0.0108 | TRAIN Acc:  99.77% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:38:29,330] Gradient total norm was 0.44188281893730164. Clipping to 0.25.
[2023-03-18 00:38:29,333] Step: 1849| lr: 0.5680 | Time: 13.90s |TRAIN loss  0.0088 | TRAIN Acc:  99.96% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:38:43,379] Gradient total norm was 0.40173596143722534. Clipping to 0.25.
[2023-03-18 00:38:43,383] Step: 1850| lr: 0.5677 | Time: 14.04s |TRAIN loss  0.0085 | TRAIN Acc:  99.94% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:38:57,313] Gradient total norm was 0.3472771942615509. Clipping to 0.25.
[2023-03-18 00:38:57,317] Step: 1851| lr: 0.5675 | Time: 13.92s |TRAIN loss  0.0064 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:39:11,312] Gradient total norm was 0.4063835144042969. Clipping to 0.25.
[2023-03-18 00:39:11,315] Step: 1852| lr: 0.5672 | Time: 13.98s |TRAIN loss  0.0058 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:39:25,267] Gradient total norm was 0.5047690868377686. Clipping to 0.25.
[2023-03-18 00:39:25,270] Step: 1853| lr: 0.5669 | Time: 13.94s |TRAIN loss  0.0055 | TRAIN Acc:  99.98% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:39:39,238] Gradient total norm was 1.5142492055892944. Clipping to 0.25.
[2023-03-18 00:39:39,241] Step: 1854| lr: 0.5666 | Time: 13.96s |TRAIN loss  0.0092 | TRAIN Acc:  99.85% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:39:53,253] Gradient total norm was 0.5312960147857666. Clipping to 0.25.
[2023-03-18 00:39:53,256] Step: 1855| lr: 0.5663 | Time: 14.00s |TRAIN loss  0.0082 | TRAIN Acc:  99.91% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:40:07,563] Gradient total norm was 0.5540531873703003. Clipping to 0.25.
[2023-03-18 00:40:07,566] Step: 1856| lr: 0.5660 | Time: 14.30s |TRAIN loss  0.0101 | TRAIN Acc:  99.89% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:40:22,060] Gradient total norm was 0.4741067588329315. Clipping to 0.25.
[2023-03-18 00:40:22,063] Step: 1857| lr: 0.5658 | Time: 14.48s |TRAIN loss  0.0132 | TRAIN Acc:  99.68% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:40:36,055] Gradient total norm was 0.39486756920814514. Clipping to 0.25.
[2023-03-18 00:40:36,058] Step: 1858| lr: 0.5655 | Time: 13.98s |TRAIN loss  0.0106 | TRAIN Acc:  99.95% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:40:49,991] Gradient total norm was 0.3469623029232025. Clipping to 0.25.
[2023-03-18 00:40:49,994] Step: 1859| lr: 0.5652 | Time: 13.92s |TRAIN loss  0.0106 | TRAIN Acc:  99.88% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:41:04,021] Gradient total norm was 0.30113834142684937. Clipping to 0.25.
[2023-03-18 00:41:04,024] Step: 1860| lr: 0.5649 | Time: 14.02s |TRAIN loss  0.0094 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:41:18,049] Gradient total norm was 0.6088275909423828. Clipping to 0.25.
[2023-03-18 00:41:18,052] Step: 1861| lr: 0.5646 | Time: 14.01s |TRAIN loss  0.0078 | TRAIN Acc:  99.97% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:41:32,000] Gradient total norm was 1.2937953472137451. Clipping to 0.25.
[2023-03-18 00:41:32,003] Step: 1862| lr: 0.5643 | Time: 13.94s |TRAIN loss  0.0153 | TRAIN Acc:  99.72% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:41:45,936] Gradient total norm was 0.6586268544197083. Clipping to 0.25.
[2023-03-18 00:41:45,940] Step: 1863| lr: 0.5640 | Time: 13.92s |TRAIN loss  0.0124 | TRAIN Acc:  99.88% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:41:59,946] Gradient total norm was 0.4576711058616638. Clipping to 0.25.
[2023-03-18 00:41:59,949] Step: 1864| lr: 0.5637 | Time: 14.00s |TRAIN loss  0.0108 | TRAIN Acc:  99.91% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:42:14,007] Gradient total norm was 0.5125278830528259. Clipping to 0.25.
[2023-03-18 00:42:14,010] Step: 1865| lr: 0.5635 | Time: 14.05s |TRAIN loss  0.0130 | TRAIN Acc:  99.93% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:42:27,945] Gradient total norm was 0.3839806914329529. Clipping to 0.25.
[2023-03-18 00:42:27,948] Step: 1866| lr: 0.5632 | Time: 13.92s |TRAIN loss  0.0099 | TRAIN Acc:  99.95% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:42:41,894] Gradient total norm was 0.5045415759086609. Clipping to 0.25.
[2023-03-18 00:42:41,897] Step: 1867| lr: 0.5629 | Time: 13.94s |TRAIN loss  0.0093 | TRAIN Acc:  99.96% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:42:55,828] Gradient total norm was 0.5077481865882874. Clipping to 0.25.
[2023-03-18 00:42:55,832] Step: 1868| lr: 0.5626 | Time: 13.92s |TRAIN loss  0.0099 | TRAIN Acc:  99.95% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:43:09,832] Gradient total norm was 0.2766281068325043. Clipping to 0.25.
[2023-03-18 00:43:09,835] Step: 1869| lr: 0.5623 | Time: 13.99s |TRAIN loss  0.0080 | TRAIN Acc:  99.98% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:43:23,785] Step: 1870| lr: 0.5620 | Time: 13.94s |TRAIN loss  0.0072 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:43:37,703] Gradient total norm was 0.28918951749801636. Clipping to 0.25.
[2023-03-18 00:43:37,707] Step: 1871| lr: 0.5617 | Time: 13.91s |TRAIN loss  0.0063 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:43:51,807] Gradient total norm was 0.45873257517814636. Clipping to 0.25.
[2023-03-18 00:43:51,810] Step: 1872| lr: 0.5615 | Time: 14.09s |TRAIN loss  0.0063 | TRAIN Acc:  99.98% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:44:05,711] Gradient total norm was 0.6171903610229492. Clipping to 0.25.
[2023-03-18 00:44:05,715] Step: 1873| lr: 0.5612 | Time: 13.89s |TRAIN loss  0.0076 | TRAIN Acc:  99.97% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:44:19,918] Gradient total norm was 1.0738457441329956. Clipping to 0.25.
[2023-03-18 00:44:19,921] Step: 1874| lr: 0.5609 | Time: 14.19s |TRAIN loss  0.0088 | TRAIN Acc:  99.93% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:44:35,629] Gradient total norm was 0.578728199005127. Clipping to 0.25.
[2023-03-18 00:44:35,633] Step: 1875| lr: 0.5606 | Time: 15.70s |TRAIN loss  0.0086 | TRAIN Acc:  99.95% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:44:49,803] Gradient total norm was 0.4509701728820801. Clipping to 0.25.
[2023-03-18 00:44:49,807] Step: 1876| lr: 0.5603 | Time: 14.16s |TRAIN loss  0.0086 | TRAIN Acc:  99.97% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:45:03,843] Gradient total norm was 0.48835450410842896. Clipping to 0.25.
[2023-03-18 00:45:03,846] Step: 1877| lr: 0.5600 | Time: 14.03s |TRAIN loss  0.0097 | TRAIN Acc:  99.97% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:45:17,743] Gradient total norm was 0.3512915074825287. Clipping to 0.25.
[2023-03-18 00:45:17,747] Step: 1878| lr: 0.5597 | Time: 13.89s |TRAIN loss  0.0089 | TRAIN Acc:  99.94% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:45:31,778] Gradient total norm was 0.3740461766719818. Clipping to 0.25.
[2023-03-18 00:45:31,782] Step: 1879| lr: 0.5594 | Time: 14.02s |TRAIN loss  0.0093 | TRAIN Acc:  99.98% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:45:45,877] Gradient total norm was 0.26354795694351196. Clipping to 0.25.
[2023-03-18 00:45:45,881] Step: 1880| lr: 0.5591 | Time: 14.09s |TRAIN loss  0.0078 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:45:59,921] Gradient total norm was 0.45088696479797363. Clipping to 0.25.
[2023-03-18 00:45:59,924] Step: 1881| lr: 0.5589 | Time: 14.03s |TRAIN loss  0.0077 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:46:13,992] Gradient total norm was 0.3318203389644623. Clipping to 0.25.
[2023-03-18 00:46:13,995] Step: 1882| lr: 0.5586 | Time: 14.06s |TRAIN loss  0.0070 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:46:28,059] Gradient total norm was 0.6424546837806702. Clipping to 0.25.
[2023-03-18 00:46:28,062] Step: 1883| lr: 0.5583 | Time: 14.05s |TRAIN loss  0.0062 | TRAIN Acc:  99.98% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:46:42,072] Gradient total norm was 1.4901823997497559. Clipping to 0.25.
[2023-03-18 00:46:42,075] Step: 1884| lr: 0.5580 | Time: 14.00s |TRAIN loss  0.0108 | TRAIN Acc:  99.86% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:46:56,169] Gradient total norm was 0.7057383060455322. Clipping to 0.25.
[2023-03-18 00:46:56,173] Step: 1885| lr: 0.5577 | Time: 14.08s |TRAIN loss  0.0109 | TRAIN Acc:  99.94% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:47:10,493] Gradient total norm was 1.1358230113983154. Clipping to 0.25.
[2023-03-18 00:47:10,496] Step: 1886| lr: 0.5574 | Time: 14.31s |TRAIN loss  0.0096 | TRAIN Acc:  99.92% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:47:24,789] Gradient total norm was 0.6352714896202087. Clipping to 0.25.
[2023-03-18 00:47:24,793] Step: 1887| lr: 0.5571 | Time: 14.28s |TRAIN loss  0.0099 | TRAIN Acc:  99.93% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:47:39,215] Gradient total norm was 0.6183983087539673. Clipping to 0.25.
[2023-03-18 00:47:39,218] Step: 1888| lr: 0.5568 | Time: 14.41s |TRAIN loss  0.0116 | TRAIN Acc:  99.93% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:47:53,398] Gradient total norm was 0.6585174798965454. Clipping to 0.25.
[2023-03-18 00:47:53,401] Step: 1889| lr: 0.5565 | Time: 14.17s |TRAIN loss  0.0125 | TRAIN Acc:  99.86% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:48:07,569] Gradient total norm was 0.3602731227874756. Clipping to 0.25.
[2023-03-18 00:48:07,573] Step: 1890| lr: 0.5563 | Time: 14.16s |TRAIN loss  0.0113 | TRAIN Acc:  99.95% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:48:21,761] Gradient total norm was 0.2929626405239105. Clipping to 0.25.
[2023-03-18 00:48:21,764] Step: 1891| lr: 0.5560 | Time: 14.18s |TRAIN loss  0.0094 | TRAIN Acc:  99.98% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:48:35,950] Step: 1892| lr: 0.5557 | Time: 14.18s |TRAIN loss  0.0076 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:48:50,129] Gradient total norm was 0.3515770733356476. Clipping to 0.25.
[2023-03-18 00:48:50,133] Step: 1893| lr: 0.5554 | Time: 14.17s |TRAIN loss  0.0068 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:49:04,307] Gradient total norm was 0.4671216905117035. Clipping to 0.25.
[2023-03-18 00:49:04,311] Step: 1894| lr: 0.5551 | Time: 14.16s |TRAIN loss  0.0067 | TRAIN Acc:  99.97% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:49:18,609] Gradient total norm was 0.3272436559200287. Clipping to 0.25.
[2023-03-18 00:49:18,613] Step: 1895| lr: 0.5548 | Time: 14.29s |TRAIN loss  0.0061 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:49:32,614] Gradient total norm was 0.3208836317062378. Clipping to 0.25.
[2023-03-18 00:49:32,617] Step: 1896| lr: 0.5545 | Time: 13.99s |TRAIN loss  0.0055 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:49:46,559] Gradient total norm was 0.27297940850257874. Clipping to 0.25.
[2023-03-18 00:49:46,562] Step: 1897| lr: 0.5542 | Time: 13.93s |TRAIN loss  0.0057 | TRAIN Acc: 100.00% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:50:00,641] Gradient total norm was 0.27316197752952576. Clipping to 0.25.
[2023-03-18 00:50:00,645] Step: 1898| lr: 0.5539 | Time: 14.07s |TRAIN loss  0.0048 | TRAIN Acc: 100.00% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:50:14,715] Gradient total norm was 0.2783811688423157. Clipping to 0.25.
[2023-03-18 00:50:14,719] Step: 1899| lr: 0.5537 | Time: 14.06s |TRAIN loss  0.0054 | TRAIN Acc: 100.00% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:50:28,933] Gradient total norm was 0.3150503933429718. Clipping to 0.25.
[2023-03-18 00:50:28,936] Step: 1900| lr: 0.5534 | Time: 14.20s |TRAIN loss  0.0049 | TRAIN Acc:  99.99% |VAL loss  0.3014 | VAL Acc:  91.12% |
[2023-03-18 00:50:43,099] Gradient total norm was 0.4516128599643707. Clipping to 0.25.
[2023-03-18 00:50:48,770] Step: 1901| lr: 0.5531 | Time: 14.15s |TRAIN loss  0.0051 | TRAIN Acc:  99.97% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:51:02,726] Gradient total norm was 1.540601372718811. Clipping to 0.25.
[2023-03-18 00:51:02,729] Step: 1902| lr: 0.5528 | Time: 13.94s |TRAIN loss  0.0113 | TRAIN Acc:  99.76% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:51:16,777] Gradient total norm was 1.3171030282974243. Clipping to 0.25.
[2023-03-18 00:51:16,780] Step: 1903| lr: 0.5525 | Time: 14.04s |TRAIN loss  0.0149 | TRAIN Acc:  99.65% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:51:31,010] Gradient total norm was 0.6182128190994263. Clipping to 0.25.
[2023-03-18 00:51:31,014] Step: 1904| lr: 0.5522 | Time: 14.22s |TRAIN loss  0.0133 | TRAIN Acc:  99.86% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:51:45,079] Gradient total norm was 0.4265071153640747. Clipping to 0.25.
[2023-03-18 00:51:45,082] Step: 1905| lr: 0.5519 | Time: 14.05s |TRAIN loss  0.0122 | TRAIN Acc:  99.92% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:51:59,511] Gradient total norm was 0.3674895167350769. Clipping to 0.25.
[2023-03-18 00:51:59,514] Step: 1906| lr: 0.5516 | Time: 14.42s |TRAIN loss  0.0125 | TRAIN Acc:  99.90% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:52:13,902] Gradient total norm was 0.33017802238464355. Clipping to 0.25.
[2023-03-18 00:52:13,905] Step: 1907| lr: 0.5513 | Time: 14.38s |TRAIN loss  0.0114 | TRAIN Acc:  99.91% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:52:28,339] Gradient total norm was 0.26529428362846375. Clipping to 0.25.
[2023-03-18 00:52:28,342] Step: 1908| lr: 0.5510 | Time: 14.42s |TRAIN loss  0.0087 | TRAIN Acc:  99.98% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:52:42,455] Gradient total norm was 0.32639095187187195. Clipping to 0.25.
[2023-03-18 00:52:42,459] Step: 1909| lr: 0.5507 | Time: 14.10s |TRAIN loss  0.0080 | TRAIN Acc:  99.96% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:52:56,678] Gradient total norm was 0.7437546253204346. Clipping to 0.25.
[2023-03-18 00:52:56,681] Step: 1910| lr: 0.5505 | Time: 14.21s |TRAIN loss  0.0078 | TRAIN Acc:  99.94% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:53:10,660] Gradient total norm was 1.660304307937622. Clipping to 0.25.
[2023-03-18 00:53:10,663] Step: 1911| lr: 0.5502 | Time: 13.97s |TRAIN loss  0.0128 | TRAIN Acc:  99.72% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:53:24,614] Gradient total norm was 0.8822665810585022. Clipping to 0.25.
[2023-03-18 00:53:24,617] Step: 1912| lr: 0.5499 | Time: 13.94s |TRAIN loss  0.0128 | TRAIN Acc:  99.83% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:53:38,794] Gradient total norm was 0.6440941691398621. Clipping to 0.25.
[2023-03-18 00:53:38,797] Step: 1913| lr: 0.5496 | Time: 14.17s |TRAIN loss  0.0128 | TRAIN Acc:  99.81% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:53:52,800] Gradient total norm was 0.5249709486961365. Clipping to 0.25.
[2023-03-18 00:53:52,804] Step: 1914| lr: 0.5493 | Time: 13.99s |TRAIN loss  0.0148 | TRAIN Acc:  99.83% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:54:06,911] Gradient total norm was 0.4434277415275574. Clipping to 0.25.
[2023-03-18 00:54:06,914] Step: 1915| lr: 0.5490 | Time: 14.10s |TRAIN loss  0.0125 | TRAIN Acc:  99.93% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:54:20,963] Gradient total norm was 0.30764150619506836. Clipping to 0.25.
[2023-03-18 00:54:20,966] Step: 1916| lr: 0.5487 | Time: 14.04s |TRAIN loss  0.0107 | TRAIN Acc:  99.95% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:54:34,994] Gradient total norm was 0.33548152446746826. Clipping to 0.25.
[2023-03-18 00:54:34,997] Step: 1917| lr: 0.5484 | Time: 14.02s |TRAIN loss  0.0093 | TRAIN Acc:  99.98% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:54:49,000] Step: 1918| lr: 0.5481 | Time: 13.99s |TRAIN loss  0.0080 | TRAIN Acc:  99.99% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:55:03,048] Gradient total norm was 0.3123120367527008. Clipping to 0.25.
[2023-03-18 00:55:03,052] Step: 1919| lr: 0.5478 | Time: 14.04s |TRAIN loss  0.0060 | TRAIN Acc:  99.99% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:55:17,157] Gradient total norm was 0.3642953336238861. Clipping to 0.25.
[2023-03-18 00:55:17,161] Step: 1920| lr: 0.5475 | Time: 14.09s |TRAIN loss  0.0064 | TRAIN Acc:  99.99% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:55:31,292] Gradient total norm was 0.4847170412540436. Clipping to 0.25.
[2023-03-18 00:55:31,295] Step: 1921| lr: 0.5472 | Time: 14.12s |TRAIN loss  0.0057 | TRAIN Acc:  99.99% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:55:45,288] Gradient total norm was 1.0091594457626343. Clipping to 0.25.
[2023-03-18 00:55:45,291] Step: 1922| lr: 0.5470 | Time: 13.98s |TRAIN loss  0.0073 | TRAIN Acc:  99.93% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:55:59,386] Gradient total norm was 0.5640665888786316. Clipping to 0.25.
[2023-03-18 00:55:59,389] Step: 1923| lr: 0.5467 | Time: 14.08s |TRAIN loss  0.0075 | TRAIN Acc:  99.96% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:56:13,351] Gradient total norm was 0.5061173439025879. Clipping to 0.25.
[2023-03-18 00:56:13,354] Step: 1924| lr: 0.5464 | Time: 13.95s |TRAIN loss  0.0074 | TRAIN Acc:  99.98% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:56:27,420] Gradient total norm was 0.4862860441207886. Clipping to 0.25.
[2023-03-18 00:56:27,423] Step: 1925| lr: 0.5461 | Time: 14.06s |TRAIN loss  0.0079 | TRAIN Acc:  99.99% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:56:41,469] Gradient total norm was 1.0130635499954224. Clipping to 0.25.
[2023-03-18 00:56:41,473] Step: 1926| lr: 0.5458 | Time: 14.04s |TRAIN loss  0.0101 | TRAIN Acc:  99.90% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:56:55,542] Gradient total norm was 0.6180399656295776. Clipping to 0.25.
[2023-03-18 00:56:55,546] Step: 1927| lr: 0.5455 | Time: 14.06s |TRAIN loss  0.0110 | TRAIN Acc:  99.93% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:57:09,674] Gradient total norm was 0.5284190773963928. Clipping to 0.25.
[2023-03-18 00:57:09,677] Step: 1928| lr: 0.5452 | Time: 14.12s |TRAIN loss  0.0099 | TRAIN Acc:  99.92% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:57:23,786] Gradient total norm was 0.3794272541999817. Clipping to 0.25.
[2023-03-18 00:57:23,789] Step: 1929| lr: 0.5449 | Time: 14.10s |TRAIN loss  0.0105 | TRAIN Acc:  99.98% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:57:37,966] Gradient total norm was 0.3413057029247284. Clipping to 0.25.
[2023-03-18 00:57:37,970] Step: 1930| lr: 0.5446 | Time: 14.17s |TRAIN loss  0.0088 | TRAIN Acc:  99.93% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:57:52,028] Gradient total norm was 0.42139729857444763. Clipping to 0.25.
[2023-03-18 00:57:52,032] Step: 1931| lr: 0.5443 | Time: 14.05s |TRAIN loss  0.0087 | TRAIN Acc:  99.99% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:58:06,102] Gradient total norm was 2.945605516433716. Clipping to 0.25.
[2023-03-18 00:58:06,105] Step: 1932| lr: 0.5440 | Time: 14.06s |TRAIN loss  0.0311 | TRAIN Acc:  99.16% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:58:20,327] Gradient total norm was 0.40893319249153137. Clipping to 0.25.
[2023-03-18 00:58:20,330] Step: 1933| lr: 0.5437 | Time: 14.21s |TRAIN loss  0.0131 | TRAIN Acc:  99.96% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:58:34,531] Gradient total norm was 0.6091480851173401. Clipping to 0.25.
[2023-03-18 00:58:34,535] Step: 1934| lr: 0.5434 | Time: 14.19s |TRAIN loss  0.0103 | TRAIN Acc:  99.99% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:58:48,560] Gradient total norm was 0.38991743326187134. Clipping to 0.25.
[2023-03-18 00:58:48,563] Step: 1935| lr: 0.5432 | Time: 14.01s |TRAIN loss  0.0111 | TRAIN Acc:  99.99% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:59:02,596] Gradient total norm was 0.313973605632782. Clipping to 0.25.
[2023-03-18 00:59:02,600] Step: 1936| lr: 0.5429 | Time: 14.02s |TRAIN loss  0.0080 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:59:16,726] Gradient total norm was 0.2568695843219757. Clipping to 0.25.
[2023-03-18 00:59:16,730] Step: 1937| lr: 0.5426 | Time: 14.12s |TRAIN loss  0.0077 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:59:30,879] Gradient total norm was 0.290221244096756. Clipping to 0.25.
[2023-03-18 00:59:30,883] Step: 1938| lr: 0.5423 | Time: 14.14s |TRAIN loss  0.0063 | TRAIN Acc:  99.99% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:59:45,078] Step: 1939| lr: 0.5420 | Time: 14.19s |TRAIN loss  0.0057 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 00:59:59,131] Step: 1940| lr: 0.5417 | Time: 14.04s |TRAIN loss  0.0054 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:00:13,343] Gradient total norm was 0.280536025762558. Clipping to 0.25.
[2023-03-18 01:00:13,346] Step: 1941| lr: 0.5414 | Time: 14.20s |TRAIN loss  0.0050 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:00:27,499] Step: 1942| lr: 0.5411 | Time: 14.14s |TRAIN loss  0.0051 | TRAIN Acc:  99.99% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:00:41,614] Gradient total norm was 0.25136733055114746. Clipping to 0.25.
[2023-03-18 01:00:41,617] Step: 1943| lr: 0.5408 | Time: 14.10s |TRAIN loss  0.0046 | TRAIN Acc:  99.99% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:00:55,913] Gradient total norm was 0.38947248458862305. Clipping to 0.25.
[2023-03-18 01:00:55,916] Step: 1944| lr: 0.5405 | Time: 14.29s |TRAIN loss  0.0052 | TRAIN Acc:  99.98% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:01:09,981] Gradient total norm was 0.39017966389656067. Clipping to 0.25.
[2023-03-18 01:01:09,984] Step: 1945| lr: 0.5402 | Time: 14.05s |TRAIN loss  0.0059 | TRAIN Acc:  99.95% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:01:24,002] Gradient total norm was 0.29354411363601685. Clipping to 0.25.
[2023-03-18 01:01:24,006] Step: 1946| lr: 0.5399 | Time: 14.01s |TRAIN loss  0.0055 | TRAIN Acc:  99.98% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:01:38,176] Step: 1947| lr: 0.5396 | Time: 14.16s |TRAIN loss  0.0050 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:01:52,264] Step: 1948| lr: 0.5393 | Time: 14.08s |TRAIN loss  0.0040 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:02:06,250] Step: 1949| lr: 0.5390 | Time: 13.98s |TRAIN loss  0.0038 | TRAIN Acc:  99.99% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:02:20,386] Step: 1950| lr: 0.5387 | Time: 14.13s |TRAIN loss  0.0035 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:02:34,496] Step: 1951| lr: 0.5384 | Time: 14.10s |TRAIN loss  0.0034 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:02:48,765] Step: 1952| lr: 0.5382 | Time: 14.26s |TRAIN loss  0.0030 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:03:02,912] Step: 1953| lr: 0.5379 | Time: 14.14s |TRAIN loss  0.0030 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:03:17,117] Step: 1954| lr: 0.5376 | Time: 14.20s |TRAIN loss  0.0028 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:03:31,240] Step: 1955| lr: 0.5373 | Time: 14.11s |TRAIN loss  0.0028 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:03:45,272] Step: 1956| lr: 0.5370 | Time: 14.02s |TRAIN loss  0.0028 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:03:59,440] Step: 1957| lr: 0.5367 | Time: 14.16s |TRAIN loss  0.0026 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:04:13,591] Step: 1958| lr: 0.5364 | Time: 14.14s |TRAIN loss  0.0025 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:04:27,642] Step: 1959| lr: 0.5361 | Time: 14.04s |TRAIN loss  0.0024 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:04:41,714] Step: 1960| lr: 0.5358 | Time: 14.06s |TRAIN loss  0.0023 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:04:55,816] Step: 1961| lr: 0.5355 | Time: 14.09s |TRAIN loss  0.0022 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:05:09,875] Step: 1962| lr: 0.5352 | Time: 14.05s |TRAIN loss  0.0023 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:05:23,920] Step: 1963| lr: 0.5349 | Time: 14.04s |TRAIN loss  0.0023 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:05:38,186] Step: 1964| lr: 0.5346 | Time: 14.26s |TRAIN loss  0.0025 | TRAIN Acc:  99.99% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:05:52,406] Gradient total norm was 0.6739629507064819. Clipping to 0.25.
[2023-03-18 01:05:52,410] Step: 1965| lr: 0.5343 | Time: 14.21s |TRAIN loss  0.0055 | TRAIN Acc:  99.87% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:06:06,577] Gradient total norm was 0.8085629343986511. Clipping to 0.25.
[2023-03-18 01:06:06,581] Step: 1966| lr: 0.5340 | Time: 14.16s |TRAIN loss  0.0086 | TRAIN Acc:  99.78% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:06:20,647] Gradient total norm was 0.9184235334396362. Clipping to 0.25.
[2023-03-18 01:06:20,650] Step: 1967| lr: 0.5337 | Time: 14.06s |TRAIN loss  0.0129 | TRAIN Acc:  99.57% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:06:35,021] Gradient total norm was 0.5386798977851868. Clipping to 0.25.
[2023-03-18 01:06:35,025] Step: 1968| lr: 0.5334 | Time: 14.36s |TRAIN loss  0.0097 | TRAIN Acc:  99.90% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:06:49,342] Gradient total norm was 0.550460159778595. Clipping to 0.25.
[2023-03-18 01:06:49,347] Step: 1969| lr: 0.5331 | Time: 14.30s |TRAIN loss  0.0121 | TRAIN Acc:  99.83% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:07:03,732] Gradient total norm was 0.8260654807090759. Clipping to 0.25.
[2023-03-18 01:07:03,735] Step: 1970| lr: 0.5328 | Time: 14.37s |TRAIN loss  0.0109 | TRAIN Acc:  99.89% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:07:18,095] Gradient total norm was 0.6635269522666931. Clipping to 0.25.
[2023-03-18 01:07:18,098] Step: 1971| lr: 0.5325 | Time: 14.35s |TRAIN loss  0.0105 | TRAIN Acc:  99.91% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:07:32,388] Gradient total norm was 0.7979030609130859. Clipping to 0.25.
[2023-03-18 01:07:32,391] Step: 1972| lr: 0.5322 | Time: 14.28s |TRAIN loss  0.0111 | TRAIN Acc:  99.85% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:07:46,922] Gradient total norm was 0.6557087302207947. Clipping to 0.25.
[2023-03-18 01:07:46,926] Step: 1973| lr: 0.5319 | Time: 14.52s |TRAIN loss  0.0112 | TRAIN Acc:  99.89% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:08:01,752] Gradient total norm was 0.5178592205047607. Clipping to 0.25.
[2023-03-18 01:08:01,756] Step: 1974| lr: 0.5316 | Time: 14.82s |TRAIN loss  0.0116 | TRAIN Acc:  99.93% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:08:16,151] Gradient total norm was 0.7894196510314941. Clipping to 0.25.
[2023-03-18 01:08:16,154] Step: 1975| lr: 0.5313 | Time: 14.39s |TRAIN loss  0.0108 | TRAIN Acc:  99.92% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:08:30,448] Gradient total norm was 1.3739196062088013. Clipping to 0.25.
[2023-03-18 01:08:30,452] Step: 1976| lr: 0.5311 | Time: 14.28s |TRAIN loss  0.0160 | TRAIN Acc:  99.78% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:08:44,535] Gradient total norm was 0.6726770997047424. Clipping to 0.25.
[2023-03-18 01:08:44,538] Step: 1977| lr: 0.5308 | Time: 14.07s |TRAIN loss  0.0130 | TRAIN Acc:  99.91% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:08:58,749] Gradient total norm was 0.6178821325302124. Clipping to 0.25.
[2023-03-18 01:08:58,752] Step: 1978| lr: 0.5305 | Time: 14.20s |TRAIN loss  0.0145 | TRAIN Acc:  99.86% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:09:12,812] Gradient total norm was 0.47584477066993713. Clipping to 0.25.
[2023-03-18 01:09:12,815] Step: 1979| lr: 0.5302 | Time: 14.05s |TRAIN loss  0.0127 | TRAIN Acc:  99.96% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:09:26,939] Gradient total norm was 0.315347820520401. Clipping to 0.25.
[2023-03-18 01:09:26,943] Step: 1980| lr: 0.5299 | Time: 14.11s |TRAIN loss  0.0112 | TRAIN Acc:  99.98% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:09:41,659] Gradient total norm was 0.4043155908584595. Clipping to 0.25.
[2023-03-18 01:09:41,663] Step: 1981| lr: 0.5296 | Time: 14.70s |TRAIN loss  0.0079 | TRAIN Acc:  99.99% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:09:57,120] Gradient total norm was 0.2907133102416992. Clipping to 0.25.
[2023-03-18 01:09:57,124] Step: 1982| lr: 0.5293 | Time: 15.45s |TRAIN loss  0.0075 | TRAIN Acc:  99.99% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:10:12,537] Gradient total norm was 0.30324921011924744. Clipping to 0.25.
[2023-03-18 01:10:12,540] Step: 1983| lr: 0.5290 | Time: 15.40s |TRAIN loss  0.0059 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:10:27,156] Gradient total norm was 0.28306496143341064. Clipping to 0.25.
[2023-03-18 01:10:27,159] Step: 1984| lr: 0.5287 | Time: 14.61s |TRAIN loss  0.0056 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:10:41,532] Gradient total norm was 0.28947460651397705. Clipping to 0.25.
[2023-03-18 01:10:41,536] Step: 1985| lr: 0.5284 | Time: 14.36s |TRAIN loss  0.0057 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:10:55,642] Gradient total norm was 0.36430609226226807. Clipping to 0.25.
[2023-03-18 01:10:55,645] Step: 1986| lr: 0.5281 | Time: 14.10s |TRAIN loss  0.0051 | TRAIN Acc:  99.99% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:11:10,081] Gradient total norm was 0.2971726357936859. Clipping to 0.25.
[2023-03-18 01:11:10,085] Step: 1987| lr: 0.5278 | Time: 14.43s |TRAIN loss  0.0057 | TRAIN Acc:  99.99% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:11:24,633] Gradient total norm was 0.3379380404949188. Clipping to 0.25.
[2023-03-18 01:11:24,636] Step: 1988| lr: 0.5275 | Time: 14.54s |TRAIN loss  0.0048 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:11:38,959] Gradient total norm was 0.3659031391143799. Clipping to 0.25.
[2023-03-18 01:11:38,962] Step: 1989| lr: 0.5272 | Time: 14.31s |TRAIN loss  0.0050 | TRAIN Acc:  99.99% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:11:53,463] Gradient total norm was 0.7506392598152161. Clipping to 0.25.
[2023-03-18 01:11:53,466] Step: 1990| lr: 0.5269 | Time: 14.49s |TRAIN loss  0.0061 | TRAIN Acc:  99.96% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:12:08,315] Gradient total norm was 0.767113208770752. Clipping to 0.25.
[2023-03-18 01:12:08,318] Step: 1991| lr: 0.5266 | Time: 14.84s |TRAIN loss  0.0082 | TRAIN Acc:  99.91% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:12:23,633] Gradient total norm was 0.6663997769355774. Clipping to 0.25.
[2023-03-18 01:12:23,637] Step: 1992| lr: 0.5263 | Time: 15.30s |TRAIN loss  0.0092 | TRAIN Acc:  99.92% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:12:39,472] Gradient total norm was 0.5791083574295044. Clipping to 0.25.
[2023-03-18 01:12:39,476] Step: 1993| lr: 0.5260 | Time: 15.82s |TRAIN loss  0.0112 | TRAIN Acc:  99.89% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:12:54,628] Gradient total norm was 0.4154149889945984. Clipping to 0.25.
[2023-03-18 01:12:54,631] Step: 1994| lr: 0.5257 | Time: 15.14s |TRAIN loss  0.0110 | TRAIN Acc:  99.95% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:13:10,676] Gradient total norm was 0.3559810519218445. Clipping to 0.25.
[2023-03-18 01:13:10,680] Step: 1995| lr: 0.5254 | Time: 16.03s |TRAIN loss  0.0105 | TRAIN Acc:  99.96% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:13:25,861] Gradient total norm was 0.29017794132232666. Clipping to 0.25.
[2023-03-18 01:13:25,864] Step: 1996| lr: 0.5251 | Time: 15.17s |TRAIN loss  0.0081 | TRAIN Acc:  99.98% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:13:40,500] Step: 1997| lr: 0.5248 | Time: 14.63s |TRAIN loss  0.0069 | TRAIN Acc:  99.99% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:13:55,418] Step: 1998| lr: 0.5245 | Time: 14.91s |TRAIN loss  0.0050 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:14:10,285] Gradient total norm was 0.37252339720726013. Clipping to 0.25.
[2023-03-18 01:14:10,288] Step: 1999| lr: 0.5242 | Time: 14.86s |TRAIN loss  0.0050 | TRAIN Acc: 100.00% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:14:24,743] Gradient total norm was 0.7260835766792297. Clipping to 0.25.
[2023-03-18 01:14:24,746] Step: 2000| lr: 0.5239 | Time: 14.44s |TRAIN loss  0.0076 | TRAIN Acc:  99.88% |VAL loss  0.2639 | VAL Acc:  92.21% |
[2023-03-18 01:14:39,793] Gradient total norm was 0.30818241834640503. Clipping to 0.25.
[2023-03-18 01:14:45,651] Step: 2001| lr: 0.5236 | Time: 15.04s |TRAIN loss  0.0061 | TRAIN Acc:  99.99% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:15:01,026] Gradient total norm was 0.28268495202064514. Clipping to 0.25.
[2023-03-18 01:15:01,029] Step: 2002| lr: 0.5233 | Time: 15.36s |TRAIN loss  0.0055 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:15:16,469] Step: 2003| lr: 0.5230 | Time: 15.43s |TRAIN loss  0.0046 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:15:31,626] Step: 2004| lr: 0.5227 | Time: 15.15s |TRAIN loss  0.0042 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:15:47,455] Step: 2005| lr: 0.5224 | Time: 15.82s |TRAIN loss  0.0038 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:16:03,085] Gradient total norm was 0.33462318778038025. Clipping to 0.25.
[2023-03-18 01:16:03,089] Step: 2006| lr: 0.5221 | Time: 15.62s |TRAIN loss  0.0039 | TRAIN Acc:  99.99% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:16:18,975] Gradient total norm was 2.8390822410583496. Clipping to 0.25.
[2023-03-18 01:16:18,979] Step: 2007| lr: 0.5218 | Time: 15.88s |TRAIN loss  0.0145 | TRAIN Acc:  99.57% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:16:33,913] Gradient total norm was 0.6101201772689819. Clipping to 0.25.
[2023-03-18 01:16:33,916] Step: 2008| lr: 0.5215 | Time: 14.92s |TRAIN loss  0.0073 | TRAIN Acc:  99.95% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:16:49,984] Gradient total norm was 0.6789286732673645. Clipping to 0.25.
[2023-03-18 01:16:49,988] Step: 2009| lr: 0.5212 | Time: 16.05s |TRAIN loss  0.0089 | TRAIN Acc:  99.88% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:17:05,753] Gradient total norm was 0.7783942222595215. Clipping to 0.25.
[2023-03-18 01:17:05,757] Step: 2010| lr: 0.5209 | Time: 15.75s |TRAIN loss  0.0159 | TRAIN Acc:  99.65% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:17:21,213] Gradient total norm was 0.42782077193260193. Clipping to 0.25.
[2023-03-18 01:17:21,216] Step: 2011| lr: 0.5206 | Time: 15.45s |TRAIN loss  0.0142 | TRAIN Acc:  99.86% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:17:37,210] Gradient total norm was 0.4459800124168396. Clipping to 0.25.
[2023-03-18 01:17:37,215] Step: 2012| lr: 0.5203 | Time: 15.97s |TRAIN loss  0.0102 | TRAIN Acc:  99.98% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:17:53,221] Gradient total norm was 1.10094153881073. Clipping to 0.25.
[2023-03-18 01:17:53,224] Step: 2013| lr: 0.5200 | Time: 15.99s |TRAIN loss  0.0110 | TRAIN Acc:  99.89% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:18:09,719] Gradient total norm was 0.7767447233200073. Clipping to 0.25.
[2023-03-18 01:18:09,723] Step: 2014| lr: 0.5197 | Time: 16.48s |TRAIN loss  0.0110 | TRAIN Acc:  99.88% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:18:25,739] Gradient total norm was 0.5535831451416016. Clipping to 0.25.
[2023-03-18 01:18:25,743] Step: 2015| lr: 0.5194 | Time: 16.00s |TRAIN loss  0.0103 | TRAIN Acc:  99.94% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:18:41,294] Gradient total norm was 0.801856517791748. Clipping to 0.25.
[2023-03-18 01:18:41,298] Step: 2016| lr: 0.5191 | Time: 15.54s |TRAIN loss  0.0107 | TRAIN Acc:  99.93% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:18:57,008] Gradient total norm was 1.4369159936904907. Clipping to 0.25.
[2023-03-18 01:18:57,013] Step: 2017| lr: 0.5188 | Time: 15.69s |TRAIN loss  0.0152 | TRAIN Acc:  99.79% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:19:13,120] Gradient total norm was 0.590522050857544. Clipping to 0.25.
[2023-03-18 01:19:13,124] Step: 2018| lr: 0.5185 | Time: 16.10s |TRAIN loss  0.0140 | TRAIN Acc:  99.94% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:19:29,973] Gradient total norm was 0.638741135597229. Clipping to 0.25.
[2023-03-18 01:19:29,977] Step: 2019| lr: 0.5182 | Time: 16.84s |TRAIN loss  0.0158 | TRAIN Acc:  99.82% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:19:46,183] Gradient total norm was 0.42103224992752075. Clipping to 0.25.
[2023-03-18 01:19:46,186] Step: 2020| lr: 0.5179 | Time: 16.19s |TRAIN loss  0.0126 | TRAIN Acc:  99.93% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:20:02,287] Gradient total norm was 0.4164671003818512. Clipping to 0.25.
[2023-03-18 01:20:02,291] Step: 2021| lr: 0.5176 | Time: 16.09s |TRAIN loss  0.0136 | TRAIN Acc:  99.92% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:20:18,065] Gradient total norm was 0.27657121419906616. Clipping to 0.25.
[2023-03-18 01:20:18,068] Step: 2022| lr: 0.5173 | Time: 15.76s |TRAIN loss  0.0096 | TRAIN Acc:  99.99% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:20:33,483] Gradient total norm was 0.41962185502052307. Clipping to 0.25.
[2023-03-18 01:20:33,486] Step: 2023| lr: 0.5170 | Time: 15.40s |TRAIN loss  0.0088 | TRAIN Acc:  99.96% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:20:49,726] Gradient total norm was 1.4769893884658813. Clipping to 0.25.
[2023-03-18 01:20:49,730] Step: 2024| lr: 0.5167 | Time: 16.23s |TRAIN loss  0.0139 | TRAIN Acc:  99.69% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:21:06,097] Gradient total norm was 0.30843961238861084. Clipping to 0.25.
[2023-03-18 01:21:06,102] Step: 2025| lr: 0.5164 | Time: 16.35s |TRAIN loss  0.0091 | TRAIN Acc:  99.92% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:21:22,829] Gradient total norm was 0.30822432041168213. Clipping to 0.25.
[2023-03-18 01:21:22,832] Step: 2026| lr: 0.5161 | Time: 16.71s |TRAIN loss  0.0082 | TRAIN Acc:  99.99% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:21:39,102] Gradient total norm was 0.2681470215320587. Clipping to 0.25.
[2023-03-18 01:21:39,106] Step: 2027| lr: 0.5158 | Time: 16.26s |TRAIN loss  0.0082 | TRAIN Acc:  99.94% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:21:55,429] Step: 2028| lr: 0.5155 | Time: 16.31s |TRAIN loss  0.0062 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:22:11,251] Step: 2029| lr: 0.5152 | Time: 15.81s |TRAIN loss  0.0057 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:22:28,100] Step: 2030| lr: 0.5149 | Time: 16.84s |TRAIN loss  0.0051 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:22:44,094] Step: 2031| lr: 0.5146 | Time: 15.98s |TRAIN loss  0.0045 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:22:59,922] Step: 2032| lr: 0.5143 | Time: 15.82s |TRAIN loss  0.0041 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:23:16,534] Step: 2033| lr: 0.5140 | Time: 16.60s |TRAIN loss  0.0037 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:23:32,337] Step: 2034| lr: 0.5137 | Time: 15.79s |TRAIN loss  0.0034 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:23:47,965] Step: 2035| lr: 0.5134 | Time: 15.61s |TRAIN loss  0.0032 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:24:04,545] Step: 2036| lr: 0.5131 | Time: 16.57s |TRAIN loss  0.0032 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:24:20,491] Step: 2037| lr: 0.5128 | Time: 15.94s |TRAIN loss  0.0029 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:24:36,948] Step: 2038| lr: 0.5125 | Time: 16.45s |TRAIN loss  0.0027 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:24:53,056] Step: 2039| lr: 0.5122 | Time: 16.10s |TRAIN loss  0.0026 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:25:09,268] Step: 2040| lr: 0.5119 | Time: 16.20s |TRAIN loss  0.0025 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:25:25,439] Step: 2041| lr: 0.5116 | Time: 16.16s |TRAIN loss  0.0024 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:25:41,276] Step: 2042| lr: 0.5113 | Time: 15.83s |TRAIN loss  0.0023 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:25:57,080] Step: 2043| lr: 0.5110 | Time: 15.79s |TRAIN loss  0.0023 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:26:13,648] Step: 2044| lr: 0.5107 | Time: 16.56s |TRAIN loss  0.0021 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:26:30,003] Step: 2045| lr: 0.5104 | Time: 16.34s |TRAIN loss  0.0021 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:26:46,294] Step: 2046| lr: 0.5101 | Time: 16.28s |TRAIN loss  0.0020 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:27:02,095] Step: 2047| lr: 0.5098 | Time: 15.79s |TRAIN loss  0.0019 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:27:18,529] Step: 2048| lr: 0.5095 | Time: 16.42s |TRAIN loss  0.0018 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:27:33,885] Step: 2049| lr: 0.5092 | Time: 15.34s |TRAIN loss  0.0019 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:27:50,517] Step: 2050| lr: 0.5089 | Time: 16.62s |TRAIN loss  0.0018 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:28:07,021] Step: 2051| lr: 0.5086 | Time: 16.49s |TRAIN loss  0.0017 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:28:22,946] Step: 2052| lr: 0.5083 | Time: 15.91s |TRAIN loss  0.0017 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:28:39,232] Step: 2053| lr: 0.5080 | Time: 16.28s |TRAIN loss  0.0018 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:28:55,348] Step: 2054| lr: 0.5077 | Time: 16.11s |TRAIN loss  0.0018 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:29:10,754] Step: 2055| lr: 0.5074 | Time: 15.39s |TRAIN loss  0.0018 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:29:27,196] Step: 2056| lr: 0.5071 | Time: 16.43s |TRAIN loss  0.0019 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:29:43,481] Step: 2057| lr: 0.5068 | Time: 16.27s |TRAIN loss  0.0019 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:29:59,541] Step: 2058| lr: 0.5065 | Time: 16.05s |TRAIN loss  0.0019 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:30:16,073] Step: 2059| lr: 0.5062 | Time: 16.52s |TRAIN loss  0.0018 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:30:32,238] Step: 2060| lr: 0.5059 | Time: 16.15s |TRAIN loss  0.0019 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:30:48,653] Step: 2061| lr: 0.5055 | Time: 16.40s |TRAIN loss  0.0019 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:31:04,542] Step: 2062| lr: 0.5052 | Time: 15.88s |TRAIN loss  0.0019 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:31:21,515] Step: 2063| lr: 0.5049 | Time: 16.96s |TRAIN loss  0.0018 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:31:38,253] Step: 2064| lr: 0.5046 | Time: 16.73s |TRAIN loss  0.0018 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:31:54,452] Step: 2065| lr: 0.5043 | Time: 16.19s |TRAIN loss  0.0018 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:32:10,941] Step: 2066| lr: 0.5040 | Time: 16.48s |TRAIN loss  0.0017 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:32:27,270] Step: 2067| lr: 0.5037 | Time: 16.32s |TRAIN loss  0.0018 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:32:43,486] Step: 2068| lr: 0.5034 | Time: 16.21s |TRAIN loss  0.0019 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:32:58,170] Step: 2069| lr: 0.5031 | Time: 14.67s |TRAIN loss  0.0020 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:33:14,814] Gradient total norm was 0.37225407361984253. Clipping to 0.25.
[2023-03-18 01:33:14,819] Step: 2070| lr: 0.5028 | Time: 16.63s |TRAIN loss  0.0024 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:33:30,201] Gradient total norm was 1.0397132635116577. Clipping to 0.25.
[2023-03-18 01:33:30,206] Step: 2071| lr: 0.5025 | Time: 15.36s |TRAIN loss  0.0046 | TRAIN Acc:  99.94% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:33:46,034] Gradient total norm was 0.5355057120323181. Clipping to 0.25.
[2023-03-18 01:33:46,040] Step: 2072| lr: 0.5022 | Time: 15.81s |TRAIN loss  0.0038 | TRAIN Acc:  99.99% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:34:02,088] Gradient total norm was 0.7130106687545776. Clipping to 0.25.
[2023-03-18 01:34:02,092] Step: 2073| lr: 0.5019 | Time: 16.04s |TRAIN loss  0.0056 | TRAIN Acc:  99.96% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:34:17,379] Gradient total norm was 0.8270957469940186. Clipping to 0.25.
[2023-03-18 01:34:17,383] Step: 2074| lr: 0.5016 | Time: 15.27s |TRAIN loss  0.0063 | TRAIN Acc:  99.97% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:34:33,873] Gradient total norm was 0.8103532195091248. Clipping to 0.25.
[2023-03-18 01:34:33,879] Step: 2075| lr: 0.5013 | Time: 16.47s |TRAIN loss  0.0093 | TRAIN Acc:  99.88% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:34:49,411] Gradient total norm was 0.8158782720565796. Clipping to 0.25.
[2023-03-18 01:34:49,414] Step: 2076| lr: 0.5010 | Time: 15.52s |TRAIN loss  0.0086 | TRAIN Acc:  99.91% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:35:04,930] Gradient total norm was 0.45744454860687256. Clipping to 0.25.
[2023-03-18 01:35:04,934] Step: 2077| lr: 0.5007 | Time: 15.51s |TRAIN loss  0.0095 | TRAIN Acc:  99.95% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:35:21,421] Gradient total norm was 1.0017091035842896. Clipping to 0.25.
[2023-03-18 01:35:21,426] Step: 2078| lr: 0.5004 | Time: 16.47s |TRAIN loss  0.0081 | TRAIN Acc:  99.95% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:35:37,942] Gradient total norm was 0.7194427251815796. Clipping to 0.25.
[2023-03-18 01:35:37,945] Step: 2079| lr: 0.5001 | Time: 16.50s |TRAIN loss  0.0100 | TRAIN Acc:  99.94% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:35:53,957] Gradient total norm was 0.6369807720184326. Clipping to 0.25.
[2023-03-18 01:35:53,961] Step: 2080| lr: 0.4998 | Time: 16.00s |TRAIN loss  0.0113 | TRAIN Acc:  99.95% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:36:10,537] Gradient total norm was 0.6439669132232666. Clipping to 0.25.
[2023-03-18 01:36:10,542] Step: 2081| lr: 0.4995 | Time: 16.56s |TRAIN loss  0.0112 | TRAIN Acc:  99.95% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:36:26,900] Gradient total norm was 0.6075166463851929. Clipping to 0.25.
[2023-03-18 01:36:26,904] Step: 2082| lr: 0.4992 | Time: 16.35s |TRAIN loss  0.0106 | TRAIN Acc:  99.97% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:36:43,744] Gradient total norm was 0.5032454133033752. Clipping to 0.25.
[2023-03-18 01:36:43,748] Step: 2083| lr: 0.4989 | Time: 16.82s |TRAIN loss  0.0107 | TRAIN Acc:  99.98% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:36:58,565] Gradient total norm was 0.6462940573692322. Clipping to 0.25.
[2023-03-18 01:36:58,568] Step: 2084| lr: 0.4986 | Time: 14.81s |TRAIN loss  0.0086 | TRAIN Acc:  99.99% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:37:13,113] Gradient total norm was 0.8511479496955872. Clipping to 0.25.
[2023-03-18 01:37:13,117] Step: 2085| lr: 0.4983 | Time: 14.53s |TRAIN loss  0.0102 | TRAIN Acc:  99.96% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:37:27,619] Gradient total norm was 0.8540966510772705. Clipping to 0.25.
[2023-03-18 01:37:27,622] Step: 2086| lr: 0.4980 | Time: 14.49s |TRAIN loss  0.0108 | TRAIN Acc:  99.91% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:37:42,034] Gradient total norm was 0.5387130379676819. Clipping to 0.25.
[2023-03-18 01:37:42,038] Step: 2087| lr: 0.4976 | Time: 14.40s |TRAIN loss  0.0100 | TRAIN Acc:  99.99% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:37:57,001] Gradient total norm was 0.34673887491226196. Clipping to 0.25.
[2023-03-18 01:37:57,004] Step: 2088| lr: 0.4973 | Time: 14.95s |TRAIN loss  0.0090 | TRAIN Acc:  99.98% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:38:12,532] Gradient total norm was 0.35514962673187256. Clipping to 0.25.
[2023-03-18 01:38:12,536] Step: 2089| lr: 0.4970 | Time: 15.52s |TRAIN loss  0.0081 | TRAIN Acc:  99.99% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:38:27,903] Gradient total norm was 0.27297595143318176. Clipping to 0.25.
[2023-03-18 01:38:27,906] Step: 2090| lr: 0.4967 | Time: 15.36s |TRAIN loss  0.0075 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:38:43,947] Gradient total norm was 0.29958415031433105. Clipping to 0.25.
[2023-03-18 01:38:43,952] Step: 2091| lr: 0.4964 | Time: 16.02s |TRAIN loss  0.0060 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:39:00,521] Gradient total norm was 0.3087047040462494. Clipping to 0.25.
[2023-03-18 01:39:00,525] Step: 2092| lr: 0.4961 | Time: 16.56s |TRAIN loss  0.0058 | TRAIN Acc:  99.99% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:39:16,600] Gradient total norm was 0.3481040298938751. Clipping to 0.25.
[2023-03-18 01:39:16,605] Step: 2093| lr: 0.4958 | Time: 16.06s |TRAIN loss  0.0056 | TRAIN Acc:  99.99% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:39:33,329] Gradient total norm was 0.3122386932373047. Clipping to 0.25.
[2023-03-18 01:39:33,334] Step: 2094| lr: 0.4955 | Time: 16.71s |TRAIN loss  0.0053 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:39:49,055] Step: 2095| lr: 0.4952 | Time: 15.71s |TRAIN loss  0.0048 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:40:04,515] Step: 2096| lr: 0.4949 | Time: 15.45s |TRAIN loss  0.0041 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:40:20,141] Step: 2097| lr: 0.4946 | Time: 15.62s |TRAIN loss  0.0040 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:40:35,357] Step: 2098| lr: 0.4943 | Time: 15.21s |TRAIN loss  0.0037 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:40:50,661] Step: 2099| lr: 0.4940 | Time: 15.29s |TRAIN loss  0.0035 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:41:06,520] Step: 2100| lr: 0.4937 | Time: 15.85s |TRAIN loss  0.0034 | TRAIN Acc: 100.00% |VAL loss  0.2517 | VAL Acc:  92.51% |
[2023-03-18 01:41:21,916] Gradient total norm was 0.5447843670845032. Clipping to 0.25.
[2023-03-18 01:41:27,910] Step: 2101| lr: 0.4934 | Time: 15.38s |TRAIN loss  0.0037 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:41:43,984] Gradient total norm was 2.7610220909118652. Clipping to 0.25.
[2023-03-18 01:41:43,988] Step: 2102| lr: 0.4931 | Time: 16.06s |TRAIN loss  0.0241 | TRAIN Acc:  99.20% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:42:00,453] Gradient total norm was 0.6673517823219299. Clipping to 0.25.
[2023-03-18 01:42:00,457] Step: 2103| lr: 0.4928 | Time: 16.45s |TRAIN loss  0.0096 | TRAIN Acc:  99.95% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:42:16,500] Gradient total norm was 0.35339927673339844. Clipping to 0.25.
[2023-03-18 01:42:16,504] Step: 2104| lr: 0.4925 | Time: 16.03s |TRAIN loss  0.0075 | TRAIN Acc:  99.98% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:42:33,408] Gradient total norm was 0.38011953234672546. Clipping to 0.25.
[2023-03-18 01:42:33,413] Step: 2105| lr: 0.4922 | Time: 16.89s |TRAIN loss  0.0074 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:42:48,119] Gradient total norm was 1.0203133821487427. Clipping to 0.25.
[2023-03-18 01:42:48,122] Step: 2106| lr: 0.4919 | Time: 14.69s |TRAIN loss  0.0102 | TRAIN Acc:  99.89% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:43:03,228] Gradient total norm was 1.146195888519287. Clipping to 0.25.
[2023-03-18 01:43:03,232] Step: 2107| lr: 0.4915 | Time: 15.09s |TRAIN loss  0.0148 | TRAIN Acc:  99.73% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:43:18,483] Gradient total norm was 0.47330668568611145. Clipping to 0.25.
[2023-03-18 01:43:18,487] Step: 2108| lr: 0.4912 | Time: 15.24s |TRAIN loss  0.0108 | TRAIN Acc:  99.97% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:43:33,155] Gradient total norm was 0.8856262564659119. Clipping to 0.25.
[2023-03-18 01:43:33,159] Step: 2109| lr: 0.4909 | Time: 14.66s |TRAIN loss  0.0107 | TRAIN Acc:  99.94% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:43:47,771] Gradient total norm was 1.0747135877609253. Clipping to 0.25.
[2023-03-18 01:43:47,774] Step: 2110| lr: 0.4906 | Time: 14.60s |TRAIN loss  0.0144 | TRAIN Acc:  99.90% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:44:03,182] Gradient total norm was 0.6726822257041931. Clipping to 0.25.
[2023-03-18 01:44:03,185] Step: 2111| lr: 0.4903 | Time: 15.40s |TRAIN loss  0.0149 | TRAIN Acc:  99.84% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:44:18,726] Gradient total norm was 0.4605127274990082. Clipping to 0.25.
[2023-03-18 01:44:18,730] Step: 2112| lr: 0.4900 | Time: 15.53s |TRAIN loss  0.0134 | TRAIN Acc:  99.92% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:44:34,902] Gradient total norm was 0.43708518147468567. Clipping to 0.25.
[2023-03-18 01:44:34,906] Step: 2113| lr: 0.4897 | Time: 16.16s |TRAIN loss  0.0123 | TRAIN Acc:  99.93% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:44:50,809] Gradient total norm was 0.4035327434539795. Clipping to 0.25.
[2023-03-18 01:44:50,813] Step: 2114| lr: 0.4894 | Time: 15.89s |TRAIN loss  0.0118 | TRAIN Acc:  99.95% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:45:07,304] Gradient total norm was 0.2642282545566559. Clipping to 0.25.
[2023-03-18 01:45:07,309] Step: 2115| lr: 0.4891 | Time: 16.48s |TRAIN loss  0.0089 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:45:23,746] Gradient total norm was 0.2890078127384186. Clipping to 0.25.
[2023-03-18 01:45:23,749] Step: 2116| lr: 0.4888 | Time: 16.42s |TRAIN loss  0.0071 | TRAIN Acc: 100.00% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:45:40,022] Gradient total norm was 0.5228593945503235. Clipping to 0.25.
[2023-03-18 01:45:40,026] Step: 2117| lr: 0.4885 | Time: 16.26s |TRAIN loss  0.0072 | TRAIN Acc:  99.96% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:45:55,837] Gradient total norm was 0.5035363435745239. Clipping to 0.25.
[2023-03-18 01:45:55,843] Step: 2118| lr: 0.4882 | Time: 15.80s |TRAIN loss  0.0072 | TRAIN Acc:  99.98% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:46:11,698] Gradient total norm was 0.2807043790817261. Clipping to 0.25.
[2023-03-18 01:46:11,702] Step: 2119| lr: 0.4879 | Time: 15.84s |TRAIN loss  0.0062 | TRAIN Acc:  99.98% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:46:26,718] Step: 2120| lr: 0.4876 | Time: 15.01s |TRAIN loss  0.0053 | TRAIN Acc: 100.00% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:46:43,176] Gradient total norm was 0.27448126673698425. Clipping to 0.25.
[2023-03-18 01:46:43,181] Step: 2121| lr: 0.4873 | Time: 16.45s |TRAIN loss  0.0056 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:47:00,107] Gradient total norm was 0.48914214968681335. Clipping to 0.25.
[2023-03-18 01:47:00,111] Step: 2122| lr: 0.4870 | Time: 16.91s |TRAIN loss  0.0060 | TRAIN Acc:  99.96% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:47:16,329] Gradient total norm was 0.6012634634971619. Clipping to 0.25.
[2023-03-18 01:47:16,332] Step: 2123| lr: 0.4866 | Time: 16.21s |TRAIN loss  0.0068 | TRAIN Acc:  99.95% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:47:30,731] Gradient total norm was 0.5978896617889404. Clipping to 0.25.
[2023-03-18 01:47:30,734] Step: 2124| lr: 0.4863 | Time: 14.39s |TRAIN loss  0.0086 | TRAIN Acc:  99.89% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:47:44,980] Gradient total norm was 0.43481817841529846. Clipping to 0.25.
[2023-03-18 01:47:44,984] Step: 2125| lr: 0.4860 | Time: 14.24s |TRAIN loss  0.0086 | TRAIN Acc:  99.93% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:48:01,584] Gradient total norm was 0.2866823673248291. Clipping to 0.25.
[2023-03-18 01:48:01,588] Step: 2126| lr: 0.4857 | Time: 16.59s |TRAIN loss  0.0080 | TRAIN Acc:  99.96% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:48:17,383] Gradient total norm was 0.25861334800720215. Clipping to 0.25.
[2023-03-18 01:48:17,386] Step: 2127| lr: 0.4854 | Time: 15.78s |TRAIN loss  0.0073 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:48:32,282] Step: 2128| lr: 0.4851 | Time: 14.89s |TRAIN loss  0.0053 | TRAIN Acc: 100.00% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:48:47,236] Gradient total norm was 0.38395458459854126. Clipping to 0.25.
[2023-03-18 01:48:47,241] Step: 2129| lr: 0.4848 | Time: 14.94s |TRAIN loss  0.0051 | TRAIN Acc: 100.00% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:49:01,237] Gradient total norm was 0.6702902317047119. Clipping to 0.25.
[2023-03-18 01:49:01,241] Step: 2130| lr: 0.4845 | Time: 13.99s |TRAIN loss  0.0057 | TRAIN Acc:  99.98% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:49:16,249] Gradient total norm was 0.8814778923988342. Clipping to 0.25.
[2023-03-18 01:49:16,253] Step: 2131| lr: 0.4842 | Time: 15.00s |TRAIN loss  0.0065 | TRAIN Acc:  99.95% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:49:32,234] Gradient total norm was 0.6605994701385498. Clipping to 0.25.
[2023-03-18 01:49:32,238] Step: 2132| lr: 0.4839 | Time: 15.97s |TRAIN loss  0.0075 | TRAIN Acc:  99.93% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:49:47,095] Gradient total norm was 0.8499047160148621. Clipping to 0.25.
[2023-03-18 01:49:47,099] Step: 2133| lr: 0.4836 | Time: 14.85s |TRAIN loss  0.0111 | TRAIN Acc:  99.81% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:50:02,331] Gradient total norm was 0.3603576719760895. Clipping to 0.25.
[2023-03-18 01:50:02,336] Step: 2134| lr: 0.4833 | Time: 15.22s |TRAIN loss  0.0111 | TRAIN Acc:  99.79% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:50:18,197] Gradient total norm was 0.2611650228500366. Clipping to 0.25.
[2023-03-18 01:50:18,201] Step: 2135| lr: 0.4830 | Time: 15.85s |TRAIN loss  0.0103 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:50:33,467] Gradient total norm was 0.26000455021858215. Clipping to 0.25.
[2023-03-18 01:50:33,471] Step: 2136| lr: 0.4827 | Time: 15.26s |TRAIN loss  0.0084 | TRAIN Acc:  99.91% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:50:48,533] Gradient total norm was 0.27762770652770996. Clipping to 0.25.
[2023-03-18 01:50:48,537] Step: 2137| lr: 0.4823 | Time: 15.05s |TRAIN loss  0.0070 | TRAIN Acc: 100.00% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:51:04,714] Gradient total norm was 0.6300709247589111. Clipping to 0.25.
[2023-03-18 01:51:04,718] Step: 2138| lr: 0.4820 | Time: 16.17s |TRAIN loss  0.0069 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:51:20,846] Gradient total norm was 1.2337262630462646. Clipping to 0.25.
[2023-03-18 01:51:20,850] Step: 2139| lr: 0.4817 | Time: 16.12s |TRAIN loss  0.0085 | TRAIN Acc:  99.92% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:51:36,129] Gradient total norm was 0.841020405292511. Clipping to 0.25.
[2023-03-18 01:51:36,133] Step: 2140| lr: 0.4814 | Time: 15.27s |TRAIN loss  0.0088 | TRAIN Acc:  99.94% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:51:51,158] Gradient total norm was 0.5759111642837524. Clipping to 0.25.
[2023-03-18 01:51:51,161] Step: 2141| lr: 0.4811 | Time: 15.01s |TRAIN loss  0.0089 | TRAIN Acc:  99.96% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:52:07,453] Gradient total norm was 0.44750890135765076. Clipping to 0.25.
[2023-03-18 01:52:07,459] Step: 2142| lr: 0.4808 | Time: 16.28s |TRAIN loss  0.0094 | TRAIN Acc:  99.97% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:52:22,480] Gradient total norm was 0.48432138562202454. Clipping to 0.25.
[2023-03-18 01:52:22,484] Step: 2143| lr: 0.4805 | Time: 15.01s |TRAIN loss  0.0091 | TRAIN Acc:  99.94% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:52:37,452] Gradient total norm was 0.35423147678375244. Clipping to 0.25.
[2023-03-18 01:52:37,455] Step: 2144| lr: 0.4802 | Time: 14.96s |TRAIN loss  0.0101 | TRAIN Acc: 100.00% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:52:51,427] Gradient total norm was 0.4211205244064331. Clipping to 0.25.
[2023-03-18 01:52:51,430] Step: 2145| lr: 0.4799 | Time: 13.96s |TRAIN loss  0.0079 | TRAIN Acc:  99.98% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:53:05,479] Gradient total norm was 0.2946673631668091. Clipping to 0.25.
[2023-03-18 01:53:05,483] Step: 2146| lr: 0.4796 | Time: 14.04s |TRAIN loss  0.0084 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:53:19,490] Gradient total norm was 0.39766359329223633. Clipping to 0.25.
[2023-03-18 01:53:19,494] Step: 2147| lr: 0.4793 | Time: 14.00s |TRAIN loss  0.0065 | TRAIN Acc:  99.98% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:53:33,528] Gradient total norm was 0.32298779487609863. Clipping to 0.25.
[2023-03-18 01:53:33,531] Step: 2148| lr: 0.4790 | Time: 14.02s |TRAIN loss  0.0069 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:53:47,637] Gradient total norm was 0.3045597970485687. Clipping to 0.25.
[2023-03-18 01:53:47,641] Step: 2149| lr: 0.4787 | Time: 14.10s |TRAIN loss  0.0063 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:54:02,282] Gradient total norm was 0.25491204857826233. Clipping to 0.25.
[2023-03-18 01:54:02,287] Step: 2150| lr: 0.4783 | Time: 14.63s |TRAIN loss  0.0057 | TRAIN Acc: 100.00% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:54:18,272] Gradient total norm was 0.26871490478515625. Clipping to 0.25.
[2023-03-18 01:54:18,276] Step: 2151| lr: 0.4780 | Time: 15.97s |TRAIN loss  0.0053 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:54:34,478] Gradient total norm was 0.4196011424064636. Clipping to 0.25.
[2023-03-18 01:54:34,484] Step: 2152| lr: 0.4777 | Time: 16.19s |TRAIN loss  0.0052 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:54:49,514] Gradient total norm was 0.26170089840888977. Clipping to 0.25.
[2023-03-18 01:54:49,517] Step: 2153| lr: 0.4774 | Time: 15.02s |TRAIN loss  0.0052 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:55:05,430] Gradient total norm was 0.34122732281684875. Clipping to 0.25.
[2023-03-18 01:55:05,435] Step: 2154| lr: 0.4771 | Time: 15.90s |TRAIN loss  0.0048 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:55:20,812] Gradient total norm was 0.3018123209476471. Clipping to 0.25.
[2023-03-18 01:55:20,816] Step: 2155| lr: 0.4768 | Time: 15.37s |TRAIN loss  0.0050 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:55:35,936] Gradient total norm was 0.3168324828147888. Clipping to 0.25.
[2023-03-18 01:55:35,940] Step: 2156| lr: 0.4765 | Time: 15.11s |TRAIN loss  0.0044 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:55:51,649] Gradient total norm was 1.8002170324325562. Clipping to 0.25.
[2023-03-18 01:55:51,655] Step: 2157| lr: 0.4762 | Time: 15.70s |TRAIN loss  0.0077 | TRAIN Acc:  99.89% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:56:08,004] Gradient total norm was 1.8874253034591675. Clipping to 0.25.
[2023-03-18 01:56:08,008] Step: 2158| lr: 0.4759 | Time: 16.34s |TRAIN loss  0.0162 | TRAIN Acc:  99.57% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:56:23,186] Gradient total norm was 0.6456634998321533. Clipping to 0.25.
[2023-03-18 01:56:23,189] Step: 2159| lr: 0.4756 | Time: 15.17s |TRAIN loss  0.0105 | TRAIN Acc:  99.93% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:56:37,769] Gradient total norm was 0.5961375832557678. Clipping to 0.25.
[2023-03-18 01:56:37,772] Step: 2160| lr: 0.4753 | Time: 14.57s |TRAIN loss  0.0121 | TRAIN Acc:  99.89% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:56:53,737] Gradient total norm was 0.651740312576294. Clipping to 0.25.
[2023-03-18 01:56:53,742] Step: 2161| lr: 0.4750 | Time: 15.95s |TRAIN loss  0.0142 | TRAIN Acc:  99.81% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:57:08,401] Gradient total norm was 0.3141692578792572. Clipping to 0.25.
[2023-03-18 01:57:08,405] Step: 2162| lr: 0.4746 | Time: 14.65s |TRAIN loss  0.0103 | TRAIN Acc:  99.94% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:57:23,084] Gradient total norm was 0.27288132905960083. Clipping to 0.25.
[2023-03-18 01:57:23,089] Step: 2163| lr: 0.4743 | Time: 14.67s |TRAIN loss  0.0076 | TRAIN Acc:  99.98% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:57:37,382] Gradient total norm was 0.27071672677993774. Clipping to 0.25.
[2023-03-18 01:57:37,386] Step: 2164| lr: 0.4740 | Time: 14.28s |TRAIN loss  0.0067 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:57:52,111] Gradient total norm was 0.30516013503074646. Clipping to 0.25.
[2023-03-18 01:57:52,114] Step: 2165| lr: 0.4737 | Time: 14.71s |TRAIN loss  0.0058 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:58:06,267] Gradient total norm was 0.4110170006752014. Clipping to 0.25.
[2023-03-18 01:58:06,271] Step: 2166| lr: 0.4734 | Time: 14.14s |TRAIN loss  0.0056 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:58:20,406] Gradient total norm was 0.4827967584133148. Clipping to 0.25.
[2023-03-18 01:58:20,409] Step: 2167| lr: 0.4731 | Time: 14.12s |TRAIN loss  0.0060 | TRAIN Acc:  99.98% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:58:34,523] Gradient total norm was 0.49351605772972107. Clipping to 0.25.
[2023-03-18 01:58:34,527] Step: 2168| lr: 0.4728 | Time: 14.10s |TRAIN loss  0.0056 | TRAIN Acc:  99.97% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:58:48,498] Gradient total norm was 0.6791388988494873. Clipping to 0.25.
[2023-03-18 01:58:48,502] Step: 2169| lr: 0.4725 | Time: 13.96s |TRAIN loss  0.0069 | TRAIN Acc:  99.96% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:59:02,555] Gradient total norm was 0.5173133611679077. Clipping to 0.25.
[2023-03-18 01:59:02,558] Step: 2170| lr: 0.4722 | Time: 14.04s |TRAIN loss  0.0078 | TRAIN Acc:  99.96% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:59:16,595] Gradient total norm was 0.4045306146144867. Clipping to 0.25.
[2023-03-18 01:59:16,598] Step: 2171| lr: 0.4719 | Time: 14.03s |TRAIN loss  0.0075 | TRAIN Acc:  99.98% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:59:30,623] Gradient total norm was 0.6637293696403503. Clipping to 0.25.
[2023-03-18 01:59:30,626] Step: 2172| lr: 0.4716 | Time: 14.01s |TRAIN loss  0.0079 | TRAIN Acc:  99.97% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:59:44,662] Gradient total norm was 0.6187232136726379. Clipping to 0.25.
[2023-03-18 01:59:44,665] Step: 2173| lr: 0.4712 | Time: 14.03s |TRAIN loss  0.0100 | TRAIN Acc:  99.95% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 01:59:58,717] Gradient total norm was 0.47090017795562744. Clipping to 0.25.
[2023-03-18 01:59:58,720] Step: 2174| lr: 0.4709 | Time: 14.04s |TRAIN loss  0.0080 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:00:12,969] Gradient total norm was 0.4351164996623993. Clipping to 0.25.
[2023-03-18 02:00:12,974] Step: 2175| lr: 0.4706 | Time: 14.24s |TRAIN loss  0.0084 | TRAIN Acc:  99.97% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:00:27,181] Gradient total norm was 0.6458910703659058. Clipping to 0.25.
[2023-03-18 02:00:27,184] Step: 2176| lr: 0.4703 | Time: 14.20s |TRAIN loss  0.0081 | TRAIN Acc:  99.98% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:00:41,143] Gradient total norm was 0.4249516427516937. Clipping to 0.25.
[2023-03-18 02:00:41,146] Step: 2177| lr: 0.4700 | Time: 13.95s |TRAIN loss  0.0077 | TRAIN Acc:  99.97% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:00:55,120] Gradient total norm was 0.5805057883262634. Clipping to 0.25.
[2023-03-18 02:00:55,123] Step: 2178| lr: 0.4697 | Time: 13.96s |TRAIN loss  0.0086 | TRAIN Acc:  99.94% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:01:09,103] Gradient total norm was 0.6818320751190186. Clipping to 0.25.
[2023-03-18 02:01:09,106] Step: 2179| lr: 0.4694 | Time: 13.97s |TRAIN loss  0.0102 | TRAIN Acc:  99.87% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:01:23,090] Gradient total norm was 0.3053092956542969. Clipping to 0.25.
[2023-03-18 02:01:23,093] Step: 2180| lr: 0.4691 | Time: 13.97s |TRAIN loss  0.0101 | TRAIN Acc:  99.97% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:01:37,115] Gradient total norm was 0.2720569372177124. Clipping to 0.25.
[2023-03-18 02:01:37,118] Step: 2181| lr: 0.4688 | Time: 14.01s |TRAIN loss  0.0082 | TRAIN Acc: 100.00% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:01:51,056] Step: 2182| lr: 0.4685 | Time: 13.93s |TRAIN loss  0.0068 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:02:05,030] Step: 2183| lr: 0.4682 | Time: 13.96s |TRAIN loss  0.0055 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:02:19,002] Gradient total norm was 0.3407348692417145. Clipping to 0.25.
[2023-03-18 02:02:19,005] Step: 2184| lr: 0.4678 | Time: 13.96s |TRAIN loss  0.0051 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:02:33,042] Gradient total norm was 0.5300673246383667. Clipping to 0.25.
[2023-03-18 02:02:33,045] Step: 2185| lr: 0.4675 | Time: 14.03s |TRAIN loss  0.0063 | TRAIN Acc:  99.97% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:02:46,983] Gradient total norm was 0.3256050646305084. Clipping to 0.25.
[2023-03-18 02:02:46,987] Step: 2186| lr: 0.4672 | Time: 13.93s |TRAIN loss  0.0057 | TRAIN Acc:  99.98% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:03:00,948] Gradient total norm was 0.2992863357067108. Clipping to 0.25.
[2023-03-18 02:03:00,952] Step: 2187| lr: 0.4669 | Time: 13.95s |TRAIN loss  0.0053 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:03:14,958] Step: 2188| lr: 0.4666 | Time: 14.00s |TRAIN loss  0.0046 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:03:28,961] Step: 2189| lr: 0.4663 | Time: 13.99s |TRAIN loss  0.0046 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:03:42,956] Step: 2190| lr: 0.4660 | Time: 13.99s |TRAIN loss  0.0044 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:03:56,871] Gradient total norm was 0.7655560374259949. Clipping to 0.25.
[2023-03-18 02:03:56,874] Step: 2191| lr: 0.4657 | Time: 13.90s |TRAIN loss  0.0055 | TRAIN Acc:  99.94% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:04:10,850] Gradient total norm was 1.0368956327438354. Clipping to 0.25.
[2023-03-18 02:04:10,854] Step: 2192| lr: 0.4654 | Time: 13.97s |TRAIN loss  0.0086 | TRAIN Acc:  99.87% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:04:24,825] Gradient total norm was 0.5875070095062256. Clipping to 0.25.
[2023-03-18 02:04:24,828] Step: 2193| lr: 0.4651 | Time: 13.96s |TRAIN loss  0.0090 | TRAIN Acc:  99.93% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:04:38,775] Gradient total norm was 0.5153691172599792. Clipping to 0.25.
[2023-03-18 02:04:38,778] Step: 2194| lr: 0.4647 | Time: 13.94s |TRAIN loss  0.0104 | TRAIN Acc:  99.89% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:04:52,696] Gradient total norm was 0.5384615063667297. Clipping to 0.25.
[2023-03-18 02:04:52,699] Step: 2195| lr: 0.4644 | Time: 13.91s |TRAIN loss  0.0115 | TRAIN Acc:  99.90% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:05:06,685] Gradient total norm was 0.37908539175987244. Clipping to 0.25.
[2023-03-18 02:05:06,688] Step: 2196| lr: 0.4641 | Time: 13.98s |TRAIN loss  0.0114 | TRAIN Acc:  99.94% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:05:20,612] Gradient total norm was 0.2542721927165985. Clipping to 0.25.
[2023-03-18 02:05:20,615] Step: 2197| lr: 0.4638 | Time: 13.91s |TRAIN loss  0.0075 | TRAIN Acc:  99.99% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:05:34,607] Step: 2198| lr: 0.4635 | Time: 13.98s |TRAIN loss  0.0059 | TRAIN Acc: 100.00% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:05:49,039] Step: 2199| lr: 0.4632 | Time: 14.42s |TRAIN loss  0.0047 | TRAIN Acc: 100.00% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:06:02,986] Step: 2200| lr: 0.4629 | Time: 13.94s |TRAIN loss  0.0038 | TRAIN Acc: 100.00% |VAL loss  0.4713 | VAL Acc:  87.81% |
[2023-03-18 02:06:22,442] Step: 2201| lr: 0.4626 | Time: 13.98s |TRAIN loss  0.0035 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:06:36,331] Step: 2202| lr: 0.4623 | Time: 13.88s |TRAIN loss  0.0032 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:06:50,340] Step: 2203| lr: 0.4620 | Time: 14.00s |TRAIN loss  0.0032 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:07:04,328] Step: 2204| lr: 0.4616 | Time: 13.98s |TRAIN loss  0.0031 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:07:18,527] Step: 2205| lr: 0.4613 | Time: 14.19s |TRAIN loss  0.0030 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:07:32,851] Step: 2206| lr: 0.4610 | Time: 14.32s |TRAIN loss  0.0026 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:07:46,843] Step: 2207| lr: 0.4607 | Time: 13.98s |TRAIN loss  0.0025 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:08:00,820] Step: 2208| lr: 0.4604 | Time: 13.97s |TRAIN loss  0.0026 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:08:14,778] Step: 2209| lr: 0.4601 | Time: 13.95s |TRAIN loss  0.0025 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:08:28,764] Step: 2210| lr: 0.4598 | Time: 13.98s |TRAIN loss  0.0023 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:08:42,715] Step: 2211| lr: 0.4595 | Time: 13.94s |TRAIN loss  0.0023 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:08:56,693] Step: 2212| lr: 0.4592 | Time: 13.97s |TRAIN loss  0.0021 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:09:10,626] Step: 2213| lr: 0.4588 | Time: 13.92s |TRAIN loss  0.0022 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:09:24,555] Step: 2214| lr: 0.4585 | Time: 13.92s |TRAIN loss  0.0021 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:09:38,561] Step: 2215| lr: 0.4582 | Time: 14.00s |TRAIN loss  0.0020 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:09:52,495] Step: 2216| lr: 0.4579 | Time: 13.93s |TRAIN loss  0.0019 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:10:06,516] Step: 2217| lr: 0.4576 | Time: 14.01s |TRAIN loss  0.0018 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:10:20,525] Step: 2218| lr: 0.4573 | Time: 14.00s |TRAIN loss  0.0018 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:10:34,462] Step: 2219| lr: 0.4570 | Time: 13.93s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:10:48,420] Step: 2220| lr: 0.4567 | Time: 13.95s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:11:02,390] Step: 2221| lr: 0.4564 | Time: 13.96s |TRAIN loss  0.0017 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:11:16,427] Step: 2222| lr: 0.4560 | Time: 14.03s |TRAIN loss  0.0017 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:11:30,374] Step: 2223| lr: 0.4557 | Time: 13.94s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:11:44,315] Step: 2224| lr: 0.4554 | Time: 13.93s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:11:58,250] Step: 2225| lr: 0.4551 | Time: 13.93s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:12:12,348] Step: 2226| lr: 0.4548 | Time: 14.09s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:12:26,347] Step: 2227| lr: 0.4545 | Time: 13.99s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:12:40,256] Step: 2228| lr: 0.4542 | Time: 13.90s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:12:54,682] Step: 2229| lr: 0.4539 | Time: 14.42s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:13:08,621] Step: 2230| lr: 0.4536 | Time: 13.93s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:13:22,512] Step: 2231| lr: 0.4532 | Time: 13.88s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:13:36,495] Step: 2232| lr: 0.4529 | Time: 13.97s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:13:50,404] Step: 2233| lr: 0.4526 | Time: 13.90s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:14:04,404] Step: 2234| lr: 0.4523 | Time: 13.99s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:14:18,399] Step: 2235| lr: 0.4520 | Time: 13.99s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:14:32,333] Step: 2236| lr: 0.4517 | Time: 13.93s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:14:46,293] Step: 2237| lr: 0.4514 | Time: 13.95s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:15:00,189] Step: 2238| lr: 0.4511 | Time: 13.89s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:15:14,162] Step: 2239| lr: 0.4508 | Time: 13.96s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:15:28,131] Step: 2240| lr: 0.4504 | Time: 13.96s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:15:42,153] Step: 2241| lr: 0.4501 | Time: 14.01s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:15:56,167] Step: 2242| lr: 0.4498 | Time: 14.01s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:16:10,118] Step: 2243| lr: 0.4495 | Time: 13.94s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:16:24,159] Step: 2244| lr: 0.4492 | Time: 14.03s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:16:38,119] Step: 2245| lr: 0.4489 | Time: 13.95s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:16:52,025] Step: 2246| lr: 0.4486 | Time: 13.90s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:17:05,950] Step: 2247| lr: 0.4483 | Time: 13.92s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:17:19,875] Step: 2248| lr: 0.4480 | Time: 13.92s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:17:33,832] Step: 2249| lr: 0.4476 | Time: 13.95s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:17:47,727] Step: 2250| lr: 0.4473 | Time: 13.89s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:18:01,675] Step: 2251| lr: 0.4470 | Time: 13.94s |TRAIN loss  0.0013 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:18:15,659] Step: 2252| lr: 0.4467 | Time: 13.98s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:18:29,539] Step: 2253| lr: 0.4464 | Time: 13.87s |TRAIN loss  0.0013 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:18:43,492] Step: 2254| lr: 0.4461 | Time: 13.94s |TRAIN loss  0.0013 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:18:57,516] Step: 2255| lr: 0.4458 | Time: 14.02s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:19:11,523] Step: 2256| lr: 0.4455 | Time: 14.00s |TRAIN loss  0.0013 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:19:25,557] Step: 2257| lr: 0.4451 | Time: 14.02s |TRAIN loss  0.0013 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:19:39,508] Step: 2258| lr: 0.4448 | Time: 13.94s |TRAIN loss  0.0013 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:19:53,524] Step: 2259| lr: 0.4445 | Time: 14.01s |TRAIN loss  0.0013 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:20:07,419] Step: 2260| lr: 0.4442 | Time: 13.88s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:20:21,354] Step: 2261| lr: 0.4439 | Time: 13.92s |TRAIN loss  0.0013 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:20:35,298] Step: 2262| lr: 0.4436 | Time: 13.94s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:20:49,304] Step: 2263| lr: 0.4433 | Time: 14.00s |TRAIN loss  0.0013 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:21:03,268] Step: 2264| lr: 0.4430 | Time: 13.95s |TRAIN loss  0.0013 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:21:17,195] Step: 2265| lr: 0.4426 | Time: 13.92s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:21:31,215] Step: 2266| lr: 0.4423 | Time: 14.01s |TRAIN loss  0.0013 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:21:45,154] Step: 2267| lr: 0.4420 | Time: 13.93s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:21:59,045] Step: 2268| lr: 0.4417 | Time: 13.88s |TRAIN loss  0.0013 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:22:13,026] Step: 2269| lr: 0.4414 | Time: 13.97s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:22:26,955] Step: 2270| lr: 0.4411 | Time: 13.92s |TRAIN loss  0.0013 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:22:40,943] Step: 2271| lr: 0.4408 | Time: 13.98s |TRAIN loss  0.0013 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:22:54,928] Step: 2272| lr: 0.4405 | Time: 13.98s |TRAIN loss  0.0013 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:23:08,870] Step: 2273| lr: 0.4401 | Time: 13.93s |TRAIN loss  0.0013 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:23:22,782] Step: 2274| lr: 0.4398 | Time: 13.90s |TRAIN loss  0.0013 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:23:36,794] Step: 2275| lr: 0.4395 | Time: 14.00s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:23:50,724] Step: 2276| lr: 0.4392 | Time: 13.92s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:24:04,719] Step: 2277| lr: 0.4389 | Time: 13.99s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:24:18,710] Step: 2278| lr: 0.4386 | Time: 13.98s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:24:32,713] Step: 2279| lr: 0.4383 | Time: 13.99s |TRAIN loss  0.0013 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:24:46,627] Step: 2280| lr: 0.4380 | Time: 13.90s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:25:00,611] Step: 2281| lr: 0.4376 | Time: 13.98s |TRAIN loss  0.0013 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:25:14,691] Step: 2282| lr: 0.4373 | Time: 14.07s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:25:28,621] Step: 2283| lr: 0.4370 | Time: 13.92s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:25:42,623] Step: 2284| lr: 0.4367 | Time: 13.99s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:25:56,609] Step: 2285| lr: 0.4364 | Time: 13.98s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:26:10,575] Step: 2286| lr: 0.4361 | Time: 13.96s |TRAIN loss  0.0013 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:26:24,463] Step: 2287| lr: 0.4358 | Time: 13.88s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:26:38,444] Step: 2288| lr: 0.4355 | Time: 13.97s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:26:52,404] Step: 2289| lr: 0.4351 | Time: 13.95s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:27:06,372] Step: 2290| lr: 0.4348 | Time: 13.96s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:27:20,382] Step: 2291| lr: 0.4345 | Time: 14.00s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:27:34,347] Step: 2292| lr: 0.4342 | Time: 13.96s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:27:48,227] Step: 2293| lr: 0.4339 | Time: 13.87s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:28:02,223] Step: 2294| lr: 0.4336 | Time: 13.99s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:28:16,157] Step: 2295| lr: 0.4333 | Time: 13.93s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:28:30,084] Step: 2296| lr: 0.4329 | Time: 13.92s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:28:44,040] Step: 2297| lr: 0.4326 | Time: 13.95s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:28:58,028] Step: 2298| lr: 0.4323 | Time: 13.98s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:29:11,993] Step: 2299| lr: 0.4320 | Time: 13.96s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:29:25,874] Step: 2300| lr: 0.4317 | Time: 13.87s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.2021 | VAL Acc:  94.24% |
[2023-03-18 02:29:45,274] Step: 2301| lr: 0.4314 | Time: 14.02s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:29:59,177] Step: 2302| lr: 0.4311 | Time: 13.89s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:30:13,182] Step: 2303| lr: 0.4308 | Time: 14.00s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:30:27,130] Step: 2304| lr: 0.4304 | Time: 13.94s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:30:41,054] Step: 2305| lr: 0.4301 | Time: 13.92s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:30:54,977] Step: 2306| lr: 0.4298 | Time: 13.91s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:31:08,895] Step: 2307| lr: 0.4295 | Time: 13.91s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:31:22,879] Step: 2308| lr: 0.4292 | Time: 13.97s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:31:36,741] Step: 2309| lr: 0.4289 | Time: 13.85s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:31:50,713] Step: 2310| lr: 0.4286 | Time: 13.96s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:32:04,608] Step: 2311| lr: 0.4283 | Time: 13.89s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:32:18,538] Step: 2312| lr: 0.4279 | Time: 13.92s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:32:32,552] Step: 2313| lr: 0.4276 | Time: 14.01s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:32:46,446] Step: 2314| lr: 0.4273 | Time: 13.88s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:33:00,385] Step: 2315| lr: 0.4270 | Time: 13.93s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:33:14,323] Step: 2316| lr: 0.4267 | Time: 13.93s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:33:28,278] Step: 2317| lr: 0.4264 | Time: 13.95s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:33:42,233] Step: 2318| lr: 0.4261 | Time: 13.95s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:33:56,195] Step: 2319| lr: 0.4257 | Time: 13.95s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:34:10,097] Step: 2320| lr: 0.4254 | Time: 13.89s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:34:24,019] Step: 2321| lr: 0.4251 | Time: 13.91s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:34:37,886] Step: 2322| lr: 0.4248 | Time: 13.86s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:34:51,869] Step: 2323| lr: 0.4245 | Time: 13.97s |TRAIN loss  0.0014 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:35:05,860] Step: 2324| lr: 0.4242 | Time: 13.98s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:35:19,846] Step: 2325| lr: 0.4239 | Time: 13.98s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:35:33,741] Step: 2326| lr: 0.4235 | Time: 13.89s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:35:47,739] Step: 2327| lr: 0.4232 | Time: 13.99s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:36:01,679] Step: 2328| lr: 0.4229 | Time: 13.93s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:36:15,577] Step: 2329| lr: 0.4226 | Time: 13.89s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:36:29,590] Step: 2330| lr: 0.4223 | Time: 14.00s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:36:43,536] Step: 2331| lr: 0.4220 | Time: 13.94s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:36:57,470] Step: 2332| lr: 0.4217 | Time: 13.93s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:37:11,455] Step: 2333| lr: 0.4214 | Time: 13.98s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:37:25,359] Step: 2334| lr: 0.4210 | Time: 13.90s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:37:39,281] Step: 2335| lr: 0.4207 | Time: 13.91s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:37:53,225] Step: 2336| lr: 0.4204 | Time: 13.93s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:38:07,171] Step: 2337| lr: 0.4201 | Time: 13.94s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:38:21,185] Step: 2338| lr: 0.4198 | Time: 14.00s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:38:35,156] Step: 2339| lr: 0.4195 | Time: 13.96s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:38:49,084] Step: 2340| lr: 0.4192 | Time: 13.92s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:39:03,071] Step: 2341| lr: 0.4188 | Time: 13.98s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:39:17,314] Step: 2342| lr: 0.4185 | Time: 14.23s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:39:32,273] Step: 2343| lr: 0.4182 | Time: 14.95s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:39:46,570] Step: 2344| lr: 0.4179 | Time: 14.29s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:40:00,727] Step: 2345| lr: 0.4176 | Time: 14.15s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:40:15,392] Step: 2346| lr: 0.4173 | Time: 14.66s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:40:29,810] Step: 2347| lr: 0.4170 | Time: 14.41s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:40:44,350] Step: 2348| lr: 0.4166 | Time: 14.53s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:40:58,762] Step: 2349| lr: 0.4163 | Time: 14.40s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:41:13,079] Step: 2350| lr: 0.4160 | Time: 14.31s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:41:27,674] Step: 2351| lr: 0.4157 | Time: 14.59s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:41:42,360] Step: 2352| lr: 0.4154 | Time: 14.68s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:41:56,450] Step: 2353| lr: 0.4151 | Time: 14.08s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:42:10,509] Step: 2354| lr: 0.4148 | Time: 14.05s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:42:24,415] Step: 2355| lr: 0.4144 | Time: 13.90s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:42:38,293] Step: 2356| lr: 0.4141 | Time: 13.87s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:42:52,118] Step: 2357| lr: 0.4138 | Time: 13.81s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:43:06,042] Step: 2358| lr: 0.4135 | Time: 13.91s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:43:19,891] Step: 2359| lr: 0.4132 | Time: 13.84s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:43:33,741] Step: 2360| lr: 0.4129 | Time: 13.84s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:43:47,573] Step: 2361| lr: 0.4126 | Time: 13.82s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:44:01,491] Step: 2362| lr: 0.4123 | Time: 13.91s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:44:15,349] Step: 2363| lr: 0.4119 | Time: 13.85s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:44:29,192] Step: 2364| lr: 0.4116 | Time: 13.83s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:44:43,154] Step: 2365| lr: 0.4113 | Time: 13.95s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:44:57,025] Step: 2366| lr: 0.4110 | Time: 13.86s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:45:10,941] Step: 2367| lr: 0.4107 | Time: 13.91s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:45:24,836] Step: 2368| lr: 0.4104 | Time: 13.89s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:45:38,778] Step: 2369| lr: 0.4101 | Time: 13.93s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:45:52,724] Step: 2370| lr: 0.4097 | Time: 13.94s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:46:06,687] Step: 2371| lr: 0.4094 | Time: 13.95s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:46:20,581] Step: 2372| lr: 0.4091 | Time: 13.89s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:46:34,510] Step: 2373| lr: 0.4088 | Time: 13.92s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:46:48,387] Step: 2374| lr: 0.4085 | Time: 13.87s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:47:02,333] Step: 2375| lr: 0.4082 | Time: 13.94s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:47:16,235] Step: 2376| lr: 0.4079 | Time: 13.89s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:47:30,192] Step: 2377| lr: 0.4075 | Time: 13.95s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:47:44,136] Step: 2378| lr: 0.4072 | Time: 13.93s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:47:58,016] Step: 2379| lr: 0.4069 | Time: 13.87s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:48:11,956] Step: 2380| lr: 0.4066 | Time: 13.93s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:48:25,790] Step: 2381| lr: 0.4063 | Time: 13.82s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:48:39,741] Step: 2382| lr: 0.4060 | Time: 13.94s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:48:53,643] Step: 2383| lr: 0.4057 | Time: 13.89s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:49:07,563] Step: 2384| lr: 0.4053 | Time: 13.91s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:49:21,483] Step: 2385| lr: 0.4050 | Time: 13.91s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:49:35,379] Step: 2386| lr: 0.4047 | Time: 13.89s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:49:49,326] Step: 2387| lr: 0.4044 | Time: 13.94s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:50:03,250] Step: 2388| lr: 0.4041 | Time: 13.91s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:50:17,162] Step: 2389| lr: 0.4038 | Time: 13.90s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:50:31,015] Step: 2390| lr: 0.4035 | Time: 13.84s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:50:44,922] Step: 2391| lr: 0.4031 | Time: 13.90s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:50:58,880] Step: 2392| lr: 0.4028 | Time: 13.95s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:51:12,820] Step: 2393| lr: 0.4025 | Time: 13.93s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:51:26,851] Step: 2394| lr: 0.4022 | Time: 14.02s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:51:40,794] Step: 2395| lr: 0.4019 | Time: 13.93s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:51:54,756] Step: 2396| lr: 0.4016 | Time: 13.95s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:52:08,737] Step: 2397| lr: 0.4013 | Time: 13.97s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:52:22,622] Step: 2398| lr: 0.4009 | Time: 13.88s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:52:36,601] Step: 2399| lr: 0.4006 | Time: 13.97s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:52:50,557] Step: 2400| lr: 0.4003 | Time: 13.95s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1938 | VAL Acc:  94.83% |
[2023-03-18 02:53:09,926] Step: 2401| lr: 0.4000 | Time: 13.91s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:53:23,852] Step: 2402| lr: 0.3997 | Time: 13.92s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:53:37,735] Step: 2403| lr: 0.3994 | Time: 13.87s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:53:51,701] Step: 2404| lr: 0.3991 | Time: 13.96s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:54:05,636] Step: 2405| lr: 0.3987 | Time: 13.93s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:54:19,642] Step: 2406| lr: 0.3984 | Time: 14.00s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:54:33,538] Step: 2407| lr: 0.3981 | Time: 13.89s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:54:47,486] Step: 2408| lr: 0.3978 | Time: 13.94s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:55:01,475] Step: 2409| lr: 0.3975 | Time: 13.98s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:55:15,438] Step: 2410| lr: 0.3972 | Time: 13.95s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:55:29,360] Step: 2411| lr: 0.3969 | Time: 13.91s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:55:43,216] Step: 2412| lr: 0.3965 | Time: 13.85s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:55:57,179] Step: 2413| lr: 0.3962 | Time: 13.95s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:56:11,212] Step: 2414| lr: 0.3959 | Time: 14.02s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:56:25,154] Step: 2415| lr: 0.3956 | Time: 13.93s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:56:39,097] Step: 2416| lr: 0.3953 | Time: 13.93s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:56:52,934] Step: 2417| lr: 0.3950 | Time: 13.83s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:57:06,842] Step: 2418| lr: 0.3947 | Time: 13.90s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:57:20,765] Step: 2419| lr: 0.3943 | Time: 13.91s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:57:34,613] Step: 2420| lr: 0.3940 | Time: 13.84s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:57:48,562] Step: 2421| lr: 0.3937 | Time: 13.94s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:58:02,458] Step: 2422| lr: 0.3934 | Time: 13.89s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:58:16,357] Step: 2423| lr: 0.3931 | Time: 13.89s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:58:30,265] Step: 2424| lr: 0.3928 | Time: 13.90s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:58:44,183] Step: 2425| lr: 0.3925 | Time: 13.91s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:58:58,089] Step: 2426| lr: 0.3921 | Time: 13.90s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:59:12,002] Step: 2427| lr: 0.3918 | Time: 13.90s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:59:25,936] Step: 2428| lr: 0.3915 | Time: 13.92s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:59:39,920] Step: 2429| lr: 0.3912 | Time: 13.98s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 02:59:53,861] Step: 2430| lr: 0.3909 | Time: 13.93s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:00:07,779] Step: 2431| lr: 0.3906 | Time: 13.91s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:00:21,660] Step: 2432| lr: 0.3903 | Time: 13.87s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:00:35,650] Step: 2433| lr: 0.3899 | Time: 13.98s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:00:49,651] Step: 2434| lr: 0.3896 | Time: 13.99s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:01:03,620] Step: 2435| lr: 0.3893 | Time: 13.96s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:01:17,594] Step: 2436| lr: 0.3890 | Time: 13.97s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:01:31,506] Step: 2437| lr: 0.3887 | Time: 13.90s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:01:45,445] Step: 2438| lr: 0.3884 | Time: 13.93s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:01:59,390] Step: 2439| lr: 0.3881 | Time: 13.94s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:02:13,418] Step: 2440| lr: 0.3877 | Time: 14.02s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:02:27,418] Step: 2441| lr: 0.3874 | Time: 13.99s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:02:41,327] Step: 2442| lr: 0.3871 | Time: 13.90s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:02:55,312] Step: 2443| lr: 0.3868 | Time: 13.98s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:03:09,287] Step: 2444| lr: 0.3865 | Time: 13.97s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:03:23,182] Step: 2445| lr: 0.3862 | Time: 13.89s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:03:37,100] Step: 2446| lr: 0.3859 | Time: 13.91s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:03:51,075] Step: 2447| lr: 0.3856 | Time: 13.97s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:04:05,073] Step: 2448| lr: 0.3852 | Time: 13.99s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:04:19,024] Step: 2449| lr: 0.3849 | Time: 13.94s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:04:33,060] Step: 2450| lr: 0.3846 | Time: 14.03s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:04:47,041] Step: 2451| lr: 0.3843 | Time: 13.97s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:05:00,951] Step: 2452| lr: 0.3840 | Time: 13.90s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:05:14,833] Step: 2453| lr: 0.3837 | Time: 13.87s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:05:28,734] Step: 2454| lr: 0.3834 | Time: 13.89s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:05:42,699] Step: 2455| lr: 0.3830 | Time: 13.96s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:05:56,734] Step: 2456| lr: 0.3827 | Time: 14.03s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:06:11,625] Step: 2457| lr: 0.3824 | Time: 14.88s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:06:27,281] Step: 2458| lr: 0.3821 | Time: 15.65s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:06:41,419] Step: 2459| lr: 0.3818 | Time: 14.13s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:06:55,379] Step: 2460| lr: 0.3815 | Time: 13.95s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:07:09,277] Step: 2461| lr: 0.3812 | Time: 13.89s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:07:23,162] Step: 2462| lr: 0.3808 | Time: 13.88s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:07:37,177] Step: 2463| lr: 0.3805 | Time: 14.01s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:07:51,186] Step: 2464| lr: 0.3802 | Time: 14.00s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:08:05,375] Step: 2465| lr: 0.3799 | Time: 14.18s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:08:19,525] Step: 2466| lr: 0.3796 | Time: 14.14s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:08:33,607] Step: 2467| lr: 0.3793 | Time: 14.07s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:08:48,010] Step: 2468| lr: 0.3790 | Time: 14.39s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:09:02,338] Step: 2469| lr: 0.3786 | Time: 14.32s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:09:17,173] Step: 2470| lr: 0.3783 | Time: 14.82s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:09:31,510] Step: 2471| lr: 0.3780 | Time: 14.33s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:09:46,317] Step: 2472| lr: 0.3777 | Time: 14.80s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:10:00,759] Step: 2473| lr: 0.3774 | Time: 14.43s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:10:15,095] Step: 2474| lr: 0.3771 | Time: 14.33s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:10:29,873] Step: 2475| lr: 0.3768 | Time: 14.77s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:10:44,978] Step: 2476| lr: 0.3765 | Time: 15.10s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:10:59,830] Step: 2477| lr: 0.3761 | Time: 14.84s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:11:14,463] Step: 2478| lr: 0.3758 | Time: 14.62s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:11:29,060] Step: 2479| lr: 0.3755 | Time: 14.59s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:11:43,441] Step: 2480| lr: 0.3752 | Time: 14.37s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:11:58,050] Step: 2481| lr: 0.3749 | Time: 14.60s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:12:12,772] Step: 2482| lr: 0.3746 | Time: 14.71s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:12:27,627] Step: 2483| lr: 0.3743 | Time: 14.85s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:12:41,985] Step: 2484| lr: 0.3739 | Time: 14.35s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:12:56,893] Step: 2485| lr: 0.3736 | Time: 14.90s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:13:11,470] Step: 2486| lr: 0.3733 | Time: 14.57s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:13:25,646] Step: 2487| lr: 0.3730 | Time: 14.17s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:13:40,601] Step: 2488| lr: 0.3727 | Time: 14.95s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:13:55,054] Step: 2489| lr: 0.3724 | Time: 14.44s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:14:09,744] Step: 2490| lr: 0.3721 | Time: 14.68s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:14:24,045] Step: 2491| lr: 0.3717 | Time: 14.29s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:14:38,570] Step: 2492| lr: 0.3714 | Time: 14.52s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:14:53,633] Step: 2493| lr: 0.3711 | Time: 15.05s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:15:07,912] Step: 2494| lr: 0.3708 | Time: 14.27s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:15:22,814] Step: 2495| lr: 0.3705 | Time: 14.89s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:15:37,401] Step: 2496| lr: 0.3702 | Time: 14.58s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:15:51,957] Step: 2497| lr: 0.3699 | Time: 14.55s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:16:06,703] Step: 2498| lr: 0.3696 | Time: 14.74s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:16:22,107] Step: 2499| lr: 0.3692 | Time: 15.39s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:16:37,893] Step: 2500| lr: 0.3689 | Time: 15.77s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1990 | VAL Acc:  94.71% |
[2023-03-18 03:16:59,893] Step: 2501| lr: 0.3686 | Time: 16.15s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:17:15,208] Step: 2502| lr: 0.3683 | Time: 15.31s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:17:31,293] Step: 2503| lr: 0.3680 | Time: 16.08s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:17:48,007] Step: 2504| lr: 0.3677 | Time: 16.70s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:18:03,173] Step: 2505| lr: 0.3674 | Time: 15.15s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:18:18,573] Step: 2506| lr: 0.3671 | Time: 15.39s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:18:34,086] Step: 2507| lr: 0.3667 | Time: 15.50s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:18:49,665] Step: 2508| lr: 0.3664 | Time: 15.57s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:19:05,106] Step: 2509| lr: 0.3661 | Time: 15.43s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:19:21,315] Step: 2510| lr: 0.3658 | Time: 16.20s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:19:38,026] Step: 2511| lr: 0.3655 | Time: 16.70s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:19:55,015] Step: 2512| lr: 0.3652 | Time: 16.98s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:20:09,880] Step: 2513| lr: 0.3649 | Time: 14.86s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:20:25,205] Step: 2514| lr: 0.3645 | Time: 15.32s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:20:41,589] Step: 2515| lr: 0.3642 | Time: 16.37s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:20:58,035] Step: 2516| lr: 0.3639 | Time: 16.44s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:21:14,253] Step: 2517| lr: 0.3636 | Time: 16.21s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:21:30,480] Step: 2518| lr: 0.3633 | Time: 16.22s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:21:47,264] Step: 2519| lr: 0.3630 | Time: 16.77s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:22:03,225] Step: 2520| lr: 0.3627 | Time: 15.95s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:22:18,775] Step: 2521| lr: 0.3624 | Time: 15.54s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:22:35,319] Step: 2522| lr: 0.3620 | Time: 16.53s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:22:51,739] Step: 2523| lr: 0.3617 | Time: 16.41s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:23:07,780] Step: 2524| lr: 0.3614 | Time: 16.03s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:23:23,730] Step: 2525| lr: 0.3611 | Time: 15.94s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:23:39,912] Step: 2526| lr: 0.3608 | Time: 16.17s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:23:56,281] Step: 2527| lr: 0.3605 | Time: 16.36s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:24:12,463] Step: 2528| lr: 0.3602 | Time: 16.17s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:24:27,705] Step: 2529| lr: 0.3599 | Time: 15.23s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:24:42,951] Step: 2530| lr: 0.3595 | Time: 15.23s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:24:59,493] Step: 2531| lr: 0.3592 | Time: 16.53s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:25:15,705] Step: 2532| lr: 0.3589 | Time: 16.20s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:25:32,313] Step: 2533| lr: 0.3586 | Time: 16.60s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:25:48,947] Gradient total norm was 41.159549713134766. Clipping to 0.25.
[2023-03-18 03:25:48,951] Step: 2534| lr: 0.3583 | Time: 16.62s |TRAIN loss  0.0265 | TRAIN Acc:  99.04% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:26:05,475] Gradient total norm was 37.37564468383789. Clipping to 0.25.
[2023-03-18 03:26:05,480] Step: 2535| lr: 0.3580 | Time: 16.51s |TRAIN loss  0.0691 | TRAIN Acc:  97.88% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:26:21,892] Gradient total norm was 20.22689437866211. Clipping to 0.25.
[2023-03-18 03:26:21,896] Step: 2536| lr: 0.3577 | Time: 16.40s |TRAIN loss  0.0470 | TRAIN Acc:  99.15% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:26:37,700] Gradient total norm was 26.013874053955078. Clipping to 0.25.
[2023-03-18 03:26:37,703] Step: 2537| lr: 0.3574 | Time: 15.79s |TRAIN loss  0.0757 | TRAIN Acc:  98.94% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:26:52,863] Gradient total norm was 11.429097175598145. Clipping to 0.25.
[2023-03-18 03:26:52,867] Step: 2538| lr: 0.3570 | Time: 15.15s |TRAIN loss  0.0998 | TRAIN Acc:  98.27% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:27:09,263] Gradient total norm was 7.784121513366699. Clipping to 0.25.
[2023-03-18 03:27:09,267] Step: 2539| lr: 0.3567 | Time: 16.39s |TRAIN loss  0.0686 | TRAIN Acc:  99.48% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:27:25,902] Gradient total norm was 8.73059368133545. Clipping to 0.25.
[2023-03-18 03:27:25,905] Step: 2540| lr: 0.3564 | Time: 16.62s |TRAIN loss  0.0666 | TRAIN Acc:  99.55% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:27:42,943] Gradient total norm was 7.340005874633789. Clipping to 0.25.
[2023-03-18 03:27:42,946] Step: 2541| lr: 0.3561 | Time: 17.03s |TRAIN loss  0.0626 | TRAIN Acc:  99.64% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:27:58,520] Gradient total norm was 6.801815509796143. Clipping to 0.25.
[2023-03-18 03:27:58,524] Step: 2542| lr: 0.3558 | Time: 15.56s |TRAIN loss  0.0598 | TRAIN Acc:  99.66% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:28:14,603] Gradient total norm was 7.551751613616943. Clipping to 0.25.
[2023-03-18 03:28:14,606] Step: 2543| lr: 0.3555 | Time: 16.07s |TRAIN loss  0.0623 | TRAIN Acc:  99.53% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:28:31,541] Gradient total norm was 7.21285343170166. Clipping to 0.25.
[2023-03-18 03:28:31,546] Step: 2544| lr: 0.3552 | Time: 16.92s |TRAIN loss  0.0556 | TRAIN Acc:  99.80% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:28:48,006] Gradient total norm was 8.128549575805664. Clipping to 0.25.
[2023-03-18 03:28:48,010] Step: 2545| lr: 0.3549 | Time: 16.45s |TRAIN loss  0.0584 | TRAIN Acc:  99.72% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:29:04,611] Gradient total norm was 5.423393249511719. Clipping to 0.25.
[2023-03-18 03:29:04,616] Step: 2546| lr: 0.3545 | Time: 16.59s |TRAIN loss  0.0523 | TRAIN Acc:  99.86% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:29:19,712] Gradient total norm was 12.169931411743164. Clipping to 0.25.
[2023-03-18 03:29:19,715] Step: 2547| lr: 0.3542 | Time: 15.08s |TRAIN loss  0.0550 | TRAIN Acc:  99.73% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:29:34,304] Gradient total norm was 5.2576375007629395. Clipping to 0.25.
[2023-03-18 03:29:34,307] Step: 2548| lr: 0.3539 | Time: 14.58s |TRAIN loss  0.0449 | TRAIN Acc:  99.93% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:29:50,314] Gradient total norm was 4.31837272644043. Clipping to 0.25.
[2023-03-18 03:29:50,317] Step: 2549| lr: 0.3536 | Time: 16.00s |TRAIN loss  0.0430 | TRAIN Acc:  99.92% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:30:06,162] Gradient total norm was 9.282572746276855. Clipping to 0.25.
[2023-03-18 03:30:06,167] Step: 2550| lr: 0.3533 | Time: 15.83s |TRAIN loss  0.0505 | TRAIN Acc:  99.65% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:30:22,069] Gradient total norm was 3.8429417610168457. Clipping to 0.25.
[2023-03-18 03:30:22,075] Step: 2551| lr: 0.3530 | Time: 15.89s |TRAIN loss  0.0401 | TRAIN Acc:  99.95% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:30:38,159] Gradient total norm was 7.705196857452393. Clipping to 0.25.
[2023-03-18 03:30:38,163] Step: 2552| lr: 0.3527 | Time: 16.07s |TRAIN loss  0.0431 | TRAIN Acc:  99.88% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:30:54,553] Gradient total norm was 3.128920555114746. Clipping to 0.25.
[2023-03-18 03:30:54,558] Step: 2553| lr: 0.3524 | Time: 16.38s |TRAIN loss  0.0352 | TRAIN Acc:  99.96% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:31:10,815] Gradient total norm was 4.906955242156982. Clipping to 0.25.
[2023-03-18 03:31:10,819] Step: 2554| lr: 0.3520 | Time: 16.25s |TRAIN loss  0.0354 | TRAIN Acc:  99.90% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:31:27,267] Gradient total norm was 4.526017189025879. Clipping to 0.25.
[2023-03-18 03:31:27,272] Step: 2555| lr: 0.3517 | Time: 16.43s |TRAIN loss  0.0355 | TRAIN Acc:  99.91% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:31:42,849] Gradient total norm was 5.512993335723877. Clipping to 0.25.
[2023-03-18 03:31:42,852] Step: 2556| lr: 0.3514 | Time: 15.57s |TRAIN loss  0.0348 | TRAIN Acc:  99.90% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:31:57,662] Gradient total norm was 2.696729898452759. Clipping to 0.25.
[2023-03-18 03:31:57,666] Step: 2557| lr: 0.3511 | Time: 14.80s |TRAIN loss  0.0305 | TRAIN Acc:  99.97% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:32:13,486] Gradient total norm was 3.827746868133545. Clipping to 0.25.
[2023-03-18 03:32:13,490] Step: 2558| lr: 0.3508 | Time: 15.81s |TRAIN loss  0.0301 | TRAIN Acc:  99.96% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:32:29,611] Gradient total norm was 3.1468305587768555. Clipping to 0.25.
[2023-03-18 03:32:29,615] Step: 2559| lr: 0.3505 | Time: 16.11s |TRAIN loss  0.0285 | TRAIN Acc:  99.96% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:32:45,644] Gradient total norm was 2.9289968013763428. Clipping to 0.25.
[2023-03-18 03:32:45,647] Step: 2560| lr: 0.3502 | Time: 16.02s |TRAIN loss  0.0264 | TRAIN Acc:  99.95% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:33:01,402] Gradient total norm was 2.9084668159484863. Clipping to 0.25.
[2023-03-18 03:33:01,406] Step: 2561| lr: 0.3499 | Time: 15.74s |TRAIN loss  0.0267 | TRAIN Acc:  99.96% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:33:17,380] Gradient total norm was 3.359529972076416. Clipping to 0.25.
[2023-03-18 03:33:17,384] Step: 2562| lr: 0.3496 | Time: 15.96s |TRAIN loss  0.0265 | TRAIN Acc:  99.90% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:33:32,187] Gradient total norm was 1.755776286125183. Clipping to 0.25.
[2023-03-18 03:33:32,191] Step: 2563| lr: 0.3492 | Time: 14.79s |TRAIN loss  0.0239 | TRAIN Acc:  99.98% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:33:48,816] Gradient total norm was 2.452592372894287. Clipping to 0.25.
[2023-03-18 03:33:48,821] Step: 2564| lr: 0.3489 | Time: 16.61s |TRAIN loss  0.0239 | TRAIN Acc:  99.94% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:34:05,338] Gradient total norm was 1.6455973386764526. Clipping to 0.25.
[2023-03-18 03:34:05,341] Step: 2565| lr: 0.3486 | Time: 16.51s |TRAIN loss  0.0218 | TRAIN Acc:  99.96% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:34:21,718] Gradient total norm was 3.2967395782470703. Clipping to 0.25.
[2023-03-18 03:34:21,723] Step: 2566| lr: 0.3483 | Time: 16.36s |TRAIN loss  0.0238 | TRAIN Acc:  99.86% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:34:38,060] Gradient total norm was 1.5813268423080444. Clipping to 0.25.
[2023-03-18 03:34:38,065] Step: 2567| lr: 0.3480 | Time: 16.32s |TRAIN loss  0.0212 | TRAIN Acc:  99.92% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:34:54,130] Gradient total norm was 3.5177080631256104. Clipping to 0.25.
[2023-03-18 03:34:54,135] Step: 2568| lr: 0.3477 | Time: 16.05s |TRAIN loss  0.0282 | TRAIN Acc:  99.77% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:35:10,124] Gradient total norm was 2.5416488647460938. Clipping to 0.25.
[2023-03-18 03:35:10,128] Step: 2569| lr: 0.3474 | Time: 15.98s |TRAIN loss  0.0277 | TRAIN Acc:  99.73% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:35:24,203] Gradient total norm was 1.5531786680221558. Clipping to 0.25.
[2023-03-18 03:35:24,206] Step: 2570| lr: 0.3471 | Time: 14.06s |TRAIN loss  0.0377 | TRAIN Acc:  99.70% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:35:39,905] Gradient total norm was 1.2569233179092407. Clipping to 0.25.
[2023-03-18 03:35:39,909] Step: 2571| lr: 0.3468 | Time: 15.69s |TRAIN loss  0.0302 | TRAIN Acc:  99.84% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:35:56,040] Gradient total norm was 1.0408406257629395. Clipping to 0.25.
[2023-03-18 03:35:56,045] Step: 2572| lr: 0.3464 | Time: 16.12s |TRAIN loss  0.0265 | TRAIN Acc:  99.93% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:36:10,472] Gradient total norm was 1.355538249015808. Clipping to 0.25.
[2023-03-18 03:36:10,477] Step: 2573| lr: 0.3461 | Time: 14.41s |TRAIN loss  0.0239 | TRAIN Acc:  99.98% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:36:26,020] Gradient total norm was 1.212293267250061. Clipping to 0.25.
[2023-03-18 03:36:26,024] Step: 2574| lr: 0.3458 | Time: 15.53s |TRAIN loss  0.0176 | TRAIN Acc:  99.98% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:36:42,214] Gradient total norm was 2.183177947998047. Clipping to 0.25.
[2023-03-18 03:36:42,219] Step: 2575| lr: 0.3455 | Time: 16.18s |TRAIN loss  0.0195 | TRAIN Acc:  99.96% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:36:58,654] Gradient total norm was 1.7617970705032349. Clipping to 0.25.
[2023-03-18 03:36:58,658] Step: 2576| lr: 0.3452 | Time: 16.42s |TRAIN loss  0.0176 | TRAIN Acc:  99.87% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:37:14,645] Gradient total norm was 1.6840018033981323. Clipping to 0.25.
[2023-03-18 03:37:14,649] Step: 2577| lr: 0.3449 | Time: 15.97s |TRAIN loss  0.0187 | TRAIN Acc:  99.94% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:37:30,082] Gradient total norm was 2.168456792831421. Clipping to 0.25.
[2023-03-18 03:37:30,086] Step: 2578| lr: 0.3446 | Time: 15.42s |TRAIN loss  0.0221 | TRAIN Acc:  99.76% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:37:46,248] Gradient total norm was 1.984202265739441. Clipping to 0.25.
[2023-03-18 03:37:46,252] Step: 2579| lr: 0.3443 | Time: 16.15s |TRAIN loss  0.0326 | TRAIN Acc:  99.46% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:38:01,730] Gradient total norm was 1.075939416885376. Clipping to 0.25.
[2023-03-18 03:38:01,734] Step: 2580| lr: 0.3440 | Time: 15.47s |TRAIN loss  0.0281 | TRAIN Acc:  99.88% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:38:16,906] Gradient total norm was 1.3830697536468506. Clipping to 0.25.
[2023-03-18 03:38:16,909] Step: 2581| lr: 0.3436 | Time: 15.16s |TRAIN loss  0.0262 | TRAIN Acc:  99.87% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:38:31,459] Gradient total norm was 1.3375319242477417. Clipping to 0.25.
[2023-03-18 03:38:31,462] Step: 2582| lr: 0.3433 | Time: 14.54s |TRAIN loss  0.0200 | TRAIN Acc:  99.95% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:38:46,347] Gradient total norm was 2.7234041690826416. Clipping to 0.25.
[2023-03-18 03:38:46,352] Step: 2583| lr: 0.3430 | Time: 14.87s |TRAIN loss  0.0224 | TRAIN Acc:  99.86% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:39:01,194] Gradient total norm was 0.874622642993927. Clipping to 0.25.
[2023-03-18 03:39:01,199] Step: 2584| lr: 0.3427 | Time: 14.83s |TRAIN loss  0.0208 | TRAIN Acc:  99.94% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:39:16,852] Gradient total norm was 1.4606492519378662. Clipping to 0.25.
[2023-03-18 03:39:16,857] Step: 2585| lr: 0.3424 | Time: 15.64s |TRAIN loss  0.0173 | TRAIN Acc:  99.97% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:39:32,837] Gradient total norm was 1.7374091148376465. Clipping to 0.25.
[2023-03-18 03:39:32,841] Step: 2586| lr: 0.3421 | Time: 15.97s |TRAIN loss  0.0222 | TRAIN Acc:  99.92% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:39:49,576] Gradient total norm was 2.551215171813965. Clipping to 0.25.
[2023-03-18 03:39:49,579] Step: 2587| lr: 0.3418 | Time: 16.72s |TRAIN loss  0.0245 | TRAIN Acc:  99.79% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:40:05,072] Gradient total norm was 0.9705798625946045. Clipping to 0.25.
[2023-03-18 03:40:05,076] Step: 2588| lr: 0.3415 | Time: 15.48s |TRAIN loss  0.0243 | TRAIN Acc:  99.90% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:40:19,783] Gradient total norm was 1.3089425563812256. Clipping to 0.25.
[2023-03-18 03:40:19,787] Step: 2589| lr: 0.3412 | Time: 14.70s |TRAIN loss  0.0238 | TRAIN Acc:  99.90% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:40:34,249] Gradient total norm was 3.0706958770751953. Clipping to 0.25.
[2023-03-18 03:40:34,252] Step: 2590| lr: 0.3408 | Time: 14.45s |TRAIN loss  0.0235 | TRAIN Acc:  99.78% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:40:50,521] Gradient total norm was 2.005601167678833. Clipping to 0.25.
[2023-03-18 03:40:50,526] Step: 2591| lr: 0.3405 | Time: 16.25s |TRAIN loss  0.0312 | TRAIN Acc:  99.59% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:41:06,928] Gradient total norm was 1.5836447477340698. Clipping to 0.25.
[2023-03-18 03:41:06,933] Step: 2592| lr: 0.3402 | Time: 16.39s |TRAIN loss  0.0318 | TRAIN Acc:  99.87% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:41:23,166] Gradient total norm was 2.259711265563965. Clipping to 0.25.
[2023-03-18 03:41:23,169] Step: 2593| lr: 0.3399 | Time: 16.22s |TRAIN loss  0.0328 | TRAIN Acc:  99.59% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:41:38,651] Gradient total norm was 5.687464237213135. Clipping to 0.25.
[2023-03-18 03:41:38,656] Step: 2594| lr: 0.3396 | Time: 15.47s |TRAIN loss  0.0539 | TRAIN Acc:  98.96% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:41:54,393] Gradient total norm was 1.6377625465393066. Clipping to 0.25.
[2023-03-18 03:41:54,397] Step: 2595| lr: 0.3393 | Time: 15.73s |TRAIN loss  0.0467 | TRAIN Acc:  99.54% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:42:08,642] Gradient total norm was 4.390626907348633. Clipping to 0.25.
[2023-03-18 03:42:08,646] Step: 2596| lr: 0.3390 | Time: 14.23s |TRAIN loss  0.0621 | TRAIN Acc:  98.89% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:42:24,814] Gradient total norm was 2.6771395206451416. Clipping to 0.25.
[2023-03-18 03:42:24,817] Step: 2597| lr: 0.3387 | Time: 16.16s |TRAIN loss  0.0494 | TRAIN Acc:  99.50% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:42:40,226] Gradient total norm was 2.614123821258545. Clipping to 0.25.
[2023-03-18 03:42:40,229] Step: 2598| lr: 0.3384 | Time: 15.40s |TRAIN loss  0.0643 | TRAIN Acc:  98.84% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:42:55,464] Gradient total norm was 1.3939992189407349. Clipping to 0.25.
[2023-03-18 03:42:55,468] Step: 2599| lr: 0.3380 | Time: 15.22s |TRAIN loss  0.0576 | TRAIN Acc:  99.49% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:43:11,659] Gradient total norm was 1.0162577629089355. Clipping to 0.25.
[2023-03-18 03:43:11,663] Step: 2600| lr: 0.3377 | Time: 16.18s |TRAIN loss  0.0491 | TRAIN Acc:  99.60% |VAL loss  0.2001 | VAL Acc:  94.84% |
[2023-03-18 03:43:26,275] Gradient total norm was 1.2232352495193481. Clipping to 0.25.
[2023-03-18 03:43:32,212] Step: 2601| lr: 0.3374 | Time: 14.60s |TRAIN loss  0.0376 | TRAIN Acc:  99.78% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:43:48,186] Gradient total norm was 0.9157793521881104. Clipping to 0.25.
[2023-03-18 03:43:48,190] Step: 2602| lr: 0.3371 | Time: 15.96s |TRAIN loss  0.0309 | TRAIN Acc:  99.86% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:44:04,306] Gradient total norm was 1.0867923498153687. Clipping to 0.25.
[2023-03-18 03:44:04,314] Step: 2603| lr: 0.3368 | Time: 16.10s |TRAIN loss  0.0257 | TRAIN Acc:  99.90% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:44:20,112] Gradient total norm was 1.7546714544296265. Clipping to 0.25.
[2023-03-18 03:44:20,116] Step: 2604| lr: 0.3365 | Time: 15.78s |TRAIN loss  0.0256 | TRAIN Acc:  99.81% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:44:34,904] Gradient total norm was 1.3801177740097046. Clipping to 0.25.
[2023-03-18 03:44:34,910] Step: 2605| lr: 0.3362 | Time: 14.77s |TRAIN loss  0.0262 | TRAIN Acc:  99.79% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:44:49,701] Gradient total norm was 0.8379508256912231. Clipping to 0.25.
[2023-03-18 03:44:49,706] Step: 2606| lr: 0.3359 | Time: 14.78s |TRAIN loss  0.0228 | TRAIN Acc:  99.95% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:45:04,473] Gradient total norm was 1.5713225603103638. Clipping to 0.25.
[2023-03-18 03:45:04,476] Step: 2607| lr: 0.3356 | Time: 14.75s |TRAIN loss  0.0231 | TRAIN Acc:  99.86% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:45:19,175] Gradient total norm was 2.0659403800964355. Clipping to 0.25.
[2023-03-18 03:45:19,178] Step: 2608| lr: 0.3353 | Time: 14.69s |TRAIN loss  0.0278 | TRAIN Acc:  99.75% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:45:33,991] Gradient total norm was 0.9731940031051636. Clipping to 0.25.
[2023-03-18 03:45:33,994] Step: 2609| lr: 0.3349 | Time: 14.80s |TRAIN loss  0.0261 | TRAIN Acc:  99.86% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:45:48,764] Gradient total norm was 0.9899742603302002. Clipping to 0.25.
[2023-03-18 03:45:48,767] Step: 2610| lr: 0.3346 | Time: 14.76s |TRAIN loss  0.0285 | TRAIN Acc:  99.83% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:46:03,023] Gradient total norm was 0.7238331437110901. Clipping to 0.25.
[2023-03-18 03:46:03,026] Step: 2611| lr: 0.3343 | Time: 14.24s |TRAIN loss  0.0235 | TRAIN Acc:  99.87% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:46:17,037] Gradient total norm was 0.6922785639762878. Clipping to 0.25.
[2023-03-18 03:46:17,041] Step: 2612| lr: 0.3340 | Time: 14.00s |TRAIN loss  0.0200 | TRAIN Acc:  99.96% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:46:31,085] Gradient total norm was 0.7483779788017273. Clipping to 0.25.
[2023-03-18 03:46:31,088] Step: 2613| lr: 0.3337 | Time: 14.03s |TRAIN loss  0.0174 | TRAIN Acc:  99.94% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:46:45,189] Gradient total norm was 0.8212796449661255. Clipping to 0.25.
[2023-03-18 03:46:45,193] Step: 2614| lr: 0.3334 | Time: 14.09s |TRAIN loss  0.0148 | TRAIN Acc:  99.98% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:46:59,259] Gradient total norm was 1.113691806793213. Clipping to 0.25.
[2023-03-18 03:46:59,263] Step: 2615| lr: 0.3331 | Time: 14.06s |TRAIN loss  0.0151 | TRAIN Acc:  99.96% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:47:13,351] Gradient total norm was 0.830513596534729. Clipping to 0.25.
[2023-03-18 03:47:13,355] Step: 2616| lr: 0.3328 | Time: 14.08s |TRAIN loss  0.0156 | TRAIN Acc:  99.91% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:47:27,463] Gradient total norm was 0.9429953098297119. Clipping to 0.25.
[2023-03-18 03:47:27,466] Step: 2617| lr: 0.3325 | Time: 14.10s |TRAIN loss  0.0135 | TRAIN Acc:  99.98% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:47:41,453] Gradient total norm was 0.9812893867492676. Clipping to 0.25.
[2023-03-18 03:47:41,457] Step: 2618| lr: 0.3322 | Time: 13.98s |TRAIN loss  0.0149 | TRAIN Acc:  99.96% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:47:55,451] Gradient total norm was 0.6546860933303833. Clipping to 0.25.
[2023-03-18 03:47:55,455] Step: 2619| lr: 0.3318 | Time: 13.98s |TRAIN loss  0.0125 | TRAIN Acc:  99.99% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:48:09,562] Gradient total norm was 0.6342145204544067. Clipping to 0.25.
[2023-03-18 03:48:09,565] Step: 2620| lr: 0.3315 | Time: 14.10s |TRAIN loss  0.0124 | TRAIN Acc:  99.99% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:48:23,828] Gradient total norm was 0.6054370403289795. Clipping to 0.25.
[2023-03-18 03:48:23,833] Step: 2621| lr: 0.3312 | Time: 14.25s |TRAIN loss  0.0111 | TRAIN Acc:  99.99% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:48:37,827] Gradient total norm was 3.1222269535064697. Clipping to 0.25.
[2023-03-18 03:48:37,830] Step: 2622| lr: 0.3309 | Time: 13.98s |TRAIN loss  0.0156 | TRAIN Acc:  99.79% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:48:51,827] Gradient total norm was 1.0930687189102173. Clipping to 0.25.
[2023-03-18 03:48:51,830] Step: 2623| lr: 0.3306 | Time: 13.99s |TRAIN loss  0.0141 | TRAIN Acc:  99.95% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:49:05,833] Gradient total norm was 1.0254497528076172. Clipping to 0.25.
[2023-03-18 03:49:05,837] Step: 2624| lr: 0.3303 | Time: 13.99s |TRAIN loss  0.0154 | TRAIN Acc:  99.91% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:49:19,846] Gradient total norm was 1.0189414024353027. Clipping to 0.25.
[2023-03-18 03:49:19,850] Step: 2625| lr: 0.3300 | Time: 14.00s |TRAIN loss  0.0186 | TRAIN Acc:  99.93% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:49:34,050] Gradient total norm was 0.9199502468109131. Clipping to 0.25.
[2023-03-18 03:49:34,053] Step: 2626| lr: 0.3297 | Time: 14.19s |TRAIN loss  0.0224 | TRAIN Acc:  99.91% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:49:48,091] Gradient total norm was 0.998772919178009. Clipping to 0.25.
[2023-03-18 03:49:48,095] Step: 2627| lr: 0.3294 | Time: 14.03s |TRAIN loss  0.0170 | TRAIN Acc:  99.96% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:50:02,150] Gradient total norm was 1.0681623220443726. Clipping to 0.25.
[2023-03-18 03:50:02,153] Step: 2628| lr: 0.3291 | Time: 14.04s |TRAIN loss  0.0196 | TRAIN Acc:  99.99% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:50:16,511] Gradient total norm was 1.1167738437652588. Clipping to 0.25.
[2023-03-18 03:50:16,514] Step: 2629| lr: 0.3288 | Time: 14.35s |TRAIN loss  0.0144 | TRAIN Acc:  99.98% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:50:30,530] Gradient total norm was 1.3990044593811035. Clipping to 0.25.
[2023-03-18 03:50:30,534] Step: 2630| lr: 0.3284 | Time: 14.01s |TRAIN loss  0.0156 | TRAIN Acc:  99.94% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:50:44,591] Gradient total norm was 1.285920262336731. Clipping to 0.25.
[2023-03-18 03:50:44,595] Step: 2631| lr: 0.3281 | Time: 14.05s |TRAIN loss  0.0161 | TRAIN Acc:  99.91% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:50:58,744] Gradient total norm was 0.6918258666992188. Clipping to 0.25.
[2023-03-18 03:50:58,747] Step: 2632| lr: 0.3278 | Time: 14.14s |TRAIN loss  0.0155 | TRAIN Acc:  99.98% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:51:12,814] Gradient total norm was 0.6969468593597412. Clipping to 0.25.
[2023-03-18 03:51:12,817] Step: 2633| lr: 0.3275 | Time: 14.06s |TRAIN loss  0.0153 | TRAIN Acc:  99.95% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:51:26,827] Gradient total norm was 0.5095641613006592. Clipping to 0.25.
[2023-03-18 03:51:26,830] Step: 2634| lr: 0.3272 | Time: 14.00s |TRAIN loss  0.0139 | TRAIN Acc:  99.99% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:51:40,776] Gradient total norm was 0.48466160893440247. Clipping to 0.25.
[2023-03-18 03:51:40,779] Step: 2635| lr: 0.3269 | Time: 13.93s |TRAIN loss  0.0120 | TRAIN Acc:  99.99% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:51:54,835] Gradient total norm was 0.6730532646179199. Clipping to 0.25.
[2023-03-18 03:51:54,839] Step: 2636| lr: 0.3266 | Time: 14.05s |TRAIN loss  0.0103 | TRAIN Acc: 100.00% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:52:08,868] Gradient total norm was 1.1422579288482666. Clipping to 0.25.
[2023-03-18 03:52:08,871] Step: 2637| lr: 0.3263 | Time: 14.02s |TRAIN loss  0.0111 | TRAIN Acc:  99.97% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:52:23,025] Gradient total norm was 1.0069637298583984. Clipping to 0.25.
[2023-03-18 03:52:23,028] Step: 2638| lr: 0.3260 | Time: 14.14s |TRAIN loss  0.0112 | TRAIN Acc:  99.97% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:52:37,093] Gradient total norm was 0.820938766002655. Clipping to 0.25.
[2023-03-18 03:52:37,096] Step: 2639| lr: 0.3257 | Time: 14.05s |TRAIN loss  0.0118 | TRAIN Acc:  99.96% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:52:51,114] Gradient total norm was 0.6601482629776001. Clipping to 0.25.
[2023-03-18 03:52:51,117] Step: 2640| lr: 0.3254 | Time: 14.01s |TRAIN loss  0.0117 | TRAIN Acc:  99.99% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:53:05,276] Gradient total norm was 0.6867517232894897. Clipping to 0.25.
[2023-03-18 03:53:05,279] Step: 2641| lr: 0.3250 | Time: 14.15s |TRAIN loss  0.0126 | TRAIN Acc:  99.98% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:53:19,376] Gradient total norm was 0.6878535747528076. Clipping to 0.25.
[2023-03-18 03:53:19,380] Step: 2642| lr: 0.3247 | Time: 14.09s |TRAIN loss  0.0114 | TRAIN Acc:  99.97% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:53:33,457] Gradient total norm was 0.8186815977096558. Clipping to 0.25.
[2023-03-18 03:53:33,460] Step: 2643| lr: 0.3244 | Time: 14.07s |TRAIN loss  0.0128 | TRAIN Acc:  99.97% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:53:47,576] Gradient total norm was 0.6344942450523376. Clipping to 0.25.
[2023-03-18 03:53:47,579] Step: 2644| lr: 0.3241 | Time: 14.10s |TRAIN loss  0.0115 | TRAIN Acc:  99.96% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:54:01,625] Gradient total norm was 0.7419738173484802. Clipping to 0.25.
[2023-03-18 03:54:01,630] Step: 2645| lr: 0.3238 | Time: 14.03s |TRAIN loss  0.0117 | TRAIN Acc:  99.99% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:54:15,655] Gradient total norm was 1.2938467264175415. Clipping to 0.25.
[2023-03-18 03:54:15,658] Step: 2646| lr: 0.3235 | Time: 14.01s |TRAIN loss  0.0135 | TRAIN Acc:  99.91% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:54:29,670] Gradient total norm was 0.8338662385940552. Clipping to 0.25.
[2023-03-18 03:54:29,674] Step: 2647| lr: 0.3232 | Time: 14.00s |TRAIN loss  0.0146 | TRAIN Acc:  99.93% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:54:43,783] Gradient total norm was 0.7312496900558472. Clipping to 0.25.
[2023-03-18 03:54:43,786] Step: 2648| lr: 0.3229 | Time: 14.10s |TRAIN loss  0.0176 | TRAIN Acc:  99.80% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:54:58,055] Gradient total norm was 0.4318738579750061. Clipping to 0.25.
[2023-03-18 03:54:58,058] Step: 2649| lr: 0.3226 | Time: 14.26s |TRAIN loss  0.0158 | TRAIN Acc:  99.97% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:55:12,180] Gradient total norm was 0.4246070384979248. Clipping to 0.25.
[2023-03-18 03:55:12,184] Step: 2650| lr: 0.3223 | Time: 14.11s |TRAIN loss  0.0130 | TRAIN Acc:  99.96% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:55:26,234] Gradient total norm was 0.4846828281879425. Clipping to 0.25.
[2023-03-18 03:55:26,237] Step: 2651| lr: 0.3220 | Time: 14.04s |TRAIN loss  0.0105 | TRAIN Acc:  99.97% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:55:40,248] Gradient total norm was 0.4537540674209595. Clipping to 0.25.
[2023-03-18 03:55:40,252] Step: 2652| lr: 0.3217 | Time: 14.00s |TRAIN loss  0.0095 | TRAIN Acc:  99.99% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:55:54,282] Gradient total norm was 0.9750760197639465. Clipping to 0.25.
[2023-03-18 03:55:54,285] Step: 2653| lr: 0.3213 | Time: 14.02s |TRAIN loss  0.0090 | TRAIN Acc:  99.98% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:56:08,263] Gradient total norm was 0.6349962949752808. Clipping to 0.25.
[2023-03-18 03:56:08,266] Step: 2654| lr: 0.3210 | Time: 13.97s |TRAIN loss  0.0089 | TRAIN Acc:  99.98% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:56:22,305] Gradient total norm was 1.7680484056472778. Clipping to 0.25.
[2023-03-18 03:56:22,309] Step: 2655| lr: 0.3207 | Time: 14.03s |TRAIN loss  0.0132 | TRAIN Acc:  99.84% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:56:36,353] Gradient total norm was 0.6488328576087952. Clipping to 0.25.
[2023-03-18 03:56:36,357] Step: 2656| lr: 0.3204 | Time: 14.03s |TRAIN loss  0.0118 | TRAIN Acc:  99.94% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:56:50,377] Gradient total norm was 0.9217281341552734. Clipping to 0.25.
[2023-03-18 03:56:50,381] Step: 2657| lr: 0.3201 | Time: 14.01s |TRAIN loss  0.0137 | TRAIN Acc:  99.90% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:57:04,450] Gradient total norm was 0.470633864402771. Clipping to 0.25.
[2023-03-18 03:57:04,454] Step: 2658| lr: 0.3198 | Time: 14.06s |TRAIN loss  0.0138 | TRAIN Acc:  99.93% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:57:18,407] Gradient total norm was 0.34331002831459045. Clipping to 0.25.
[2023-03-18 03:57:18,410] Step: 2659| lr: 0.3195 | Time: 13.94s |TRAIN loss  0.0109 | TRAIN Acc:  99.98% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:57:32,454] Gradient total norm was 0.41912534832954407. Clipping to 0.25.
[2023-03-18 03:57:32,458] Step: 2660| lr: 0.3192 | Time: 14.03s |TRAIN loss  0.0089 | TRAIN Acc:  99.99% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:57:46,521] Gradient total norm was 0.3575453758239746. Clipping to 0.25.
[2023-03-18 03:57:46,525] Step: 2661| lr: 0.3189 | Time: 14.05s |TRAIN loss  0.0081 | TRAIN Acc:  99.99% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:58:00,571] Gradient total norm was 0.5950852036476135. Clipping to 0.25.
[2023-03-18 03:58:00,574] Step: 2662| lr: 0.3186 | Time: 14.04s |TRAIN loss  0.0078 | TRAIN Acc:  99.98% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:58:14,578] Gradient total norm was 0.6219774484634399. Clipping to 0.25.
[2023-03-18 03:58:14,582] Step: 2663| lr: 0.3183 | Time: 13.99s |TRAIN loss  0.0079 | TRAIN Acc:  99.98% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:58:28,591] Gradient total norm was 0.9943801164627075. Clipping to 0.25.
[2023-03-18 03:58:28,595] Step: 2664| lr: 0.3180 | Time: 14.00s |TRAIN loss  0.0099 | TRAIN Acc:  99.92% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:58:42,619] Gradient total norm was 0.5137513875961304. Clipping to 0.25.
[2023-03-18 03:58:42,622] Step: 2665| lr: 0.3177 | Time: 14.01s |TRAIN loss  0.0101 | TRAIN Acc:  99.96% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:58:56,630] Gradient total norm was 0.48013004660606384. Clipping to 0.25.
[2023-03-18 03:58:56,633] Step: 2666| lr: 0.3173 | Time: 14.00s |TRAIN loss  0.0102 | TRAIN Acc:  99.97% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:59:10,763] Gradient total norm was 0.3604445457458496. Clipping to 0.25.
[2023-03-18 03:59:10,766] Step: 2667| lr: 0.3170 | Time: 14.12s |TRAIN loss  0.0099 | TRAIN Acc:  99.99% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:59:24,861] Gradient total norm was 0.3619031310081482. Clipping to 0.25.
[2023-03-18 03:59:24,865] Step: 2668| lr: 0.3167 | Time: 14.08s |TRAIN loss  0.0082 | TRAIN Acc:  99.97% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:59:38,861] Step: 2669| lr: 0.3164 | Time: 13.99s |TRAIN loss  0.0073 | TRAIN Acc:  99.99% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 03:59:52,941] Step: 2670| lr: 0.3161 | Time: 14.07s |TRAIN loss  0.0062 | TRAIN Acc:  99.99% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:00:07,077] Gradient total norm was 0.8050563335418701. Clipping to 0.25.
[2023-03-18 04:00:07,080] Step: 2671| lr: 0.3158 | Time: 14.12s |TRAIN loss  0.0062 | TRAIN Acc:  99.99% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:00:21,250] Gradient total norm was 4.540778160095215. Clipping to 0.25.
[2023-03-18 04:00:21,253] Step: 2672| lr: 0.3155 | Time: 14.16s |TRAIN loss  0.0220 | TRAIN Acc:  99.36% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:00:35,339] Gradient total norm was 1.093313455581665. Clipping to 0.25.
[2023-03-18 04:00:35,342] Step: 2673| lr: 0.3152 | Time: 14.08s |TRAIN loss  0.0126 | TRAIN Acc:  99.93% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:00:49,431] Gradient total norm was 0.5867341756820679. Clipping to 0.25.
[2023-03-18 04:00:49,434] Step: 2674| lr: 0.3149 | Time: 14.08s |TRAIN loss  0.0110 | TRAIN Acc:  99.98% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:01:03,426] Gradient total norm was 0.825962483882904. Clipping to 0.25.
[2023-03-18 04:01:03,429] Step: 2675| lr: 0.3146 | Time: 13.98s |TRAIN loss  0.0124 | TRAIN Acc:  99.97% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:01:17,459] Gradient total norm was 1.4237185716629028. Clipping to 0.25.
[2023-03-18 04:01:17,463] Step: 2676| lr: 0.3143 | Time: 14.02s |TRAIN loss  0.0134 | TRAIN Acc:  99.90% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:01:31,500] Gradient total norm was 0.7817387580871582. Clipping to 0.25.
[2023-03-18 04:01:31,503] Step: 2677| lr: 0.3140 | Time: 14.03s |TRAIN loss  0.0138 | TRAIN Acc:  99.94% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:01:45,524] Gradient total norm was 0.7159910798072815. Clipping to 0.25.
[2023-03-18 04:01:45,528] Step: 2678| lr: 0.3137 | Time: 14.01s |TRAIN loss  0.0131 | TRAIN Acc:  99.94% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:01:59,605] Gradient total norm was 0.526954710483551. Clipping to 0.25.
[2023-03-18 04:01:59,608] Step: 2679| lr: 0.3134 | Time: 14.07s |TRAIN loss  0.0122 | TRAIN Acc:  99.97% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:02:13,731] Gradient total norm was 0.5201559066772461. Clipping to 0.25.
[2023-03-18 04:02:13,734] Step: 2680| lr: 0.3130 | Time: 14.11s |TRAIN loss  0.0114 | TRAIN Acc:  99.97% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:02:27,799] Gradient total norm was 0.537227988243103. Clipping to 0.25.
[2023-03-18 04:02:27,802] Step: 2681| lr: 0.3127 | Time: 14.05s |TRAIN loss  0.0106 | TRAIN Acc:  99.98% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:02:41,914] Gradient total norm was 0.6651482582092285. Clipping to 0.25.
[2023-03-18 04:02:41,917] Step: 2682| lr: 0.3124 | Time: 14.10s |TRAIN loss  0.0105 | TRAIN Acc:  99.97% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:02:56,111] Gradient total norm was 0.742425799369812. Clipping to 0.25.
[2023-03-18 04:02:56,114] Step: 2683| lr: 0.3121 | Time: 14.18s |TRAIN loss  0.0101 | TRAIN Acc:  99.96% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:03:10,168] Gradient total norm was 1.2264039516448975. Clipping to 0.25.
[2023-03-18 04:03:10,172] Step: 2684| lr: 0.3118 | Time: 14.04s |TRAIN loss  0.0130 | TRAIN Acc:  99.87% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:03:24,290] Gradient total norm was 0.5150641798973083. Clipping to 0.25.
[2023-03-18 04:03:24,294] Step: 2685| lr: 0.3115 | Time: 14.11s |TRAIN loss  0.0130 | TRAIN Acc:  99.96% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:03:38,406] Gradient total norm was 0.5211238861083984. Clipping to 0.25.
[2023-03-18 04:03:38,409] Step: 2686| lr: 0.3112 | Time: 14.10s |TRAIN loss  0.0130 | TRAIN Acc:  99.95% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:03:52,564] Gradient total norm was 0.43235933780670166. Clipping to 0.25.
[2023-03-18 04:03:52,567] Step: 2687| lr: 0.3109 | Time: 14.14s |TRAIN loss  0.0117 | TRAIN Acc:  99.98% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:04:06,614] Gradient total norm was 0.37852996587753296. Clipping to 0.25.
[2023-03-18 04:04:06,617] Step: 2688| lr: 0.3106 | Time: 14.04s |TRAIN loss  0.0098 | TRAIN Acc:  99.99% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:04:20,669] Gradient total norm was 1.4853484630584717. Clipping to 0.25.
[2023-03-18 04:04:20,672] Step: 2689| lr: 0.3103 | Time: 14.04s |TRAIN loss  0.0101 | TRAIN Acc:  99.92% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:04:34,776] Gradient total norm was 0.6715173721313477. Clipping to 0.25.
[2023-03-18 04:04:34,779] Step: 2690| lr: 0.3100 | Time: 14.09s |TRAIN loss  0.0106 | TRAIN Acc:  99.83% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:04:48,886] Gradient total norm was 0.5708014369010925. Clipping to 0.25.
[2023-03-18 04:04:48,889] Step: 2691| lr: 0.3097 | Time: 14.10s |TRAIN loss  0.0122 | TRAIN Acc:  99.93% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:05:03,059] Gradient total norm was 0.41275811195373535. Clipping to 0.25.
[2023-03-18 04:05:03,062] Step: 2692| lr: 0.3094 | Time: 14.16s |TRAIN loss  0.0114 | TRAIN Acc:  99.81% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:05:17,131] Gradient total norm was 0.3861329257488251. Clipping to 0.25.
[2023-03-18 04:05:17,135] Step: 2693| lr: 0.3091 | Time: 14.06s |TRAIN loss  0.0099 | TRAIN Acc:  99.97% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:05:31,193] Gradient total norm was 0.37492311000823975. Clipping to 0.25.
[2023-03-18 04:05:31,196] Step: 2694| lr: 0.3088 | Time: 14.05s |TRAIN loss  0.0105 | TRAIN Acc:  99.86% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:05:45,208] Gradient total norm was 0.27210044860839844. Clipping to 0.25.
[2023-03-18 04:05:45,212] Step: 2695| lr: 0.3085 | Time: 14.00s |TRAIN loss  0.0088 | TRAIN Acc:  99.99% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:05:59,274] Gradient total norm was 0.26406338810920715. Clipping to 0.25.
[2023-03-18 04:05:59,277] Step: 2696| lr: 0.3081 | Time: 14.05s |TRAIN loss  0.0078 | TRAIN Acc:  99.94% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:06:13,278] Gradient total norm was 1.6149457693099976. Clipping to 0.25.
[2023-03-18 04:06:13,281] Step: 2697| lr: 0.3078 | Time: 13.99s |TRAIN loss  0.0087 | TRAIN Acc:  99.93% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:06:27,276] Gradient total norm was 1.0072829723358154. Clipping to 0.25.
[2023-03-18 04:06:27,279] Step: 2698| lr: 0.3075 | Time: 13.98s |TRAIN loss  0.0084 | TRAIN Acc:  99.95% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:06:41,387] Gradient total norm was 1.125193476676941. Clipping to 0.25.
[2023-03-18 04:06:41,390] Step: 2699| lr: 0.3072 | Time: 14.10s |TRAIN loss  0.0108 | TRAIN Acc:  99.93% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:06:55,429] Gradient total norm was 0.9749226570129395. Clipping to 0.25.
[2023-03-18 04:06:55,432] Step: 2700| lr: 0.3069 | Time: 14.03s |TRAIN loss  0.0124 | TRAIN Acc:  99.89% |VAL loss  0.3609 | VAL Acc:  89.21% |
[2023-03-18 04:07:09,551] Gradient total norm was 0.6255133748054504. Clipping to 0.25.
[2023-03-18 04:07:15,221] Step: 2701| lr: 0.3066 | Time: 14.11s |TRAIN loss  0.0148 | TRAIN Acc:  99.94% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:07:29,264] Gradient total norm was 0.5809308886528015. Clipping to 0.25.
[2023-03-18 04:07:29,268] Step: 2702| lr: 0.3063 | Time: 14.03s |TRAIN loss  0.0135 | TRAIN Acc:  99.92% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:07:43,294] Gradient total norm was 0.40779027342796326. Clipping to 0.25.
[2023-03-18 04:07:43,297] Step: 2703| lr: 0.3060 | Time: 14.02s |TRAIN loss  0.0127 | TRAIN Acc:  99.98% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:07:57,369] Gradient total norm was 0.43472859263420105. Clipping to 0.25.
[2023-03-18 04:07:57,372] Step: 2704| lr: 0.3057 | Time: 14.06s |TRAIN loss  0.0096 | TRAIN Acc:  99.98% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:08:11,406] Gradient total norm was 0.5568538308143616. Clipping to 0.25.
[2023-03-18 04:08:11,409] Step: 2705| lr: 0.3054 | Time: 14.02s |TRAIN loss  0.0102 | TRAIN Acc:  99.96% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:08:25,511] Gradient total norm was 0.5156111121177673. Clipping to 0.25.
[2023-03-18 04:08:25,515] Step: 2706| lr: 0.3051 | Time: 14.09s |TRAIN loss  0.0098 | TRAIN Acc:  99.98% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:08:39,673] Gradient total norm was 0.46371978521347046. Clipping to 0.25.
[2023-03-18 04:08:39,676] Step: 2707| lr: 0.3048 | Time: 14.15s |TRAIN loss  0.0081 | TRAIN Acc:  99.97% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:08:53,796] Gradient total norm was 0.35126376152038574. Clipping to 0.25.
[2023-03-18 04:08:53,800] Step: 2708| lr: 0.3045 | Time: 14.11s |TRAIN loss  0.0077 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:09:07,872] Gradient total norm was 0.6158713698387146. Clipping to 0.25.
[2023-03-18 04:09:07,876] Step: 2709| lr: 0.3042 | Time: 14.06s |TRAIN loss  0.0087 | TRAIN Acc:  99.97% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:09:21,952] Gradient total norm was 0.39045363664627075. Clipping to 0.25.
[2023-03-18 04:09:21,955] Step: 2710| lr: 0.3039 | Time: 14.07s |TRAIN loss  0.0072 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:09:35,970] Gradient total norm was 0.3908519148826599. Clipping to 0.25.
[2023-03-18 04:09:35,973] Step: 2711| lr: 0.3036 | Time: 14.00s |TRAIN loss  0.0073 | TRAIN Acc:  99.98% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:09:50,059] Gradient total norm was 0.28182509541511536. Clipping to 0.25.
[2023-03-18 04:09:50,063] Step: 2712| lr: 0.3033 | Time: 14.08s |TRAIN loss  0.0062 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:10:04,072] Gradient total norm was 0.27277296781539917. Clipping to 0.25.
[2023-03-18 04:10:04,076] Step: 2713| lr: 0.3030 | Time: 14.00s |TRAIN loss  0.0062 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:10:18,220] Gradient total norm was 0.2581174075603485. Clipping to 0.25.
[2023-03-18 04:10:18,224] Step: 2714| lr: 0.3027 | Time: 14.13s |TRAIN loss  0.0053 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:10:32,525] Step: 2715| lr: 0.3024 | Time: 14.29s |TRAIN loss  0.0052 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:10:46,496] Step: 2716| lr: 0.3020 | Time: 13.96s |TRAIN loss  0.0049 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:11:00,544] Step: 2717| lr: 0.3017 | Time: 14.04s |TRAIN loss  0.0045 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:11:14,536] Step: 2718| lr: 0.3014 | Time: 13.98s |TRAIN loss  0.0042 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:11:28,771] Step: 2719| lr: 0.3011 | Time: 14.23s |TRAIN loss  0.0039 | TRAIN Acc: 100.00% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:11:42,823] Step: 2720| lr: 0.3008 | Time: 14.04s |TRAIN loss  0.0039 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:11:57,023] Step: 2721| lr: 0.3005 | Time: 14.19s |TRAIN loss  0.0038 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:12:11,073] Step: 2722| lr: 0.3002 | Time: 14.04s |TRAIN loss  0.0038 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:12:25,137] Step: 2723| lr: 0.2999 | Time: 14.05s |TRAIN loss  0.0037 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:12:39,216] Step: 2724| lr: 0.2996 | Time: 14.07s |TRAIN loss  0.0032 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:12:53,209] Step: 2725| lr: 0.2993 | Time: 13.98s |TRAIN loss  0.0035 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:13:07,253] Step: 2726| lr: 0.2990 | Time: 14.03s |TRAIN loss  0.0033 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:13:21,275] Step: 2727| lr: 0.2987 | Time: 14.01s |TRAIN loss  0.0030 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:13:35,337] Step: 2728| lr: 0.2984 | Time: 14.05s |TRAIN loss  0.0031 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:13:49,460] Step: 2729| lr: 0.2981 | Time: 14.11s |TRAIN loss  0.0029 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:14:03,396] Step: 2730| lr: 0.2978 | Time: 13.93s |TRAIN loss  0.0030 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:14:17,407] Step: 2731| lr: 0.2975 | Time: 14.00s |TRAIN loss  0.0027 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:14:31,351] Step: 2732| lr: 0.2972 | Time: 13.93s |TRAIN loss  0.0027 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:14:45,549] Step: 2733| lr: 0.2969 | Time: 14.19s |TRAIN loss  0.0025 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:15:00,417] Step: 2734| lr: 0.2966 | Time: 14.86s |TRAIN loss  0.0025 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:15:14,827] Step: 2735| lr: 0.2963 | Time: 14.40s |TRAIN loss  0.0025 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:15:28,834] Step: 2736| lr: 0.2960 | Time: 14.00s |TRAIN loss  0.0024 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:15:42,867] Step: 2737| lr: 0.2957 | Time: 14.02s |TRAIN loss  0.0023 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:15:56,901] Step: 2738| lr: 0.2954 | Time: 14.03s |TRAIN loss  0.0024 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:16:10,948] Step: 2739| lr: 0.2951 | Time: 14.04s |TRAIN loss  0.0022 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:16:25,003] Step: 2740| lr: 0.2948 | Time: 14.05s |TRAIN loss  0.0024 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:16:39,101] Step: 2741| lr: 0.2945 | Time: 14.09s |TRAIN loss  0.0025 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:16:53,083] Step: 2742| lr: 0.2941 | Time: 13.97s |TRAIN loss  0.0023 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:17:07,166] Step: 2743| lr: 0.2938 | Time: 14.07s |TRAIN loss  0.0020 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:17:21,252] Step: 2744| lr: 0.2935 | Time: 14.08s |TRAIN loss  0.0020 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:17:35,344] Step: 2745| lr: 0.2932 | Time: 14.08s |TRAIN loss  0.0022 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:17:49,364] Step: 2746| lr: 0.2929 | Time: 14.01s |TRAIN loss  0.0023 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:18:03,367] Step: 2747| lr: 0.2926 | Time: 13.99s |TRAIN loss  0.0022 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:18:17,466] Step: 2748| lr: 0.2923 | Time: 14.09s |TRAIN loss  0.0022 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:18:31,523] Step: 2749| lr: 0.2920 | Time: 14.05s |TRAIN loss  0.0022 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:18:45,682] Step: 2750| lr: 0.2917 | Time: 14.15s |TRAIN loss  0.0022 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:18:59,665] Step: 2751| lr: 0.2914 | Time: 13.97s |TRAIN loss  0.0021 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:19:13,617] Step: 2752| lr: 0.2911 | Time: 13.94s |TRAIN loss  0.0020 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:19:27,636] Step: 2753| lr: 0.2908 | Time: 14.01s |TRAIN loss  0.0021 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:19:41,621] Step: 2754| lr: 0.2905 | Time: 13.98s |TRAIN loss  0.0020 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:19:55,660] Step: 2755| lr: 0.2902 | Time: 14.03s |TRAIN loss  0.0020 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:20:09,624] Step: 2756| lr: 0.2899 | Time: 13.95s |TRAIN loss  0.0019 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:20:23,652] Step: 2757| lr: 0.2896 | Time: 14.02s |TRAIN loss  0.0019 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:20:37,727] Step: 2758| lr: 0.2893 | Time: 14.07s |TRAIN loss  0.0019 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:20:54,519] Step: 2759| lr: 0.2890 | Time: 16.78s |TRAIN loss  0.0018 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:21:12,841] Step: 2760| lr: 0.2887 | Time: 18.31s |TRAIN loss  0.0017 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:21:26,991] Step: 2761| lr: 0.2884 | Time: 14.14s |TRAIN loss  0.0020 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:21:42,296] Step: 2762| lr: 0.2881 | Time: 15.29s |TRAIN loss  0.0018 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:21:57,270] Step: 2763| lr: 0.2878 | Time: 14.96s |TRAIN loss  0.0019 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:22:12,039] Step: 2764| lr: 0.2875 | Time: 14.76s |TRAIN loss  0.0019 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:22:27,537] Step: 2765| lr: 0.2872 | Time: 15.49s |TRAIN loss  0.0019 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:22:43,074] Step: 2766| lr: 0.2869 | Time: 15.53s |TRAIN loss  0.0018 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:22:57,724] Step: 2767| lr: 0.2866 | Time: 14.64s |TRAIN loss  0.0019 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:23:12,699] Step: 2768| lr: 0.2863 | Time: 14.97s |TRAIN loss  0.0020 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:23:27,653] Step: 2769| lr: 0.2860 | Time: 14.94s |TRAIN loss  0.0020 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:23:42,371] Step: 2770| lr: 0.2857 | Time: 14.71s |TRAIN loss  0.0019 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:23:56,775] Step: 2771| lr: 0.2854 | Time: 14.39s |TRAIN loss  0.0018 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:24:11,224] Step: 2772| lr: 0.2851 | Time: 14.44s |TRAIN loss  0.0019 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:24:25,656] Step: 2773| lr: 0.2848 | Time: 14.42s |TRAIN loss  0.0020 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:24:40,011] Step: 2774| lr: 0.2845 | Time: 14.35s |TRAIN loss  0.0017 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:24:54,669] Step: 2775| lr: 0.2842 | Time: 14.65s |TRAIN loss  0.0018 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:25:08,916] Step: 2776| lr: 0.2839 | Time: 14.24s |TRAIN loss  0.0019 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:25:24,122] Step: 2777| lr: 0.2836 | Time: 15.20s |TRAIN loss  0.0016 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:25:38,428] Step: 2778| lr: 0.2833 | Time: 14.30s |TRAIN loss  0.0019 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:25:52,619] Step: 2779| lr: 0.2830 | Time: 14.18s |TRAIN loss  0.0019 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:26:07,144] Step: 2780| lr: 0.2827 | Time: 14.51s |TRAIN loss  0.0019 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:26:21,586] Step: 2781| lr: 0.2824 | Time: 14.43s |TRAIN loss  0.0018 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:26:35,910] Step: 2782| lr: 0.2821 | Time: 14.31s |TRAIN loss  0.0017 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:26:51,371] Step: 2783| lr: 0.2818 | Time: 15.45s |TRAIN loss  0.0018 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:27:05,652] Step: 2784| lr: 0.2815 | Time: 14.27s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:27:20,118] Step: 2785| lr: 0.2812 | Time: 14.46s |TRAIN loss  0.0018 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:27:34,457] Step: 2786| lr: 0.2809 | Time: 14.33s |TRAIN loss  0.0017 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:27:48,767] Step: 2787| lr: 0.2806 | Time: 14.30s |TRAIN loss  0.0016 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:28:03,194] Step: 2788| lr: 0.2803 | Time: 14.42s |TRAIN loss  0.0019 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:28:17,475] Step: 2789| lr: 0.2800 | Time: 14.27s |TRAIN loss  0.0019 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:28:32,096] Step: 2790| lr: 0.2797 | Time: 14.61s |TRAIN loss  0.0017 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:28:46,429] Step: 2791| lr: 0.2794 | Time: 14.32s |TRAIN loss  0.0016 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:29:01,394] Step: 2792| lr: 0.2791 | Time: 14.96s |TRAIN loss  0.0017 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:29:15,851] Step: 2793| lr: 0.2788 | Time: 14.45s |TRAIN loss  0.0018 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:29:30,292] Step: 2794| lr: 0.2785 | Time: 14.43s |TRAIN loss  0.0016 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:29:44,634] Step: 2795| lr: 0.2782 | Time: 14.33s |TRAIN loss  0.0018 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:29:59,492] Step: 2796| lr: 0.2779 | Time: 14.85s |TRAIN loss  0.0018 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:30:13,905] Step: 2797| lr: 0.2776 | Time: 14.40s |TRAIN loss  0.0018 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:30:28,250] Step: 2798| lr: 0.2773 | Time: 14.34s |TRAIN loss  0.0016 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:30:42,322] Step: 2799| lr: 0.2770 | Time: 14.06s |TRAIN loss  0.0017 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:30:56,467] Step: 2800| lr: 0.2767 | Time: 14.13s |TRAIN loss  0.0017 | TRAIN Acc:  99.99% |VAL loss  0.2245 | VAL Acc:  93.08% |
[2023-03-18 04:31:15,976] Step: 2801| lr: 0.2764 | Time: 14.07s |TRAIN loss  0.0017 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:31:30,043] Step: 2802| lr: 0.2761 | Time: 14.06s |TRAIN loss  0.0017 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:31:44,077] Step: 2803| lr: 0.2758 | Time: 14.02s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:31:58,171] Step: 2804| lr: 0.2755 | Time: 14.08s |TRAIN loss  0.0018 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:32:12,307] Step: 2805| lr: 0.2752 | Time: 14.13s |TRAIN loss  0.0018 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:32:27,239] Step: 2806| lr: 0.2749 | Time: 14.92s |TRAIN loss  0.0016 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:32:41,355] Step: 2807| lr: 0.2746 | Time: 14.11s |TRAIN loss  0.0016 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:32:55,460] Step: 2808| lr: 0.2743 | Time: 14.10s |TRAIN loss  0.0016 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:33:10,033] Step: 2809| lr: 0.2740 | Time: 14.56s |TRAIN loss  0.0016 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:33:25,298] Step: 2810| lr: 0.2737 | Time: 15.25s |TRAIN loss  0.0016 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:33:40,138] Step: 2811| lr: 0.2734 | Time: 14.83s |TRAIN loss  0.0016 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:33:54,941] Step: 2812| lr: 0.2731 | Time: 14.79s |TRAIN loss  0.0016 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:34:10,020] Step: 2813| lr: 0.2728 | Time: 15.07s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:34:24,794] Step: 2814| lr: 0.2725 | Time: 14.76s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:34:39,350] Step: 2815| lr: 0.2722 | Time: 14.54s |TRAIN loss  0.0016 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:34:53,860] Step: 2816| lr: 0.2719 | Time: 14.50s |TRAIN loss  0.0017 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:35:08,265] Step: 2817| lr: 0.2716 | Time: 14.39s |TRAIN loss  0.0017 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:35:23,262] Step: 2818| lr: 0.2713 | Time: 14.98s |TRAIN loss  0.0017 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:35:40,067] Step: 2819| lr: 0.2710 | Time: 16.79s |TRAIN loss  0.0017 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:35:56,474] Step: 2820| lr: 0.2707 | Time: 16.39s |TRAIN loss  0.0016 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:36:11,106] Step: 2821| lr: 0.2704 | Time: 14.62s |TRAIN loss  0.0017 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:36:25,546] Step: 2822| lr: 0.2701 | Time: 14.43s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:36:40,055] Step: 2823| lr: 0.2698 | Time: 14.50s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:36:54,627] Step: 2824| lr: 0.2695 | Time: 14.56s |TRAIN loss  0.0017 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:37:09,323] Step: 2825| lr: 0.2692 | Time: 14.69s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:37:24,064] Step: 2826| lr: 0.2689 | Time: 14.73s |TRAIN loss  0.0017 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:37:38,794] Step: 2827| lr: 0.2687 | Time: 14.72s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:37:53,630] Step: 2828| lr: 0.2684 | Time: 14.83s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:38:08,356] Step: 2829| lr: 0.2681 | Time: 14.71s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:38:23,967] Step: 2830| lr: 0.2678 | Time: 15.60s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:38:39,337] Step: 2831| lr: 0.2675 | Time: 15.36s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:38:54,569] Step: 2832| lr: 0.2672 | Time: 15.22s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:39:09,688] Step: 2833| lr: 0.2669 | Time: 15.11s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:39:24,751] Step: 2834| lr: 0.2666 | Time: 15.05s |TRAIN loss  0.0016 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:39:40,352] Step: 2835| lr: 0.2663 | Time: 15.59s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:39:55,641] Step: 2836| lr: 0.2660 | Time: 15.28s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:40:10,826] Step: 2837| lr: 0.2657 | Time: 15.18s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:40:25,574] Step: 2838| lr: 0.2654 | Time: 14.74s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:40:40,385] Step: 2839| lr: 0.2651 | Time: 14.80s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:40:54,804] Step: 2840| lr: 0.2648 | Time: 14.41s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:41:09,441] Step: 2841| lr: 0.2645 | Time: 14.63s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:41:24,076] Step: 2842| lr: 0.2642 | Time: 14.63s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:41:38,894] Step: 2843| lr: 0.2639 | Time: 14.81s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:41:54,293] Step: 2844| lr: 0.2636 | Time: 15.39s |TRAIN loss  0.0017 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:42:09,226] Step: 2845| lr: 0.2633 | Time: 14.92s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:42:25,310] Step: 2846| lr: 0.2630 | Time: 16.07s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:42:40,600] Step: 2847| lr: 0.2627 | Time: 15.28s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:42:56,002] Step: 2848| lr: 0.2624 | Time: 15.39s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:43:11,955] Step: 2849| lr: 0.2621 | Time: 15.94s |TRAIN loss  0.0016 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:43:27,651] Step: 2850| lr: 0.2618 | Time: 15.69s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:43:43,978] Step: 2851| lr: 0.2616 | Time: 16.31s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:43:59,430] Step: 2852| lr: 0.2613 | Time: 15.44s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:44:15,802] Step: 2853| lr: 0.2610 | Time: 16.36s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:44:32,377] Step: 2854| lr: 0.2607 | Time: 16.56s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:44:48,465] Step: 2855| lr: 0.2604 | Time: 16.07s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:45:04,770] Step: 2856| lr: 0.2601 | Time: 16.29s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:45:20,752] Step: 2857| lr: 0.2598 | Time: 15.97s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:45:35,368] Step: 2858| lr: 0.2595 | Time: 14.61s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:45:50,799] Step: 2859| lr: 0.2592 | Time: 15.42s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:46:07,276] Step: 2860| lr: 0.2589 | Time: 16.46s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:46:23,022] Step: 2861| lr: 0.2586 | Time: 15.73s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:46:38,604] Step: 2862| lr: 0.2583 | Time: 15.57s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:46:54,031] Step: 2863| lr: 0.2580 | Time: 15.41s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:47:10,838] Step: 2864| lr: 0.2577 | Time: 16.79s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:47:27,006] Step: 2865| lr: 0.2574 | Time: 16.15s |TRAIN loss  0.0016 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:47:43,175] Step: 2866| lr: 0.2571 | Time: 16.16s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:47:59,137] Step: 2867| lr: 0.2568 | Time: 15.95s |TRAIN loss  0.0016 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:48:15,737] Step: 2868| lr: 0.2566 | Time: 16.59s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:48:31,669] Step: 2869| lr: 0.2563 | Time: 15.92s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:48:47,777] Step: 2870| lr: 0.2560 | Time: 16.10s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:49:04,052] Step: 2871| lr: 0.2557 | Time: 16.26s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:49:19,245] Step: 2872| lr: 0.2554 | Time: 15.18s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:49:35,349] Step: 2873| lr: 0.2551 | Time: 16.09s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:49:51,946] Step: 2874| lr: 0.2548 | Time: 16.59s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:50:08,270] Step: 2875| lr: 0.2545 | Time: 16.31s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:50:25,222] Step: 2876| lr: 0.2542 | Time: 16.94s |TRAIN loss  0.0016 | TRAIN Acc:  99.99% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:50:41,561] Step: 2877| lr: 0.2539 | Time: 16.32s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:50:57,683] Step: 2878| lr: 0.2536 | Time: 16.11s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:51:14,475] Step: 2879| lr: 0.2533 | Time: 16.78s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:51:30,664] Step: 2880| lr: 0.2530 | Time: 16.17s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:51:46,856] Step: 2881| lr: 0.2528 | Time: 16.18s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:52:02,901] Step: 2882| lr: 0.2525 | Time: 16.04s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:52:17,885] Step: 2883| lr: 0.2522 | Time: 14.97s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:52:32,422] Step: 2884| lr: 0.2519 | Time: 14.53s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:52:48,631] Step: 2885| lr: 0.2516 | Time: 16.20s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:53:05,061] Step: 2886| lr: 0.2513 | Time: 16.42s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:53:21,447] Step: 2887| lr: 0.2510 | Time: 16.38s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:53:38,606] Step: 2888| lr: 0.2507 | Time: 17.14s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:53:56,560] Step: 2889| lr: 0.2504 | Time: 17.94s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:54:14,349] Step: 2890| lr: 0.2501 | Time: 17.78s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:54:32,409] Step: 2891| lr: 0.2498 | Time: 18.05s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:54:49,290] Step: 2892| lr: 0.2495 | Time: 16.87s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:55:06,714] Step: 2893| lr: 0.2493 | Time: 17.41s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:55:24,245] Step: 2894| lr: 0.2490 | Time: 17.52s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:55:42,574] Step: 2895| lr: 0.2487 | Time: 18.32s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:55:59,256] Step: 2896| lr: 0.2484 | Time: 16.67s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:56:18,006] Step: 2897| lr: 0.2481 | Time: 18.73s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:56:36,244] Step: 2898| lr: 0.2478 | Time: 18.23s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:56:54,240] Step: 2899| lr: 0.2475 | Time: 17.98s |TRAIN loss  0.0016 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:57:11,991] Step: 2900| lr: 0.2472 | Time: 17.74s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1907 | VAL Acc:  94.95% |
[2023-03-18 04:57:36,064] Step: 2901| lr: 0.2469 | Time: 17.69s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 04:57:54,386] Step: 2902| lr: 0.2466 | Time: 18.31s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 04:58:12,169] Step: 2903| lr: 0.2463 | Time: 17.77s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 04:58:30,890] Step: 2904| lr: 0.2461 | Time: 18.70s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 04:58:49,076] Step: 2905| lr: 0.2458 | Time: 18.17s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 04:59:07,020] Step: 2906| lr: 0.2455 | Time: 17.93s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 04:59:25,231] Step: 2907| lr: 0.2452 | Time: 18.20s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 04:59:43,140] Step: 2908| lr: 0.2449 | Time: 17.90s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:00:01,155] Step: 2909| lr: 0.2446 | Time: 18.00s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:00:18,970] Step: 2910| lr: 0.2443 | Time: 17.80s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:00:34,964] Step: 2911| lr: 0.2440 | Time: 15.98s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:00:51,509] Step: 2912| lr: 0.2437 | Time: 16.53s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:01:08,104] Step: 2913| lr: 0.2435 | Time: 16.58s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:01:24,373] Step: 2914| lr: 0.2432 | Time: 16.26s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:01:40,656] Step: 2915| lr: 0.2429 | Time: 16.27s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:01:56,531] Step: 2916| lr: 0.2426 | Time: 15.86s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:02:13,830] Step: 2917| lr: 0.2423 | Time: 17.29s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:02:30,419] Step: 2918| lr: 0.2420 | Time: 16.58s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:02:47,767] Step: 2919| lr: 0.2417 | Time: 17.33s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:03:04,914] Step: 2920| lr: 0.2414 | Time: 17.13s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:03:22,914] Step: 2921| lr: 0.2411 | Time: 17.98s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:03:40,784] Step: 2922| lr: 0.2409 | Time: 17.85s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:03:58,457] Step: 2923| lr: 0.2406 | Time: 17.66s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:04:16,713] Step: 2924| lr: 0.2403 | Time: 18.24s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:04:34,630] Step: 2925| lr: 0.2400 | Time: 17.90s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:04:53,231] Step: 2926| lr: 0.2397 | Time: 18.59s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:05:10,687] Step: 2927| lr: 0.2394 | Time: 17.44s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:05:27,721] Step: 2928| lr: 0.2391 | Time: 17.02s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:05:46,041] Step: 2929| lr: 0.2388 | Time: 18.31s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:06:04,451] Step: 2930| lr: 0.2385 | Time: 18.39s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:06:22,780] Step: 2931| lr: 0.2383 | Time: 18.32s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:06:40,986] Step: 2932| lr: 0.2380 | Time: 18.19s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:06:59,248] Step: 2933| lr: 0.2377 | Time: 18.25s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:07:18,500] Step: 2934| lr: 0.2374 | Time: 19.24s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:07:36,194] Step: 2935| lr: 0.2371 | Time: 17.68s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:07:53,412] Step: 2936| lr: 0.2368 | Time: 17.21s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:08:11,565] Step: 2937| lr: 0.2365 | Time: 18.14s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:08:29,920] Step: 2938| lr: 0.2363 | Time: 18.34s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:08:47,747] Step: 2939| lr: 0.2360 | Time: 17.82s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:09:04,074] Step: 2940| lr: 0.2357 | Time: 16.32s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:09:20,644] Step: 2941| lr: 0.2354 | Time: 16.56s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:09:36,635] Step: 2942| lr: 0.2351 | Time: 15.98s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:09:52,603] Step: 2943| lr: 0.2348 | Time: 15.95s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:10:08,914] Step: 2944| lr: 0.2345 | Time: 16.30s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:10:25,211] Step: 2945| lr: 0.2342 | Time: 16.28s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:10:41,718] Step: 2946| lr: 0.2340 | Time: 16.49s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:10:58,288] Step: 2947| lr: 0.2337 | Time: 16.56s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:11:14,820] Step: 2948| lr: 0.2334 | Time: 16.52s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:11:31,171] Step: 2949| lr: 0.2331 | Time: 16.34s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:11:48,119] Step: 2950| lr: 0.2328 | Time: 16.93s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:12:04,240] Step: 2951| lr: 0.2325 | Time: 16.11s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:12:20,270] Step: 2952| lr: 0.2323 | Time: 16.02s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:12:36,381] Step: 2953| lr: 0.2320 | Time: 16.10s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:12:53,117] Step: 2954| lr: 0.2317 | Time: 16.73s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:13:09,519] Step: 2955| lr: 0.2314 | Time: 16.39s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:13:25,879] Step: 2956| lr: 0.2311 | Time: 16.35s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:13:43,002] Step: 2957| lr: 0.2308 | Time: 17.11s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:13:59,619] Step: 2958| lr: 0.2305 | Time: 16.61s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:14:15,848] Step: 2959| lr: 0.2303 | Time: 16.22s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:14:31,957] Step: 2960| lr: 0.2300 | Time: 16.10s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:14:47,586] Step: 2961| lr: 0.2297 | Time: 15.62s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:15:04,670] Step: 2962| lr: 0.2294 | Time: 17.07s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:15:20,328] Step: 2963| lr: 0.2291 | Time: 15.65s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:15:36,826] Step: 2964| lr: 0.2288 | Time: 16.49s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:15:52,784] Step: 2965| lr: 0.2286 | Time: 15.95s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:16:09,121] Step: 2966| lr: 0.2283 | Time: 16.32s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:16:23,827] Step: 2967| lr: 0.2280 | Time: 14.69s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:16:39,026] Step: 2968| lr: 0.2277 | Time: 15.19s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:16:54,413] Step: 2969| lr: 0.2274 | Time: 15.38s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:17:10,470] Step: 2970| lr: 0.2271 | Time: 16.05s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:17:27,029] Step: 2971| lr: 0.2269 | Time: 16.55s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:17:41,679] Step: 2972| lr: 0.2266 | Time: 14.64s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:17:58,492] Step: 2973| lr: 0.2263 | Time: 16.80s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:18:14,924] Step: 2974| lr: 0.2260 | Time: 16.42s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:18:31,533] Step: 2975| lr: 0.2257 | Time: 16.59s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:18:48,418] Step: 2976| lr: 0.2254 | Time: 16.87s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:19:03,552] Step: 2977| lr: 0.2252 | Time: 15.12s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:19:21,165] Step: 2978| lr: 0.2249 | Time: 17.60s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:19:38,000] Step: 2979| lr: 0.2246 | Time: 16.82s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:19:55,396] Step: 2980| lr: 0.2243 | Time: 17.38s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:20:12,573] Step: 2981| lr: 0.2240 | Time: 17.17s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:20:28,993] Step: 2982| lr: 0.2237 | Time: 16.41s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:20:46,681] Step: 2983| lr: 0.2235 | Time: 17.67s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:21:03,489] Step: 2984| lr: 0.2232 | Time: 16.79s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:21:20,068] Step: 2985| lr: 0.2229 | Time: 16.56s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:21:34,727] Step: 2986| lr: 0.2226 | Time: 14.65s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:21:50,211] Step: 2987| lr: 0.2223 | Time: 15.47s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:22:04,950] Step: 2988| lr: 0.2221 | Time: 14.73s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:22:20,913] Step: 2989| lr: 0.2218 | Time: 15.95s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:22:36,869] Step: 2990| lr: 0.2215 | Time: 15.94s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:22:52,109] Step: 2991| lr: 0.2212 | Time: 15.23s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:23:06,017] Step: 2992| lr: 0.2209 | Time: 13.90s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:23:21,312] Step: 2993| lr: 0.2206 | Time: 15.28s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:23:35,964] Step: 2994| lr: 0.2204 | Time: 14.64s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:23:50,080] Step: 2995| lr: 0.2201 | Time: 14.10s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:24:04,454] Step: 2996| lr: 0.2198 | Time: 14.36s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:24:18,709] Step: 2997| lr: 0.2195 | Time: 14.25s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:24:32,743] Step: 2998| lr: 0.2192 | Time: 14.02s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:24:46,709] Step: 2999| lr: 0.2190 | Time: 13.96s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1952 | VAL Acc:  94.89% |
[2023-03-18 05:25:06,297] Step: 3000| lr: 0.2187 | Time: 14.05s |TRAIN loss  0.0015 | TRAIN Acc: 100.00% |VAL loss  0.1973 | VAL Acc:  94.85% |
[2023-03-18 05:25:08,895] ---------------------------------------------------
[2023-03-18 05:25:08,895] Finished computations with total train time: 11:57:32.772808
[2023-03-18 05:25:08,895] -------------Job finished.-------------------------