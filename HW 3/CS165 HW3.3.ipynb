{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e821ff9",
   "metadata": {},
   "source": [
    "# 1. Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d0673dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/dli/task/bootcamp/data/kf/KFvorticity_Re100_N50_T500.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6720\\2920968132.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/dli/task/bootcamp/data/kf/KFvorticity_Re100_N50_T500.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/dli/task/bootcamp/data/kf/KFvorticity_Re100_N50_T500.npy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.load('/dli/task/bootcamp/data/kf/KFvorticity_Re100_N50_T500.npy')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de12b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape # 50 trajectories, each trajectory has 501 time frames, each time frame is represented as a 64 × 64 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f59d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d1bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "ax.imshow(data[0][0])\n",
    "ax.set_title('1st trajectory: 1st time frame')\n",
    "ax = fig.add_subplot(2, 2, 2)\n",
    "ax.imshow(data[0][1])\n",
    "ax.set_title('1st trajectory: 2nd time frame')\n",
    "ax = fig.add_subplot(2, 2, 3)\n",
    "ax.imshow(data[0][2])\n",
    "ax.set_title('1st trajectory: 3rd time frame')\n",
    "ax = fig.add_subplot(2, 2, 4)\n",
    "ax.imshow(data[0][3])\n",
    "ax.set_title('1st trajectory: 4th time frame')\n",
    "plt.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c0e0c6",
   "metadata": {},
   "source": [
    "# 2. Prepare the input and output dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0a03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from neuralop.utils import UnitGaussianNormalizer\n",
    "from neuralop.datasets.tensor_dataset import TensorDataset\n",
    "from neuralop.datasets.transforms import Normalizer, PositionalEmbedding, MGPTensorDataset\n",
    "data = np.load('/dli/task/bootcamp/data/kf/KFvorticity_Re100_N50_T500.npy')\n",
    "\n",
    "ns_input = data[:, 0:500, :, :] # define the input as [50, 0:500, 64, 64]\n",
    "ns_output = data[:, 1:501, :, :] # define the output one-frame off [50, 1:501, 64, 64]\n",
    "grid_boundaries=[[0,1],[0,1]]\n",
    "batch_size=config.data.batch_size\n",
    "test_batch_size=config.data.test_batch_sizes.pop(0)\n",
    "num_workers = 2\n",
    "pin_memory=True\n",
    "persistent_workers=True\n",
    "train_resolution=config.data.train_resolution\n",
    "test_resolutions=config.data.test_resolutions\n",
    "n_tests=config.data.n_tests\n",
    "\n",
    "n_train=config.data.n_train\n",
    "positional_encoding=config.data.positional_encoding\n",
    "test_batch_sizes=config.data.test_batch_sizes\n",
    "\n",
    "\n",
    "x_train = torch.zeros(40*500, 64, 64) # training input\n",
    "for i in range(40):\n",
    "    for j in range(500):\n",
    "        x_train[500*i+j, :, :] = torch.Tensor(ns_input[i, j, :, :])\n",
    "        # mix the trajectory index and the time index to convert the time series into an image-to-image mapping\n",
    "x_train = x_train.unsqueeze(1).clone()\n",
    "\n",
    "y_train = torch.zeros(40*500, 64, 64) # training output\n",
    "for i in range(40):\n",
    "    for j in range(500):\n",
    "        y_train[500*i+j, :, :] = torch.Tensor(ns_output[i, j, :, :])\n",
    "        # mix the trajectory index and the time index to convert the time series into an image-to-image mapping\n",
    "y_train = y_train.unsqueeze(1).clone()\n",
    "\n",
    "x_test = torch.zeros(10*500, 64, 64) # testing input\n",
    "for i in range(40, 50):\n",
    "    for j in range(500):\n",
    "        x_test[500*(i-40)+j, :, :] = torch.Tensor(ns_input[i, j, :, :])\n",
    "        # mix the trajectory index and the time index to convert the time series into an image-to-image mapping\n",
    "x_test = x_test.unsqueeze(1).clone()\n",
    "\n",
    "y_test = torch.zeros(10*500, 64, 64) # testing output\n",
    "for i in range(40, 50):\n",
    "    for j in range(500):\n",
    "        y_test[500*(i-40)+j, :, :] = torch.Tensor(ns_output[i, j, :, :])\n",
    "        # mix the trajectory index and the time index to convert the time series into an image-to-image mapping\n",
    "y_test = y_test.unsqueeze(1).clone()\n",
    "\n",
    "'''\n",
    "# Original data shape is (50, 501, 64, 64)\n",
    "# ns_input = ns_output shape is (50, 500, 64, 64),\n",
    "# then convert the time series into an image-to-image mapping of (50*500, 64, 64)\n",
    "# here, x_train.shape = y_train.shape = torch.Size([20000, 1, 64, 64]),\n",
    "# x_test.shape = y_test.shape = torch.Size([5000, 1, 64, 64])\n",
    "'''\n",
    "\n",
    "reduce_dims = list(range(x_train.ndim))\n",
    "input_encoder = UnitGaussianNormalizer(x_train, reduce_dim=reduce_dims)\n",
    "x_train = input_encoder.encode(x_train)\n",
    "x_test = input_encoder.encode(x_test.contiguous())\n",
    "\n",
    "reduce_dims = list(range(y_train.ndim))\n",
    "output_encoder = UnitGaussianNormalizer(y_train, reduce_dim=reduce_dims)\n",
    "y_train = output_encoder.encode(y_train)\n",
    "\n",
    "train_db = TensorDataset(x_train, y_train, transform_x=PositionalEmbedding(grid_boundaries, 0))\n",
    "train_loader = torch.utils.data.DataLoader(train_db,\n",
    "                                           batch_size=batch_size, shuffle=True,\n",
    "                                           num_workers=num_workers, pin_memory=pin_memory, persistent_workers=persistent_workers)\n",
    "\n",
    "test_db = TensorDataset(x_test, y_test,transform_x=PositionalEmbedding(grid_boundaries, 0))\n",
    "test_loader = torch.utils.data.DataLoader(test_db,\n",
    "                                          batch_size=test_batch_size, shuffle=False,\n",
    "                                          num_workers=num_workers, pin_memory=pin_memory, persistent_workers=persistent_workers)\n",
    "\n",
    "test_loaders =  {train_resolution: test_loader}\n",
    "\n",
    "'''\n",
    "# 经过DataLoader后x_train, x_test均被拆为多个torch.Size([64, 3, 64, 64])\n",
    "# 经过Encoder处理后归一化，此后plot需要decode\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b6c53",
   "metadata": {},
   "source": [
    "# 4. Visualize the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287953d6",
   "metadata": {},
   "source": [
    "## Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21950c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "for sample in test_loader:\n",
    "    x, y = sample['x'], sample['y']\n",
    "    x_recurrent = x[:,-3:]\n",
    "    for i in range(4):\n",
    "        out = model(x_recurrent[:,-3:].to(device))\n",
    "        out = output_encoder.decode(out)\n",
    "        out = out.cpu()\n",
    "        y = output_encoder.decode(y.to(device))\n",
    "        y = y.cpu()\n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        ax = fig.add_subplot(1, 2, 1)\n",
    "        ax.imshow(out[0][0].detach().numpy())\n",
    "        ax.set_title('Model predict')\n",
    "        ax = fig.add_subplot(1, 2, 2)\n",
    "        ax.imshow(y[0+i][0].detach().numpy())\n",
    "        ax.set_title('Ground truth')\n",
    "        x_recurrent = torch.cat((x_recurrent, out), 1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9893ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "for sample in test_loader:\n",
    "    x, y = sample['x'], sample['y']\n",
    "    out = model(x.to(device))\n",
    "    out = output_encoder.decode(out)\n",
    "    out = out.cpu()\n",
    "    y = output_encoder.decode(y.to(device))\n",
    "    y = y.cpu()\n",
    "    for i in range(4):\n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        ax = fig.add_subplot(1, 2, 1)\n",
    "        ax.imshow(out[0+i][0].detach().numpy())\n",
    "        ax.set_title('Model predict')\n",
    "        ax = fig.add_subplot(1, 2, 2)\n",
    "        ax.imshow(y[0+i][0].detach().numpy())\n",
    "        ax.set_title('Ground truth')\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
